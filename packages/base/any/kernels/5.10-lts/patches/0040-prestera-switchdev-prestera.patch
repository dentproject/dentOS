diff --git a/drivers/net/ethernet/marvell/prestera/Makefile b/drivers/net/ethernet/marvell/prestera/Makefile
index 29093e4..4b08ca6 100644
--- a/drivers/net/ethernet/marvell/prestera/Makefile
+++ b/drivers/net/ethernet/marvell/prestera/Makefile
@@ -1,11 +1,16 @@
 # SPDX-License-Identifier: GPL-2.0
-obj-$(CONFIG_PRESTERA)	+= prestera.o
-prestera-objs		:= prestera_main.o \
-			   prestera_hw.o prestera_switchdev.o prestera_devlink.o prestera_fw_log.o \
-			   prestera_rxtx.o prestera_rxtx_sdma.o prestera_dsa.o prestera_router.o \
-			   prestera_acl.o prestera_flower.o prestera_debugfs.o
+#
+# Makefile for the Marvell Switch driver.
+#
 
-obj-$(CONFIG_PRESTERA_PCI)	+= prestera_pci.o
+obj-$(CONFIG_PRESTERA) += prestera.o
+prestera-objs := prestera_main.o \
+	prestera_hw.o prestera_switchdev.o prestera_devlink.o prestera_fw_log.o \
+	prestera_rxtx.o prestera_dsa.o prestera_router.o \
+	prestera_acl.o prestera_flow.o prestera_flower.o prestera_matchall.o prestera_debugfs.o \
+	prestera_ct.o prestera_ethtool.o prestera_counter.o
 
-prestera-$(CONFIG_MRVL_PRESTERA_DEBUG) += prestera_log.o
-ccflags-$(CONFIG_MRVL_PRESTERA_DEBUG) += -DCONFIG_MRVL_PRESTERA_DEBUG
+prestera-$(CONFIG_PRESTERA_DEBUG) += prestera_log.o
+ccflags-$(CONFIG_PRESTERA_DEBUG) += -DCONFIG_MRVL_PRESTERA_DEBUG
+
+obj-$(CONFIG_PRESTERA_PCI) += prestera_pci.o
diff --git a/drivers/net/ethernet/marvell/prestera/prestera.h b/drivers/net/ethernet/marvell/prestera/prestera.h
index 87acd30..617c5ae 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera.h
@@ -1,11 +1,8 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
-#ifndef _MVSW_PRESTERA_H_
-#define _MVSW_PRESTERA_H_
+#ifndef _PRESTERA_H_
+#define _PRESTERA_H_
 
 #include <linux/skbuff.h>
 #include <linux/notifier.h>
@@ -18,15 +15,20 @@
 
 #define PRESTERA_DRV_NAME       "prestera"
 
-#define MVSW_MSG_MAX_SIZE 1500
+#define PRESTERA_MSG_MAX_SIZE 1500
+#define PRESTERA_MSG_CHUNK_SIZE 1024
 
-#define MVSW_PR_DEFAULT_VID 1
+#define PRESTERA_DEFAULT_VID 1
 
-#define MVSW_PR_MIN_AGEING_TIME 32000
-#define MVSW_PR_MAX_AGEING_TIME 1000000000
-#define MVSW_PR_DEFAULT_AGEING_TIME 300000
+#define PRESTERA_MIN_AGEING_TIME 32000
+#define PRESTERA_MAX_AGEING_TIME 1000000000
+#define PRESTERA_DEFAULT_AGEING_TIME 300000
 
-#define MVSW_PR_NHGR_SIZE_MAX 4
+#define PRESTERA_NHGR_SIZE_MAX 4
+
+#define PRESTERA_PORT_SRCID_ZERO 0 /* source_id */
+
+#define PRESTERA_SPAN_INVALID_ID -1
 
 struct prestera_fw_rev {
 	u16 maj;
@@ -34,21 +36,44 @@ struct prestera_fw_rev {
 	u16 sub;
 };
 
-struct mvsw_pr_bridge_port;
+struct prestera_bridge_port;
+struct prestera_kern_neigh_cache;
 struct prestera_acl;
-struct prestera_acl_block;
 struct prestera_acl_rule;
 struct prestera_acl_ruleset;
+struct prestera_acl_nat_port;
+struct prestera_span;
+struct prestera_span_entry;
+struct prestera_storm_control;
 
-struct mvsw_pr_port_vlan {
+struct prestera_flow_block_binding {
 	struct list_head list;
-	struct mvsw_pr_port *mvsw_pr_port;
+	struct prestera_port *port;
+	int span_id;
+};
+
+struct prestera_flow_block {
+	struct list_head binding_list;
+	struct list_head template_list;
+	struct prestera_switch *sw;
+	unsigned int rule_count;
+	unsigned int disable_count;
+	struct net *net;
+	struct prestera_acl_ruleset *ruleset_zero;
+	struct flow_block_cb *block_cb;
+	u32 mall_prio;
+	u32 flower_min_prio;
+};
+
+struct prestera_port_vlan {
+	struct list_head list;
+	struct prestera_port *mvsw_pr_port;
 	u16 vid;
-	struct mvsw_pr_bridge_port *bridge_port;
+	struct prestera_bridge_port *bridge_port;
 	struct list_head bridge_vlan_node;
 };
 
-struct mvsw_pr_port_stats {
+struct prestera_port_stats {
 	u64 good_octets_received;
 	u64 bad_octets_received;
 	u64 mac_trans_error;
@@ -81,50 +106,93 @@ struct mvsw_pr_port_stats {
 	u64 good_octets_sent;
 };
 
-struct mvsw_pr_port_caps {
+struct prestera_port_caps {
 	u64 supp_link_modes;
 	u8 supp_fec;
 	u8 type;
 	u8 transceiver;
 };
 
-struct mvsw_pr_port {
+struct prestera_port_link_params {
+	u64 lmode_bmap;
+	u32 speed;
+	u8 duplex;
+	bool oper_state;
+	struct {
+		bool pause;
+		bool asym_pause;
+	} remote_fc;
+	struct {
+		u8 status;
+		u8 admin_mode;
+	} mdix;
+};
+
+struct prestera_rxtx_stats {
+	u64 rx_packets;
+	u64 rx_bytes;
+	u64 tx_packets;
+	u64 tx_bytes;
+	u32 tx_dropped;
+	struct u64_stats_sync syncp;
+};
+
+/* used for hw call */
+struct prestera_port_mac_config {
+	bool admin;
+	u32 mode;
+	u8 inband;
+	u32 speed;
+	u8 duplex;
+	u8 fec;
+};
+
+/* TODO: add another paramters here: modes, etc... */
+struct prestera_port_phy_config {
+	bool admin;
+	u32 mode;
+};
+
+struct prestera_port {
 	struct devlink_port dl_port;
 	struct net_device *net_dev;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	u32 id;
 	u32 hw_id;
 	u32 dev_id;
 	u16 fp_id;
 	u16 pvid;
 	bool autoneg;
-	bool hw_oper_state; /* RS (PCS) */
-	u32 hw_speed;
-	u8 hw_duplex;
 	u64 adver_link_modes;
 	u8 adver_fec;
 	u16 lag_id;
-	struct mvsw_pr_port_caps caps;
+	struct prestera_port_caps caps;
+	struct prestera_port_mac_config cfg_mac;
+	struct prestera_port_phy_config cfg_phy;
 	struct list_head list;
 	struct list_head vlans_list;
 	struct {
-		struct mvsw_pr_port_stats stats;
+		struct prestera_port_stats stats;
 		struct delayed_work caching_dw;
 	} cached_hw_stats;
-	struct prestera_acl_block *acl_block;
+	struct prestera_flow_block *flow_block;
 
 	struct phylink_config phy_config;
 	struct phylink *phy_link;
+
+	struct prestera_port_link_params link_params;
+
+	struct prestera_rxtx_stats __percpu *rxtx_stats;
 };
 
 struct prestera_switchdev {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct notifier_block swdev_n;
 	struct notifier_block swdev_blocking_n;
 };
 
-struct mvsw_pr_fib {
-	struct mvsw_pr_switch *sw;
+struct prestera_fib {
+	struct prestera_switch *sw;
 	struct notifier_block fib_nb;
 	struct notifier_block netevent_nb;
 };
@@ -136,6 +204,10 @@ struct prestera_device {
 	u8 __iomem *pp_regs;
 	void *priv;
 
+	struct delayed_work keepalive_wdog_work;
+	atomic_t keepalive_wdog_counter;
+	bool running;
+
 	/* called by device driver to handle received packets */
 	void (*recv_pkt)(struct prestera_device *dev);
 
@@ -143,22 +215,24 @@ struct prestera_device {
 	int (*recv_msg)(struct prestera_device *dev, u8 *msg, size_t size);
 
 	/* called by higher layer to send request to the firmware */
-	int (*send_req)(struct prestera_device *dev, u8 *in_msg,
-			size_t in_size, u8 *out_msg, size_t out_size,
+	int (*send_req)(struct prestera_device *dev, int qid,
+			u8 *in_msg, size_t in_size,
+			u8 *out_msg, size_t out_size,
 			unsigned int wait);
 };
 
-enum mvsw_pr_event_type {
+enum prestera_event_type {
 	MVSW_EVENT_TYPE_UNSPEC,
 	MVSW_EVENT_TYPE_PORT,
 	MVSW_EVENT_TYPE_FDB,
 	MVSW_EVENT_TYPE_RXTX,
 	MVSW_EVENT_TYPE_FW_LOG,
+	MVSW_EVENT_TYPE_PULSE,
 
 	MVSW_EVENT_TYPE_MAX,
 };
 
-enum mvsw_pr_rxtx_event_id {
+enum prestera_rxtx_event_id {
 	MVSW_RXTX_EVENT_UNSPEC,
 
 	MVSW_RXTX_EVENT_RCV_PKT,
@@ -166,14 +240,14 @@ enum mvsw_pr_rxtx_event_id {
 	MVSW_RXTX_EVENT_MAX,
 };
 
-enum mvsw_pr_port_event_id {
+enum prestera_port_event_id {
 	MVSW_PORT_EVENT_UNSPEC,
 	MVSW_PORT_EVENT_STATE_CHANGED,
 
 	MVSW_PORT_EVENT_MAX,
 };
 
-enum mvsw_pr_fdb_event_id {
+enum prestera_fdb_event_id {
 	MVSW_FDB_EVENT_UNSPEC,
 	MVSW_FDB_EVENT_LEARNED,
 	MVSW_FDB_EVENT_AGED,
@@ -181,14 +255,14 @@ enum mvsw_pr_fdb_event_id {
 	MVSW_FDB_EVENT_MAX,
 };
 
-enum mvsw_pr_fdb_entry_type {
+enum prestera_fdb_entry_type {
 	MVSW_PR_FDB_ENTRY_TYPE_REG_PORT,
 	MVSW_PR_FDB_ENTRY_TYPE_LAG,
 	MVSW_PR_FDB_ENTRY_TYPE_MAX
 };
 
-struct mvsw_pr_fdb_event {
-	enum mvsw_pr_fdb_entry_type type;
+struct prestera_fdb_event {
+	enum prestera_fdb_entry_type type;
 	union {
 		u32 port_id;
 		u16 lag_id;
@@ -199,32 +273,36 @@ struct mvsw_pr_fdb_event {
 	} data;
 };
 
-struct mvsw_pr_port_event {
+struct prestera_port_event {
 	u32 port_id;
 	struct {
+		u64 lmode_bmap;
+		u32 link_mode;
 		u8 oper_state;
-		u8 duplex;
-		u32 speed;
+		bool pause;
+		bool asym_pause;
+		u8 status;
+		u8 admin_mode;
 	} data;
 };
 
-struct mvsw_pr_fw_log_event {
+struct prestera_fw_log_event {
 	u32 log_len;
 	u8 *data;
 };
 
-struct mvsw_pr_event {
+struct prestera_event {
 	u16 id;
 	union {
-		struct mvsw_pr_port_event port_evt;
-		struct mvsw_pr_fdb_event fdb_evt;
-		struct mvsw_pr_fw_log_event fw_log_evt;
+		struct prestera_port_event port_evt;
+		struct prestera_fdb_event fdb_evt;
+		struct prestera_fw_log_event fw_log_evt;
 	};
 };
 
 struct prestera_lag_member {
 	struct list_head list;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 };
 
 struct prestera_lag {
@@ -233,7 +311,7 @@ struct prestera_lag {
 	struct list_head members;
 };
 
-enum mvsw_pr_if_type {
+enum prestera_if_type {
 	/* the interface is of port type (dev,port) */
 	MVSW_IF_PORT_E = 0,
 
@@ -244,8 +322,8 @@ enum mvsw_pr_if_type {
 	MVSW_IF_VID_E = 3,
 };
 
-struct mvsw_pr_iface {
-	enum mvsw_pr_if_type type;
+struct prestera_iface {
+	enum prestera_if_type type;
 	struct {
 		u32 hw_dev_num;
 		u32 port_num;
@@ -256,11 +334,13 @@ struct mvsw_pr_iface {
 	u32 hw_dev_num;
 };
 
-struct mvsw_pr_bridge;
-struct mvsw_pr_router;
-struct mvsw_pr_rif;
+struct prestera_bridge;
+struct prestera_router;
+struct prestera_rif;
+struct prestera_trap_data;
+struct prestera_rxtx;
 
-struct mvsw_pr_switch {
+struct prestera_switch {
 	struct list_head list;
 	struct prestera_device *dev;
 	struct list_head event_handlers;
@@ -272,17 +352,23 @@ struct mvsw_pr_switch {
 	u8 id;
 	u8 lag_max;
 	u8 lag_member_max;
+	u32 size_tbl_router_nexthop;
+	struct prestera_storm_control *storm_control;
 	struct prestera_acl *acl;
-	struct mvsw_pr_bridge *bridge;
+	struct prestera_span *span;
+	struct prestera_bridge *bridge;
 	struct prestera_switchdev *switchdev;
-	struct mvsw_pr_router *router;
+	struct prestera_router *router;
 	struct prestera_lag *lags;
 	struct notifier_block netdevice_nb;
 	struct device_node *np;
+	struct prestera_trap_data *trap_data;
+	struct prestera_rxtx *rxtx;
+	struct prestera_counter *counter;
 };
 
-struct mvsw_pr_router {
-	struct mvsw_pr_switch *sw;
+struct prestera_router {
+	struct prestera_switch *sw;
 	struct list_head rif_list;	/* list of mvsw_pr_rif */
 	struct list_head vr_list;	/* list of mvsw_pr_vr */
 	struct rhashtable nh_neigh_ht;
@@ -290,6 +376,8 @@ struct mvsw_pr_router {
 	struct rhashtable fib_ht;
 	struct rhashtable kern_fib_cache_ht;
 	struct rhashtable kern_neigh_cache_ht;
+	u8 *nhgrp_hw_state_cache; /* Bitmap cached hw state of nhs */
+	unsigned long nhgrp_hw_cache_kick; /* jiffies */
 	struct {
 		struct delayed_work dw;
 		unsigned int interval;	/* ms */
@@ -300,89 +388,116 @@ struct mvsw_pr_router {
 	bool aborted;
 };
 
-enum mvsw_pr_fdb_flush_mode {
+enum prestera_fdb_flush_mode {
 	MVSW_PR_FDB_FLUSH_MODE_DYNAMIC = BIT(0),
 	MVSW_PR_FDB_FLUSH_MODE_STATIC = BIT(1),
 	MVSW_PR_FDB_FLUSH_MODE_ALL = MVSW_PR_FDB_FLUSH_MODE_DYNAMIC
 				   | MVSW_PR_FDB_FLUSH_MODE_STATIC,
 };
 
-enum prestera_acl_rule_match_entry_type {
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE = 1,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE
+struct prestera_ip_addr {
+	enum {
+		MVSW_PR_IPV4 = 0,
+		MVSW_PR_IPV6
+	} v;
+	union {
+		__be32 ipv4;
+		struct in6_addr ipv6;
+	} u;
+};
+
+/* Used for hw call */
+struct prestera_neigh_info {
+	struct prestera_iface iface;
+	unsigned char ha[ETH_ALEN];
+	bool connected; /* indicate, if mac/oif valid */
+};
+
+enum prestera_acl_match_type {
+	PRESTERA_ACL_RULE_MATCH_TYPE_PCL_ID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_TYPE,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_DMAC_0,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_DMAC_1,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_SMAC_0,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_SMAC_1,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_PROTO,
+	PRESTERA_ACL_RULE_MATCH_TYPE_SYS_PORT,
+	PRESTERA_ACL_RULE_MATCH_TYPE_SYS_DEV,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_RANGE_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_RANGE_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_VLAN_ID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_VLAN_TPID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ICMP_TYPE,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ICMP_CODE,
+
+	__PRESTERA_ACL_RULE_MATCH_TYPE_MAX
+};
+
+struct prestera_acl_match {
+	__be32 key[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	__be32 mask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
 };
 
 enum prestera_acl_rule_action {
 	MVSW_ACL_RULE_ACTION_ACCEPT,
 	MVSW_ACL_RULE_ACTION_DROP,
 	MVSW_ACL_RULE_ACTION_TRAP,
-	MVSW_ACL_RULE_ACTION_POLICE
+	MVSW_ACL_RULE_ACTION_POLICE,
+	MVSW_ACL_RULE_ACTION_NAT,
+	MVSW_ACL_RULE_ACTION_JUMP,
+	MVSW_ACL_RULE_ACTION_NH,
+	MVSW_ACL_RULE_ACTION_COUNT
 };
 
-struct prestera_acl_rule_match_entry {
-	struct list_head list;
-	enum prestera_acl_rule_match_entry_type type;
-	union {
-		struct {
-			u8 key, mask;
-		} u8;
-		struct {
-			u16 key, mask;
-		} u16;
-		struct {
-			u32 key, mask;
-		} u32;
-		struct {
-			u64 key, mask;
-		} u64;
-		struct {
-			u8 key[ETH_ALEN];
-			u8 mask[ETH_ALEN];
-		} mac;
-	} keymask;
-};
-
-struct prestera_acl_rule_action_entry {
-	struct list_head list;
-	enum prestera_acl_rule_action id;
-	union {
-		struct {
-			u64 rate, burst;
-		} police;
-	};
+struct prestera_acl_action_jump {
+	u32 index;
 };
 
-struct mvsw_pr_ip_addr {
-	enum {
-		MVSW_PR_IPV4 = 0,
-		MVSW_PR_IPV6
-	} v;
+struct prestera_acl_action_trap {
+	u8 hw_tc;
+};
+
+struct prestera_acl_action_police {
+	u64 rate;
+	u64 burst;
+};
+
+struct prestera_acl_action_nat {
+	__be32 old_addr;
+	__be32 new_addr;
+	u32 port;
+	u32 dev;
+	u32 flags;
+};
+
+struct prestera_acl_action_count {
+	u32 id;
+};
+
+/* Used for hw call */
+struct prestera_acl_hw_action_info {
+	enum prestera_acl_rule_action id;
 	union {
-		__be32 ipv4;
-		struct in6_addr ipv6;
-	} u;
+		struct prestera_acl_action_trap trap;
+		struct prestera_acl_action_police police;
+		u32 nh;
+		struct prestera_acl_action_nat nat;
+		struct prestera_acl_action_jump jump;
+		struct prestera_acl_action_count count;
+	};
 };
 
-struct mvsw_pr_fib_key {
-	struct mvsw_pr_ip_addr addr;
+struct prestera_fib_key {
+	struct prestera_ip_addr addr;
 	u32 prefix_len;
 	u32 tb_id;
 };
 
-struct mvsw_pr_fib_info {
+struct prestera_fib_info {
 	struct mvsw_pr_vr *vr;
 	struct list_head vr_node;
 	enum mvsw_pr_fib_type {
@@ -399,194 +514,212 @@ struct mvsw_pr_fib_info {
 	struct mvsw_pr_nexthop_group *nh_grp;
 };
 
-/* Used for hw call */
-struct mvsw_pr_neigh_info {
-	struct mvsw_pr_iface iface;
-	unsigned char ha[ETH_ALEN];
-	bool connected; /* indicate, if mac/oif valid */
-};
-
-struct mvsw_pr_nh_neigh_key {
-	struct mvsw_pr_ip_addr addr;
-	struct mvsw_pr_rif *rif;
+struct prestera_nh_neigh_key {
+	struct prestera_ip_addr addr;
+	struct prestera_rif *rif;
 };
 
 /* Used to notify nh about neigh change */
-struct mvsw_pr_nh_neigh {
-	struct mvsw_pr_nh_neigh_key key;
-	struct mvsw_pr_neigh_info info;
+struct prestera_nh_neigh {
+	struct prestera_nh_neigh_key key;
+	struct prestera_neigh_info info;
 	struct rhash_head ht_node; /* node of mvsw_pr_vr */
 	struct list_head nexthop_group_list;
-};
-
-int mvsw_pr_switch_ageing_set(struct mvsw_pr_switch *sw, u32 ageing_time);
-
-int mvsw_pr_port_learning_set(struct mvsw_pr_port *mvsw_pr_port,
-			      bool learn_enable);
-int mvsw_pr_port_uc_flood_set(struct mvsw_pr_port *mvsw_pr_port, bool flood);
-int mvsw_pr_port_mc_flood_set(struct mvsw_pr_port *mvsw_pr_port, bool flood);
-int mvsw_pr_port_pvid_set(struct mvsw_pr_port *mvsw_pr_port, u16 vid);
-int mvsw_pr_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state);
-struct mvsw_pr_port_vlan *
-mvsw_pr_port_vlan_create(struct mvsw_pr_port *mvsw_pr_port, u16 vid,
-			 bool untagged);
-void mvsw_pr_port_vlan_destroy(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan);
-int mvsw_pr_port_vlan_set(struct mvsw_pr_port *mvsw_pr_port, u16 vid,
-			  bool is_member, bool untagged);
-
-struct mvsw_pr_bridge_device *
-mvsw_pr_bridge_device_find(const struct mvsw_pr_bridge *bridge,
-			   const struct net_device *br_dev);
-u16 mvsw_pr_vlan_dev_vlan_id(struct mvsw_pr_bridge *bridge,
-			     struct net_device *dev);
-int mvsw_pr_8021d_bridge_create(struct mvsw_pr_switch *sw, u16 *bridge_id);
-int mvsw_pr_8021d_bridge_delete(struct mvsw_pr_switch *sw, u16 bridge_id);
-int mvsw_pr_8021d_bridge_port_add(struct mvsw_pr_port *mvsw_pr_port,
-				  u16 bridge_id);
-int mvsw_pr_8021d_bridge_port_delete(struct mvsw_pr_port *mvsw_pr_port,
-				     u16 bridge_id);
-
-int mvsw_pr_fdb_add(struct mvsw_pr_port *mvsw_pr_port, const unsigned char *mac,
-		    u16 vid, bool dynamic);
-int mvsw_pr_fdb_del(struct mvsw_pr_port *mvsw_pr_port, const unsigned char *mac,
-		    u16 vid);
-int mvsw_pr_fdb_flush_vlan(struct mvsw_pr_switch *sw, u16 vid,
-			   enum mvsw_pr_fdb_flush_mode mode);
-int mvsw_pr_fdb_flush_port_vlan(struct mvsw_pr_port *port, u16 vid,
-				enum mvsw_pr_fdb_flush_mode mode);
-int mvsw_pr_fdb_flush_port(struct mvsw_pr_port *port,
-			   enum mvsw_pr_fdb_flush_mode mode);
-int mvsw_pr_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid);
-int mvsw_pr_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid);
-
-int prestera_lag_member_add(struct mvsw_pr_port *port,
+	struct list_head nh_mangle_entry_list;
+};
+
+struct prestera_nexthop_group_key {
+	struct prestera_nh_neigh_key neigh[PRESTERA_NHGR_SIZE_MAX];
+};
+
+struct prestera_port *dev_to_prestera_port(struct device *dev);
+
+int prestera_switch_ageing_set(struct prestera_switch *sw, u32 ageing_time);
+
+struct prestera_port *prestera_port_find_by_fp_id(u32 fp_id);
+
+int prestera_port_learning_set(struct prestera_port *port, bool learn_enable);
+int prestera_port_uc_flood_set(struct prestera_port *port, bool flood);
+int prestera_port_mc_flood_set(struct prestera_port *port, bool flood);
+int prestera_port_isolation_grp_set(struct prestera_port *port,
+				    u32 sourceid);
+int prestera_port_pvid_set(struct prestera_port *port, u16 vid);
+int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state);
+struct prestera_port_vlan *
+prestera_port_vlan_create(struct prestera_port *port, u16 vid, bool untagged);
+void prestera_port_vlan_destroy(struct prestera_port_vlan *mvsw_pr_port_vlan);
+int prestera_port_vlan_set(struct prestera_port *port, u16 vid,
+			   bool is_member, bool untagged);
+
+struct prestera_bridge_device *
+prestera_bridge_device_find(const struct prestera_bridge *bridge,
+			    const struct net_device *br_dev);
+u16 prestera_vlan_dev_vlan_id(struct prestera_bridge *bridge,
+			      struct net_device *dev);
+int prestera_8021d_bridge_create(struct prestera_switch *sw, u16 *bridge_id);
+int prestera_8021d_bridge_delete(struct prestera_switch *sw, u16 bridge_id);
+int prestera_8021d_bridge_port_add(struct prestera_port *port, u16 bridge_id);
+int prestera_8021d_bridge_port_delete(struct prestera_port *port,
+				      u16 bridge_id);
+
+int prestera_fdb_add(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid, bool dynamic);
+int prestera_fdb_del(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid);
+int prestera_fdb_flush_vlan(struct prestera_switch *sw, u16 vid,
+			    enum prestera_fdb_flush_mode mode);
+int prestera_fdb_flush_port_vlan(struct prestera_port *port, u16 vid,
+				 enum prestera_fdb_flush_mode mode);
+int prestera_fdb_flush_port(struct prestera_port *port,
+			    enum prestera_fdb_flush_mode mode);
+int prestera_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid);
+int prestera_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid);
+
+int prestera_lag_member_add(struct prestera_port *port,
 			    struct net_device *lag_dev, u16 lag_id);
-int prestera_lag_member_del(struct mvsw_pr_port *port);
-int prestera_lag_member_enable(struct mvsw_pr_port *port, bool enable);
-bool mvsw_pr_port_is_lag_member(const struct mvsw_pr_port *port);
-int prestera_lag_id_find(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
+int prestera_lag_member_del(struct prestera_port *port);
+int prestera_lag_member_enable(struct prestera_port *port, bool enable);
+bool prestera_port_is_lag_member(const struct prestera_port *port);
+struct prestera_lag *prestera_lag_get(struct prestera_switch *sw, u8 id);
+int prestera_lag_id_find(struct prestera_switch *sw, struct net_device *lag_dev,
 			 u16 *lag_id);
-void prestera_lag_member_rif_leave(const struct mvsw_pr_port *port,
+void prestera_lag_member_rif_leave(const struct prestera_port *port,
 				   u16 lag_id, u16 vr_id);
 
-int mvsw_pr_dev_if_type(const struct net_device *dev);
+/* SPAN */
+int prestera_span_get(struct prestera_port *port, u8 *span_id);
+int prestera_span_put(const struct prestera_switch *sw, u8 span_id);
+
+int prestera_dev_if_type(const struct net_device *dev);
 
 /* prestera_flower.c */
-int mvsw_pr_flower_replace(struct mvsw_pr_switch *sw,
-			   struct prestera_acl_block *block,
-			   struct flow_cls_offload *f);
-void mvsw_pr_flower_destroy(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
+int prestera_flower_replace(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
 			    struct flow_cls_offload *f);
-int mvsw_pr_flower_stats(struct mvsw_pr_switch *sw,
-			 struct prestera_acl_block *block,
-			 struct flow_cls_offload *f);
+void prestera_flower_destroy(struct prestera_switch *sw,
+			     struct prestera_flow_block *block,
+			     struct flow_cls_offload *f);
+int prestera_flower_stats(struct prestera_switch *sw,
+			  struct prestera_flow_block *block,
+			  struct flow_cls_offload *f);
+int prestera_flower_prio_get(struct prestera_flow_block *block,
+			     u32 *prio);
+int prestera_flower_tmplt_create(struct prestera_switch *sw,
+				 struct prestera_flow_block *block,
+				 struct flow_cls_offload *f);
+void prestera_flower_tmplt_destroy(struct prestera_switch *sw,
+				   struct prestera_flow_block *block,
+				   struct flow_cls_offload *f);
+void prestera_flower_template_cleanup(struct prestera_flow_block *block);
+
+/* prestera_matchall.c */
+int prestera_mall_replace(struct prestera_flow_block *block,
+			  struct tc_cls_matchall_offload *f);
+void prestera_mall_destroy(struct prestera_flow_block *block);
+int prestera_mall_prio_get(struct prestera_flow_block *block,
+			   u32 *prio);
+
+/* prestera_flow.c */
+int prestera_setup_tc_block(struct prestera_port *port,
+			    struct flow_block_offload *f);
 
 /* prestera_acl.c */
-int prestera_acl_init(struct mvsw_pr_switch *sw);
-void prestera_acl_fini(struct mvsw_pr_switch *sw);
-struct prestera_acl_block *
-prestera_acl_block_create(struct mvsw_pr_switch *sw, struct net *net);
-void prestera_acl_block_destroy(struct prestera_acl_block *block);
-struct net *prestera_acl_block_net(struct prestera_acl_block *block);
-struct mvsw_pr_switch *prestera_acl_block_sw(struct prestera_acl_block *block);
-unsigned int prestera_acl_block_rule_count(struct prestera_acl_block *block);
-void prestera_acl_block_disable_inc(struct prestera_acl_block *block);
-void prestera_acl_block_disable_dec(struct prestera_acl_block *block);
-bool prestera_acl_block_disabled(const struct prestera_acl_block *block);
-int prestera_acl_block_bind(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
-			    struct mvsw_pr_port *port);
-int prestera_acl_block_unbind(struct mvsw_pr_switch *sw,
-			      struct prestera_acl_block *block,
-			      struct mvsw_pr_port *port);
-struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_acl_block *block);
-struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_acl_block *block,
-			 unsigned long cookie);
-u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule);
-void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
-				    u32 priority);
-u8 prestera_acl_rule_hw_tc_get(struct prestera_acl_rule *rule);
-void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc);
-u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule);
-struct list_head *
-prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule);
-u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule);
-void prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				  struct prestera_acl_rule_action_entry *entry);
-struct list_head *
-prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule);
-void prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_match_entry *entry);
-void prestera_acl_rule_destroy(struct prestera_acl_rule *rule);
-struct prestera_acl_rule *
-prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
-			 unsigned long cookie);
-int prestera_acl_rule_add(struct mvsw_pr_switch *sw,
-			  struct prestera_acl_rule *rule);
-void prestera_acl_rule_del(struct mvsw_pr_switch *sw,
-			   struct prestera_acl_rule *rule);
-int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
-				struct prestera_acl_rule *rule,
-				u64 *packets, u64 *bytes, u64 *last_use);
+int prestera_acl_init(struct prestera_switch *sw);
+void prestera_acl_fini(struct prestera_switch *sw);
+struct net *prestera_acl_block_net(struct prestera_flow_block *block);
+struct prestera_switch *
+prestera_acl_block_sw(struct prestera_flow_block *block);
+unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block);
+void prestera_acl_block_disable_inc(struct prestera_flow_block *block);
+void prestera_acl_block_disable_dec(struct prestera_flow_block *block);
+bool prestera_acl_block_disabled(const struct prestera_flow_block *block);
+void prestera_acl_block_prio_update(struct prestera_switch *sw,
+				    struct prestera_flow_block *block);
+
+/* ACL-NAT */
+struct prestera_acl_nat_port *
+prestera_acl_nat_port_get(struct prestera_acl *acl, u32 port_hw_id,
+			  u32 port_dev_id);
+void prestera_acl_nat_port_put(struct prestera_acl_nat_port *nat_port);
+struct prestera_port *
+prestera_acl_nat_port_to_port(struct prestera_acl_nat_port *nat_port);
 
 /* VLAN API */
-struct mvsw_pr_port_vlan *
-mvsw_pr_port_vlan_find_by_vid(const struct mvsw_pr_port *mvsw_pr_port, u16 vid);
+struct prestera_port_vlan *
+prestera_port_vlan_find_by_vid(const struct prestera_port *port, u16 vid);
 void
-mvsw_pr_port_vlan_bridge_leave(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan);
+prestera_port_vlan_bridge_leave(struct prestera_port_vlan *mvsw_pr_port_vlan);
 
-int prestera_switchdev_register(struct mvsw_pr_switch *sw);
-void prestera_switchdev_unregister(struct mvsw_pr_switch *sw);
+int prestera_switchdev_register(struct prestera_switch *sw);
+void prestera_switchdev_unregister(struct prestera_switch *sw);
 
 int prestera_device_register(struct prestera_device *dev);
 void prestera_device_unregister(struct prestera_device *dev);
 
-bool mvsw_pr_netdev_check(const struct net_device *dev);
-struct mvsw_pr_switch *mvsw_pr_switch_get(struct net_device *dev);
-struct mvsw_pr_port *mvsw_pr_port_dev_lower_find(struct net_device *dev);
+bool prestera_netdev_check(const struct net_device *dev);
+struct prestera_switch *prestera_switch_get(struct net_device *dev);
+int prestera_port_cfg_mac_read(struct prestera_port *port,
+			       struct prestera_port_mac_config *cfg);
+int prestera_port_cfg_mac_write(struct prestera_port *port,
+				struct prestera_port_mac_config *cfg);
+struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev);
+
+struct prestera_port *prestera_port_find(u32 dev_hw_id, u32 port_hw_id);
 
-const struct mvsw_pr_port *mvsw_pr_port_find(u32 dev_hw_id, u32 port_hw_id);
-int mvsw_pr_schedule_dw(struct delayed_work *dwork, unsigned long delay);
+int prestera_port_autoneg_set(struct prestera_port *port, u64 link_modes);
 
 /* prestera_router.c */
-int mvsw_pr_router_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_router_fini(struct mvsw_pr_switch *sw);
-int mvsw_pr_netdevice_router_port_event(struct net_device *dev,
-					unsigned long event, void *ptr);
-int mvsw_pr_inetaddr_valid_event(struct notifier_block *unused,
-				 unsigned long event, void *ptr);
-int mvsw_pr_netdevice_vrf_event(struct net_device *dev, unsigned long event,
-				struct netdev_notifier_changeupper_info *info);
-void mvsw_pr_port_router_leave(struct mvsw_pr_port *mvsw_pr_port);
-int mvsw_pr_lpm_add(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len, u32 grp_id);
-int mvsw_pr_lpm_del(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len);
-int mvsw_pr_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 *grp_id);
-int mvsw_pr_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 grp_id);
-int mvsw_pr_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy);
-
-void mvsw_pr_rif_enable(struct mvsw_pr_switch *sw, struct net_device *dev,
-			bool enable);
-bool mvsw_pr_rif_exists(const struct mvsw_pr_switch *sw,
-			const struct net_device *dev);
-void mvsw_pr_router_lag_member_leave(const struct mvsw_pr_port *port,
-				     const struct net_device *dev);
-void prestera_lag_router_leave(struct mvsw_pr_switch *sw,
+int prestera_router_init(struct prestera_switch *sw);
+void prestera_router_fini(struct prestera_switch *sw);
+int prestera_netdevice_router_port_event(struct net_device *dev,
+					 unsigned long event, void *ptr);
+int prestera_inetaddr_valid_event(struct notifier_block *unused,
+				  unsigned long event, void *ptr);
+int prestera_netdevice_vrf_event(struct net_device *dev, unsigned long event,
+				 struct netdev_notifier_changeupper_info *info);
+void prestera_port_router_leave(struct prestera_port *port);
+int prestera_lpm_add(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len, u32 grp_id);
+int prestera_lpm_del(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len);
+int prestera_nh_entries_set(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id);
+int prestera_nh_entries_get(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id);
+int prestera_nhgrp_blk_get(const struct prestera_switch *sw, u8 *hw_state,
+			   u32 buf_size);
+int prestera_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+			     u32 *grp_id);
+int prestera_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+			     u32 grp_id);
+int prestera_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy);
+
+struct prestera_nh_neigh *
+prestera_nh_neigh_find(struct prestera_switch *sw,
+		       struct prestera_nh_neigh_key *key);
+struct prestera_nh_neigh *
+prestera_nh_neigh_get(struct prestera_switch *sw,
+		      struct prestera_nh_neigh_key *key);
+void prestera_nh_neigh_put(struct prestera_switch *sw,
+			   struct prestera_nh_neigh *neigh);
+int prestera_util_kern_dip2nh_grp_key(struct prestera_switch *sw,
+				      u32 tb_id, struct prestera_ip_addr *addr,
+				      struct prestera_nexthop_group_key *res);
+void prestera_rif_enable(struct prestera_switch *sw, struct net_device *dev,
+			 bool enable);
+bool prestera_rif_exists(const struct prestera_switch *sw,
+			 const struct net_device *dev);
+void prestera_router_lag_member_leave(const struct prestera_port *port,
+				      const struct net_device *dev);
+void prestera_lag_router_leave(struct prestera_switch *sw,
 			       struct net_device *lag_dev);
 
-void mvsw_pr_bridge_device_rifs_destroy(struct mvsw_pr_switch *sw,
-					struct net_device *bridge_dev);
+void prestera_bridge_device_rifs_destroy(struct prestera_switch *sw,
+					 struct net_device *bridge_dev);
+void prestera_k_arb_fdb_evt(struct prestera_switch *sw, struct net_device *dev);
+struct prestera_neigh_info *
+prestera_kern_neigh_cache_to_neigh_info(struct prestera_kern_neigh_cache *nc);
 
-#endif /* _MVSW_PRESTERA_H_ */
+#endif /* _PRESTERA_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.c b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
index 143df72..8591c04 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_acl.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
@@ -1,53 +1,58 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-//
-// Copyright (c) 2020 Marvell International Ltd. All rights reserved.
-//
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <linux/rhashtable.h>
 
 #include "prestera.h"
 #include "prestera_hw.h"
+#include "prestera_log.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
 
-#define MVSW_ACL_RULE_DEF_HW_TC		3
+#define PRESTERA_ACL_RULE_DEF_HW_TC	3
+#define ACL_KEYMASK_SIZE	\
+	(sizeof(__be32) * __PRESTERA_ACL_RULE_MATCH_TYPE_MAX)
 
-struct prestera_acl {
-	struct mvsw_pr_switch *sw;
-	struct list_head rules;
-};
-
-struct prestera_acl_block_binding {
-	struct list_head list;
-	struct mvsw_pr_port *port;
+struct prestera_acl_ruleset_ht_key {
+	struct prestera_flow_block *block;
+	u32 chain_index;
 };
 
 struct prestera_acl_ruleset {
+	struct rhash_head ht_node; /* Member of acl HT */
+	struct prestera_acl_ruleset_ht_key ht_key;
 	struct rhashtable rule_ht;
-	struct mvsw_pr_switch *sw;
-	u16 id;
+	struct prestera_acl *acl;
+	unsigned long rule_count;
+	refcount_t refcount;
+	void *keymask;
+	bool offload;
+	u32 vtcam_id;
+	u16 pcl_id;
+	u32 index;
 };
 
-struct prestera_acl_block {
-	struct list_head binding_list;
-	struct mvsw_pr_switch *sw;
-	unsigned int rule_count;
-	unsigned int disable_count;
-	struct net *net;
-	struct prestera_acl_ruleset *ruleset;
+struct prestera_acl_uid_entry {
+	struct list_head list;
+	u8 id;
 };
 
-struct prestera_acl_rule {
-	struct rhash_head ht_node; /* Member of acl HT */
+struct prestera_acl_vtcam {
 	struct list_head list;
-	struct list_head match_list;
-	struct list_head action_list;
-	struct prestera_acl_block *block;
-	unsigned long cookie;
-	u32 priority;
-	u8 n_actions;
-	u8 hw_tc;
+	__be32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	bool is_keymask_set;
+	refcount_t refcount;
+	u8 lookup;
 	u32 id;
 };
 
+static const struct rhashtable_params prestera_acl_ruleset_ht_params = {
+	.key_len = sizeof(struct prestera_acl_ruleset_ht_key),
+	.key_offset = offsetof(struct prestera_acl_ruleset, ht_key),
+	.head_offset = offsetof(struct prestera_acl_ruleset, ht_node),
+	.automatic_shrinking = true,
+};
+
 static const struct rhashtable_params prestera_acl_rule_ht_params = {
 	.key_len = sizeof(unsigned long),
 	.key_offset = offsetof(struct prestera_acl_rule, cookie),
@@ -55,28 +60,132 @@ static const struct rhashtable_params prestera_acl_rule_ht_params = {
 	.automatic_shrinking = true,
 };
 
+static const struct rhashtable_params __prestera_nh_mangle_entry_ht_params = {
+	.key_offset  = offsetof(struct prestera_nh_mangle_entry, key),
+	.head_offset = offsetof(struct prestera_nh_mangle_entry, ht_node),
+	.key_len     = sizeof(struct prestera_nh_mangle_entry_key),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params __prestera_acl_rule_entry_ht_params = {
+	.key_offset  = offsetof(struct prestera_acl_rule_entry, key),
+	.head_offset = offsetof(struct prestera_acl_rule_entry, ht_node),
+	.key_len     = sizeof(struct prestera_acl_rule_entry_key),
+	.automatic_shrinking = true,
+};
+
+enum prestera_counter_client prestera_acl_chain_to_client(u32 chain_index)
+{
+	enum prestera_counter_client client[] = {
+		PRESTERA_COUNTER_CLIENT_LOOKUP_0,
+		PRESTERA_COUNTER_CLIENT_LOOKUP_1,
+		PRESTERA_COUNTER_CLIENT_LOOKUP_2
+	};
+
+	if (chain_index > 2)
+		return PRESTERA_COUNTER_CLIENT_LOOKUP_LAST;
+
+	return client[chain_index];
+}
+
+struct prestera_acl_nat_port *
+prestera_acl_nat_port_get(struct prestera_acl *acl, u32 port_hw_id,
+			  u32 port_dev_id)
+{
+	struct prestera_acl_nat_port *nat_port;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &acl->nat_port_list) {
+		nat_port = list_entry(pos, typeof(*nat_port), list);
+		if (nat_port->port->hw_id == port_hw_id &&
+		    nat_port->port->dev_id == port_dev_id) {
+			refcount_inc(&nat_port->refcount);
+			return nat_port;
+		}
+	}
+
+	return NULL;
+}
+
+void prestera_acl_nat_port_put(struct prestera_acl_nat_port *nat_port)
+{
+	if (!refcount_dec_and_test(&nat_port->refcount))
+		return;
+
+	list_del(&nat_port->list);
+	kfree(nat_port);
+}
+
+struct prestera_port *
+prestera_acl_nat_port_to_port(struct prestera_acl_nat_port *nat_port)
+{
+	return nat_port->port;
+}
+
+static struct prestera_acl_nat_port *
+prestera_acl_nat_port_create(struct prestera_acl *acl,
+			     struct prestera_port *port)
+{
+	struct prestera_acl_nat_port *nat_port;
+
+	nat_port = kzalloc(sizeof(*nat_port), GFP_KERNEL);
+	if (!nat_port)
+		return ERR_PTR(-ENOMEM);
+
+	nat_port->port = port;
+	refcount_set(&nat_port->refcount, 1);
+	list_add(&nat_port->list, &acl->nat_port_list);
+
+	return nat_port;
+}
+
+static inline bool prestera_acl_chain_is_supported(u32 chain_index)
+{
+	return (chain_index & ~PRESTERA_ACL_CHAIN_MASK) == 0;
+}
+
 static struct prestera_acl_ruleset *
-prestera_acl_ruleset_create(struct mvsw_pr_switch *sw)
+prestera_acl_ruleset_create(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index)
 {
-	int err;
 	struct prestera_acl_ruleset *ruleset;
+	int err;
+	u8 uid;
+
+	if (!prestera_acl_chain_is_supported(chain_index))
+		return ERR_PTR(-EINVAL);
 
 	ruleset = kzalloc(sizeof(*ruleset), GFP_KERNEL);
 	if (!ruleset)
 		return ERR_PTR(-ENOMEM);
 
+	ruleset->acl = acl;
+	ruleset->ht_key.block = block;
+	ruleset->ht_key.chain_index = chain_index;
+	refcount_set(&ruleset->refcount, 1);
+
 	err = rhashtable_init(&ruleset->rule_ht, &prestera_acl_rule_ht_params);
 	if (err)
 		goto err_rhashtable_init;
 
-	err = mvsw_pr_hw_acl_ruleset_create(sw, &ruleset->id);
+	err = prestera_acl_uid_new_get(acl, &uid);
 	if (err)
 		goto err_ruleset_create;
 
-	ruleset->sw = sw;
+	/* make pcl-id based on uid and chain */
+	ruleset->pcl_id = PRESTERA_ACL_PCL_ID_MAKE(uid, chain_index);
+	ruleset->index = uid;
+
+	err = rhashtable_insert_fast(&acl->ruleset_ht, &ruleset->ht_node,
+				     prestera_acl_ruleset_ht_params);
+	if (err)
+		goto err_ruleset_ht_insert;
 
 	return ruleset;
 
+err_ruleset_ht_insert:
+	prestera_acl_uid_release(acl, uid);
 err_ruleset_create:
 	rhashtable_destroy(&ruleset->rule_ht);
 err_rhashtable_init:
@@ -84,138 +193,255 @@ prestera_acl_ruleset_create(struct mvsw_pr_switch *sw)
 	return ERR_PTR(err);
 }
 
-static void prestera_acl_ruleset_destroy(struct prestera_acl_ruleset *ruleset)
+int prestera_acl_ruleset_keymask_set(struct prestera_acl_ruleset *ruleset,
+				     void *keymask)
 {
-	mvsw_pr_hw_acl_ruleset_del(ruleset->sw, ruleset->id);
-	rhashtable_destroy(&ruleset->rule_ht);
-	kfree(ruleset);
+	void *__keymask;
+
+	if (!keymask || !ruleset)
+		return -EINVAL;
+
+	__keymask = kmalloc(ACL_KEYMASK_SIZE, GFP_KERNEL);
+	if (!__keymask)
+		return -ENOMEM;
+
+	memcpy(__keymask, keymask, ACL_KEYMASK_SIZE);
+	ruleset->keymask = __keymask;
+
+	return 0;
 }
 
-struct prestera_acl_block *
-prestera_acl_block_create(struct mvsw_pr_switch *sw, struct net *net)
+int prestera_acl_ruleset_offload(struct prestera_acl_ruleset *ruleset)
 {
-	struct prestera_acl_block *block;
+	struct prestera_acl_iface iface;
+	u32 vtcam_id;
+	int err;
+
+	if (ruleset->offload)
+		return -EEXIST;
+
+	err = prestera_acl_vtcam_id_get(ruleset->acl,
+					ruleset->ht_key.chain_index,
+					ruleset->keymask, &vtcam_id);
+	if (err)
+		goto err_vtcam_create;
+
+	if (ruleset->ht_key.chain_index) {
+		/* for chain > 0, bind iface index to pcl-id to be able
+		 * to jump from any other ruleset to this one using the index.
+		 */
+		iface.index = ruleset->index;
+		iface.type = PRESTERA_ACL_IFACE_TYPE_INDEX;
+		err = prestera_hw_vtcam_iface_bind(ruleset->acl->sw, &iface,
+						   vtcam_id, ruleset->pcl_id);
+		if (err)
+			goto err_ruleset_bind;
+	}
+
+	ruleset->vtcam_id = vtcam_id;
+	ruleset->offload = true;
+	return 0;
 
-	block = kzalloc(sizeof(*block), GFP_KERNEL);
-	if (!block)
-		return NULL;
-	INIT_LIST_HEAD(&block->binding_list);
-	block->net = net;
-	block->sw = sw;
+err_ruleset_bind:
+	prestera_acl_vtcam_id_put(ruleset->acl, ruleset->vtcam_id);
+err_vtcam_create:
+	return err;
+}
 
-	block->ruleset = prestera_acl_ruleset_create(sw);
-	if (IS_ERR(block->ruleset)) {
-		kfree(block);
-		return NULL;
+static void prestera_acl_ruleset_destroy(struct prestera_acl_ruleset *ruleset)
+{
+	struct prestera_acl *acl = ruleset->acl;
+	u8 uid = ruleset->pcl_id & PRESTERA_ACL_KEYMASK_PCL_ID_USER;
+	int err;
+
+	rhashtable_remove_fast(&acl->ruleset_ht, &ruleset->ht_node,
+			       prestera_acl_ruleset_ht_params);
+
+	if (ruleset->offload) {
+		if (ruleset->ht_key.chain_index) {
+			struct prestera_acl_iface iface = {
+				.type = PRESTERA_ACL_IFACE_TYPE_INDEX,
+				.index = ruleset->index
+			};
+			err = prestera_hw_vtcam_iface_unbind(acl->sw, &iface,
+							     ruleset->vtcam_id);
+			WARN_ON(err);
+		}
+		WARN_ON(prestera_acl_vtcam_id_put(acl, ruleset->vtcam_id));
 	}
 
-	return block;
+	WARN_ON(prestera_acl_uid_release(acl, uid));
+
+	rhashtable_destroy(&ruleset->rule_ht);
+	kfree(ruleset->keymask);
+	kfree(ruleset);
 }
 
-void prestera_acl_block_destroy(struct prestera_acl_block *block)
+static struct prestera_acl_ruleset *
+__prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			      struct prestera_flow_block *block,
+			      u32 chain_index)
 {
-	prestera_acl_ruleset_destroy(block->ruleset);
-	WARN_ON(!list_empty(&block->binding_list));
-	kfree(block);
+	struct prestera_acl_ruleset_ht_key ht_key;
+
+	memset(&ht_key, 0, sizeof(ht_key));
+	ht_key.block = block;
+	ht_key.chain_index = chain_index;
+	return rhashtable_lookup_fast(&acl->ruleset_ht, &ht_key,
+				      prestera_acl_ruleset_ht_params);
 }
 
-static struct prestera_acl_block_binding *
-prestera_acl_block_lookup(struct prestera_acl_block *block,
-			  struct mvsw_pr_port *port)
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index)
 {
-	struct prestera_acl_block_binding *binding;
+	struct prestera_acl_ruleset *ruleset;
 
-	list_for_each_entry(binding, &block->binding_list, list)
-		if (binding->port == port)
-			return binding;
+	ruleset = __prestera_acl_ruleset_lookup(acl, block, chain_index);
+	if (!ruleset)
+		return ERR_PTR(-ENOENT);
 
-	return NULL;
+	refcount_inc(&ruleset->refcount);
+	return ruleset;
 }
 
-unsigned int prestera_acl_block_rule_count(struct prestera_acl_block *block)
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_get(struct prestera_acl *acl,
+			 struct prestera_flow_block *block,
+			 u32 chain_index)
 {
-	return block ? block->rule_count : 0;
+	struct prestera_acl_ruleset *ruleset;
+
+	ruleset = __prestera_acl_ruleset_lookup(acl, block, chain_index);
+	if (ruleset) {
+		refcount_inc(&ruleset->refcount);
+		return ruleset;
+	}
+
+	return prestera_acl_ruleset_create(acl, block, chain_index);
 }
 
-void prestera_acl_block_disable_inc(struct prestera_acl_block *block)
+void prestera_acl_ruleset_put(struct prestera_acl_ruleset *ruleset)
 {
-	if (block)
-		block->disable_count++;
+	if (!refcount_dec_and_test(&ruleset->refcount))
+		return;
+
+	prestera_acl_ruleset_destroy(ruleset);
 }
 
-void prestera_acl_block_disable_dec(struct prestera_acl_block *block)
+int prestera_acl_ruleset_bind(struct prestera_acl_ruleset *ruleset,
+			      struct prestera_port *port)
 {
-	if (block)
-		block->disable_count--;
+	struct prestera_acl_iface iface = {
+		.type = PRESTERA_ACL_IFACE_TYPE_PORT,
+		.port = port
+	};
+
+	return prestera_hw_vtcam_iface_bind(port->sw, &iface, ruleset->vtcam_id,
+					    ruleset->pcl_id);
 }
 
-bool prestera_acl_block_disabled(const struct prestera_acl_block *block)
+int prestera_acl_ruleset_unbind(struct prestera_acl_ruleset *ruleset,
+				struct prestera_port *port)
 {
-	return block->disable_count;
+	struct prestera_acl_iface iface = {
+		.type = PRESTERA_ACL_IFACE_TYPE_PORT,
+		.port = port
+	};
+
+	return prestera_hw_vtcam_iface_unbind(port->sw, &iface,
+					      ruleset->vtcam_id);
 }
 
-int prestera_acl_block_bind(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
-			    struct mvsw_pr_port *port)
+static int prestera_acl_ruleset_block_bind(struct prestera_acl_ruleset *ruleset,
+					   struct prestera_flow_block *block)
 {
-	struct prestera_acl_block_binding *binding;
+	struct prestera_flow_block_binding *binding;
 	int err;
 
-	if (WARN_ON(prestera_acl_block_lookup(block, port)))
-		return -EEXIST;
+	block->ruleset_zero = ruleset;
+	list_for_each_entry(binding, &block->binding_list, list) {
+		err = prestera_acl_ruleset_bind(ruleset, binding->port);
+		if (err)
+			goto rollback;
+	}
+	return 0;
 
-	binding = kzalloc(sizeof(*binding), GFP_KERNEL);
-	if (!binding)
-		return -ENOMEM;
-	binding->port = port;
+rollback:
+	list_for_each_entry_continue_reverse(binding, &block->binding_list,
+					     list)
+		err = prestera_acl_ruleset_unbind(ruleset, binding->port);
+	block->ruleset_zero = NULL;
 
-	err = mvsw_pr_hw_acl_port_bind(port, block->ruleset->id);
-	if (err)
-		goto err_rules_bind;
+	return err;
+}
 
-	list_add(&binding->list, &block->binding_list);
-	return 0;
+static void
+prestera_acl_ruleset_block_unbind(struct prestera_acl_ruleset *ruleset,
+				  struct prestera_flow_block *block)
+{
+	struct prestera_flow_block_binding *binding;
 
-err_rules_bind:
-	kfree(binding);
-	return err;
+	list_for_each_entry(binding, &block->binding_list, list)
+		prestera_acl_ruleset_unbind(ruleset, binding->port);
+	block->ruleset_zero = NULL;
 }
 
-int prestera_acl_block_unbind(struct mvsw_pr_switch *sw,
-			      struct prestera_acl_block *block,
-			      struct mvsw_pr_port *port)
+void prestera_acl_block_prio_update(struct prestera_switch *sw,
+				    struct prestera_flow_block *block)
 {
-	struct prestera_acl_block_binding *binding;
+	struct prestera_acl *acl = sw->acl;
+	struct prestera_acl_rule *rule;
+	u32 new_prio = UINT_MAX;
 
-	binding = prestera_acl_block_lookup(block, port);
-	if (!binding)
-		return -ENOENT;
+	list_for_each_entry(rule, &acl->rules, list) {
+		if (rule->priority < new_prio)
+			new_prio = rule->priority;
+	}
 
-	list_del(&binding->list);
+	block->flower_min_prio = new_prio;
+}
 
-	mvsw_pr_hw_acl_port_unbind(port, block->ruleset->id);
+unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block)
+{
+	return block ? block->rule_count : 0;
+}
 
-	kfree(binding);
-	return 0;
+void prestera_acl_block_disable_inc(struct prestera_flow_block *block)
+{
+	if (block)
+		block->disable_count++;
 }
 
-struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_acl_block *block)
+void prestera_acl_block_disable_dec(struct prestera_flow_block *block)
 {
-	return block->ruleset;
+	if (block)
+		block->disable_count--;
 }
 
-u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule)
+bool prestera_acl_block_disabled(const struct prestera_flow_block *block)
 {
-	return rule->block->ruleset->id;
+	return block->disable_count;
+}
+
+void
+prestera_acl_rule_keymask_pcl_id_set(struct prestera_acl_rule *rule, u16 pcl_id)
+{
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	__be16 pcl_id_mask = htons(PRESTERA_ACL_KEYMASK_PCL_ID);
+	__be16 pcl_id_key = htons(pcl_id);
+
+	rule_match_set(r_match->key, PCL_ID, pcl_id_key);
+	rule_match_set(r_match->mask, PCL_ID, pcl_id_mask);
 }
 
-struct net *prestera_acl_block_net(struct prestera_acl_block *block)
+struct net *prestera_acl_block_net(struct prestera_flow_block *block)
 {
 	return block->net;
 }
 
-struct mvsw_pr_switch *prestera_acl_block_sw(struct prestera_acl_block *block)
+struct prestera_switch *prestera_acl_block_sw(struct prestera_flow_block *block)
 {
 	return block->sw;
 }
@@ -228,9 +454,19 @@ prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
 				      prestera_acl_rule_ht_params);
 }
 
+u32 prestera_acl_ruleset_index_get(const struct prestera_acl_ruleset *ruleset)
+{
+	return ruleset->index;
+}
+
+bool prestera_acl_ruleset_is_offload(struct prestera_acl_ruleset *ruleset)
+{
+	return ruleset->offload;
+}
+
 struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_acl_block *block,
-			 unsigned long cookie)
+prestera_acl_rule_create(struct prestera_acl_ruleset *ruleset,
+			 unsigned long cookie, u32 chain_index)
 {
 	struct prestera_acl_rule *rule;
 
@@ -238,42 +474,27 @@ prestera_acl_rule_create(struct prestera_acl_block *block,
 	if (!rule)
 		return ERR_PTR(-ENOMEM);
 
-	INIT_LIST_HEAD(&rule->match_list);
-	INIT_LIST_HEAD(&rule->action_list);
+	rule->ruleset = ruleset;
 	rule->cookie = cookie;
-	rule->block = block;
-	rule->hw_tc = MVSW_ACL_RULE_DEF_HW_TC;
-
-	return rule;
-}
-
-struct list_head *
-prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule)
-{
-	return &rule->match_list;
-}
+	rule->chain_index = chain_index;
+	rule->hw_tc = PRESTERA_ACL_RULE_DEF_HW_TC;
 
-struct list_head *
-prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule)
-{
-	return &rule->action_list;
-}
+	refcount_inc(&ruleset->refcount);
 
-void prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				  struct prestera_acl_rule_action_entry *entry)
-{
-	list_add(&entry->list, &rule->action_list);
-	rule->n_actions++;
+	return rule;
 }
 
-u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule)
+void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
+				unsigned long flag)
 {
-	return rule->n_actions;
+	set_bit(flag, &rule->attr.flags);
 }
 
-u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule)
+bool
+prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
+			    unsigned long flag)
 {
-	return rule->priority;
+	return test_bit(flag, &rule->attr.flags);
 }
 
 void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
@@ -292,73 +513,188 @@ void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc)
 	rule->hw_tc = hw_tc;
 }
 
-void prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_match_entry *entry)
+static int prestera_acl_nat_port_neigh_lookup(struct prestera_port *port,
+					      struct prestera_neigh_info *ni)
 {
-	list_add(&entry->list, &rule->match_list);
+	struct prestera_kern_neigh_cache *n_cache;
+	struct prestera_neigh_info *n_info;
+	struct rhashtable_iter iter;
+	int err = -ENOENT;
+
+	rhashtable_walk_enter(&port->sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while ((n_cache = rhashtable_walk_next(&iter)) != NULL) {
+		if (IS_ERR(n_cache))
+			continue;
+		n_info = prestera_kern_neigh_cache_to_neigh_info(n_cache);
+		if (n_info->iface.type == MVSW_IF_PORT_E &&
+		    n_info->iface.dev_port.port_num == port->hw_id &&
+		    n_info->iface.dev_port.hw_dev_num == port->dev_id) {
+			memcpy(ni, n_info, sizeof(*n_info));
+			err = 0;
+			break;
+		}
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+	return err;
 }
 
 void prestera_acl_rule_destroy(struct prestera_acl_rule *rule)
 {
-	struct prestera_acl_rule_action_entry *a_entry;
-	struct prestera_acl_rule_match_entry *m_entry;
-	struct list_head *pos, *n;
+	if (rule->nat_port)
+		prestera_acl_nat_port_put(rule->nat_port);
 
-	list_for_each_safe(pos, n, &rule->match_list) {
-		m_entry = list_entry(pos, typeof(*m_entry), list);
-		list_del(pos);
-		kfree(m_entry);
-	}
-	list_for_each_safe(pos, n, &rule->action_list) {
-		a_entry = list_entry(pos, typeof(*a_entry), list);
-		list_del(pos);
-		kfree(a_entry);
-	}
+	if (rule->jump_ruleset)
+		/* release ruleset kept by jump action */
+		prestera_acl_ruleset_put(rule->jump_ruleset);
+
+	prestera_acl_ruleset_put(rule->ruleset);
 	kfree(rule);
 }
 
-int prestera_acl_rule_add(struct mvsw_pr_switch *sw,
+int prestera_acl_rule_add(struct prestera_switch *sw,
 			  struct prestera_acl_rule *rule)
 {
 	int err;
-	u32 rule_id;
+	struct prestera_acl_ruleset *ruleset = rule->ruleset;
+	struct prestera_flow_block *block = ruleset->ht_key.block;
+	struct prestera_flow_block_binding *binding;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_neigh_info n_info;
+
+	err = rule_flag_test(rule, CT) && rule_flag_test(rule, GOTO) ?
+	      -ENOTSUPP : 0;
+	if (err)
+		goto err_sanity;
 
 	/* try to add rule to hash table first */
-	err = rhashtable_insert_fast(&rule->block->ruleset->rule_ht,
-				     &rule->ht_node,
+	err = rhashtable_insert_fast(&ruleset->rule_ht, &rule->ht_node,
 				     prestera_acl_rule_ht_params);
 	if (err)
-		return err;
+		goto err_ht_insert;
+
+	prestera_acl_rule_keymask_pcl_id_set(rule, ruleset->pcl_id);
+	rule->re_arg.vtcam_id = ruleset->vtcam_id;
+	rule->re_key.prio = rule->priority;
+
+	/* setup counter */
+	rule->re_arg.count.valid = true;
+	rule->re_arg.count.client =
+		prestera_acl_chain_to_client(ruleset->ht_key.chain_index);
+	if (rule->re_arg.count.client == PRESTERA_COUNTER_CLIENT_LOOKUP_LAST) {
+		err = -EINVAL;
+		goto err_rule_add;
+	}
+
+	if (rule_flag_test(rule, CT)) {
+		err = prestera_ct_ft_offload_add_cb(sw, rule);
+		if (err)
+			goto err_rule_add;
 
-	/* add rule to hw */
-	err = mvsw_pr_hw_acl_rule_add(sw, rule, &rule_id);
+		goto hw_handled;
+	}
+
+	rule->re = prestera_acl_rule_entry_find(sw->acl, &rule->re_key);
+	err = WARN_ON(rule->re) ? -EEXIST : 0;
 	if (err)
 		goto err_rule_add;
 
-	rule->id = rule_id;
+	rule->re = prestera_acl_rule_entry_create(sw->acl, &rule->re_key,
+						  &rule->re_arg);
+	err = !rule->re ? -EINVAL : 0;
+	if (err)
+		goto err_rule_add;
 
-	list_add_tail(&rule->list, &sw->acl->rules);
-	rule->block->rule_count++;
+	if (!rule_flag_test(rule, NAT))
+		goto nat_port_neigh_not_found;
+
+	/* TODO: assign port to NAT here instead of doing this in
+	 * flower action.
+	 *
+	 * Get first interface bound to the block same as
+	 * in NAT action for now
+	 */
+	binding = list_first_entry(&block->binding_list,
+				   struct prestera_flow_block_binding, list);
+	nat_port = prestera_acl_nat_port_get(sw->acl, binding->port->hw_id,
+					     binding->port->dev_id);
+	if (!nat_port) {
+		nat_port = prestera_acl_nat_port_create(sw->acl, binding->port);
+		MVSW_LOG_INFO("NAT port created");
+		err = !nat_port ? -EINVAL : 0;
+		if (err)
+			goto err_rule_add_nat;
+	}
+	rule->nat_port = nat_port;
+
+	/* try to lookup neigh for this port and update HW */
+	err = prestera_acl_nat_port_neigh_lookup(nat_port->port, &n_info);
+	if (err == -ENOENT) {
+		MVSW_LOG_INFO("Neighbour for NAT port not found");
+		goto nat_port_neigh_not_found;
+	}
+	if (err)
+		goto err_rule_add_nat;
+
+	MVSW_LOG_INFO("Found a neighbour for NAT port");
+	err = prestera_hw_nat_port_neigh_update(nat_port->port, n_info.ha);
+	if (err)
+		goto err_rule_add_nat;
+
+hw_handled:
+nat_port_neigh_not_found:
+	/* bind the block (all ports) to chain index 0, rest of
+	 * the chains are bound to goto action
+	 */
+	if (!ruleset->ht_key.chain_index && !ruleset->rule_count) {
+		err = prestera_acl_ruleset_block_bind(ruleset, block);
+		if (err)
+			goto err_acl_block_bind;
+	}
 
+	list_add_tail(&rule->list, &sw->acl->rules);
+	ruleset->ht_key.block->rule_count++;
+	ruleset->rule_count++;
 	return 0;
 
+err_acl_block_bind:
+err_rule_add_nat:
+	prestera_acl_rule_entry_destroy(sw->acl, rule->re);
 err_rule_add:
-	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
+	rule->re = NULL;
+	rhashtable_remove_fast(&ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
+err_ht_insert:
+err_sanity:
 	return err;
 }
 
-void prestera_acl_rule_del(struct mvsw_pr_switch *sw,
+void prestera_acl_rule_del(struct prestera_switch *sw,
 			   struct prestera_acl_rule *rule)
 {
-	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
+	struct prestera_acl_ruleset *ruleset = rule->ruleset;
+	struct prestera_flow_block *block = ruleset->ht_key.block;
+
+	rhashtable_remove_fast(&ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
-	rule->block->rule_count--;
+	block->rule_count--;
+	ruleset->rule_count--;
 	list_del(&rule->list);
-	mvsw_pr_hw_acl_rule_del(sw, rule->id);
+
+	if (rule_flag_test(rule, CT)) {
+		prestera_ct_ft_offload_del_cb(sw, rule);
+	} else {
+		prestera_acl_rule_entry_destroy(sw->acl, rule->re);
+		prestera_acl_block_prio_update(sw, block);
+	}
+
+	/* unbind block (all ports) */
+	if (!ruleset->ht_key.chain_index && !ruleset->rule_count)
+		prestera_acl_ruleset_block_unbind(ruleset, block);
 }
 
-int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
+int prestera_acl_rule_get_stats(struct prestera_acl *acl,
 				struct prestera_acl_rule *rule,
 				u64 *packets, u64 *bytes, u64 *last_use)
 {
@@ -366,8 +702,10 @@ int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
 	u64 current_bytes;
 	int err;
 
-	err = mvsw_pr_hw_acl_rule_stats_get(sw, rule->id, &current_packets,
-					    &current_bytes);
+	err = prestera_counter_stats_get(acl->sw->counter,
+					 rule->re->counter.block,
+					 rule->re->counter.id,
+					 &current_packets, &current_bytes);
 	if (err)
 		return err;
 
@@ -378,25 +716,572 @@ int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-int prestera_acl_init(struct mvsw_pr_switch *sw)
+/* HW objects infrastructure */
+static struct prestera_nh_mangle_entry *
+__prestera_nh_mangle_entry_find(struct prestera_switch *sw,
+				struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+
+	e = rhashtable_lookup_fast(&sw->acl->nh_mangle_entry_ht, key,
+				   __prestera_nh_mangle_entry_ht_params);
+	return IS_ERR(e) ? NULL : e;
+}
+
+static void
+__prestera_nh_mangle_entry_destroy(struct prestera_switch *sw,
+				   struct prestera_nh_mangle_entry *e)
+{
+	rhashtable_remove_fast(&sw->acl->nh_mangle_entry_ht, &e->ht_node,
+			       __prestera_nh_mangle_entry_ht_params);
+	list_del(&e->nh_neigh_head);
+	prestera_nh_neigh_put(sw, e->n);
+	WARN_ON(prestera_hw_nh_mangle_del(sw, e->hw_id));
+	kfree(e);
+}
+
+int prestera_nh_mangle_entry_set(struct prestera_switch *sw,
+				 struct prestera_nh_mangle_entry *e)
+{
+	return prestera_hw_nh_mangle_set(sw, e->hw_id,
+					 e->key.mangle.l4_src_valid,
+					 e->key.mangle.l4_src,
+					 e->key.mangle.l4_dst_valid,
+					 e->key.mangle.l4_dst,
+					 e->key.mangle.sip_valid,
+					 e->key.mangle.sip,
+					 e->key.mangle.dip_valid,
+					 e->key.mangle.dip,
+					 e->n->info);
+}
+
+static struct prestera_nh_mangle_entry *
+__prestera_nh_mangle_entry_create(struct prestera_switch *sw,
+				  struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+	int err;
+
+	e = kzalloc(sizeof(*e), GFP_KERNEL);
+	if (!e)
+		goto err_kzalloc;
+
+	memcpy(&e->key, key, sizeof(*key));
+	e->n = prestera_nh_neigh_get(sw, &e->key.n);
+	if (!e->n)
+		goto err_nh_get;
+
+	list_add(&e->nh_neigh_head, &e->n->nh_mangle_entry_list);
+
+	err = prestera_hw_nh_mangle_add(sw, &e->hw_id);
+	if (err)
+		goto err_hw_add;
+
+	err = prestera_nh_mangle_entry_set(sw, e);
+	if (err)
+		goto err_set;
+
+	err = rhashtable_insert_fast(&sw->acl->nh_mangle_entry_ht, &e->ht_node,
+				     __prestera_nh_mangle_entry_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	return e;
+
+err_ht_insert:
+err_set:
+	WARN_ON(prestera_hw_nh_mangle_del(sw, e->hw_id));
+err_hw_add:
+	list_del(&e->nh_neigh_head);
+	prestera_nh_neigh_put(sw, e->n);
+err_nh_get:
+	kfree(e);
+err_kzalloc:
+	return NULL;
+}
+
+static void prestera_nh_mangle_entry_put(struct prestera_switch *sw,
+					 struct prestera_nh_mangle_entry *e)
+{
+	if (!e->ref_cnt)
+		__prestera_nh_mangle_entry_destroy(sw, e);
+}
+
+static struct prestera_nh_mangle_entry *
+prestera_nh_mangle_entry_get(struct prestera_switch *sw,
+			     struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+
+	e = __prestera_nh_mangle_entry_find(sw, key);
+	if (!e)
+		e = __prestera_nh_mangle_entry_create(sw, key);
+
+	return e;
+}
+
+bool prestera_nh_mangle_entry_util_hw_state(struct prestera_switch *sw,
+					    struct prestera_nh_mangle_entry *e)
+{
+	int err;
+
+	/* Antijitter
+	 * Prevent situation, when we read state of nh_grp twice in short time,
+	 * and state bit is still cleared on second call. So just stuck active
+	 * state for MVSW_PR_NH_ACTIVE_JIFFER_FILTER, after last occurred.
+	 */
+	if (!time_before(jiffies, e->is_active_hw_cache_kick +
+			msecs_to_jiffies(MVSW_PR_NH_ACTIVE_JIFFER_FILTER))) {
+		err = prestera_hw_nh_mangle_get(sw, e->hw_id,
+						&e->is_active_hw_cache);
+		if (err) {
+			MVSW_LOG_ERROR("Failed to get nh_mangle %pI4n hw_state",
+				       &e->key.n.addr.u.ipv4);
+			return false;
+		}
+
+		e->is_active_hw_cache_kick = jiffies;
+	}
+
+	return e->is_active_hw_cache;
+}
+
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_find(struct prestera_acl *acl,
+			     struct prestera_acl_rule_entry_key *key)
+{
+	struct prestera_acl_rule_entry *e;
+
+	e = rhashtable_lookup_fast(&acl->acl_rule_entry_ht, key,
+				   __prestera_acl_rule_entry_ht_params);
+	return IS_ERR(e) ? NULL : e;
+}
+
+static int __prestera_acl_rule_entry2hw_del(struct prestera_switch *sw,
+					    struct prestera_acl_rule_entry *e)
+{
+	return prestera_hw_vtcam_rule_del(sw, e->vtcam_id, e->hw_id);
+}
+
+static int __prestera_acl_rule_entry2hw_add(struct prestera_switch *sw,
+					    struct prestera_acl_rule_entry *e)
+{
+	struct prestera_acl_hw_action_info act_hw[PRESTERA_ACL_ACTION_MAX];
+	int act_num;
+
+	memset(&act_hw, 0, sizeof(act_hw));
+	act_num = 0;
+
+	/* accept */
+	if (e->accept.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_ACCEPT;
+		act_num++;
+	}
+	/* drop */
+	if (e->drop.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_DROP;
+		act_num++;
+	}
+	/* trap */
+	if (e->trap.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_TRAP;
+		act_hw[act_num].trap = e->trap.i;
+		act_num++;
+	}
+	/* police */
+	if (e->police.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_POLICE;
+		act_hw[act_num].police = e->police.i;
+		act_num++;
+	}
+	/* nat */
+	if (e->nat.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_NAT;
+		act_hw[act_num].nat = e->nat.i;
+		act_num++;
+	}
+	/* jump */
+	if (e->jump.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_JUMP;
+		act_hw[act_num].jump = e->jump.i;
+		act_num++;
+	}
+	/* nh */
+	if (e->nh.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_NH;
+		act_hw[act_num].nh = e->nh.e->hw_id;
+		act_num++;
+	}
+	/* counter */
+	if (e->counter.block) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_COUNT;
+		act_hw[act_num].count.id = e->counter.id;
+		act_num++;
+	}
+
+	return prestera_hw_vtcam_rule_add(sw, e->vtcam_id, e->key.prio,
+					  e->key.match.key, e->key.match.mask,
+					  act_hw, act_num, &e->hw_id);
+}
+
+static void
+__prestera_acl_rule_entry_act_destruct(struct prestera_switch *sw,
+				       struct prestera_acl_rule_entry *e)
+{
+	/* nh */
+	if (e->nh.valid) {
+		e->nh.e->ref_cnt--;
+		prestera_nh_mangle_entry_put(sw, e->nh.e);
+	}
+	/* counter */
+	prestera_counter_put(sw->counter, e->counter.block, e->counter.id);
+}
+
+void prestera_acl_rule_entry_destroy(struct prestera_acl *acl,
+				     struct prestera_acl_rule_entry *e)
+{
+	int ret;
+
+	rhashtable_remove_fast(&acl->acl_rule_entry_ht, &e->ht_node,
+			       __prestera_acl_rule_entry_ht_params);
+
+	ret = __prestera_acl_rule_entry2hw_del(acl->sw, e);
+	WARN_ON(ret && ret != -ENODEV);
+
+	__prestera_acl_rule_entry_act_destruct(acl->sw, e);
+	kfree(e);
+}
+
+static int
+__prestera_acl_rule_entry_act_construct(struct prestera_switch *sw,
+					struct prestera_acl_rule_entry *e,
+					struct prestera_acl_rule_entry_arg *arg)
+{
+	/* accept */
+	e->accept.valid = arg->accept.valid;
+	/* drop */
+	e->drop.valid = arg->drop.valid;
+	/* trap */
+	e->trap.valid = arg->trap.valid;
+	e->trap.i = arg->trap.i;
+	/* police */
+	e->police.valid = arg->police.valid;
+	e->police.i = arg->police.i;
+	/* nat */
+	e->nat.valid = arg->nat.valid;
+	e->nat.i = arg->nat.i;
+	/* jump */
+	e->jump.valid = arg->jump.valid;
+	e->jump.i = arg->jump.i;
+	/* nh */
+	if (arg->nh.valid) {
+		e->nh.e = prestera_nh_mangle_entry_get(sw, &arg->nh.k);
+		if (!e->nh.e)
+			goto err_out;
+
+		e->nh.e->ref_cnt++;
+		e->nh.valid = 1;
+	}
+	/* counter */
+	if (arg->count.valid) {
+		int err;
+
+		err = prestera_counter_get(sw->counter, arg->count.client,
+					   &e->counter.block,
+					   &e->counter.id);
+		if (err && arg->count.fail_on_err)
+			goto err_out;
+	}
+
+	return 0;
+
+err_out:
+	__prestera_acl_rule_entry_act_destruct(sw, e);
+	return -EINVAL;
+}
+
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_create(struct prestera_acl *acl,
+			       struct prestera_acl_rule_entry_key *key,
+			       struct prestera_acl_rule_entry_arg *arg)
+{
+	struct prestera_acl_rule_entry *e;
+	int err;
+
+	e = kzalloc(sizeof(*e), GFP_KERNEL);
+	if (!e)
+		goto err_kzalloc;
+
+	memcpy(&e->key, key, sizeof(*key));
+	e->vtcam_id = arg->vtcam_id;
+	err = __prestera_acl_rule_entry_act_construct(acl->sw, e, arg);
+	if (err)
+		goto err_act_construct;
+
+	err = __prestera_acl_rule_entry2hw_add(acl->sw, e);
+	if (err)
+		goto err_hw_add;
+
+	err = rhashtable_insert_fast(&acl->acl_rule_entry_ht, &e->ht_node,
+				     __prestera_acl_rule_entry_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	return e;
+
+err_ht_insert:
+	WARN_ON(__prestera_acl_rule_entry2hw_del(acl->sw, e));
+err_hw_add:
+	__prestera_acl_rule_entry_act_destruct(acl->sw, e);
+err_act_construct:
+	kfree(e);
+err_kzalloc:
+	return NULL;
+}
+
+int prestera_acl_uid_new_get(struct prestera_acl *acl, u8 *uid)
+{
+	struct prestera_acl_uid_entry *uid_entry;
+
+	uid_entry = list_first_entry_or_null(&acl->uid.free_list,
+					     typeof(*uid_entry), list);
+	if (uid_entry) {
+		list_del(&uid_entry->list);
+		*uid = uid_entry->id;
+		kfree(uid_entry);
+		return 0;
+	}
+
+	if (!(acl->uid.next + 1))
+		/* max number reached */
+		return -ENOENT;
+
+	*uid = acl->uid.next++;
+	return 0;
+}
+
+int prestera_acl_uid_release(struct prestera_acl *acl, u8 id)
+{
+	struct prestera_acl_uid_entry *uid_entry;
+
+	if (!(id < acl->uid.next))
+		return -EINVAL;
+
+	uid_entry = kmalloc(sizeof(*uid_entry), GFP_KERNEL);
+	if (!uid_entry)
+		return -ENOMEM;
+
+	uid_entry->id = id;
+	list_add_rcu(&uid_entry->list, &acl->uid.free_list);
+
+	return 0;
+}
+
+static void prestera_acl_uid_destroy(struct prestera_acl *acl)
+{
+	struct prestera_acl_uid_entry *uid_entry;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &acl->uid.free_list) {
+		uid_entry = list_entry(pos, typeof(*uid_entry), list);
+		list_del(&uid_entry->list);
+		kfree(uid_entry);
+	}
+}
+
+static int __prestera_acl_vtcam_id_try_fit(struct prestera_acl *acl, u8 lookup,
+					   void *keymask, u32 *vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	int i;
+
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (lookup != vtcam->lookup)
+			continue;
+
+		if (!keymask && !vtcam->is_keymask_set)
+			goto vtcam_found;
+
+		if (!(keymask && vtcam->is_keymask_set))
+			continue;
+
+		/* try to fit with vtcam keymask */
+		for (i = 0; i < __PRESTERA_ACL_RULE_MATCH_TYPE_MAX; i++) {
+			__be32 __keymask = ((__be32 *)keymask)[i];
+
+			if (!__keymask)
+				/* vtcam keymask in not interested */
+				continue;
+
+			if (__keymask & ~vtcam->keymask[i])
+				/* keymask does not fit the vtcam keymask */
+				break;
+		}
+
+		if (i == __PRESTERA_ACL_RULE_MATCH_TYPE_MAX)
+			/* keymask fits vtcam keymask, return it */
+			goto vtcam_found;
+	}
+
+	/* nothing is found */
+	return -ENOENT;
+
+vtcam_found:
+	refcount_inc(&vtcam->refcount);
+	*vtcam_id = vtcam->id;
+	return 0;
+}
+
+int prestera_acl_vtcam_id_get(struct prestera_acl *acl, u8 lookup,
+			      void *keymask, u32 *vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	u32 new_vtcam_id;
+	int err;
+
+	/* find the vtcam that suits keymask. We do not expect to have
+	 * a big number of vtcams, so, the list type for vtcam list is
+	 * fine for now
+	 */
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (lookup != vtcam->lookup)
+			continue;
+
+		if (!keymask && !vtcam->is_keymask_set) {
+			refcount_inc(&vtcam->refcount);
+			goto vtcam_found;
+		}
+
+		if (keymask && vtcam->is_keymask_set &&
+		    !memcmp(keymask, vtcam->keymask, sizeof(vtcam->keymask))) {
+			refcount_inc(&vtcam->refcount);
+			goto vtcam_found;
+		}
+	}
+
+	/* vtcam not found, try to create new one */
+	vtcam = kzalloc(sizeof(*vtcam), GFP_KERNEL);
+	if (!vtcam)
+		return -ENOMEM;
+
+	err = prestera_hw_vtcam_create(acl->sw, lookup, keymask, &new_vtcam_id);
+	if (err) {
+		kfree(vtcam);
+
+		/* cannot create new, try to fit into existing vtcam */
+		if (__prestera_acl_vtcam_id_try_fit(acl, lookup,
+						    keymask, &new_vtcam_id))
+			return err;
+
+		*vtcam_id = new_vtcam_id;
+		return 0;
+	}
+
+	vtcam->id = new_vtcam_id;
+	vtcam->lookup = lookup;
+	if (keymask) {
+		memcpy(vtcam->keymask, keymask, sizeof(vtcam->keymask));
+		vtcam->is_keymask_set = true;
+	}
+	refcount_set(&vtcam->refcount, 1);
+	list_add_rcu(&vtcam->list, &acl->vtcam_list);
+
+vtcam_found:
+	*vtcam_id = vtcam->id;
+	return 0;
+}
+
+int prestera_acl_vtcam_id_put(struct prestera_acl *acl, u32 vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	int err;
+
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (vtcam_id != vtcam->id)
+			continue;
+
+		if (!refcount_dec_and_test(&vtcam->refcount))
+			return 0;
+
+		err = prestera_hw_vtcam_destroy(acl->sw, vtcam->id);
+		if (err && err != -ENODEV) {
+			refcount_set(&vtcam->refcount, 1);
+			return err;
+		}
+
+		list_del(&vtcam->list);
+		kfree(vtcam);
+		return 0;
+	}
+
+	return -ENOENT;
+}
+
+int prestera_acl_init(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl;
+	int err;
 
 	acl = kzalloc(sizeof(*acl), GFP_KERNEL);
 	if (!acl)
 		return -ENOMEM;
 
+	acl->sw = sw;
 	INIT_LIST_HEAD(&acl->rules);
+	INIT_LIST_HEAD(&acl->nat_port_list);
+	INIT_LIST_HEAD(&acl->vtcam_list);
+	INIT_LIST_HEAD(&acl->uid.free_list);
+
+	err = rhashtable_init(&acl->acl_rule_entry_ht,
+			      &__prestera_acl_rule_entry_ht_params);
+	if (err)
+		goto err_acl_rule_entry_ht_init;
+
+	err = rhashtable_init(&acl->nh_mangle_entry_ht,
+			      &__prestera_nh_mangle_entry_ht_params);
+	if (err)
+		goto err_nh_mangle_entry_ht_init;
+
+	err = rhashtable_init(&acl->ruleset_ht,
+			      &prestera_acl_ruleset_ht_params);
+	if (err)
+		goto err_ruleset_ht_init;
+
+	acl->ct_priv = prestera_ct_init(acl);
+	if (IS_ERR(acl->ct_priv)) {
+		err = PTR_ERR(acl->ct_priv);
+		goto err_ct_init;
+	}
+
 	sw->acl = acl;
-	acl->sw = sw;
 
 	return 0;
+
+err_ct_init:
+	rhashtable_destroy(&acl->ruleset_ht);
+err_ruleset_ht_init:
+	rhashtable_destroy(&acl->nh_mangle_entry_ht);
+err_nh_mangle_entry_ht_init:
+	rhashtable_destroy(&acl->acl_rule_entry_ht);
+err_acl_rule_entry_ht_init:
+	kfree(acl);
+	return err;
 }
 
-void prestera_acl_fini(struct mvsw_pr_switch *sw)
+void prestera_acl_fini(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl = sw->acl;
 
+	prestera_ct_clean(acl->ct_priv);
+	prestera_acl_uid_destroy(acl);
+
+	WARN_ON(!list_empty(&acl->vtcam_list));
+	WARN_ON(!list_empty(&acl->nat_port_list));
 	WARN_ON(!list_empty(&acl->rules));
+
+	rhashtable_destroy(&acl->ruleset_ht);
+	rhashtable_destroy(&acl->nh_mangle_entry_ht);
+	rhashtable_destroy(&acl->acl_rule_entry_ht);
+
 	kfree(acl);
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.h b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
new file mode 100644
index 0000000..d516bed
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
@@ -0,0 +1,294 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_ACL_H_
+#define _PRESTERA_ACL_H_
+
+#include <linux/types.h>
+#include "prestera_ct.h"
+#include "prestera_counter.h"
+
+#define PRESTERA_ACL_RULE_DEF_HW_CHAIN_ID	0
+
+#define PRESTERA_ACL_KEYMASK_PCL_ID		0x3FF
+#define PRESTERA_ACL_KEYMASK_PCL_ID_USER			\
+	(PRESTERA_ACL_KEYMASK_PCL_ID & 0x00FF)
+#define PRESTERA_ACL_KEYMASK_PCL_ID_CHAIN			\
+	(PRESTERA_ACL_KEYMASK_PCL_ID & 0xFF00)
+#define PRESTERA_ACL_CHAIN_MASK					\
+	(PRESTERA_ACL_KEYMASK_PCL_ID >> 8)
+
+#define PRESTERA_ACL_PCL_ID_MAKE(uid, chain_id)			\
+	(((uid) & PRESTERA_ACL_KEYMASK_PCL_ID_USER) |		\
+	(((chain_id) << 8) & PRESTERA_ACL_KEYMASK_PCL_ID_CHAIN))
+
+#define rule_flag_set(rule, flag) \
+	prestera_acl_rule_flag_set(rule, PRESTERA_ACL_RULE_FLAG_##flag)
+#define rule_flag_test(rule, flag) \
+	prestera_acl_rule_flag_test(rule, PRESTERA_ACL_RULE_FLAG_##flag)
+
+#define rule_match_set_n(match_p, type, val_p, size)		\
+	memcpy(&(match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type],	\
+	       val_p, size)
+#define rule_match_set(match_p, type, val)			\
+	memcpy(&(match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type],	\
+	       &(val), sizeof(val))
+#define rule_match_set_u32(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       htonl(val))
+#define rule_match_set_u16(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       (__force __be32)htons(val))
+#define rule_match_set_u8(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       (__force __be32)(val))
+#define rule_match_get_u32(match_p, type)			\
+	(match_p[PRESTERA_ACL_RULE_MATCH_TYPE_##type])
+
+#define MVSW_PR_NH_ACTIVE_JIFFER_FILTER 3000 /* ms */
+#define MVSW_ACL_RULE_DEF_HW_CHAIN_ID	0
+#define MVSW_ACL_RULESET_ALL		0xff
+
+#define PRESTERA_ACL_ACTION_MAX 8
+
+/* HW objects infrastructure */
+struct prestera_mangle_cfg {
+	u8 l4_src_valid:1, l4_dst_valid:1,
+	   sip_valid:1, dip_valid:1;
+	__be16 l4_src;
+	__be16 l4_dst;
+	struct prestera_ip_addr sip;
+	struct prestera_ip_addr dip;
+};
+
+/* TODO: Move mangle_entry to router ? */
+struct prestera_nh_mangle_entry {
+	struct rhash_head ht_node; /* node of prestera_router */
+	struct prestera_nh_mangle_entry_key {
+		struct prestera_mangle_cfg mangle;
+		struct prestera_nh_neigh_key n;
+	} key;
+	struct prestera_nh_neigh *n;
+	u32 hw_id;
+	unsigned long is_active_hw_cache_kick; /* jiffies */
+	bool is_active_hw_cache;
+	u32 ref_cnt;
+	struct list_head nh_neigh_head;
+};
+
+struct prestera_acl_rule_entry {
+	struct rhash_head ht_node; /* node of prestera_sw */
+	struct prestera_acl_rule_entry_key {
+		u32 prio;
+		struct prestera_acl_match match;
+	} key;
+	u32 hw_id;
+	u32 vtcam_id;
+	/* This struct seems to be dublicate of arg, but purpose is to pass
+	 * in cfg objet keys, resolve them and save object links here.
+	 * E.g. chain can be link to object, when chain_id just key in cfg.
+	 */
+	struct {
+		struct {
+			u8 valid:1;
+		} accept, drop;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_trap i;
+		} trap;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_police i;
+		} police;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_nat i;
+		} nat;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_jump i;
+		} jump;
+		struct {
+			u8 valid:1;
+			struct prestera_nh_mangle_entry *e; /* entry */
+		} nh;
+		struct {
+			u32 id;
+			struct prestera_counter_block *block;
+		} counter;
+	};
+};
+
+/* This struct (arg) used only to be passed as parameter for
+ * acl_rule_entry_create. Must be flat. Can contain object keys, which will be
+ * resolved to object links, before saving to acl_rule_entry struct
+ */
+struct prestera_acl_rule_entry_arg {
+	u32 vtcam_id;
+	struct {
+		struct {
+			u8 valid:1;
+		} accept, drop;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_trap i;
+		} trap;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_police i;
+		} police;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_nat i;
+		} nat;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_jump i;
+		} jump;
+		struct {
+			u8 valid:1;
+			struct prestera_nh_mangle_entry_key k; /* key */
+		} nh;
+		struct {
+			u8 valid:1, fail_on_err:1;
+			enum prestera_counter_client client;
+		} count;
+	};
+};
+
+enum {
+	PRESTERA_ACL_RULE_FLAG_CT,
+	PRESTERA_ACL_RULE_FLAG_GOTO,
+	PRESTERA_ACL_RULE_FLAG_NAT
+};
+
+struct prestera_acl_stats {
+	u64 packets;
+	u64 bytes;
+};
+
+struct prestera_acl {
+	struct prestera_switch *sw;
+	struct list_head nat_port_list;
+	struct list_head vtcam_list;
+	struct list_head rules;
+	struct rhashtable ruleset_ht;
+	struct rhashtable acl_rule_entry_ht;
+	/* TODO: move nh_mangle_entry_ht to router ? */
+	struct rhashtable nh_mangle_entry_ht;
+	struct prestera_ct_priv *ct_priv;
+	struct {
+		struct list_head free_list;
+		u8 next;
+	} uid;
+};
+
+struct prestera_acl_nat_port {
+	struct list_head list;
+	struct prestera_port *port;
+	refcount_t refcount;
+};
+
+struct prestera_acl_rule_attr {
+	struct prestera_ct_attr ct_attr;
+	unsigned long flags;
+};
+
+struct prestera_acl_rule {
+	struct rhash_head ht_node; /* Member of acl HT */
+	struct list_head list;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_acl_rule_attr attr;
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl_ruleset *jump_ruleset;
+	unsigned long cookie;
+	u32 chain_index;
+	u32 priority;
+	u8 hw_tc;
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_rule_entry *re;
+};
+
+enum {
+	PRESTERA_ACL_IFACE_TYPE_PORT,
+	PRESTERA_ACL_IFACE_TYPE_INDEX
+};
+
+struct prestera_acl_iface {
+	u8 type;
+	union {
+		struct prestera_port *port;
+		u32 index;
+	};
+};
+
+void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
+				unsigned long flag);
+bool
+prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
+			    unsigned long flag);
+struct prestera_acl_rule *
+prestera_acl_rule_create(struct prestera_acl_ruleset *ruleset,
+			 unsigned long cookie, u32 chain_index);
+void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
+				    u32 priority);
+u8 prestera_acl_rule_hw_tc_get(struct prestera_acl_rule *rule);
+void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc);
+u8 prestera_acl_rule_hw_chain_id_get(const struct prestera_acl_rule *rule);
+void prestera_acl_rule_destroy(struct prestera_acl_rule *rule);
+struct prestera_acl_rule *
+prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
+			 unsigned long cookie);
+int prestera_acl_rule_add(struct prestera_switch *sw,
+			  struct prestera_acl_rule *rule);
+void prestera_acl_rule_del(struct prestera_switch *sw,
+			   struct prestera_acl_rule *rule);
+int prestera_acl_rule_get_stats(struct prestera_acl *acl,
+				struct prestera_acl_rule *rule,
+				u64 *packets, u64 *bytes, u64 *last_use);
+
+int prestera_nh_mangle_entry_set(struct prestera_switch *sw,
+				 struct prestera_nh_mangle_entry *e);
+bool prestera_nh_mangle_entry_util_hw_state(struct prestera_switch *sw,
+					    struct prestera_nh_mangle_entry *e);
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_find(struct prestera_acl *acl,
+			     struct prestera_acl_rule_entry_key *key);
+void prestera_acl_rule_entry_destroy(struct prestera_acl *acl,
+				     struct prestera_acl_rule_entry *e);
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_create(struct prestera_acl *acl,
+			       struct prestera_acl_rule_entry_key *key,
+			       struct prestera_acl_rule_entry_arg *arg);
+enum prestera_counter_client prestera_acl_chain_to_client(u32 chain_index);
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_get(struct prestera_acl *acl,
+			 struct prestera_flow_block *block,
+			 u32 chain_index);
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index);
+int prestera_acl_ruleset_keymask_set(struct prestera_acl_ruleset *ruleset,
+				     void *keymask);
+int prestera_acl_ruleset_offload(struct prestera_acl_ruleset *ruleset);
+u32 prestera_acl_ruleset_index_get(const struct prestera_acl_ruleset *ruleset);
+bool prestera_acl_ruleset_is_offload(struct prestera_acl_ruleset *ruleset);
+void prestera_acl_ruleset_put(struct prestera_acl_ruleset *ruleset);
+int prestera_acl_ruleset_bind(struct prestera_acl_ruleset *ruleset,
+			      struct prestera_port *port);
+int prestera_acl_ruleset_unbind(struct prestera_acl_ruleset *ruleset,
+				struct prestera_port *port);
+void
+prestera_acl_rule_keymask_pcl_id_set(struct prestera_acl_rule *rule,
+				     u16 pcl_id);
+
+int prestera_acl_uid_new_get(struct prestera_acl *acl, u8 *uid);
+int prestera_acl_uid_release(struct prestera_acl *acl, u8 uid);
+
+int prestera_acl_vtcam_id_get(struct prestera_acl *acl, u8 lookup,
+			      void *keymask, u32 *vtcam_id);
+int prestera_acl_vtcam_id_put(struct prestera_acl *acl, u32 vtcam_id);
+
+#endif /* _PRESTERA_ACL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_counter.c b/drivers/net/ethernet/marvell/prestera/prestera_counter.c
new file mode 100644
index 0000000..ee4ac8c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_counter.c
@@ -0,0 +1,476 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2021 Marvell International Ltd. All rights reserved */
+
+#include "prestera.h"
+#include "prestera_hw.h"
+#include "prestera_acl.h"
+#include "prestera_counter.h"
+
+#define COUNTER_POLL_TIME	(msecs_to_jiffies(1000))
+#define COUNTER_RESCHED_TIME	(msecs_to_jiffies(50))
+#define COUNTER_BULK_SIZE	(256)
+
+struct prestera_counter {
+	struct prestera_switch *sw;
+	struct delayed_work stats_dw;
+	bool is_fetching;
+	u32 total_read;
+	struct mutex mtx;  /* protect block_list */
+	struct prestera_counter_block **block_list;
+	u32 block_list_len;
+	u32 curr_idx;
+};
+
+struct prestera_counter_block {
+	struct list_head list;
+	u32 id;
+	u32 offset;
+	u32 num_counters;
+	enum prestera_counter_client client;
+	struct idr counter_idr;
+	bool full;
+	bool is_updating;
+	refcount_t refcnt;
+	struct mutex mtx;  /* protect stats and counter_idr */
+	struct prestera_counter_stats *stats;
+	u8 *counter_flag;
+};
+
+enum {
+	COUNTER_FLAG_READY = 0,
+	COUNTER_FLAG_INVALID = 1
+};
+
+static inline bool
+prestera_counter_is_ready(struct prestera_counter_block *block, u32 id)
+{
+	return block->counter_flag[id - block->offset] == COUNTER_FLAG_READY;
+}
+
+static void prestera_counter_lock(struct prestera_counter *counter)
+{
+	mutex_lock(&counter->mtx);
+}
+
+static void prestera_counter_unlock(struct prestera_counter *counter)
+{
+	mutex_unlock(&counter->mtx);
+}
+
+static void prestera_counter_block_lock(struct prestera_counter_block *block)
+{
+	mutex_lock(&block->mtx);
+}
+
+static void prestera_counter_block_unlock(struct prestera_counter_block *block)
+{
+	mutex_unlock(&block->mtx);
+}
+
+static bool prestera_counter_block_incref(struct prestera_counter_block *block)
+{
+	return refcount_inc_not_zero(&block->refcnt);
+}
+
+static bool prestera_counter_block_decref(struct prestera_counter_block *block)
+{
+	return refcount_dec_and_test(&block->refcnt);
+}
+
+/* must be called with prestera_counter_block_lock() */
+static void prestera_counter_stats_clear(struct prestera_counter_block *block,
+					 u32 counter_id)
+{
+	memset(&block->stats[counter_id - block->offset], 0,
+	       sizeof(*block->stats));
+}
+
+static struct prestera_counter_block *
+prestera_counter_block_lookup_not_full(struct prestera_counter *counter,
+				       enum prestera_counter_client client)
+{
+	u32 i;
+
+	prestera_counter_lock(counter);
+	for (i = 0; i < counter->block_list_len; i++) {
+		if (counter->block_list[i] &&
+		    counter->block_list[i]->client == client &&
+		    !counter->block_list[i]->full &&
+		    prestera_counter_block_incref(counter->block_list[i])) {
+			prestera_counter_unlock(counter);
+			return counter->block_list[i];
+		}
+	}
+	prestera_counter_unlock(counter);
+
+	return NULL;
+}
+
+static int prestera_counter_block_list_add(struct prestera_counter *counter,
+					   struct prestera_counter_block *block)
+{
+	struct prestera_counter_block **arr;
+	u32 i;
+
+	prestera_counter_lock(counter);
+
+	for (i = 0; i < counter->block_list_len; i++) {
+		if (counter->block_list[i])
+			continue;
+
+		counter->block_list[i] = block;
+		prestera_counter_unlock(counter);
+		return 0;
+	}
+
+	arr = krealloc(counter->block_list, (counter->block_list_len + 1) *
+		       sizeof(*counter->block_list), GFP_KERNEL);
+	if (!arr) {
+		prestera_counter_unlock(counter);
+		return -ENOMEM;
+	}
+
+	counter->block_list = arr;
+	counter->block_list[counter->block_list_len] = block;
+	counter->block_list_len++;
+	prestera_counter_unlock(counter);
+	return 0;
+}
+
+static struct prestera_counter_block *
+prestera_counter_block_get(struct prestera_counter *counter,
+			   enum prestera_counter_client client)
+{
+	struct prestera_counter_block *block;
+	int err;
+
+	block = prestera_counter_block_lookup_not_full(counter, client);
+	if (!block) {
+		block = kzalloc(sizeof(*block), GFP_KERNEL);
+		if (!block)
+			return ERR_PTR(-ENOMEM);
+
+		err = prestera_hw_counter_block_get(counter->sw, client,
+						    &block->id, &block->offset,
+						    &block->num_counters);
+		if (err)
+			goto err_block;
+
+		block->stats = kcalloc(block->num_counters,
+				       sizeof(*block->stats), GFP_KERNEL);
+		if (!block->stats) {
+			err = -ENOMEM;
+			goto err_stats;
+		}
+
+		block->counter_flag = kcalloc(block->num_counters,
+					      sizeof(*block->counter_flag),
+					      GFP_KERNEL);
+		if (!block->counter_flag) {
+			err = -ENOMEM;
+			goto err_flag;
+		}
+
+		block->client = client;
+		mutex_init(&block->mtx);
+		refcount_set(&block->refcnt, 1);
+		idr_init_base(&block->counter_idr, block->offset);
+
+		err = prestera_counter_block_list_add(counter, block);
+		if (err)
+			goto err_list_add;
+	}
+
+	return block;
+
+err_list_add:
+	idr_destroy(&block->counter_idr);
+	mutex_destroy(&block->mtx);
+	kfree(block->counter_flag);
+err_flag:
+	kfree(block->stats);
+err_stats:
+	prestera_hw_counter_block_release(counter->sw, block->id);
+err_block:
+	kfree(block);
+	return ERR_PTR(err);
+}
+
+static void prestera_counter_block_put(struct prestera_counter *counter,
+				       struct prestera_counter_block *block)
+{
+	u32 i;
+
+	if (!prestera_counter_block_decref(block))
+		return;
+
+	prestera_counter_lock(counter);
+	for (i = 0; i < counter->block_list_len; i++) {
+		if (counter->block_list[i] &&
+		    counter->block_list[i]->id == block->id) {
+			counter->block_list[i] = NULL;
+			break;
+		}
+	}
+	prestera_counter_unlock(counter);
+
+	WARN_ON(!idr_is_empty(&block->counter_idr));
+
+	prestera_hw_counter_block_release(counter->sw, block->id);
+	idr_destroy(&block->counter_idr);
+	mutex_destroy(&block->mtx);
+	kfree(block->stats);
+	kfree(block);
+}
+
+static int prestera_counter_get_vacant(struct prestera_counter_block *block,
+				       u32 *id)
+{
+	int free_id;
+
+	if (block->full)
+		return -ENOSPC;
+
+	prestera_counter_block_lock(block);
+	free_id = idr_alloc_cyclic(&block->counter_idr, NULL, block->offset,
+				   block->offset + block->num_counters,
+				   GFP_KERNEL);
+	if (free_id < 0) {
+		if (free_id == -ENOSPC)
+			block->full = true;
+
+		prestera_counter_block_unlock(block);
+		return free_id;
+	}
+	*id = free_id;
+	prestera_counter_block_unlock(block);
+
+	return 0;
+}
+
+int prestera_counter_get(struct prestera_counter *counter,
+			 enum prestera_counter_client client,
+			 struct prestera_counter_block **bl, u32 *counter_id)
+{
+	struct prestera_counter_block *block;
+	int err;
+	u32 id;
+
+get_next_block:
+	block = prestera_counter_block_get(counter, client);
+	if (IS_ERR(block))
+		return PTR_ERR(block);
+
+	err = prestera_counter_get_vacant(block, &id);
+	if (err) {
+		prestera_counter_block_put(counter, block);
+
+		if (err == -ENOSPC)
+			goto get_next_block;
+
+		return err;
+	}
+
+	prestera_counter_block_lock(block);
+	if (block->is_updating)
+		block->counter_flag[id - block->offset] = COUNTER_FLAG_INVALID;
+	prestera_counter_block_unlock(block);
+
+	*counter_id = id;
+	*bl = block;
+
+	return 0;
+}
+
+void prestera_counter_put(struct prestera_counter *counter,
+			  struct prestera_counter_block *block, u32 counter_id)
+{
+	if (!block)
+		return;
+
+	prestera_counter_block_lock(block);
+	idr_remove(&block->counter_idr, counter_id);
+	block->full = false;
+	prestera_counter_stats_clear(block, counter_id);
+	prestera_counter_block_unlock(block);
+
+	prestera_hw_counter_clear(counter->sw, block->id, counter_id);
+	prestera_counter_block_put(counter, block);
+}
+
+static u32 prestera_counter_block_idx_next(struct prestera_counter *counter,
+					   u32 curr_idx)
+{
+	u32 idx, i, start = curr_idx + 1;
+
+	prestera_counter_lock(counter);
+	for (i = 0; i < counter->block_list_len; i++) {
+		idx = (start + i) % counter->block_list_len;
+		if (!counter->block_list[idx])
+			continue;
+
+		prestera_counter_unlock(counter);
+		return idx;
+	}
+	prestera_counter_unlock(counter);
+
+	return 0;
+}
+
+static struct prestera_counter_block *
+prestera_counter_block_get_by_idx(struct prestera_counter *counter, u32 idx)
+{
+	if (idx >= counter->block_list_len)
+		return NULL;
+
+	prestera_counter_lock(counter);
+
+	if (!counter->block_list[idx] ||
+	    !prestera_counter_block_incref(counter->block_list[idx])) {
+		prestera_counter_unlock(counter);
+		return NULL;
+	}
+
+	prestera_counter_unlock(counter);
+	return counter->block_list[idx];
+}
+
+static void prestera_counter_stats_work(struct work_struct *work)
+{
+	struct delayed_work *dl_work =
+		container_of(work, struct delayed_work, work);
+	struct prestera_counter *counter =
+		container_of(dl_work, struct prestera_counter, stats_dw);
+	struct prestera_counter_block *block;
+	u32 resched_time = COUNTER_POLL_TIME;
+	u32 count = COUNTER_BULK_SIZE;
+	bool done = false;
+	int err;
+	u32 i;
+
+	block = prestera_counter_block_get_by_idx(counter, counter->curr_idx);
+	if (!block) {
+		if (counter->is_fetching)
+			goto abort;
+
+		goto next;
+	}
+
+	if (!counter->is_fetching) {
+		err = prestera_hw_counter_trigger(counter->sw, block->id);
+		if (err)
+			goto abort;
+
+		prestera_counter_block_lock(block);
+		block->is_updating = true;
+		prestera_counter_block_unlock(block);
+
+		counter->is_fetching = true;
+		counter->total_read = 0;
+		resched_time = COUNTER_RESCHED_TIME;
+		goto resched;
+	}
+
+	prestera_counter_block_lock(block);
+	err = prestera_hw_counters_get(counter->sw, counter->total_read,
+				       &count, &done,
+				       &block->stats[counter->total_read]);
+	prestera_counter_block_unlock(block);
+	if (err)
+		goto abort;
+
+	counter->total_read += count;
+	if (!done || counter->total_read < block->num_counters) {
+		resched_time = COUNTER_RESCHED_TIME;
+		goto resched;
+	}
+
+	for (i = 0; i < block->num_counters; i++) {
+		if (block->counter_flag[i] == COUNTER_FLAG_INVALID) {
+			prestera_counter_block_lock(block);
+			block->counter_flag[i] = COUNTER_FLAG_READY;
+			memset(&block->stats[i], 0, sizeof(*block->stats));
+			prestera_counter_block_unlock(block);
+		}
+	}
+
+	prestera_counter_block_lock(block);
+	block->is_updating = false;
+	prestera_counter_block_unlock(block);
+
+	goto next;
+abort:
+	prestera_hw_counter_abort(counter->sw);
+next:
+	counter->is_fetching = false;
+	counter->curr_idx =
+		prestera_counter_block_idx_next(counter, counter->curr_idx);
+resched:
+	if (block)
+		prestera_counter_block_put(counter, block);
+
+	schedule_delayed_work(&counter->stats_dw, resched_time);
+}
+
+/* Can be executed without rtnl_lock().
+ * So pay attention when something changing.
+ */
+int prestera_counter_stats_get(struct prestera_counter *counter,
+			       struct prestera_counter_block *block,
+			       u32 counter_id, u64 *packets, u64 *bytes)
+{
+	if (!block || !prestera_counter_is_ready(block, counter_id)) {
+		*packets = 0;
+		*bytes = 0;
+		return 0;
+	}
+
+	prestera_counter_block_lock(block);
+	*packets = block->stats[counter_id - block->offset].packets;
+	*bytes = block->stats[counter_id - block->offset].bytes;
+
+	prestera_counter_stats_clear(block, counter_id);
+	prestera_counter_block_unlock(block);
+
+	return 0;
+}
+
+int prestera_counter_init(struct prestera_switch *sw)
+{
+	struct prestera_counter *counter;
+
+	counter = kzalloc(sizeof(*counter), GFP_KERNEL);
+	if (!counter)
+		return -ENOMEM;
+
+	counter->block_list = kzalloc(sizeof(*counter->block_list), GFP_KERNEL);
+	if (!counter->block_list) {
+		kfree(counter);
+		return -ENOMEM;
+	}
+
+	mutex_init(&counter->mtx);
+	counter->block_list_len = 1;
+	counter->sw = sw;
+	sw->counter = counter;
+
+	INIT_DELAYED_WORK(&counter->stats_dw, prestera_counter_stats_work);
+	schedule_delayed_work(&counter->stats_dw, COUNTER_POLL_TIME);
+
+	return 0;
+}
+
+void prestera_counter_fini(struct prestera_switch *sw)
+{
+	struct prestera_counter *counter = sw->counter;
+	u32 i;
+
+	cancel_delayed_work_sync(&counter->stats_dw);
+
+	for (i = 0; i < counter->block_list_len; i++)
+		WARN_ON(counter->block_list[i]);
+
+	mutex_destroy(&counter->mtx);
+	kfree(counter->block_list);
+	kfree(counter);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_counter.h b/drivers/net/ethernet/marvell/prestera/prestera_counter.h
new file mode 100644
index 0000000..009fa77
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_counter.h
@@ -0,0 +1,37 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_COUNTER_H_
+#define _PRESTERA_COUNTER_H_
+
+#include <linux/types.h>
+
+enum prestera_counter_client {
+	PRESTERA_COUNTER_CLIENT_LOOKUP_0,
+	PRESTERA_COUNTER_CLIENT_LOOKUP_1,
+	PRESTERA_COUNTER_CLIENT_LOOKUP_2,
+
+	PRESTERA_COUNTER_CLIENT_LOOKUP_LAST
+};
+
+struct prestera_counter_stats {
+	u64 packets;
+	u64 bytes;
+};
+
+struct prestera_counter_block;
+
+int prestera_counter_init(struct prestera_switch *sw);
+void prestera_counter_fini(struct prestera_switch *sw);
+
+int prestera_counter_get(struct prestera_counter *counter,
+			 enum prestera_counter_client client,
+			 struct prestera_counter_block **block,
+			 u32 *counter_id);
+void prestera_counter_put(struct prestera_counter *counter,
+			  struct prestera_counter_block *block, u32 counter_id);
+int prestera_counter_stats_get(struct prestera_counter *counter,
+			       struct prestera_counter_block *block,
+			       u32 counter_id, u64 *packets, u64 *bytes);
+
+#endif /* _PRESTERA_COUNTER_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.c b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
new file mode 100644
index 0000000..524a50c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
@@ -0,0 +1,779 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/rhashtable.h>
+#include <net/netfilter/nf_flow_table.h>
+#include <net/tc_act/tc_ct.h>
+#include <linux/bitops.h>
+
+#include "prestera.h"
+#include "prestera_log.h"
+#include "prestera_hw.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
+#include "prestera_counter.h"
+
+#define PRESTERA_ACL_CT_CHAIN 1
+#define PRESTERA_ACL_CT_TRAP_PRIO 0xfffffffe
+#define PRESTERA_ACL_CT_MATCHES 4
+#define PRESTERA_ACL_CT_HW_TC	18
+
+enum mangle_act_mask {
+	MANGLE_ACT_IP4_SRC_BIT = BIT(0),
+	MANGLE_ACT_IP4_DST_BIT = BIT(1),
+	MANGLE_ACT_PORT_SRC_BIT = BIT(2),
+	MANGLE_ACT_PORT_DST_BIT = BIT(3)
+};
+
+struct prestera_ct_tuple {
+	u16 zone;
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_rule_entry *re;
+};
+
+struct prestera_ct_priv {
+	struct prestera_acl *acl;
+	struct rhashtable zone_ht;
+	struct prestera_acl_rule_entry *re;
+	u32 vtcam_id;
+	u16 pcl_id;
+	u32 index;
+};
+
+struct prestera_ct_entry {
+	struct rhash_head node;
+	unsigned long cookie;
+	struct prestera_ct_tuple tuple;
+	volatile struct {
+		u64 lastuse, packets, bytes;
+	} stats; /* cache */
+};
+
+struct prestera_ct_ft {
+	struct rhash_head node;
+	u16 zone;
+	refcount_t refcount;
+	struct prestera_ct_priv *ct_priv;
+	struct nf_flowtable *nf_ft;
+	struct rhashtable ct_entries_ht;
+};
+
+static const struct rhashtable_params ct_entry_ht_params = {
+	.head_offset = offsetof(struct prestera_ct_entry, node),
+	.key_offset = offsetof(struct prestera_ct_entry, cookie),
+	.key_len = sizeof(((struct prestera_ct_entry *)0)->cookie),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params ct_zone_ht_params = {
+	.head_offset = offsetof(struct prestera_ct_ft, node),
+	.key_offset = offsetof(struct prestera_ct_ft, zone),
+	.key_len = sizeof(((struct prestera_ct_ft *)0)->zone),
+	.automatic_shrinking = true,
+};
+
+static struct workqueue_struct *prestera_ct_owq;
+
+static int prestera_ct_chain_init(struct prestera_ct_priv *priv)
+{
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_iface iface;
+	u16 pcl_id;
+	int err;
+	u8 uid;
+
+	err = prestera_acl_uid_new_get(priv->acl, &uid);
+	if (err)
+		return err;
+
+	/* create vtcam with specific keymask/template */
+	memset(&re_key, 0, sizeof(re_key));
+	rule_match_set_u16(re_key.match.mask, PCL_ID,
+			   PRESTERA_ACL_KEYMASK_PCL_ID);
+	rule_match_set_u16(re_key.match.mask, ETH_TYPE, 0xFFFF);
+	rule_match_set_u8(re_key.match.mask, IP_PROTO, 0xFF);
+	rule_match_set_u32(re_key.match.mask, IP_SRC, 0xFFFFFFFF);
+	rule_match_set_u32(re_key.match.mask, IP_DST, 0xFFFFFFFF);
+	rule_match_set_u16(re_key.match.mask, L4_PORT_SRC, 0xFFFF);
+	rule_match_set_u16(re_key.match.mask, L4_PORT_DST, 0xFFFF);
+
+	err = prestera_acl_vtcam_id_get(priv->acl, PRESTERA_ACL_CT_CHAIN,
+					re_key.match.mask, &priv->vtcam_id);
+	if (err)
+		goto err_vtcam_create;
+
+	/* make pcl-id based on uid and chain */
+	pcl_id = PRESTERA_ACL_PCL_ID_MAKE(uid, PRESTERA_ACL_CT_CHAIN);
+
+	/* bind iface index to pcl-id to be able to jump to this from
+	 * any other rules.
+	 */
+	iface.index = uid;
+	iface.type = PRESTERA_ACL_IFACE_TYPE_INDEX;
+	err = prestera_hw_vtcam_iface_bind(priv->acl->sw, &iface,
+					   priv->vtcam_id, pcl_id);
+	if (err)
+		goto err_rule_entry_bind;
+
+	memset(&re_key, 0, sizeof(re_key));
+	re_key.prio = PRESTERA_ACL_CT_TRAP_PRIO;
+	rule_match_set_u16(re_key.match.key, PCL_ID, pcl_id);
+	rule_match_set_u16(re_key.match.mask, PCL_ID,
+			   PRESTERA_ACL_KEYMASK_PCL_ID);
+
+	memset(&re_arg, 0, sizeof(re_arg));
+	re_arg.trap.valid = 1;
+	re_arg.trap.i.hw_tc = PRESTERA_ACL_CT_HW_TC;
+	re_arg.vtcam_id = priv->vtcam_id;
+
+	priv->re = prestera_acl_rule_entry_create(priv->acl, &re_key, &re_arg);
+	if (!priv->re) {
+		err = -EINVAL;
+		goto err_rule_entry_create;
+	}
+
+	priv->pcl_id = pcl_id;
+	priv->index = uid;
+	return 0;
+
+err_rule_entry_create:
+	prestera_hw_vtcam_iface_unbind(priv->acl->sw, &iface, priv->vtcam_id);
+err_rule_entry_bind:
+	prestera_acl_vtcam_id_put(priv->acl, priv->vtcam_id);
+err_vtcam_create:
+	prestera_acl_uid_release(priv->acl, uid);
+	return err;
+}
+
+struct prestera_ct_priv *prestera_ct_init(struct prestera_acl *acl)
+{
+	struct prestera_ct_priv *ct_priv;
+
+	ct_priv = kzalloc(sizeof(*ct_priv), GFP_KERNEL);
+	if (!ct_priv)
+		return ERR_PTR(-ENOMEM);
+
+	rhashtable_init(&ct_priv->zone_ht, &ct_zone_ht_params);
+	ct_priv->acl = acl;
+
+	if (prestera_ct_chain_init(ct_priv))
+		return ERR_PTR(-EINVAL);
+
+	prestera_ct_owq = alloc_ordered_workqueue("%s_ordered", 0,
+						  "prestera_ct");
+	if (!prestera_ct_owq)
+		return ERR_PTR(-ENOMEM);
+
+	return ct_priv;
+}
+
+void prestera_ct_clean(struct prestera_ct_priv *ct_priv)
+{
+	u8 uid = ct_priv->pcl_id & PRESTERA_ACL_KEYMASK_PCL_ID_USER;
+
+	if (!ct_priv)
+		return;
+
+	destroy_workqueue(prestera_ct_owq);
+
+	prestera_acl_rule_entry_destroy(ct_priv->acl, ct_priv->re);
+	prestera_acl_vtcam_id_put(ct_priv->acl, ct_priv->vtcam_id);
+	prestera_acl_uid_release(ct_priv->acl, uid);
+
+	rhashtable_destroy(&ct_priv->zone_ht);
+	kfree(ct_priv);
+}
+
+int prestera_ct_match_parse(struct flow_cls_offload *f,
+			    struct netlink_ext_ack *extack)
+{
+	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
+	struct flow_dissector_key_ct *mask, *key;
+	bool trk, est, untrk, unest, new;
+	u16 ct_state_on, ct_state_off;
+	u16 ct_state, ct_state_mask;
+	struct flow_match_ct match;
+
+	if (!flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_CT))
+		return 0;
+
+	flow_rule_match_ct(f_rule, &match);
+
+	key = match.key;
+	mask = match.mask;
+
+	ct_state = key->ct_state;
+	ct_state_mask = mask->ct_state;
+
+	if (ct_state_mask & ~(TCA_FLOWER_KEY_CT_FLAGS_TRACKED |
+			      TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED |
+			      TCA_FLOWER_KEY_CT_FLAGS_NEW)) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "only ct_state trk, est and new are supported for offload");
+		return -EOPNOTSUPP;
+	}
+
+	ct_state_on = ct_state & ct_state_mask;
+	ct_state_off = (ct_state & ct_state_mask) ^ ct_state_mask;
+
+	trk = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	new = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_NEW;
+	est = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+
+	untrk = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	unest = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+
+	MVSW_LOG_INFO("trk=%d new=%d est=%d untrk=%d unest=%d",
+		      trk, new, est, untrk, unest);
+
+	if (new) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "matching on ct_state +new isn't supported");
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+int prestera_ct_parse_action(const struct flow_action_entry *act,
+			     struct prestera_acl_rule *rule,
+			     struct netlink_ext_ack *extack)
+
+{
+	struct prestera_ct_attr *ct_attr;
+
+	ct_attr = &rule->attr.ct_attr;
+
+	ct_attr->zone = act->ct.zone;
+	ct_attr->ct_action = act->ct.action;
+	ct_attr->nf_ft = act->ct.flow_table;
+
+	return 0;
+}
+
+static struct flow_action_entry *
+prestera_ct_get_ct_metadata_action(struct flow_rule *flow_rule)
+{
+	struct flow_action *flow_action = &flow_rule->action;
+	struct flow_action_entry *act;
+	int i;
+
+	flow_action_for_each(i, act, flow_action) {
+		if (act->id == FLOW_ACTION_CT_METADATA)
+			return act;
+	}
+
+	return NULL;
+}
+
+static int
+prestera_ct_flow_rule_to_tuple(struct flow_rule *rule,
+			       struct prestera_ct_tuple *tuple)
+{
+	struct prestera_acl_match *r_match = &tuple->re_key.match;
+	struct flow_match_ipv4_addrs ipv4_match;
+	struct flow_match_ports ports_match;
+	struct flow_match_control control;
+	struct flow_match_basic basic;
+	u16 addr_type;
+	u8 ip_proto;
+
+	flow_rule_match_basic(rule, &basic);
+	flow_rule_match_control(rule, &control);
+
+	ip_proto = basic.key->ip_proto;
+	addr_type = control.key->addr_type;
+
+	if (addr_type != FLOW_DISSECTOR_KEY_IPV4_ADDRS)
+		return -EOPNOTSUPP;
+
+	flow_rule_match_ipv4_addrs(rule, &ipv4_match);
+
+	rule_match_set(r_match->key, IP_SRC, ipv4_match.key->src);
+	rule_match_set(r_match->mask, IP_SRC, ipv4_match.mask->src);
+
+	rule_match_set(r_match->key, IP_DST, ipv4_match.key->dst);
+	rule_match_set(r_match->mask, IP_DST, ipv4_match.mask->dst);
+
+	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS))
+		return -EOPNOTSUPP;
+
+	flow_rule_match_ports(rule, &ports_match);
+	switch (ip_proto) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+		rule_match_set(r_match->key,
+			       L4_PORT_SRC, ports_match.key->src);
+		rule_match_set(r_match->mask,
+			       L4_PORT_SRC, ports_match.mask->src);
+
+		rule_match_set(r_match->key,
+			       L4_PORT_DST, ports_match.key->dst);
+		rule_match_set(r_match->mask,
+			       L4_PORT_DST, ports_match.mask->dst);
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_META))
+		return -EOPNOTSUPP;
+
+	/* metadata match is set but not information is present.
+	 * Issue? Need to investigate on kernel side.
+	 */
+	return 0;
+}
+
+static int
+__prestera_ct_tuple_get_mangle(struct flow_rule *rule,
+			       struct prestera_ct_tuple *tuple)
+{
+	struct flow_action *flow_action = &rule->action;
+	struct flow_action_entry *act;
+	u32 offset, val;
+	int i;
+	struct prestera_mangle_cfg *mc;
+
+	mc = &tuple->re_arg.nh.k.mangle;
+	flow_action_for_each(i, act, flow_action) {
+		if (act->id != FLOW_ACTION_MANGLE)
+			continue;
+
+		offset = act->mangle.offset;
+		val = act->mangle.val;
+		switch (act->mangle.htype) {
+		case FLOW_ACT_MANGLE_HDR_TYPE_IP4:
+			if (offset == offsetof(struct iphdr, saddr)) {
+				mc->sip.u.ipv4 =
+					cpu_to_be32(val);
+				mc->sip_valid = true;
+			} else if (offset == offsetof(struct iphdr, daddr)) {
+				mc->dip.u.ipv4 =
+					cpu_to_be32(val);
+				mc->dip_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		case FLOW_ACT_MANGLE_HDR_TYPE_TCP:
+			if (offset == offsetof(struct tcphdr, source)) {
+				mc->l4_src = cpu_to_be16(val);
+				mc->l4_src_valid = true;
+			} else if (offset == offsetof(struct tcphdr, dest)) {
+				mc->l4_dst = cpu_to_be16(val);
+				mc->l4_dst_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		case FLOW_ACT_MANGLE_HDR_TYPE_UDP:
+			if (offset == offsetof(struct udphdr, source)) {
+				mc->l4_src = cpu_to_be16(val);
+				mc->l4_src_valid = true;
+			} else if (offset == offsetof(struct udphdr, dest)) {
+				mc->l4_dst = cpu_to_be16(val);
+				mc->l4_dst_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		default:
+			return -EOPNOTSUPP;
+		}
+	}
+
+	return 0;
+}
+
+static int __prestera_ct_tuple_get_nh(struct prestera_switch *sw,
+				      struct prestera_ct_tuple *tuple)
+{
+	struct prestera_ip_addr ip;
+	struct prestera_nexthop_group_key nh_grp_key;
+	struct prestera_mangle_cfg *mc;
+
+	mc = &tuple->re_arg.nh.k.mangle;
+	memset(&ip, 0, sizeof(ip));
+	memcpy(&ip.u.ipv4,
+	       mc->sip_valid ?
+	       (void *)&rule_match_get_u32(tuple->re_key.match.key, IP_DST) :
+	       (void *)&mc->dip.u.ipv4,
+	       sizeof(ip.u.ipv4));
+
+	/* TODO: VRF */
+	/* TODO: ECMP */
+	if (prestera_util_kern_dip2nh_grp_key(sw, RT_TABLE_MAIN, &ip,
+					      &nh_grp_key) != 1)
+		return -ENOTSUPP;
+
+	tuple->re_arg.nh.k.n = nh_grp_key.neigh[0];
+
+	return 0;
+}
+
+static int __prestera_ct_tuple2acl_add(struct prestera_acl *acl,
+				       struct prestera_ct_tuple *tuple)
+{
+	tuple->re = prestera_acl_rule_entry_find(acl, &tuple->re_key);
+	if (tuple->re) {
+		tuple->re = NULL;
+		return -EEXIST;
+	}
+
+	tuple->re = prestera_acl_rule_entry_create(acl, &tuple->re_key,
+						   &tuple->re_arg);
+	if (!tuple->re)
+		return -EINVAL;
+
+	return 0;
+}
+
+static int
+prestera_ct_block_flow_offload_add(struct prestera_ct_ft *ft,
+				   struct flow_cls_offload *flow)
+{
+	struct flow_rule *flow_rule = flow_cls_offload_flow_rule(flow);
+	struct flow_action_entry *meta_action;
+	unsigned long cookie = flow->cookie;
+	struct prestera_ct_entry *entry;
+	int err;
+
+	meta_action = prestera_ct_get_ct_metadata_action(flow_rule);
+	if (!meta_action)
+		return -EOPNOTSUPP;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (entry)
+		return 0;
+
+	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+	if (!entry)
+		return -ENOMEM;
+
+	entry->tuple.zone = ft->zone;
+	entry->cookie = flow->cookie;
+	entry->tuple.re_key.prio = flow->common.prio;
+	entry->tuple.re_arg.vtcam_id = ft->ct_priv->vtcam_id;
+
+	/* set pcl-id for this rule */
+	rule_match_set_u16(entry->tuple.re_key.match.key,
+			   PCL_ID, ft->ct_priv->pcl_id);
+	rule_match_set_u16(entry->tuple.re_key.match.mask,
+			   PCL_ID, PRESTERA_ACL_KEYMASK_PCL_ID);
+
+	err = prestera_ct_flow_rule_to_tuple(flow_rule, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	/* Do we need sanity check before "valid = 1" ? */
+	entry->tuple.re_arg.nh.valid = 1;
+
+	err = __prestera_ct_tuple_get_mangle(flow_rule, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	/* setup counter */
+	entry->tuple.re_arg.count.valid = true;
+	entry->tuple.re_arg.count.fail_on_err = true;
+	entry->tuple.re_arg.count.client =
+		prestera_acl_chain_to_client(PRESTERA_ACL_CT_CHAIN);
+	if (entry->tuple.re_arg.count.client ==
+	    PRESTERA_COUNTER_CLIENT_LOOKUP_LAST) {
+		err = -EINVAL;
+		goto err_set;
+	}
+
+	err = __prestera_ct_tuple_get_nh(ft->ct_priv->acl->sw, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	/* HW offload */
+	err = __prestera_ct_tuple2acl_add(ft->ct_priv->acl, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	err = rhashtable_insert_fast(&ft->ct_entries_ht, &entry->node,
+				     ct_entry_ht_params);
+	if (err)
+		goto err_insert;
+
+	return 0;
+
+err_insert:
+	prestera_acl_rule_entry_destroy(ft->ct_priv->acl, entry->tuple.re);
+
+err_set:
+	kfree(entry);
+	return err;
+}
+
+static int
+prestera_ct_block_flow_offload_del(struct prestera_ct_ft *ft,
+				   struct flow_cls_offload *flow)
+{
+	unsigned long cookie = flow->cookie;
+	struct prestera_ct_entry *entry;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (!entry)
+		return -ENOENT;
+
+	prestera_acl_rule_entry_destroy(ft->ct_priv->acl, entry->tuple.re);
+	rhashtable_remove_fast(&ft->ct_entries_ht,
+			       &entry->node, ct_entry_ht_params);
+	kfree(entry);
+	return 0;
+}
+
+static int
+prestera_ct_block_flow_offload_stats(struct prestera_ct_ft *ft,
+				     struct flow_cls_offload *f)
+{
+	unsigned long cookie = f->cookie;
+	struct prestera_ct_entry *entry;
+	u64 packets, bytes;
+	int err;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (!entry)
+		return -ENOENT;
+
+	err = prestera_counter_stats_get(ft->ct_priv->acl->sw->counter,
+					 entry->tuple.re->counter.block,
+					 entry->tuple.re->counter.id,
+					 &packets, &bytes);
+	if (err)
+		return err;
+
+	if (packets != entry->stats.packets || bytes != entry->stats.bytes) {
+		entry->stats.packets = packets;
+		entry->stats.bytes = bytes;
+		entry->stats.lastuse = jiffies;
+	}
+
+	flow_stats_update(&f->stats,
+			  entry->stats.bytes,
+			  entry->stats.packets,
+			  0,
+			  entry->stats.lastuse,
+			  FLOW_ACTION_HW_STATS_DELAYED);
+
+	return 0;
+}
+
+static int
+prestera_ct_block_flow_offload(enum tc_setup_type type, void *type_data,
+			       void *cb_priv)
+{
+	struct flow_cls_offload *f = type_data;
+	struct prestera_ct_ft *ft = cb_priv;
+	int err;
+
+	if (type != TC_SETUP_CLSFLOWER)
+		return -EOPNOTSUPP;
+
+	switch (f->command) {
+	case FLOW_CLS_REPLACE:
+		rtnl_lock();
+		err = prestera_ct_block_flow_offload_add(ft, f);
+		rtnl_unlock();
+		break;
+	case FLOW_CLS_DESTROY:
+		rtnl_lock();
+		err = prestera_ct_block_flow_offload_del(ft, f);
+		rtnl_unlock();
+		break;
+	case FLOW_CLS_STATS:
+		err = prestera_ct_block_flow_offload_stats(ft, f);
+		break;
+	default:
+		err =  -EOPNOTSUPP;
+		break;
+	}
+
+	return err;
+}
+
+static struct prestera_ct_ft *
+__prestera_ct_ft_offload_add_cb(struct prestera_ct_priv *ct_priv,
+				u16 zone, struct nf_flowtable *nf_ft)
+{
+	struct prestera_ct_ft *ft;
+	int err;
+
+	ft = rhashtable_lookup_fast(&ct_priv->zone_ht, &zone,
+				    ct_zone_ht_params);
+	if (ft) {
+		refcount_inc(&ft->refcount);
+		return ft;
+	}
+
+	ft = kzalloc(sizeof(*ft), GFP_KERNEL);
+	if (!ft)
+		return ERR_PTR(-ENOMEM);
+
+	/* ft->net = read_pnet(&nf_ft->net); */
+	ft->zone = zone;
+	ft->nf_ft = nf_ft;
+	ft->ct_priv = ct_priv;
+	refcount_set(&ft->refcount, 1);
+
+	err = rhashtable_init(&ft->ct_entries_ht, &ct_entry_ht_params);
+	if (err)
+		goto err_init;
+
+	err = rhashtable_insert_fast(&ct_priv->zone_ht, &ft->node,
+				     ct_zone_ht_params);
+	if (err)
+		goto err_insert;
+
+	err = nf_flow_table_offload_add_cb(ft->nf_ft,
+					   prestera_ct_block_flow_offload, ft);
+	if (err)
+		goto err_add_cb;
+
+	return ft;
+
+err_add_cb:
+	rhashtable_remove_fast(&ct_priv->zone_ht, &ft->node, ct_zone_ht_params);
+err_insert:
+	rhashtable_destroy(&ft->ct_entries_ht);
+err_init:
+	kfree(ft);
+	return ERR_PTR(err);
+}
+
+/* Add gateway rule in def chain and add TRAP rule in CT chain */
+static int __prestera_ct_rule2gateway(struct prestera_switch *sw,
+				      struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_priv *ct_priv = sw->acl->ct_priv;
+
+	/* TODO: fill this in flower parse */
+
+	/* just update the action for this rule */
+	rule->re_arg.jump.valid = 1;
+	rule->re_arg.jump.i.index = ct_priv->index;
+
+	rule->re = prestera_acl_rule_entry_find(sw->acl, &rule->re_key);
+	if (WARN_ON(rule->re)) {
+		rule->re = NULL;
+		return -EEXIST;
+	}
+
+	rule->re = prestera_acl_rule_entry_create(sw->acl, &rule->re_key,
+						  &rule->re_arg);
+	if (!rule->re)
+		return -EINVAL;
+
+	return 0;
+}
+
+int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
+				  struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_attr *ct_attr;
+	int err;
+
+	ct_attr = &rule->attr.ct_attr;
+
+	if (ct_attr->ct_action & TCA_CT_ACT_CLEAR)
+		return -EOPNOTSUPP;
+
+	ct_attr->ft = __prestera_ct_ft_offload_add_cb(sw->acl->ct_priv,
+						      ct_attr->zone,
+						      ct_attr->nf_ft);
+	if (IS_ERR(ct_attr->ft))
+		return PTR_ERR(ct_attr->ft);
+
+	err = __prestera_ct_rule2gateway(sw, rule);
+	if (err) {
+		prestera_ct_ft_offload_del_cb(sw, rule);
+		return err;
+	}
+
+	return 0;
+}
+
+static void prestera_ct_flush_ft_entry(void *ptr, void *arg)
+{
+	struct prestera_ct_priv *ct_priv = arg;
+	struct prestera_ct_entry *entry = ptr;
+
+	prestera_acl_rule_entry_destroy(ct_priv->acl, entry->tuple.re);
+	kfree(entry);
+}
+
+struct prestera_ct_ft_cb_work {
+	struct work_struct work;
+	struct prestera_switch *sw;
+	struct prestera_ct_ft *ft;
+};
+
+static void __prestera_ct_ft_cb_work(struct work_struct *work)
+{
+	struct prestera_ct_ft_cb_work *ct_work;
+	struct prestera_switch *sw;
+	struct prestera_ct_ft *ft;
+
+	ct_work = container_of(work, struct prestera_ct_ft_cb_work, work);
+	sw = ct_work->sw;
+	ft = ct_work->ft;
+
+	/* Will take ct_lock inside.
+	 * Also ensures, that there is no more events.
+	 */
+	nf_flow_table_offload_del_cb(ft->nf_ft,
+				     prestera_ct_block_flow_offload, ft);
+
+	/* This code can be executed without rtnl_lock,
+	 * because nf_flow_table_offload_del_cb already delete all entries ?
+	 */
+	rtnl_lock();
+	rhashtable_free_and_destroy(&ft->ct_entries_ht,
+				    prestera_ct_flush_ft_entry,
+				    sw->acl->ct_priv);
+	rtnl_unlock();
+	kfree(ft);
+
+	kfree(ct_work);
+}
+
+void prestera_ct_ft_offload_del_cb(struct prestera_switch *sw,
+				   struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_attr *ct_attr;
+	struct prestera_ct_ft *ft;
+	struct prestera_ct_ft_cb_work *ct_work;
+
+	ct_attr = &rule->attr.ct_attr;
+	ft = ct_attr->ft;
+
+	if (rule->re)
+		prestera_acl_rule_entry_destroy(sw->acl, rule->re);
+
+	if (!refcount_dec_and_test(&ft->refcount))
+		return;
+
+	/* Delete this ft from HT to prevent occurring in search results of
+	 * __prestera_ct_ft_offload_add_cb. Prevents reusing after refcnt
+	 * became zero.
+	 */
+	rhashtable_remove_fast(&sw->acl->ct_priv->zone_ht,
+			       &ft->node, ct_zone_ht_params);
+
+	ct_work = kzalloc(sizeof(*ct_work), GFP_ATOMIC);
+	if (WARN_ON(!ct_work))
+		return;
+
+	ct_work->sw = sw;
+	ct_work->ft = ft;
+	INIT_WORK(&ct_work->work, __prestera_ct_ft_cb_work);
+	queue_work(prestera_ct_owq, &ct_work->work);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.h b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
new file mode 100644
index 0000000..3901af6
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
@@ -0,0 +1,39 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _PRESTERA_CT_H_
+#define _PRESTERA_CT_H_
+
+#include <linux/types.h>
+#include <linux/netlink.h>
+#include <net/flow_offload.h>
+
+struct prestera_switch;
+struct prestera_ct_ft;
+struct prestera_ct_priv;
+
+struct prestera_ct_attr {
+	u16 zone;
+	u16 ct_action;
+	struct net *net;
+	struct prestera_ct_ft *ft;
+	struct nf_flowtable *nf_ft;
+};
+
+struct prestera_ct_priv *prestera_ct_init(struct prestera_acl *acl);
+void prestera_ct_clean(struct prestera_ct_priv *ct_priv);
+
+/* match & action */
+int prestera_ct_match_parse(struct flow_cls_offload *f,
+			    struct netlink_ext_ack *extack);
+int prestera_ct_parse_action(const struct flow_action_entry *act,
+			     struct prestera_acl_rule *rule,
+			     struct netlink_ext_ack *extack);
+
+/* flowtable */
+int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
+				  struct prestera_acl_rule *rule);
+void prestera_ct_ft_offload_del_cb(struct prestera_switch *sw,
+				   struct prestera_acl_rule *rule);
+
+#endif /* _PRESTERA_CT_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
index 1b4b855..d824202 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
@@ -1,8 +1,6 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/*
- * Copyright (c) 2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
 #include <linux/kernel.h>
 #include <linux/fs.h>
 #include <linux/device.h>
@@ -13,148 +11,277 @@
 #include "prestera_log.h"
 #include "prestera_fw_log.h"
 #include "prestera_rxtx.h"
+#include "prestera_hw.h"
+
+#define PRESTERA_DEBUGFS_ROOTDIR	"prestera"
 
-#define DEBUGFS_ROOTDIR	"prestera"
+#define CPU_CODE_HW_CNT_SUBDIR_NAME	"hw_counters"
+#define CPU_CODE_SW_CNT_SUBDIR_NAME	"sw_counters"
 
-#define CPU_CODE_SUBDIR_NAME	"traps"
-#define CPU_CODE_MAX_BUF_SIZE	(MVSW_PR_RXTX_CPU_CODE_MAX_NUM * 32)
+#define CPU_CODE_CNT_SUBDIR_TRAP_NAME	"traps"
+#define CPU_CODE_CNT_SUBDIR_DROP_NAME	"drops"
 
-static ssize_t cpu_code_stats_read(struct file *file,
-				   char __user *ubuf,
-				   size_t count, loff_t *ppos);
+#define CPU_CODE_CNT_BUF_MAX_SIZE	(MVSW_PR_RXTX_CPU_CODE_MAX_NUM * 32)
 
-struct mvsw_pr_debugfs {
+static ssize_t prestera_cnt_read(struct file *file, char __user *ubuf,
+				 size_t count, loff_t *ppos);
+
+struct prestera_debugfs {
 	struct dentry *root_dir;
-	struct dentry *cpu_code_subdir;
-	const struct file_operations cpu_code_stats_fops;
-	char *cpu_code_stats_buf;
-	/* serialize access to cpu_code_stats_buf */
-	struct mutex cpu_code_stats_mtx;
+	const struct file_operations cpu_code_cnt_fops;
+	char *cpu_code_cnt_buf;
+	/* serialize access to cpu_code_cnt_buf */
+	struct mutex cpu_code_cnt_buf_mtx;
+	struct prestera_switch *sw;
 };
 
-static struct mvsw_pr_debugfs prestera_debugfs = {
-	.cpu_code_stats_fops = {
-		.read = cpu_code_stats_read,
+struct prestera_cpu_code_data {
+	union {
+		long data;
+		struct {
+			u16 cpu_code;
+			u8 cpu_code_cnt_type;
+		} __packed __aligned(4);
+	};
+} __packed __aligned(4);
+
+static struct prestera_debugfs prestera_debugfs = {
+	.cpu_code_cnt_fops = {
+		.read = prestera_cnt_read,
 		.open = simple_open,
 		.llseek = default_llseek,
 	},
 };
 
-int mvsw_pr_debugfs_init(struct mvsw_pr_switch *sw)
+enum {
+	CPU_CODE_CNT_TYPE_HW_DROP = PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP,
+	CPU_CODE_CNT_TYPE_HW_TRAP = PRESTERA_HW_CPU_CODE_CNT_TYPE_TRAP,
+	CPU_CODE_CNT_TYPE_SW_TRAP = CPU_CODE_CNT_TYPE_HW_TRAP + 1,
+};
+
+int prestera_debugfs_init(struct prestera_switch *sw)
 {
-	const struct file_operations *fops =
-		&prestera_debugfs.cpu_code_stats_fops;
+	struct prestera_debugfs *debugfs = &prestera_debugfs;
+	struct dentry *cpu_code_hw_cnt_trap_subdir;
+	struct dentry *cpu_code_hw_cnt_drop_subdir;
+	struct dentry *cpu_code_sw_cnt_trap_subdir;
+	struct dentry *cpu_code_sw_cnt_subdir;
+	struct dentry *cpu_code_hw_counters_subdir;
 	char file_name[] = "cpu_code_XXX_stats";
+	const struct file_operations *fops =
+		&prestera_debugfs.cpu_code_cnt_fops;
+	struct prestera_cpu_code_data f_data;
+	struct dentry *debugfs_file;
 	int err;
 	int i;
 
-	mutex_init(&prestera_debugfs.cpu_code_stats_mtx);
+	mutex_init(&debugfs->cpu_code_cnt_buf_mtx);
 
-	prestera_debugfs.cpu_code_stats_buf =
-		kzalloc(CPU_CODE_MAX_BUF_SIZE, GFP_KERNEL);
+	debugfs->sw = sw;
 
-	if (!prestera_debugfs.cpu_code_stats_buf)
+	debugfs->cpu_code_cnt_buf = kzalloc(CPU_CODE_CNT_BUF_MAX_SIZE,
+					    GFP_KERNEL);
+	if (!debugfs->cpu_code_cnt_buf)
 		return -ENOMEM;
 
 	err = mvsw_pr_fw_log_init(sw);
 	if (err)
-		return err;
+		goto err_fw_log_init;
 
-	prestera_debugfs.root_dir = debugfs_create_dir(DEBUGFS_ROOTDIR, NULL);
-	if (!prestera_debugfs.root_dir) {
-		err = -ENOMEM;
-		goto root_dir_alloc_failed;
+	debugfs->root_dir = debugfs_create_dir(PRESTERA_DEBUGFS_ROOTDIR, NULL);
+	if (PTR_ERR_OR_ZERO(debugfs->root_dir)) {
+		err = (int)PTR_ERR(debugfs->root_dir);
+		goto err_root_dir_alloc;
 	}
 
-	prestera_debugfs.cpu_code_subdir =
-		debugfs_create_dir(CPU_CODE_SUBDIR_NAME,
-				   prestera_debugfs.root_dir);
-	if (!prestera_debugfs.cpu_code_subdir) {
-		err = -ENOMEM;
-		goto cpu_code_subdir_alloc_failed;
+	cpu_code_sw_cnt_subdir = debugfs_create_dir(CPU_CODE_SW_CNT_SUBDIR_NAME,
+						    debugfs->root_dir);
+	if (PTR_ERR_OR_ZERO(cpu_code_sw_cnt_subdir)) {
+		err = (int)PTR_ERR(debugfs->root_dir);
+		goto err_subdir_alloc;
 	}
 
-	for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
-		snprintf(file_name, sizeof(file_name), "cpu_code_%d_stats", i);
-		if (!debugfs_create_file(file_name, 0644,
-					 prestera_debugfs.cpu_code_subdir,
-					 (void *)(long)i, fops)) {
-			err = -ENOMEM;
-			goto cpu_code_single_file_creation_failed;
-		}
+	cpu_code_sw_cnt_trap_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_TRAP_NAME,
+				   cpu_code_sw_cnt_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_sw_cnt_trap_subdir)) {
+		err = (int)PTR_ERR(cpu_code_sw_cnt_trap_subdir);
+		goto err_subdir_alloc;
+	}
+
+	cpu_code_hw_counters_subdir =
+		debugfs_create_dir(CPU_CODE_HW_CNT_SUBDIR_NAME,
+				   debugfs->root_dir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_counters_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_counters_subdir);
+		goto err_subdir_alloc;
+	}
+
+	cpu_code_hw_cnt_trap_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_TRAP_NAME,
+				   cpu_code_hw_counters_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_cnt_trap_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_cnt_trap_subdir);
+		goto err_subdir_alloc;
 	}
 
-	strncpy(file_name, "cpu_code_stats", sizeof(file_name));
+	cpu_code_hw_cnt_drop_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_DROP_NAME,
+				   cpu_code_hw_counters_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_cnt_drop_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_cnt_trap_subdir);
+		goto err_subdir_alloc;
+	}
+
+	for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
+		f_data.cpu_code = i;
+
+		snprintf(file_name, sizeof(file_name), "cpu_code_%d_stats", i);
 
-	if (!debugfs_create_file(file_name, 0644,
-				 prestera_debugfs.cpu_code_subdir,
-				 (void *)(long)MVSW_PR_RXTX_CPU_CODE_MAX_NUM,
-				 fops)) {
-		err = -ENOMEM;
-		goto cpu_code_single_file_creation_failed;
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_SW_TRAP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_sw_cnt_trap_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_TRAP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_hw_cnt_trap_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_DROP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_hw_cnt_drop_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
 	}
 
+	f_data.cpu_code = MVSW_PR_RXTX_CPU_CODE_MAX_NUM;
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_SW_TRAP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_sw_cnt_trap_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_TRAP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_hw_cnt_trap_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_DROP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_hw_cnt_drop_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
 	return 0;
 
-cpu_code_single_file_creation_failed:
-	debugfs_remove(prestera_debugfs.cpu_code_subdir);
-cpu_code_subdir_alloc_failed:
-	debugfs_remove(prestera_debugfs.root_dir);
-root_dir_alloc_failed:
+err_single_file_creation:
+	err = (int)PTR_ERR(debugfs_file);
+err_subdir_alloc:
+	/*
+	 * Removing root directory would result in recursive
+	 * subdirectories / files cleanup of all child nodes;
+	 */
+	debugfs_remove(debugfs->root_dir);
+err_root_dir_alloc:
 	mvsw_pr_fw_log_fini(sw);
-
+err_fw_log_init:
+	kfree(debugfs->cpu_code_cnt_buf);
 	return err;
 }
 
-void mvsw_pr_debugfs_fini(struct mvsw_pr_switch *sw)
+void prestera_debugfs_fini(struct prestera_switch *sw)
 {
 	mvsw_pr_fw_log_fini(sw);
-
-	debugfs_remove(prestera_debugfs.cpu_code_subdir);
 	debugfs_remove(prestera_debugfs.root_dir);
+	mutex_destroy(&prestera_debugfs.cpu_code_cnt_buf_mtx);
+	kfree(prestera_debugfs.cpu_code_cnt_buf);
+}
 
-	mutex_destroy(&prestera_debugfs.cpu_code_stats_mtx);
-
-	kfree(prestera_debugfs.cpu_code_stats_buf);
+/*
+ * Software: only TRAP counters are present
+ * Hardware: counters can be either TRAP or drops
+ */
+static int prestera_cpu_code_cnt_get(u64 *stats, u8 cpu_code, u8 cnt_type)
+{
+	switch (cnt_type) {
+	case CPU_CODE_CNT_TYPE_HW_DROP:
+	case CPU_CODE_CNT_TYPE_HW_TRAP:
+		/* fall through */
+		return prestera_hw_cpu_code_counters_get(prestera_debugfs.sw,
+							 cpu_code, cnt_type,
+							 stats);
+	case CPU_CODE_CNT_TYPE_SW_TRAP:
+		*stats = mvsw_pr_rxtx_get_cpu_code_stats(cpu_code);
+		return 0;
+	default:
+		return -EINVAL;
+	}
 }
 
-static ssize_t cpu_code_stats_read(struct file *file,
-				   char __user *ubuf,
-				   size_t count, loff_t *ppos)
+static ssize_t prestera_cnt_read(struct file *file, char __user *ubuf,
+				 size_t count, loff_t *ppos)
 {
-	char *buf = prestera_debugfs.cpu_code_stats_buf;
-	u16 cpu_code = (u16)(long)file->private_data;
+	char *buf = prestera_debugfs.cpu_code_cnt_buf;
+	struct prestera_cpu_code_data f_data = {
+		.data = (long)file->private_data,
+	};
 	u64 cpu_code_stats;
 	/* as the snprintf doesn't count for \0, start with 1 */
 	int buf_len = 1;
 	int ret;
 
-	mutex_lock(&prestera_debugfs.cpu_code_stats_mtx);
+	mutex_lock(&prestera_debugfs.cpu_code_cnt_buf_mtx);
 
-	if (cpu_code == MVSW_PR_RXTX_CPU_CODE_MAX_NUM) {
+	if (f_data.cpu_code == MVSW_PR_RXTX_CPU_CODE_MAX_NUM) {
 		int i;
 
-		memset(buf, 0, CPU_CODE_MAX_BUF_SIZE);
+		memset(buf, 0, CPU_CODE_CNT_BUF_MAX_SIZE);
 
 		for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
-			cpu_code_stats = mvsw_pr_rxtx_get_cpu_code_stats(i);
+			ret = prestera_cpu_code_cnt_get
+				(&cpu_code_stats, (u8)i,
+				 f_data.cpu_code_cnt_type);
+			if (ret)
+				goto err_get_stats;
 
 			if (!cpu_code_stats)
 				continue;
 
 			buf_len += snprintf(buf + buf_len,
-					    CPU_CODE_MAX_BUF_SIZE - buf_len,
+					    CPU_CODE_CNT_BUF_MAX_SIZE - buf_len,
 					    "%u:%llu\n", i, cpu_code_stats);
 		}
 
 	} else {
-		cpu_code_stats = mvsw_pr_rxtx_get_cpu_code_stats((u8)cpu_code);
+		ret = prestera_cpu_code_cnt_get(&cpu_code_stats,
+						(u8)f_data.cpu_code,
+						f_data.cpu_code_cnt_type);
+		if (ret)
+			goto err_get_stats;
 
 		buf_len += sprintf(buf, "%llu\n", cpu_code_stats);
 	}
 
 	ret = simple_read_from_buffer(ubuf, count, ppos, buf, buf_len);
-	mutex_unlock(&prestera_debugfs.cpu_code_stats_mtx);
+
+err_get_stats:
+	mutex_unlock(&prestera_debugfs.cpu_code_cnt_buf_mtx);
 
 	return ret;
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
index b3ce1a4..10c60e6 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
@@ -1,14 +1,12 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
 #ifndef _MVSW_PRESTERA_DEBUGFS_H_
 #define _MVSW_PRESTERA_DEBUGFS_H_
 
-struct mvsw_pr_switch;
+struct prestera_switch;
 
-int mvsw_pr_debugfs_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_debugfs_fini(struct mvsw_pr_switch *sw);
+int prestera_debugfs_init(struct prestera_switch *sw);
+void prestera_debugfs_fini(struct prestera_switch *sw);
 
 #endif /* _MVSW_PRESTERA_DEBUGFS_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
index 7a9d5f4..e8f14da 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
@@ -1,15 +1,500 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <net/devlink.h>
+#include <linux/version.h>
+#include <linux/bitops.h>
+#include <linux/bitfield.h>
 
 #include "prestera_devlink.h"
+#include "prestera_hw.h"
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+/* All driver-specific traps must be documented in
+ * Documentation/networking/devlink/prestera.rst
+ */
+enum {
+	DEVLINK_PRESTERA_TRAP_ID_BASE = DEVLINK_TRAP_GENERIC_ID_MAX,
+	DEVLINK_PRESTERA_TRAP_ID_ARP_BC,
+	DEVLINK_PRESTERA_TRAP_ID_IS_IS,
+	DEVLINK_PRESTERA_TRAP_ID_OSPF,
+	DEVLINK_PRESTERA_TRAP_ID_IP_BC_MAC,
+	DEVLINK_PRESTERA_TRAP_ID_ROUTER_MC,
+	DEVLINK_PRESTERA_TRAP_ID_VRRP,
+	DEVLINK_PRESTERA_TRAP_ID_DHCP,
+	DEVLINK_PRESTERA_TRAP_ID_MAC_TO_ME,
+	DEVLINK_PRESTERA_TRAP_ID_IPV4_OPTIONS,
+	DEVLINK_PRESTERA_TRAP_ID_IP_DEFAULT_ROUTE,
+	DEVLINK_PRESTERA_TRAP_ID_IP_TO_ME,
+	DEVLINK_PRESTERA_TRAP_ID_IPV4_ICMP_REDIRECT,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_0,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_1,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_2,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_3,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_4,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_5,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_6,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_7,
+	DEVLINK_PRESTERA_TRAP_ID_BGP,
+	DEVLINK_PRESTERA_TRAP_ID_SSH,
+	DEVLINK_PRESTERA_TRAP_ID_TELNET,
+	DEVLINK_PRESTERA_TRAP_ID_ICMP,
+	DEVLINK_PRESTERA_TRAP_ID_MET_RED,
+	DEVLINK_PRESTERA_TRAP_ID_IP_SIP_IS_ZERO,
+	DEVLINK_PRESTERA_TRAP_ID_IP_UC_DIP_DA_MISMATCH,
+	DEVLINK_PRESTERA_TRAP_ID_ILLEGAL_IPV4_HDR,
+	DEVLINK_PRESTERA_TRAP_ID_ILLEGAL_IP_ADDR,
+	DEVLINK_PRESTERA_TRAP_ID_INVALID_SA,
+	DEVLINK_PRESTERA_TRAP_ID_LOCAL_PORT,
+	DEVLINK_PRESTERA_TRAP_ID_PORT_NO_VLAN,
+	DEVLINK_PRESTERA_TRAP_ID_RXDMA_DROP,
+};
+
+#define DEVLINK_PRESTERA_TRAP_NAME_ARP_BC \
+	"arp_bc"
+#define DEVLINK_PRESTERA_TRAP_NAME_IS_IS \
+	"is_is"
+#define DEVLINK_PRESTERA_TRAP_NAME_OSPF \
+	"ospf"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_BC_MAC \
+	"ip_bc_mac"
+#define DEVLINK_PRESTERA_TRAP_NAME_ROUTER_MC \
+	"router_mc"
+#define DEVLINK_PRESTERA_TRAP_NAME_VRRP \
+	"vrrp"
+#define DEVLINK_PRESTERA_TRAP_NAME_DHCP \
+	"dhcp"
+#define DEVLINK_PRESTERA_TRAP_NAME_MAC_TO_ME \
+	"mac_to_me"
+#define DEVLINK_PRESTERA_TRAP_NAME_IPV4_OPTIONS \
+	"ipv4_options"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_DEFAULT_ROUTE \
+	"ip_default_route"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_TO_ME \
+	"ip_to_me"
+#define DEVLINK_PRESTERA_TRAP_NAME_IPV4_ICMP_REDIRECT \
+	"ipv4_icmp_redirect"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_0 \
+	"acl_code_0"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_1 \
+	"acl_code_1"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_2 \
+	"acl_code_2"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_3 \
+	"acl_code_3"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_4 \
+	"acl_code_4"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_5 \
+	"acl_code_5"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_6 \
+	"acl_code_6"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_7 \
+	"acl_code_7"
+#define DEVLINK_PRESTERA_TRAP_NAME_BGP \
+	"bgp"
+#define DEVLINK_PRESTERA_TRAP_NAME_SSH \
+	"ssh"
+#define DEVLINK_PRESTERA_TRAP_NAME_TELNET \
+	"telnet"
+#define DEVLINK_PRESTERA_TRAP_NAME_ICMP \
+	"icmp"
+#define DEVLINK_PRESTERA_TRAP_NAME_RXDMA_DROP \
+	"rxdma_drop"
+#define DEVLINK_PRESTERA_TRAP_NAME_PORT_NO_VLAN \
+	"port_no_vlan"
+#define DEVLINK_PRESTERA_TRAP_NAME_LOCAL_PORT \
+	"local_port"
+#define DEVLINK_PRESTERA_TRAP_NAME_INVALID_SA \
+	"invalid_sa"
+#define DEVLINK_PRESTERA_TRAP_NAME_ILLEGAL_IP_ADDR \
+	"illegal_ip_addr"
+#define DEVLINK_PRESTERA_TRAP_NAME_ILLEGAL_IPV4_HDR \
+	"illegal_ipv4_hdr"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_UC_DIP_DA_MISMATCH \
+	"ip_uc_dip_da_mismatch"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_SIP_IS_ZERO \
+	"ip_sip_is_zero"
+#define DEVLINK_PRESTERA_TRAP_NAME_MET_RED \
+	"met_red"
+
+struct prestera_trap {
+	struct devlink_trap trap;
+	u8 cpu_code;
+};
+
+struct prestera_trap_item {
+	enum devlink_trap_action action;
+	void *trap_ctx;
+};
+
+struct prestera_trap_data {
+	struct prestera_switch *sw;
+	struct prestera_trap_item *trap_items_arr;
+	u32 traps_count;
+};
+
+#define PRESTERA_TRAP_METADATA DEVLINK_TRAP_METADATA_TYPE_F_IN_PORT
+
+#define PRESTERA_TRAP_CONTROL(_id, _group_id, _action)			      \
+	DEVLINK_TRAP_GENERIC(CONTROL, _action, _id,			      \
+			     DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			     PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_TRAP_DRIVER_CONTROL(_id, _group_id)			      \
+	DEVLINK_TRAP_DRIVER(CONTROL, TRAP, DEVLINK_PRESTERA_TRAP_ID_##_id,    \
+			    DEVLINK_PRESTERA_TRAP_NAME_##_id,		      \
+			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			    PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_TRAP_EXCEPTION(_id, _group_id)				      \
+	DEVLINK_TRAP_GENERIC(EXCEPTION, TRAP, _id,			      \
+			     DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			     PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_TRAP_DRIVER_EXCEPTION(_id, _group_id)			      \
+	DEVLINK_TRAP_DRIVER(EXCEPTION, TRAP, DEVLINK_PRESTERA_TRAP_ID_##_id,  \
+			    DEVLINK_PRESTERA_TRAP_NAME_##_id,		      \
+			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			    PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_TRAP_DRIVER_DROP(_id, _group_id)			      \
+	DEVLINK_TRAP_DRIVER(DROP, DROP, DEVLINK_PRESTERA_TRAP_ID_##_id,	      \
+			    DEVLINK_PRESTERA_TRAP_NAME_##_id,		      \
+			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			    PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_DEVLINK_PORT_PARAM_NUM		(3)
+#define PRESTERA_DEVLINK_PORT_PARAM_FP_MASK	GENMASK(5, 0)
+#define PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK	GENMASK(7, 6)
+#define PRESTERA_DEVLINK_PORT_PARAM_PREP_ID(type_id, fp_id)		      \
+	((FIELD_PREP(PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK, type_id) |	      \
+	 FIELD_PREP(PRESTERA_DEVLINK_PORT_PARAM_FP_MASK, fp_id)) +	      \
+	 PRESTERA_DEVLINK_PORT_PARAM_ID_BASE)
+
+enum {
+	PORT_PARAM_ID_BC_RATE = 0,
+	PORT_PARAM_ID_UC_UNK_RATE = 1,
+	PORT_PARAM_ID_MC_RATE = 2
+};
+
+struct prestera_strom_control_cfg {
+	u32 bc_kbyte_per_sec_rate;
+	u32 unk_uc_kbyte_per_sec_rate;
+	u32 unreg_mc_kbyte_per_sec_rate;
+};
+
+struct prestera_storm_control {
+	struct prestera_switch *sw;
+	struct prestera_strom_control_cfg *cfg;
+	struct devlink_param *port_params[PRESTERA_DEVLINK_PORT_PARAM_NUM];
+};
+
+enum prestera_devlink_port_param_id {
+	PRESTERA_DEVLINK_PORT_PARAM_ID_BASE = DEVLINK_PARAM_GENERIC_ID_MAX + 1,
+};
+
+static const struct devlink_trap_group prestera_trap_groups_arr[] = {
+	/* No policer is associated with following groups (policerid == 0)*/
+	DEVLINK_TRAP_GROUP_GENERIC(L2_DROPS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(L3_DROPS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(L3_EXCEPTIONS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(NEIGH_DISCOVERY, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(ACL_TRAP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(ACL_DROPS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(ACL_SAMPLE, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(OSPF, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(STP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(LACP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(LLDP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(VRRP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(DHCP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(BGP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(LOCAL_DELIVERY, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(BUFFER_DROPS, 0),
+};
+
+/* Initialize trap list, as well as associate CPU code with them. */
+static struct prestera_trap prestera_trap_items_arr[] = {
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ARP_BC, NEIGH_DISCOVERY),
+		.cpu_code = 5,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(IS_IS, LOCAL_DELIVERY),
+		.cpu_code = 13,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(OSPF, OSPF),
+		.cpu_code = 16,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(IP_BC_MAC, LOCAL_DELIVERY),
+		.cpu_code = 19,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(STP, STP, TRAP),
+		.cpu_code = 26,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(LACP, LACP, TRAP),
+		.cpu_code = 27,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(LLDP, LLDP, TRAP),
+		.cpu_code = 28,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ROUTER_MC, LOCAL_DELIVERY),
+		.cpu_code = 29,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(VRRP, VRRP),
+		.cpu_code = 30,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(DHCP, DHCP),
+		.cpu_code = 33,
+	},
+	{
+		.trap = PRESTERA_TRAP_EXCEPTION(MTU_ERROR, L3_EXCEPTIONS),
+		.cpu_code = 63,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(MAC_TO_ME, LOCAL_DELIVERY),
+		.cpu_code = 65,
+	},
+	{
+		.trap = PRESTERA_TRAP_EXCEPTION(TTL_ERROR, L3_EXCEPTIONS),
+		.cpu_code = 133,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_EXCEPTION(IPV4_OPTIONS,
+						       L3_EXCEPTIONS),
+		.cpu_code = 141,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(IP_DEFAULT_ROUTE,
+						     LOCAL_DELIVERY),
+		.cpu_code = 160,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(LOCAL_ROUTE, LOCAL_DELIVERY,
+					      TRAP),
+		.cpu_code = 161,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_EXCEPTION(IPV4_ICMP_REDIRECT,
+						       L3_EXCEPTIONS),
+		.cpu_code = 180,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(ARP_RESPONSE, NEIGH_DISCOVERY,
+					      TRAP),
+		.cpu_code = 188,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_0, ACL_TRAP),
+		.cpu_code = 192,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_1, ACL_TRAP),
+		.cpu_code = 193,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_2, ACL_TRAP),
+		.cpu_code = 194,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_3, ACL_TRAP),
+		.cpu_code = 195,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_4, ACL_TRAP),
+		.cpu_code = 196,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_5, ACL_TRAP),
+		.cpu_code = 197,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_6, ACL_TRAP),
+		.cpu_code = 198,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_7, ACL_TRAP),
+		.cpu_code = 199,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(BGP, BGP),
+		.cpu_code = 206,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(SSH, LOCAL_DELIVERY),
+		.cpu_code = 207,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(TELNET, LOCAL_DELIVERY),
+		.cpu_code = 208,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ICMP, LOCAL_DELIVERY),
+		.cpu_code = 209,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(RXDMA_DROP, BUFFER_DROPS),
+		.cpu_code = 37,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(PORT_NO_VLAN, L2_DROPS),
+		.cpu_code = 39,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(LOCAL_PORT, L2_DROPS),
+		.cpu_code = 56,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(INVALID_SA, L2_DROPS),
+		.cpu_code = 60,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(ILLEGAL_IP_ADDR, L3_DROPS),
+		.cpu_code = 136,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(ILLEGAL_IPV4_HDR, L3_DROPS),
+		.cpu_code = 137,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(IP_UC_DIP_DA_MISMATCH,
+						  L3_DROPS),
+		.cpu_code = 138,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(IP_SIP_IS_ZERO, L3_DROPS),
+		.cpu_code = 145,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(MET_RED, BUFFER_DROPS),
+		.cpu_code = 185,
+	},
+};
+#endif
+
+static int prestera_storm_control_rate_set(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ctx);
+
+static int prestera_storm_control_rate_get(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ct);
+
+static void prestera_devlink_traps_fini(struct prestera_switch *sw);
+
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx);
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack);
+
+static int prestera_devlink_traps_register(struct prestera_switch *sw);
+
+static int prestera_drop_counter_get(struct devlink *devlink,
+				     const struct devlink_trap *trap,
+				     u64 *p_drops);
+
+static int prestera_storm_control_init(struct prestera_switch *sw);
+static void prestera_storm_control_fini(struct prestera_switch *sw);
+
+static int prestera_storm_control_rate_set(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ctx)
+{
+	struct prestera_switch *sw = devlink_priv(dl);
+	struct prestera_strom_control_cfg *cfg;
+	u32 kbyte_per_sec_rate = ctx->val.vu32;
+	struct prestera_port *port = NULL;
+	struct prestera_storm_control *sc;
+	u32 *param_to_set = NULL;
+	u32 storm_type;
+	int type_id;
+	int fp_id;
+	int ret;
+
+	id -= PRESTERA_DEVLINK_PORT_PARAM_ID_BASE;
+	fp_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_FP_MASK, id);
+	type_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK, id);
+
+	port = prestera_port_find_by_fp_id(fp_id);
+	if (!port)
+		return -EINVAL;
+
+	sc = sw->storm_control;
+	cfg = &sc->cfg[fp_id - 1];
+
+	switch (type_id) {
+	case PORT_PARAM_ID_BC_RATE:
+		param_to_set = &cfg->bc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_BC;
+		break;
+	case PORT_PARAM_ID_UC_UNK_RATE:
+		param_to_set = &cfg->unk_uc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_UC_UNK;
+		break;
+	case PORT_PARAM_ID_MC_RATE:
+		param_to_set = &cfg->unreg_mc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_MC;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (kbyte_per_sec_rate != *param_to_set) {
+		ret = mvsw_pr_hw_port_storm_control_cfg_set(port, storm_type,
+							    kbyte_per_sec_rate);
+		if (ret)
+			return ret;
+
+		*param_to_set = kbyte_per_sec_rate;
+	}
+
+	return 0;
+}
+
+static int prestera_storm_control_rate_get(struct devlink *dl, u32 id,
+					   struct devlink_param_gset_ctx *ctx)
+{
+	struct prestera_switch *sw = devlink_priv(dl);
+	struct prestera_strom_control_cfg *cfg;
+	struct prestera_storm_control *sc;
+	int type_id;
+	int fp_id;
+
+	id -= PRESTERA_DEVLINK_PORT_PARAM_ID_BASE;
+	fp_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_FP_MASK, id);
+	type_id = FIELD_GET(PRESTERA_DEVLINK_PORT_PARAM_TYPE_MASK, id);
+
+	sc = sw->storm_control;
+	cfg = &sc->cfg[fp_id - 1];
+
+	switch (type_id) {
+	case PORT_PARAM_ID_BC_RATE:
+		ctx->val.vu32 = cfg->bc_kbyte_per_sec_rate;
+		return 0;
+	case PORT_PARAM_ID_UC_UNK_RATE:
+		ctx->val.vu32 = cfg->unk_uc_kbyte_per_sec_rate;
+		return 0;
+	case PORT_PARAM_ID_MC_RATE:
+		ctx->val.vu32 = cfg->unreg_mc_kbyte_per_sec_rate;
+		return 0;
+	default:
+		return -EINVAL;
+	}
+}
 
 static int prestera_dl_info_get(struct devlink *dl,
 				struct devlink_info_req *req,
 				struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_switch *sw = devlink_priv(dl);
+	struct prestera_switch *sw = devlink_priv(dl);
 	char buf[16];
 	int err;
 
@@ -29,49 +514,80 @@ static int prestera_dl_info_get(struct devlink *dl,
 
 static const struct devlink_ops prestera_dl_ops = {
 	.info_get = prestera_dl_info_get,
+	.trap_init = prestera_trap_init,
+	.trap_action_set = prestera_trap_action_set,
+	.trap_drop_counter_get = prestera_drop_counter_get,
 };
 
-struct mvsw_pr_switch *prestera_devlink_alloc(void)
+struct prestera_switch *prestera_devlink_alloc(void)
 {
 	struct devlink *dl;
 
-	dl = devlink_alloc(&prestera_dl_ops, sizeof(struct mvsw_pr_switch));
+	dl = devlink_alloc(&prestera_dl_ops, sizeof(struct prestera_switch));
 
 	return devlink_priv(dl);
 }
 
-void prestera_devlink_free(struct mvsw_pr_switch *sw)
+void prestera_devlink_free(struct prestera_switch *sw)
 {
 	struct devlink *dl = priv_to_devlink(sw);
 
 	devlink_free(dl);
 }
 
-int prestera_devlink_register(struct mvsw_pr_switch *sw)
+int prestera_devlink_register(struct prestera_switch *sw)
 {
 	struct devlink *dl = priv_to_devlink(sw);
 	int err;
 
 	err = devlink_register(dl, sw->dev->dev);
-	if (err)
+	if (err) {
 		dev_err(sw->dev->dev, "devlink_register failed: %d\n", err);
+		return err;
+	}
 
-	return err;
+	err = prestera_devlink_traps_register(sw);
+	if (err) {
+		devlink_unregister(dl);
+		dev_err(sw->dev->dev, "devlink_traps_register failed: %d\n",
+			err);
+		return err;
+	}
+
+	err = prestera_storm_control_init(sw);
+	if (err) {
+		prestera_devlink_traps_fini(sw);
+		devlink_unregister(dl);
+		dev_err(sw->dev->dev,
+			"prestera_storm_control_init failed: %d\n",
+			err);
+		return err;
+	}
+
+	return 0;
 }
 
-void prestera_devlink_unregister(struct mvsw_pr_switch *sw)
+void prestera_devlink_unregister(struct prestera_switch *sw)
 {
 	struct devlink *dl = priv_to_devlink(sw);
 
+	prestera_devlink_traps_fini(sw);
+	prestera_storm_control_fini(sw);
 	devlink_unregister(dl);
 }
 
-int prestera_devlink_port_register(struct mvsw_pr_port *port)
+int prestera_devlink_port_register(struct prestera_port *port)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct devlink *dl = priv_to_devlink(sw);
+	struct prestera_switch *sw = port->sw;
 	struct devlink_port_attrs attrs = {};
+	struct prestera_storm_control *sc;
+	struct devlink *dl;
 	int err;
+	int i;
+
+	sc = sw->storm_control;
+
+	dl = priv_to_devlink(sw);
 
 	attrs.flavour = DEVLINK_PORT_FLAVOUR_PHYSICAL;
 	attrs.phys.port_number = port->fp_id;
@@ -86,27 +602,328 @@ int prestera_devlink_port_register(struct mvsw_pr_port *port)
 		return err;
 	}
 
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		struct devlink_param *port_params =
+			&sc->port_params[i][port->fp_id - 1];
+
+		err = devlink_port_params_register(&port->dl_port,
+						   port_params,
+						   1);
+		if (err) {
+			devlink_port_unregister(&port->dl_port);
+			dev_err(sw->dev->dev,
+				"devlink_port_params_register failed\n");
+			return err;
+		}
+	}
+
+	devlink_port_params_publish(&port->dl_port);
+
 	return 0;
 }
 
-void prestera_devlink_port_unregister(struct mvsw_pr_port *port)
+void prestera_devlink_port_unregister(struct prestera_port *port)
 {
+	struct prestera_switch *sw = port->sw;
+	struct prestera_storm_control *sc;
+	int i;
+
+	sc = sw->storm_control;
+
+	devlink_port_params_unpublish(&port->dl_port);
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		struct devlink_param *port_params = sc->port_params[i];
+
+		devlink_port_params_unregister(&port->dl_port,
+					       &port_params[port->fp_id - 1],
+					       1);
+	}
+
 	devlink_port_unregister(&port->dl_port);
 }
 
-void prestera_devlink_port_set(struct mvsw_pr_port *port)
+void prestera_devlink_port_set(struct prestera_port *port)
 {
 	devlink_port_type_eth_set(&port->dl_port, port->net_dev);
 }
 
-void prestera_devlink_port_clear(struct mvsw_pr_port *port)
+void prestera_devlink_port_clear(struct prestera_port *port)
 {
 	devlink_port_type_clear(&port->dl_port);
 }
 
 struct devlink_port *prestera_devlink_get_port(struct net_device *dev)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	return &port->dl_port;
 }
+
+static int prestera_storm_control_init(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc;
+	int i, j;
+	int err;
+
+	sc = kzalloc(sizeof(*sc), GFP_KERNEL);
+	if (!sc)
+		return -ENOMEM;
+
+	sc->cfg = kcalloc(sw->port_count,
+			  sizeof(*sc->cfg),
+			  GFP_KERNEL);
+	if (!sc->cfg) {
+		err = -ENOMEM;
+		goto err_values_alloca;
+	}
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		sc->port_params[i] =
+			kcalloc(sw->port_count, sizeof(struct devlink_param),
+				GFP_KERNEL);
+		if (!sc->port_params[i]) {
+			err = -ENOMEM;
+			goto err_params_alloca;
+		}
+	}
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i) {
+		const char *param_names[PRESTERA_DEVLINK_PORT_PARAM_NUM] = {
+			[PORT_PARAM_ID_BC_RATE] =
+				"bc_kbyte_per_sec_rate",
+			[PORT_PARAM_ID_UC_UNK_RATE] =
+				"unk_uc_kbyte_per_sec_rate",
+			[PORT_PARAM_ID_MC_RATE] =
+				"unreg_mc_kbyte_per_sec_rate",
+		};
+		struct devlink_param *port_params = sc->port_params[i];
+
+		for (j = 0; j < sw->port_count; ++j) {
+			port_params[j].id =
+				PRESTERA_DEVLINK_PORT_PARAM_PREP_ID(i, j + 1);
+			port_params[j].name = param_names[i];
+			port_params[j].type = DEVLINK_PARAM_TYPE_U32;
+			port_params[j].supported_cmodes =
+				BIT(DEVLINK_PARAM_CMODE_RUNTIME);
+			port_params[j].get = prestera_storm_control_rate_get;
+			port_params[j].set = prestera_storm_control_rate_set;
+		}
+	}
+
+	sc->sw = sw;
+	sw->storm_control = sc;
+
+	return 0;
+
+err_params_alloca:
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i)
+		kfree(sc->port_params[i]);
+	kfree(sc->cfg);
+err_values_alloca:
+	kfree(sc);
+	return err;
+}
+
+static void prestera_storm_control_fini(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc = sw->storm_control;
+	int i;
+
+	for (i = 0; i < PRESTERA_DEVLINK_PORT_PARAM_NUM; ++i)
+		kfree(sc->port_params[i]);
+
+	kfree(sc->cfg);
+	kfree(sc);
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+static int prestera_devlink_traps_register(struct prestera_switch *sw)
+{
+	const u32 groups_count = ARRAY_SIZE(prestera_trap_groups_arr);
+	const u32 traps_count = ARRAY_SIZE(prestera_trap_items_arr);
+	struct devlink *devlink = priv_to_devlink(sw);
+	struct prestera_trap *prestera_trap;
+	struct prestera_trap_data *trap_data;
+	int err, i;
+
+	trap_data = kzalloc(sizeof(*trap_data), GFP_KERNEL);
+	if (!trap_data)
+		return -ENOMEM;
+
+	trap_data->trap_items_arr = kcalloc(ARRAY_SIZE(prestera_trap_items_arr),
+					    sizeof(struct prestera_trap_item),
+					    GFP_KERNEL);
+	if (!trap_data->trap_items_arr) {
+		err = -ENOMEM;
+		goto err_trap_items_alloc;
+	}
+
+	trap_data->sw = sw;
+	trap_data->traps_count = ARRAY_SIZE(prestera_trap_items_arr);
+	sw->trap_data = trap_data;
+
+	err = devlink_trap_groups_register(devlink, prestera_trap_groups_arr,
+					   groups_count);
+	if (err)
+		goto err_groups_register;
+
+	for (i = 0; i < traps_count; i++) {
+		prestera_trap = &prestera_trap_items_arr[i];
+		err = devlink_traps_register(devlink, &prestera_trap->trap, 1,
+					     sw);
+		if (err)
+			goto err_trap_register;
+	}
+
+	return 0;
+
+err_trap_register:
+	for (i--; i >= 0; i--) {
+		prestera_trap = &prestera_trap_items_arr[i];
+		devlink_traps_unregister(devlink, &prestera_trap->trap, 1);
+	}
+err_groups_register:
+	kfree(trap_data->trap_items_arr);
+err_trap_items_alloc:
+	kfree(trap_data);
+	return err;
+}
+
+static struct prestera_trap_item *
+prestera_get_trap_item_by_cpu_code(struct prestera_switch *sw, u8 cpu_code)
+{
+	struct prestera_trap_data *trap_data = sw->trap_data;
+	struct prestera_trap *prestera_trap;
+	int i;
+
+	for (i = 0; i < trap_data->traps_count; i++) {
+		prestera_trap = &prestera_trap_items_arr[i];
+		if (cpu_code == prestera_trap->cpu_code)
+			return &trap_data->trap_items_arr[i];
+	}
+
+	return NULL;
+}
+
+void prestera_devlink_trap_report(struct prestera_port *port,
+				  struct sk_buff *skb, u8 cpu_code)
+{
+	struct prestera_trap_item *trap_item;
+	struct devlink *devlink;
+
+	devlink = port->dl_port.devlink;
+
+	trap_item = prestera_get_trap_item_by_cpu_code(port->sw, cpu_code);
+	if (unlikely(!trap_item))
+		return;
+
+	devlink_trap_report(devlink, skb, trap_item->trap_ctx,
+			    &port->dl_port, NULL);
+}
+
+static struct prestera_trap_item *
+prestera_devlink_trap_item_lookup(struct prestera_switch *sw, u16 trap_id)
+{
+	struct prestera_trap_data *trap_data = sw->trap_data;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(prestera_trap_items_arr); i++) {
+		if (prestera_trap_items_arr[i].trap.id == trap_id)
+			return &trap_data->trap_items_arr[i];
+	}
+
+	return NULL;
+}
+
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx)
+{
+	struct prestera_switch *sw = devlink_priv(devlink);
+	struct prestera_trap_item *trap_item;
+
+	trap_item = prestera_devlink_trap_item_lookup(sw, trap->id);
+	if (WARN_ON(!trap_item))
+		return -EINVAL;
+
+	trap_item->trap_ctx = trap_ctx;
+	trap_item->action = trap->init_action;
+
+	return 0;
+}
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack)
+{
+	/* Currently, driver does not support trap action altering */
+	return -ENOTSUPP;
+}
+
+static int prestera_drop_counter_get(struct devlink *devlink,
+				     const struct devlink_trap *trap,
+				     u64 *p_drops)
+{
+	struct prestera_switch *sw = devlink_priv(devlink);
+	enum prestera_hw_cpu_code_cnt_t cpu_code_type =
+		PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP;
+	struct prestera_trap *prestera_trap =
+		container_of(trap, struct prestera_trap, trap);
+	int ret;
+
+	ret = prestera_hw_cpu_code_counters_get(sw, prestera_trap->cpu_code,
+						cpu_code_type, p_drops);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static void prestera_devlink_traps_fini(struct prestera_switch *sw)
+{
+	struct prestera_trap_data *trap_data = sw->trap_data;
+	struct devlink *dl = priv_to_devlink(sw);
+	const struct devlink_trap *trap;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(prestera_trap_items_arr); ++i) {
+		trap = &prestera_trap_items_arr[i].trap;
+		devlink_traps_unregister(dl, trap, 1);
+	}
+
+	devlink_trap_groups_unregister(dl, prestera_trap_groups_arr,
+				       ARRAY_SIZE(prestera_trap_groups_arr));
+
+	kfree(trap_data->trap_items_arr);
+	kfree(trap_data);
+}
+#else
+static int prestera_devlink_traps_register(struct prestera_switch *sw)
+{
+	return 0;
+}
+
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx)
+{
+	return 0;
+}
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack)
+{
+	return 0;
+}
+
+static void prestera_devlink_traps_fini(struct prestera_switch *sw)
+{
+}
+
+void prestera_devlink_trap_report(struct prestera_port *port,
+				  struct sk_buff *skb, u8 cpu_code)
+{
+}
+#endif
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_devlink.h b/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
index 4d51c42..27bc1c8 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
@@ -1,23 +1,26 @@
 /* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
-/* Copyright (c) 2020 Marvell International Ltd. All rights reserved. */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _PRESTERA_DEVLINK_H_
 #define _PRESTERA_DEVLINK_H_
 
 #include "prestera.h"
 
-struct mvsw_pr_switch *prestera_devlink_alloc(void);
-void prestera_devlink_free(struct mvsw_pr_switch *sw);
+struct prestera_switch *prestera_devlink_alloc(void);
+void prestera_devlink_free(struct prestera_switch *sw);
 
-int prestera_devlink_register(struct mvsw_pr_switch *sw);
-void prestera_devlink_unregister(struct mvsw_pr_switch *sw);
+int prestera_devlink_register(struct prestera_switch *sw);
+void prestera_devlink_unregister(struct prestera_switch *sw);
 
-int prestera_devlink_port_register(struct mvsw_pr_port *port);
-void prestera_devlink_port_unregister(struct mvsw_pr_port *port);
+int prestera_devlink_port_register(struct prestera_port *port);
+void prestera_devlink_port_unregister(struct prestera_port *port);
 
-void prestera_devlink_port_set(struct mvsw_pr_port *port);
-void prestera_devlink_port_clear(struct mvsw_pr_port *port);
+void prestera_devlink_port_set(struct prestera_port *port);
+void prestera_devlink_port_clear(struct prestera_port *port);
 
 struct devlink_port *prestera_devlink_get_port(struct net_device *dev);
 
+void prestera_devlink_trap_report(struct prestera_port *port,
+				  struct sk_buff *skb, u8 cpu_code);
+
 #endif /* _PRESTERA_DEVLINK_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
index 29b3375..152512e 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
@@ -1,8 +1,6 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
 #ifndef _PRESTERA_DRV_VER_H_
 #define _PRESTERA_DRV_VER_H_
 
@@ -12,7 +10,7 @@
 #define PRESTERA_DRV_VER_MAJOR	2
 #define PRESTERA_DRV_VER_MINOR	0
 #define PRESTERA_DRV_VER_PATCH	0
-#define PRESTERA_DRV_VER_EXTRA
+#define PRESTERA_DRV_VER_EXTRA	-v3.0.0
 
 #define PRESTERA_DRV_VER \
 		__stringify(PRESTERA_DRV_VER_MAJOR)  "." \
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_dsa.c b/drivers/net/ethernet/marvell/prestera/prestera_dsa.c
index 3a1b819..0dd4027 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_dsa.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_dsa.c
@@ -1,8 +1,6 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/*
- * Copyright (c) 2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
 #include "prestera.h"
 #include "prestera_dsa.h"
 
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_dsa.h b/drivers/net/ethernet/marvell/prestera/prestera_dsa.h
index a118a48..d2e9c0d 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_dsa.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_dsa.h
@@ -1,8 +1,6 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
 #ifndef _MVSW_PRESTERA_DSA_H_
 #define _MVSW_PRESTERA_DSA_H_
 
@@ -42,7 +40,7 @@ struct mvsw_pr_dsa_to_cpu {
 };
 
 struct mvsw_pr_dsa_from_cpu {
-	struct mvsw_pr_iface dst_iface;	/* vid/port */
+	struct prestera_iface dst_iface;	/* vid/port */
 	bool egr_filter_en;
 	bool egr_filter_registered;
 	u32 src_id;
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c
new file mode 100644
index 0000000..ad6a64a
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c
@@ -0,0 +1,920 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/ethtool.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+
+#include "prestera_ethtool.h"
+#include "prestera.h"
+#include "prestera_hw.h"
+
+static const char prestera_driver_kind[] = "prestera";
+
+#define PORT_STATS_CNT	(sizeof(struct prestera_port_stats) / sizeof(u64))
+#define PORT_STATS_IDX(name) \
+	(offsetof(struct prestera_port_stats, name) / sizeof(u64))
+#define PORT_STATS_FIELD(name)	\
+	[PORT_STATS_IDX(name)] = __stringify(name)
+
+struct prestera_link_mode {
+	enum ethtool_link_mode_bit_indices eth_mode;
+	u32 speed;
+	u64 pr_mask;
+	u8 duplex;
+	u8 port_type;
+};
+
+static const struct prestera_link_mode
+prestera_link_modes[MVSW_LINK_MODE_MAX] = {
+	[MVSW_LINK_MODE_10baseT_Half_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Half_BIT,
+		.speed = 10,
+		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Half_BIT,
+		.duplex = MVSW_PORT_DUPLEX_HALF,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_10baseT_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Full_BIT,
+		.speed = 10,
+		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_100baseT_Half_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Half_BIT,
+		.speed = 100,
+		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Half_BIT,
+		.duplex = MVSW_PORT_DUPLEX_HALF,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_100baseT_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Full_BIT,
+		.speed = 100,
+		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_1000baseT_Half_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Half_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Half_BIT,
+		.duplex = MVSW_PORT_DUPLEX_HALF,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_1000baseT_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Full_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_1000baseX_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_1000baseX_Full_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseX_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_1000baseKX_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_1000baseKX_Full_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseKX_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_2500baseX_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_2500baseX_Full_BIT,
+		.speed = 2500,
+		.pr_mask = 1 << MVSW_LINK_MODE_2500baseX_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+	},
+	[MVSW_LINK_MODE_10GbaseKR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_10000baseKR_Full_BIT,
+		.speed = 10000,
+		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseKR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_10GbaseSR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_10000baseSR_Full_BIT,
+		.speed = 10000,
+		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseSR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_10GbaseLR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_10000baseLR_Full_BIT,
+		.speed = 10000,
+		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseLR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_20GbaseKR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_20000baseKR2_Full_BIT,
+		.speed = 20000,
+		.pr_mask = 1 << MVSW_LINK_MODE_20GbaseKR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_25GbaseCR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_25000baseCR_Full_BIT,
+		.speed = 25000,
+		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseCR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	},
+	[MVSW_LINK_MODE_25GbaseKR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_25000baseKR_Full_BIT,
+		.speed = 25000,
+		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseKR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_25GbaseSR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_25000baseSR_Full_BIT,
+		.speed = 25000,
+		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseSR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_40GbaseKR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_40000baseKR4_Full_BIT,
+		.speed = 40000,
+		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseKR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_40GbaseCR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_40000baseCR4_Full_BIT,
+		.speed = 40000,
+		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseCR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	},
+	[MVSW_LINK_MODE_40GbaseSR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_40000baseSR4_Full_BIT,
+		.speed = 40000,
+		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseSR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_50GbaseCR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_50000baseCR2_Full_BIT,
+		.speed = 50000,
+		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseCR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	},
+	[MVSW_LINK_MODE_50GbaseKR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_50000baseKR2_Full_BIT,
+		.speed = 50000,
+		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseKR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_50GbaseSR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_50000baseSR2_Full_BIT,
+		.speed = 50000,
+		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseSR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_100GbaseKR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_100000baseKR4_Full_BIT,
+		.speed = 100000,
+		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseKR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_100GbaseSR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_100000baseSR4_Full_BIT,
+		.speed = 100000,
+		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseSR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_100GbaseCR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_100000baseCR4_Full_BIT,
+		.speed = 100000,
+		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseCR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	}
+};
+
+struct prestera_fec {
+	u32 eth_fec;
+	enum ethtool_link_mode_bit_indices eth_mode;
+	u8 pr_fec;
+};
+
+static const struct prestera_fec prestera_fec_caps[MVSW_PORT_FEC_MAX] = {
+	[MVSW_PORT_FEC_OFF_BIT] = {
+		.eth_fec = ETHTOOL_FEC_OFF,
+		.eth_mode = ETHTOOL_LINK_MODE_FEC_NONE_BIT,
+		.pr_fec = 1 << MVSW_PORT_FEC_OFF_BIT,
+	},
+	[MVSW_PORT_FEC_BASER_BIT] = {
+		.eth_fec = ETHTOOL_FEC_BASER,
+		.eth_mode = ETHTOOL_LINK_MODE_FEC_BASER_BIT,
+		.pr_fec = 1 << MVSW_PORT_FEC_BASER_BIT,
+	},
+	[MVSW_PORT_FEC_RS_BIT] = {
+		.eth_fec = ETHTOOL_FEC_RS,
+		.eth_mode = ETHTOOL_LINK_MODE_FEC_RS_BIT,
+		.pr_fec = 1 << MVSW_PORT_FEC_RS_BIT,
+	}
+};
+
+struct prestera_port_type {
+	enum ethtool_link_mode_bit_indices eth_mode;
+	u8 eth_type;
+};
+
+static const struct prestera_port_type
+prestera_port_types[MVSW_PORT_TYPE_MAX] = {
+	[MVSW_PORT_TYPE_NONE] = {
+		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
+		.eth_type = PORT_NONE,
+	},
+	[MVSW_PORT_TYPE_TP] = {
+		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
+		.eth_type = PORT_TP,
+	},
+	[MVSW_PORT_TYPE_AUI] = {
+		.eth_mode = ETHTOOL_LINK_MODE_AUI_BIT,
+		.eth_type = PORT_AUI,
+	},
+	[MVSW_PORT_TYPE_MII] = {
+		.eth_mode = ETHTOOL_LINK_MODE_MII_BIT,
+		.eth_type = PORT_MII,
+	},
+	[MVSW_PORT_TYPE_FIBRE] = {
+		.eth_mode = ETHTOOL_LINK_MODE_FIBRE_BIT,
+		.eth_type = PORT_FIBRE,
+	},
+	[MVSW_PORT_TYPE_BNC] = {
+		.eth_mode = ETHTOOL_LINK_MODE_BNC_BIT,
+		.eth_type = PORT_BNC,
+	},
+	[MVSW_PORT_TYPE_DA] = {
+		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
+		.eth_type = PORT_TP,
+	},
+	[MVSW_PORT_TYPE_OTHER] = {
+		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
+		.eth_type = PORT_OTHER,
+	}
+};
+
+static const char prestera_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
+	PORT_STATS_FIELD(good_octets_received),
+	PORT_STATS_FIELD(bad_octets_received),
+	PORT_STATS_FIELD(mac_trans_error),
+	PORT_STATS_FIELD(broadcast_frames_received),
+	PORT_STATS_FIELD(multicast_frames_received),
+	PORT_STATS_FIELD(frames_64_octets),
+	PORT_STATS_FIELD(frames_65_to_127_octets),
+	PORT_STATS_FIELD(frames_128_to_255_octets),
+	PORT_STATS_FIELD(frames_256_to_511_octets),
+	PORT_STATS_FIELD(frames_512_to_1023_octets),
+	PORT_STATS_FIELD(frames_1024_to_max_octets),
+	PORT_STATS_FIELD(excessive_collision),
+	PORT_STATS_FIELD(multicast_frames_sent),
+	PORT_STATS_FIELD(broadcast_frames_sent),
+	PORT_STATS_FIELD(fc_sent),
+	PORT_STATS_FIELD(fc_received),
+	PORT_STATS_FIELD(buffer_overrun),
+	PORT_STATS_FIELD(undersize),
+	PORT_STATS_FIELD(fragments),
+	PORT_STATS_FIELD(oversize),
+	PORT_STATS_FIELD(jabber),
+	PORT_STATS_FIELD(rx_error_frame_received),
+	PORT_STATS_FIELD(bad_crc),
+	PORT_STATS_FIELD(collisions),
+	PORT_STATS_FIELD(late_collision),
+	PORT_STATS_FIELD(unicast_frames_received),
+	PORT_STATS_FIELD(unicast_frames_sent),
+	PORT_STATS_FIELD(sent_multiple),
+	PORT_STATS_FIELD(sent_deferred),
+	PORT_STATS_FIELD(good_octets_sent),
+};
+
+static void prestera_modes_to_eth(unsigned long *eth_modes, u64 link_modes,
+				  u8 fec, u8 type)
+{
+	u32 mode;
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask & link_modes) == 0)
+			continue;
+		if (type != MVSW_PORT_TYPE_NONE &&
+		    prestera_link_modes[mode].port_type != type)
+			continue;
+		__set_bit(prestera_link_modes[mode].eth_mode, eth_modes);
+	}
+
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if ((prestera_fec_caps[mode].pr_fec & fec) == 0)
+			continue;
+		__set_bit(prestera_fec_caps[mode].eth_mode, eth_modes);
+	}
+}
+
+static void prestera_port_remote_cap_cache(struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+
+	if (!params->oper_state)
+		return;
+
+	if (params->lmode_bmap &&
+	    (params->remote_fc.pause || params->remote_fc.asym_pause))
+		return;
+
+	if (mvsw_pr_hw_port_remote_cap_get(port, &params->lmode_bmap,
+					   &params->remote_fc.pause,
+					   &params->remote_fc.asym_pause))
+		netdev_warn(port->net_dev,
+			    "Remote link caps get failed %d",
+			    port->caps.transceiver);
+}
+
+static void prestera_port_mdix_cache(struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+
+	if (!params->oper_state)
+		return;
+
+	if (params->mdix.status == ETH_TP_MDI_INVALID ||
+	    params->mdix.admin_mode == ETH_TP_MDI_INVALID) {
+		if (mvsw_pr_hw_port_mdix_get(port, &params->mdix.status,
+					     &params->mdix.admin_mode)) {
+			netdev_warn(port->net_dev, "MDIX params get failed");
+			params->mdix.status = ETH_TP_MDI_INVALID;
+			params->mdix.admin_mode = ETH_TP_MDI_INVALID;
+		}
+	}
+}
+
+static void prestera_port_link_mode_cache(struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+	u32 speed;
+	u8 duplex;
+	int err;
+
+	if (!params->oper_state)
+		return;
+
+	if (params->speed == SPEED_UNKNOWN ||
+	    params->duplex == DUPLEX_UNKNOWN) {
+
+		err = mvsw_pr_hw_port_mac_mode_get(port, NULL, &speed,
+						   &duplex, NULL);
+		if (err) {
+			params->speed = SPEED_UNKNOWN;
+			params->duplex = DUPLEX_UNKNOWN;
+		} else {
+			params->speed = speed;
+			params->duplex = duplex == MVSW_PORT_DUPLEX_FULL ?
+					  DUPLEX_FULL : DUPLEX_HALF;
+		}
+	}
+}
+
+static void prestera_port_mdix_get(struct ethtool_link_ksettings *ecmd,
+				   struct prestera_port *port)
+{
+	prestera_port_mdix_cache(port);
+
+	ecmd->base.eth_tp_mdix = port->link_params.mdix.status;
+	ecmd->base.eth_tp_mdix_ctrl = port->link_params.mdix.admin_mode;
+}
+
+static void prestera_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
+					 struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+	bool asym_pause;
+	bool pause;
+	u64 bitmap;
+
+	prestera_port_remote_cap_cache(port);
+
+	bitmap = params->lmode_bmap;
+
+	prestera_modes_to_eth(ecmd->link_modes.lp_advertising,
+			      bitmap, 0, MVSW_PORT_TYPE_NONE);
+
+	if (!bitmap_empty(ecmd->link_modes.lp_advertising,
+			  __ETHTOOL_LINK_MODE_MASK_NBITS)) {
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Autoneg);
+	}
+
+	pause = params->remote_fc.pause;
+	asym_pause = params->remote_fc.asym_pause;
+
+	if (pause)
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Pause);
+	if (asym_pause)
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Asym_Pause);
+}
+
+/* TODO:  Rename, that it only for integral */
+/* TODO: use speed/duplex direct in Agent ? */
+/* TODO: remove type, as it is always integral phy */
+int prestera_port_link_mode_set(struct prestera_port *port,
+				u32 speed, u8 duplex, u8 type)
+{
+	u32 new_mode = MVSW_LINK_MODE_MAX;
+	u32 mode;
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if (speed != SPEED_UNKNOWN &&
+		    speed != prestera_link_modes[mode].speed)
+			continue;
+		if (duplex != DUPLEX_UNKNOWN &&
+		    duplex != prestera_link_modes[mode].duplex)
+			continue;
+		if (!(prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes))
+			continue;
+		if (type != prestera_link_modes[mode].port_type)
+			continue;
+
+		new_mode = mode;
+		/* Find highest compatible mode */
+	}
+
+	if (new_mode == MVSW_LINK_MODE_MAX) {
+		netdev_err(port->net_dev, "Unsupported speed/duplex requested");
+		return -EINVAL;
+	}
+
+	if (mvsw_pr_hw_port_phy_mode_set(port, port->cfg_phy.admin,
+					 false, new_mode, 0))
+		return -EINVAL;
+
+	/* TODO: move all this parameters to cfg_phy */
+	port->autoneg = false;
+	port->cfg_phy.mode = new_mode;
+	port->adver_link_modes = 0;
+	port->adver_fec = BIT(MVSW_PORT_FEC_OFF_BIT);
+
+	return 0;
+}
+
+static void prestera_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
+				      struct prestera_port *port)
+{
+	ecmd->base.autoneg = port->autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
+
+	prestera_modes_to_eth(ecmd->link_modes.supported,
+			      port->caps.supp_link_modes,
+			      port->caps.supp_fec,
+			      port->caps.type);
+
+	if (port->caps.type != MVSW_PORT_TYPE_TP)
+		return;
+
+	ethtool_link_ksettings_add_link_mode(ecmd, supported, Autoneg);
+
+	if (!netif_running(port->net_dev))
+		return;
+
+	if (port->autoneg) {
+		prestera_modes_to_eth(ecmd->link_modes.advertising,
+				      port->adver_link_modes,
+				      port->adver_fec,
+				      port->caps.type);
+		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
+						     Autoneg);
+	} else if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
+		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
+						     Autoneg);
+}
+
+static int prestera_modes_from_eth(struct prestera_port *port,
+				   const unsigned long *advertising,
+				   const unsigned long *supported,
+				   u64 *link_modes, u8 *fec)
+{
+	struct ethtool_link_ksettings curr = {};
+	u32 mode;
+
+	ethtool_link_ksettings_zero_link_mode(&curr, supported);
+	ethtool_link_ksettings_zero_link_mode(&curr, advertising);
+
+	prestera_port_autoneg_get(&curr, port);
+
+	if (linkmode_equal(advertising, curr.link_modes.advertising)) {
+		*link_modes = port->adver_link_modes;
+		*fec = port->adver_fec;
+		return 0;
+	}
+
+	if (!linkmode_subset(advertising, supported)) {
+		netdev_err(port->net_dev, "Unsupported link mode requested");
+		return -EINVAL;
+	}
+
+	*link_modes  = 0;
+	*fec = 0;
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if (!test_bit(prestera_link_modes[mode].eth_mode, advertising))
+			continue;
+		if (prestera_link_modes[mode].port_type != port->caps.type)
+			continue;
+		*link_modes |= prestera_link_modes[mode].pr_mask;
+	}
+
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if (!test_bit(prestera_fec_caps[mode].eth_mode, advertising))
+			continue;
+		*fec |= prestera_fec_caps[mode].pr_fec;
+	}
+
+	if (*link_modes == 0 && *fec == 0) {
+		netdev_err(port->net_dev, "No link modes requested");
+		return -EINVAL;
+	}
+	if (*link_modes == 0)
+		*link_modes = port->adver_link_modes;
+	if (*fec == 0)
+		*fec = port->adver_fec ? port->adver_fec :
+					 BIT(MVSW_PORT_FEC_OFF_BIT);
+
+	return 0;
+}
+
+static void prestera_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
+					 struct prestera_port *port)
+{
+	u32 mode;
+	u8 ptype;
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes) == 0)
+			continue;
+		ptype = prestera_link_modes[mode].port_type;
+		__set_bit(prestera_port_types[ptype].eth_mode,
+			  ecmd->link_modes.supported);
+	}
+}
+
+static void prestera_port_link_mode_get(struct ethtool_link_ksettings *ecmd,
+					struct prestera_port *port)
+{
+	prestera_port_link_mode_cache(port);
+
+	ecmd->base.speed = port->link_params.speed;
+	ecmd->base.duplex = port->link_params.duplex;
+}
+
+static void prestera_port_get_drvinfo(struct net_device *dev,
+				      struct ethtool_drvinfo *drvinfo)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_switch *sw = port->sw;
+
+	strlcpy(drvinfo->driver, prestera_driver_kind, sizeof(drvinfo->driver));
+	strlcpy(drvinfo->bus_info, dev_name(sw->dev->dev),
+		sizeof(drvinfo->bus_info));
+	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),
+		 "%d.%d.%d",
+		 sw->dev->fw_rev.maj,
+		 sw->dev->fw_rev.min,
+		 sw->dev->fw_rev.sub);
+}
+
+static void prestera_port_type_get(struct ethtool_link_ksettings *ecmd,
+				   struct prestera_port *port)
+{
+	if (port->caps.type < MVSW_PORT_TYPE_MAX)
+		ecmd->base.port = prestera_port_types[port->caps.type].eth_type;
+	else
+		ecmd->base.port = PORT_OTHER;
+}
+
+static int prestera_port_type_set(const struct ethtool_link_ksettings *ecmd,
+				  struct prestera_port *port)
+{
+	int err;
+	u32 type, mode;
+	u32 new_mode = MVSW_LINK_MODE_MAX;
+
+	for (type = 0; type < MVSW_PORT_TYPE_MAX; type++) {
+		if (prestera_port_types[type].eth_type == ecmd->base.port &&
+		    test_bit(prestera_port_types[type].eth_mode,
+			     ecmd->link_modes.supported)) {
+			break;
+		}
+	}
+
+	if (type == port->caps.type)
+		return 0;
+
+	if (type != port->caps.type && ecmd->base.autoneg == AUTONEG_ENABLE)
+		return -EINVAL;
+
+	if (type == MVSW_PORT_TYPE_MAX) {
+		pr_err("Unsupported port type requested\n");
+		return -EINVAL;
+	}
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes) &&
+		    type == prestera_link_modes[mode].port_type) {
+			new_mode = mode;
+		}
+	}
+
+	if (new_mode < MVSW_LINK_MODE_MAX)
+	{
+		/* err = mvsw_pr_hw_port_link_mode_set(port, new_mode); */
+		pr_err("Unexpected call of type set on integral phy");
+		err = -EINVAL;
+	}
+
+	if (!err) {
+		port->caps.type = type;
+		port->autoneg = false;
+	}
+
+	return err;
+}
+
+static int prestera_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
+				  struct prestera_port *port)
+{
+	if (ecmd->base.eth_tp_mdix_ctrl != ETH_TP_MDI_INVALID &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
+	    port->caps.type == MVSW_PORT_TYPE_TP)
+		return mvsw_pr_hw_port_mdix_set(port,
+						ecmd->base.eth_tp_mdix_ctrl);
+	return 0;
+}
+
+static int prestera_port_get_link_ksettings(struct net_device *dev,
+					    struct ethtool_link_ksettings *ecmd)
+{
+	struct prestera_port *port = netdev_priv(dev);
+
+	/* Dirty hook: Deinit ecmd.
+	 * It caused by suspicious phylink_ethtool_ksettings_get()
+	 * implementation, which can left "kset" uninitialized, when there is no
+	 * SFP plugged
+	 */
+	ethtool_link_ksettings_zero_link_mode(ecmd, supported);
+	ethtool_link_ksettings_zero_link_mode(ecmd, advertising);
+	ethtool_link_ksettings_zero_link_mode(ecmd, lp_advertising);
+	ecmd->base.speed = SPEED_UNKNOWN;
+	ecmd->base.duplex = DUPLEX_UNKNOWN;
+#ifdef CONFIG_PHYLINK
+	if (port->phy_link)
+		return phylink_ethtool_ksettings_get(port->phy_link, ecmd);
+#endif /* CONFIG_PHYLINK */
+
+	prestera_port_supp_types_get(ecmd, port);
+
+	prestera_port_autoneg_get(ecmd, port);
+
+	if (port->autoneg && netif_carrier_ok(dev) &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
+		prestera_port_remote_cap_get(ecmd, port);
+
+	if (netif_carrier_ok(dev))
+		prestera_port_link_mode_get(ecmd, port);
+
+	prestera_port_type_get(ecmd, port);
+
+	if (port->caps.type == MVSW_PORT_TYPE_TP &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
+		prestera_port_mdix_get(ecmd, port);
+
+	return 0;
+}
+
+static int prestera_port_set_link_ksettings(struct net_device *dev,
+					    const struct ethtool_link_ksettings
+					    *ecmd)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	u64 adver_modes = 0;
+	u8 adver_fec = 0;
+	int err;
+
+#ifdef CONFIG_PHYLINK
+	if (port->phy_link)
+		return phylink_ethtool_ksettings_set(port->phy_link, ecmd);
+#endif /* CONFIG_PHYLINK */
+
+	err = prestera_port_type_set(ecmd, port);
+	if (err)
+		return err;
+
+	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER) {
+		err = prestera_port_mdix_set(ecmd, port);
+		if (err)
+			return err;
+	}
+
+	if (ecmd->base.autoneg == AUTONEG_ENABLE) {
+		if (prestera_modes_from_eth(port, ecmd->link_modes.advertising,
+					    ecmd->link_modes.supported,
+					    &adver_modes, &adver_fec))
+			return -EINVAL;
+		if (!port->autoneg && !adver_modes)
+			adver_modes = port->caps.supp_link_modes;
+	} else {
+		adver_modes = port->adver_link_modes;
+		adver_fec = port->adver_fec;
+	}
+
+	if (ecmd->base.autoneg == AUTONEG_DISABLE)
+		err = prestera_port_link_mode_set(port, ecmd->base.speed,
+						  ecmd->base.duplex ==
+						  DUPLEX_UNKNOWN ?
+						  DUPLEX_UNKNOWN :
+						  (ecmd->base.duplex ==
+						   DUPLEX_HALF ?
+						   MVSW_PORT_DUPLEX_HALF :
+						   MVSW_PORT_DUPLEX_FULL),
+						  port->caps.type);
+	else
+		err = prestera_port_autoneg_set(port, adver_modes);
+
+	if (err)
+		return err;
+
+	return 0;
+}
+
+static int prestera_port_nway_reset(struct net_device *dev)
+{
+	struct prestera_port *port = netdev_priv(dev);
+
+	if (netif_running(dev) &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
+	    port->caps.type == MVSW_PORT_TYPE_TP)
+		return mvsw_pr_hw_port_autoneg_restart(port);
+
+	return -EINVAL;
+}
+
+static int prestera_port_get_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	u32 mode;
+	u8 active;
+	int err;
+
+	err = mvsw_pr_hw_port_mac_mode_get(port, NULL, NULL, NULL, &active);
+	if (err)
+		return err;
+
+	fecparam->fec = 0;
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if ((prestera_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
+			continue;
+		fecparam->fec |= prestera_fec_caps[mode].eth_fec;
+	}
+
+	if (active < MVSW_PORT_FEC_MAX)
+		fecparam->active_fec = prestera_fec_caps[active].eth_fec;
+	else
+		fecparam->active_fec = ETHTOOL_FEC_AUTO;
+
+	return 0;
+}
+
+static int prestera_port_set_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	u8 fec;
+	u32 mode;
+	struct prestera_port_mac_config cfg_mac;
+
+	if (port->autoneg) {
+		netdev_err(dev, "FEC set is not allowed while autoneg is on\n");
+		return -EINVAL;
+	}
+
+	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP) {
+		netdev_err(dev, "FEC set is not allowed on non-SFP ports\n");
+		return -EINVAL;
+	}
+
+	fec = MVSW_PORT_FEC_MAX;
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if ((prestera_fec_caps[mode].eth_fec & fecparam->fec) &&
+		    (prestera_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
+			fec = mode;
+			break;
+		}
+	}
+
+	prestera_port_cfg_mac_read(port, &cfg_mac);
+
+	if (fec == cfg_mac.fec)
+		return 0;
+
+	if (fec == MVSW_PORT_FEC_MAX) {
+		netdev_err(dev, "Unsupported FEC requested");
+		return -EINVAL;
+	}
+
+	cfg_mac.fec = fec;
+
+	return prestera_port_cfg_mac_write(port, &cfg_mac);
+}
+
+static int prestera_port_get_sset_count(struct net_device *dev, int sset)
+{
+	switch (sset) {
+	case ETH_SS_STATS:
+		return PORT_STATS_CNT;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static void prestera_port_get_ethtool_stats(struct net_device *dev,
+					    struct ethtool_stats *stats,
+					    u64 *data)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_port_stats *port_stats = &port->cached_hw_stats.stats;
+
+	memcpy((u8 *)data, port_stats, sizeof(*port_stats));
+}
+
+static void prestera_port_get_strings(struct net_device *dev,
+				      u32 stringset, u8 *data)
+{
+	if (stringset != ETH_SS_STATS)
+		return;
+
+	memcpy(data, *prestera_port_cnt_name, sizeof(prestera_port_cnt_name));
+}
+
+void prestera_ethtool_port_state_changed(struct prestera_port *port,
+					 struct prestera_port_event *evt)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+
+	params->oper_state = evt->data.oper_state;
+
+	if (params->oper_state) {
+		if (port->autoneg &&
+		    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER) {
+			params->lmode_bmap = evt->data.lmode_bmap;
+			params->remote_fc.pause = evt->data.pause;
+			params->remote_fc.asym_pause = evt->data.asym_pause;
+		}
+
+		/* TODO: must be different modes senses for MAC/PHY link */
+		params->speed = prestera_link_modes[evt->data.link_mode].speed;
+		params->duplex = prestera_link_modes[evt->data.link_mode].duplex;
+
+		if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
+		    port->caps.type == MVSW_PORT_TYPE_TP) {
+			params->mdix.status = evt->data.status;
+			params->mdix.admin_mode = evt->data.admin_mode;
+		}
+	} else {
+		params->remote_fc.pause = false;
+		params->remote_fc.asym_pause = false;
+		params->lmode_bmap = 0;
+		params->speed = SPEED_UNKNOWN;
+		params->duplex = DUPLEX_UNKNOWN;
+		params->mdix.status = ETH_TP_MDI_INVALID;
+		params->mdix.admin_mode = ETH_TP_MDI_INVALID;
+	}
+}
+
+const struct ethtool_ops prestera_ethtool_ops = {
+	.get_drvinfo = prestera_port_get_drvinfo,
+	.get_link_ksettings = prestera_port_get_link_ksettings,
+	.set_link_ksettings = prestera_port_set_link_ksettings,
+	.get_fecparam = prestera_port_get_fecparam,
+	.set_fecparam = prestera_port_set_fecparam,
+	.get_sset_count = prestera_port_get_sset_count,
+	.get_strings = prestera_port_get_strings,
+	.get_ethtool_stats = prestera_port_get_ethtool_stats,
+	.get_link = ethtool_op_get_link,
+	.nway_reset = prestera_port_nway_reset
+};
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h
new file mode 100644
index 0000000..18c6022
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h
@@ -0,0 +1,19 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef __PRESTERA_ETHTOOL_H_
+#define __PRESTERA_ETHTOOL_H_
+
+#include <linux/ethtool.h>
+
+#include "prestera.h"
+
+extern const struct ethtool_ops prestera_ethtool_ops;
+
+int prestera_port_link_mode_set(struct prestera_port *port,
+				u32 speed, u8 duplex, u8 type);
+
+void prestera_ethtool_port_state_changed(struct prestera_port *port,
+					 struct prestera_port_event *evt);
+
+#endif /* _PRESTERA_ETHTOOL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flow.c b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
new file mode 100644
index 0000000..a1d9d08
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
@@ -0,0 +1,316 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/netdevice.h>
+
+#include "prestera.h"
+#include "prestera_acl.h"
+
+static LIST_HEAD(prestera_block_cb_list);
+
+static int prestera_flow_block_mall_cb(struct prestera_flow_block *block,
+				       struct tc_cls_matchall_offload *f)
+{
+	if (f->common.chain_index != 0) {
+		NL_SET_ERR_MSG(f->common.extack, "Only chain 0 is supported");
+		return -EOPNOTSUPP;
+	}
+
+	switch (f->command) {
+	case TC_CLSMATCHALL_REPLACE:
+		return prestera_mall_replace(block, f);
+	case TC_CLSMATCHALL_DESTROY:
+		prestera_mall_destroy(block);
+		return 0;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static int prestera_flow_block_flower_cb(struct prestera_flow_block *block,
+					 struct flow_cls_offload *f)
+{
+	struct prestera_switch *sw = prestera_acl_block_sw(block);
+
+	switch (f->command) {
+	case FLOW_CLS_REPLACE:
+		return prestera_flower_replace(sw, block, f);
+	case FLOW_CLS_DESTROY:
+		prestera_flower_destroy(sw, block, f);
+		return 0;
+	case FLOW_CLS_STATS:
+		return prestera_flower_stats(sw, block, f);
+	case FLOW_CLS_TMPLT_CREATE:
+		return prestera_flower_tmplt_create(sw, block, f);
+	case FLOW_CLS_TMPLT_DESTROY:
+		prestera_flower_tmplt_destroy(sw, block, f);
+		return 0;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static int prestera_flow_block_cb(enum tc_setup_type type,
+				  void *type_data, void *cb_priv)
+{
+	struct prestera_flow_block *block = cb_priv;
+
+	if (prestera_acl_block_disabled(block))
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case TC_SETUP_CLSFLOWER:
+		return prestera_flow_block_flower_cb(block, type_data);
+	case TC_SETUP_CLSMATCHALL:
+		return prestera_flow_block_mall_cb(block, type_data);
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static void prestera_flow_block_destroy(void *cb_priv)
+{
+	struct prestera_flow_block *block = cb_priv;
+
+	prestera_flower_template_cleanup(block);
+
+	WARN_ON(!list_empty(&block->template_list));
+	WARN_ON(!list_empty(&block->binding_list));
+
+	kfree(block);
+}
+
+static void prestera_flow_block_release(void *cb_priv)
+{
+	struct prestera_flow_block *block = cb_priv;
+
+	prestera_flow_block_destroy(block);
+}
+
+static inline bool
+prestera_flow_block_is_bound(const struct prestera_flow_block *block)
+{
+	return block->ruleset_zero;
+}
+
+static struct prestera_flow_block_binding *
+prestera_flow_block_lookup(struct prestera_flow_block *block,
+			   struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+
+	list_for_each_entry(binding, &block->binding_list, list)
+		if (binding->port == port)
+			return binding;
+
+	return NULL;
+}
+
+static int prestera_flow_block_bind(struct prestera_flow_block *block,
+				    struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+	int err;
+
+	binding = kzalloc(sizeof(*binding), GFP_KERNEL);
+	if (!binding)
+		return -ENOMEM;
+
+	binding->span_id = PRESTERA_SPAN_INVALID_ID;
+	binding->port = port;
+
+	if (prestera_flow_block_is_bound(block)) {
+		err = prestera_acl_ruleset_bind(block->ruleset_zero, port);
+		if (err)
+			goto err_ruleset_bind;
+	}
+
+	list_add(&binding->list, &block->binding_list);
+	return 0;
+
+err_ruleset_bind:
+	kfree(binding);
+	return err;
+}
+
+static int prestera_flow_block_unbind(struct prestera_flow_block *block,
+				      struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+
+	binding = prestera_flow_block_lookup(block, port);
+	if (!binding)
+		return -ENOENT;
+
+	list_del(&binding->list);
+
+	if (prestera_flow_block_is_bound(block))
+		prestera_acl_ruleset_unbind(block->ruleset_zero, port);
+
+	kfree(binding);
+	return 0;
+}
+
+static struct prestera_flow_block *
+prestera_flow_block_create(struct prestera_switch *sw, struct net *net)
+{
+	struct prestera_flow_block *block;
+
+	block = kzalloc(sizeof(*block), GFP_KERNEL);
+	if (!block)
+		return NULL;
+
+	INIT_LIST_HEAD(&block->binding_list);
+	INIT_LIST_HEAD(&block->template_list);
+	block->net = net;
+	block->sw = sw;
+	block->mall_prio = UINT_MAX;
+	block->flower_min_prio = UINT_MAX;
+
+	return block;
+}
+
+static struct prestera_flow_block *
+prestera_flow_block_get(struct prestera_switch *sw,
+			struct flow_block_offload *f,
+			bool *register_block)
+{
+	struct prestera_flow_block *block;
+	struct flow_block_cb *block_cb;
+
+	block_cb = flow_block_cb_lookup(f->block,
+					prestera_flow_block_cb, sw);
+	if (!block_cb) {
+		block = prestera_flow_block_create(sw, f->net);
+		if (!block)
+			return ERR_PTR(-ENOMEM);
+
+		block_cb = flow_block_cb_alloc(prestera_flow_block_cb,
+					       sw, block,
+					       prestera_flow_block_release);
+		if (IS_ERR(block_cb)) {
+			prestera_flow_block_destroy(block);
+			return ERR_CAST(block_cb);
+		}
+
+		block->block_cb = block_cb;
+		*register_block = true;
+	} else {
+		block = flow_block_cb_priv(block_cb);
+		*register_block = false;
+	}
+
+	flow_block_cb_incref(block_cb);
+
+	return block;
+}
+
+static void prestera_flow_block_put(struct prestera_flow_block *block)
+{
+	struct flow_block_cb *block_cb = block->block_cb;
+
+	if (flow_block_cb_decref(block_cb))
+		return;
+
+	flow_block_cb_free(block_cb);
+	prestera_flow_block_destroy(block);
+}
+
+static int prestera_setup_tc_block_bind(struct prestera_port *port,
+					struct flow_block_offload *f)
+{
+	struct prestera_switch *sw = port->sw;
+	struct prestera_flow_block *block;
+	struct flow_block_cb *block_cb;
+	bool disable_block = false;
+	bool register_block;
+	int err;
+
+	block = prestera_flow_block_get(sw, f, &register_block);
+	if (IS_ERR(block))
+		return PTR_ERR(block);
+
+	block_cb = block->block_cb;
+
+	if (!tc_can_offload(port->net_dev)) {
+		if (prestera_acl_block_rule_count(block)) {
+			err = -EOPNOTSUPP;
+			goto err_block_bind;
+		}
+
+		disable_block = true;
+	}
+
+	err = prestera_flow_block_bind(block, port);
+	if (err)
+		goto err_block_bind;
+
+	if (register_block) {
+		flow_block_cb_add(block_cb, f);
+		list_add_tail(&block_cb->driver_list, &prestera_block_cb_list);
+	}
+
+	if (disable_block)
+		prestera_acl_block_disable_inc(block);
+
+	port->flow_block = block;
+	return 0;
+
+err_block_bind:
+	prestera_flow_block_put(block);
+	return err;
+}
+
+static void prestera_setup_tc_block_unbind(struct prestera_port *port,
+					   struct flow_block_offload *f)
+{
+	struct prestera_switch *sw = port->sw;
+	struct prestera_flow_block *block;
+	struct flow_block_cb *block_cb;
+	int err;
+
+	block_cb = flow_block_cb_lookup(f->block, prestera_flow_block_cb, sw);
+	if (!block_cb)
+		return;
+
+	block = flow_block_cb_priv(block_cb);
+
+	if (!tc_can_offload(port->net_dev))
+		prestera_acl_block_disable_dec(block);
+
+	prestera_mall_destroy(block);
+
+	err = prestera_flow_block_unbind(block, port);
+	if (err)
+		goto err_flow_block_unbind;
+
+	if (!flow_block_cb_decref(block_cb)) {
+		flow_block_cb_remove(block_cb, f);
+		list_del(&block_cb->driver_list);
+	}
+
+err_flow_block_unbind:
+	port->flow_block = NULL;
+}
+
+int prestera_setup_tc_block(struct prestera_port *port,
+			    struct flow_block_offload *f)
+{
+	if (f->binder_type != FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS)
+		return -EOPNOTSUPP;
+
+	f->driver_block_list = &prestera_block_cb_list;
+
+	switch (f->command) {
+	case FLOW_BLOCK_BIND:
+		return prestera_setup_tc_block_bind(port, f);
+	case FLOW_BLOCK_UNBIND:
+		prestera_setup_tc_block_unbind(port, f);
+		return 0;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flower.c b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
index 4070def..ea0fd79 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_flower.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
@@ -1,56 +1,157 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-//
-// Copyright (c) 2020 Marvell International Ltd. All rights reserved.
-//
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include "prestera.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
+#include "prestera_log.h"
 #include "prestera_hw.h"
 
 #define PRESTERA_DEFAULT_TC_NUM	8
 
-static int mvsw_pr_flower_parse_actions(struct mvsw_pr_switch *sw,
-					struct prestera_acl_block *block,
+struct prestera_flower_template {
+	struct prestera_acl_ruleset *ruleset;
+	struct list_head list;
+	u32 chain_index;
+};
+
+void prestera_flower_template_cleanup(struct prestera_flow_block *block)
+{
+	struct prestera_flower_template *template;
+	struct list_head *pos, *n;
+
+	/* put the reference to all rulesets kept in tmpl create */
+	list_for_each_safe(pos, n, &block->template_list) {
+		template = list_entry(pos, typeof(*template), list);
+		prestera_acl_ruleset_put(template->ruleset);
+		list_del(&template->list);
+		kfree(template);
+	}
+}
+
+static int
+prestera_flower_parse_goto_action(struct prestera_flow_block *block,
+				  struct prestera_acl_rule *rule,
+				  u32 chain_index,
+				  const struct flow_action_entry *act)
+{
+	struct prestera_acl_ruleset *ruleset;
+
+	if (act->chain_index <= chain_index)
+		/* we can jump only forward */
+		return -EINVAL;
+
+	if (rule->re_arg.jump.valid)
+		return -EEXIST;
+
+	ruleset = prestera_acl_ruleset_get(block->sw->acl, block,
+					   act->chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	rule->re_arg.jump.valid = 1;
+	rule->re_arg.jump.i.index = prestera_acl_ruleset_index_get(ruleset);
+
+	rule->jump_ruleset = ruleset;
+
+	return 0;
+}
+
+static int mvsw_pr_flower_parse_actions(struct prestera_flow_block *block,
 					struct prestera_acl_rule *rule,
 					struct flow_action *flow_action,
+					u32 chain_index,
 					struct netlink_ext_ack *extack)
 {
 	const struct flow_action_entry *act;
-	struct prestera_acl_rule_action_entry *a_entry;
-	int i;
+	struct prestera_flow_block_binding *binding;
+	int err, i;
 
+	/* whole struct (rule->re_arg) must be initialized with 0 */
 	if (!flow_action_has_entries(flow_action))
 		return 0;
 
 	flow_action_for_each(i, act, flow_action) {
-		/* allocate action entry */
-		a_entry = kmalloc(sizeof(*a_entry), GFP_KERNEL);
-		if (!a_entry)
-			return -ENOMEM;
-
 		switch (act->id) {
 		case FLOW_ACTION_ACCEPT:
-			a_entry->id = MVSW_ACL_RULE_ACTION_ACCEPT;
-			prestera_acl_rule_action_add(rule, a_entry);
+			if (rule->re_arg.accept.valid)
+				return -EEXIST;
+
+			rule->re_arg.accept.valid = 1;
 			break;
 		case FLOW_ACTION_DROP:
-			a_entry->id = MVSW_ACL_RULE_ACTION_DROP;
-			prestera_acl_rule_action_add(rule, a_entry);
+			if (rule->re_arg.drop.valid)
+				return -EEXIST;
+
+			rule->re_arg.drop.valid = 1;
 			break;
 		case FLOW_ACTION_TRAP:
-			a_entry->id = MVSW_ACL_RULE_ACTION_TRAP;
-			prestera_acl_rule_action_add(rule, a_entry);
+			if (rule->re_arg.trap.valid)
+				return -EEXIST;
+
+			rule->re_arg.trap.valid = 1;
+			rule->re_arg.trap.i.hw_tc =
+				prestera_acl_rule_hw_tc_get(rule);
 			break;
 		case FLOW_ACTION_POLICE:
-			a_entry->id = MVSW_ACL_RULE_ACTION_POLICE;
-			a_entry->police.rate = act->police.rate_bytes_ps;
-			a_entry->police.burst =
-				div_u64(a_entry->police.rate *
-					PSCHED_NS2TICKS(act->police.burst),
-					PSCHED_TICKS_PER_SEC);
-			prestera_acl_rule_action_add(rule, a_entry);
+			if (rule->re_arg.police.valid)
+				return -EEXIST;
+
+			rule->re_arg.police.valid = 1;
+			rule->re_arg.police.i.rate =
+				act->police.rate_bytes_ps;
+			rule->re_arg.police.i.burst = act->police.burst;
+			break;
+		case FLOW_ACTION_GOTO:
+			err = prestera_flower_parse_goto_action(block, rule,
+								chain_index,
+								act);
+			if (err)
+				return err;
+
+			rule_flag_set(rule, GOTO);
+			break;
+		case FLOW_ACTION_NAT:
+			if (rule->re_arg.nat.valid)
+				return -EEXIST;
+
+			if (~act->nat.mask) {
+				NL_SET_ERR_MSG_MOD(extack,
+						   "Netmask is not supported");
+				return -EOPNOTSUPP;
+			}
+			if (!act->nat.old_addr || !act->nat.new_addr) {
+				NL_SET_ERR_MSG_MOD
+				    (extack,
+				     "All-zero IP address isn't supported");
+				return -EOPNOTSUPP;
+			}
+
+			rule->re_arg.nat.valid = 1;
+			rule->re_arg.nat.i.old_addr = act->nat.old_addr;
+			rule->re_arg.nat.i.new_addr = act->nat.new_addr;
+			rule->re_arg.nat.i.flags = act->nat.flags;
+
+			/* TODO: move this to the rule_add() */
+			binding = list_first_entry
+			    (&block->binding_list,
+			     struct prestera_flow_block_binding, list);
+			rule->re_arg.nat.i.dev = binding->port->dev_id;
+			rule->re_arg.nat.i.port = binding->port->hw_id;
+			rule_flag_set(rule, NAT);
+			break;
+		case FLOW_ACTION_CT:
+			/* TODO: check ct nat commit */
+			if (rule_flag_test(rule, CT))
+				return -EEXIST;
+
+			err = prestera_ct_parse_action(act, rule, extack);
+			if (err)
+				return err;
+
+			rule_flag_set(rule, CT);
 			break;
 		default:
-			kfree(a_entry);
 			NL_SET_ERR_MSG_MOD(extack, "Unsupported action");
 			pr_err("Unsupported action\n");
 			return -EOPNOTSUPP;
@@ -62,13 +163,14 @@ static int mvsw_pr_flower_parse_actions(struct mvsw_pr_switch *sw,
 
 static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
 				     struct flow_cls_offload *f,
-				     struct prestera_acl_block *block)
+				     struct prestera_flow_block *block)
 {
 	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
-	struct prestera_acl_rule_match_entry *m_entry;
-	struct mvsw_pr_port *port;
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	struct prestera_port *port;
 	struct net_device *ingress_dev;
 	struct flow_match_meta match;
+	__be16 key, mask;
 
 	flow_rule_match_meta(f_rule, &match);
 	if (match.mask->ingress_ifindex != 0xFFFFFFFF) {
@@ -85,36 +187,35 @@ static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
 		return -EINVAL;
 	}
 
-	if (!mvsw_pr_netdev_check(ingress_dev)) {
+	if (!prestera_netdev_check(ingress_dev)) {
 		NL_SET_ERR_MSG_MOD(f->common.extack,
 				   "Can't match on switchdev ingress port");
 		return -EINVAL;
 	}
 	port = netdev_priv(ingress_dev);
 
-	/* add port key,mask */
-	m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-	if (!m_entry)
-		return -ENOMEM;
+	mask = htons(0x1FFF);
+	key = htons(port->hw_id);
+	rule_match_set(r_match->key, SYS_PORT, key);
+	rule_match_set(r_match->mask, SYS_PORT, mask);
 
-	m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT;
-	m_entry->keymask.u64.key = port->hw_id | ((u64)port->dev_id << 32);
-	m_entry->keymask.u64.mask = ~(u64)0;
-	prestera_acl_rule_match_add(rule, m_entry);
+	mask = htons(0x1FF);
+	key = htons(port->dev_id);
+	rule_match_set(r_match->key, SYS_DEV, key);
+	rule_match_set(r_match->mask, SYS_DEV, mask);
 
 	return 0;
 }
 
-static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
-				struct prestera_acl_block *block,
+static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 				struct prestera_acl_rule *rule,
 				struct flow_cls_offload *f)
 {
 	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
 	struct flow_dissector *dissector = f_rule->match.dissector;
-	struct prestera_acl_rule_match_entry *m_entry;
-	u16 n_proto_mask = 0;
-	u16 n_proto_key = 0;
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	__be16 n_proto_mask = 0;
+	__be16 n_proto_key = 0;
 	u16 addr_type = 0;
 	u8 ip_proto = 0;
 	u32 hwtc = 0;
@@ -130,8 +231,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 	      BIT(FLOW_DISSECTOR_KEY_ICMP) |
 	      BIT(FLOW_DISSECTOR_KEY_PORTS) |
 	      BIT(FLOW_DISSECTOR_KEY_PORTS_RANGE) |
+	      BIT(FLOW_DISSECTOR_KEY_CT) |
 	      BIT(FLOW_DISSECTOR_KEY_VLAN))) {
 		NL_SET_ERR_MSG_MOD(f->common.extack, "Unsupported key");
+		MVSW_LOG_INFO("Unsupported key");
 		return -EOPNOTSUPP;
 	}
 
@@ -157,6 +260,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 			return err;
 	}
 
+	err = prestera_ct_match_parse(f, f->common.extack);
+	if (err)
+		return err;
+
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_CONTROL)) {
 		struct flow_match_control match;
 
@@ -168,33 +275,19 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		struct flow_match_basic match;
 
 		flow_rule_match_basic(f_rule, &match);
-		n_proto_key = ntohs(match.key->n_proto);
-		n_proto_mask = ntohs(match.mask->n_proto);
+		n_proto_key = match.key->n_proto;
+		n_proto_mask = match.mask->n_proto;
 
-		if (n_proto_key == ETH_P_ALL) {
+		if (ntohs(match.key->n_proto) == ETH_P_ALL) {
 			n_proto_key = 0;
 			n_proto_mask = 0;
 		}
 
-		/* add eth type key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE;
-		m_entry->keymask.u16.key = n_proto_key;
-		m_entry->keymask.u16.mask = n_proto_mask;
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		/* add ip proto key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO;
-		m_entry->keymask.u8.key = match.key->ip_proto;
-		m_entry->keymask.u8.mask = match.mask->ip_proto;
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, ETH_TYPE, n_proto_key);
+		rule_match_set(r_match->mask, ETH_TYPE, n_proto_mask);
+
+		rule_match_set(r_match->key, IP_PROTO, match.key->ip_proto);
+		rule_match_set(r_match->mask, IP_PROTO, match.mask->ip_proto);
 		ip_proto = match.key->ip_proto;
 	}
 
@@ -203,29 +296,27 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 
 		flow_rule_match_eth_addrs(f_rule, &match);
 
-		/* add ethernet dst key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC;
-		memcpy(&m_entry->keymask.mac.key,
-		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry->keymask.mac.mask,
-		       &match.mask->dst, sizeof(match.mask->dst));
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		/* add ethernet src key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC;
-		memcpy(&m_entry->keymask.mac.key,
-		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry->keymask.mac.mask,
-		       &match.mask->src, sizeof(match.mask->src));
-		prestera_acl_rule_match_add(rule, m_entry);
+		/* DA key, mask */
+		rule_match_set_n(r_match->key,
+				 ETH_DMAC_0, &match.key->dst[0], 4);
+		rule_match_set_n(r_match->key,
+				 ETH_DMAC_1, &match.key->dst[4], 2);
+
+		rule_match_set_n(r_match->mask,
+				 ETH_DMAC_0, &match.mask->dst[0], 4);
+		rule_match_set_n(r_match->mask,
+				 ETH_DMAC_1, &match.mask->dst[4], 2);
+
+		/* SA key, mask */
+		rule_match_set_n(r_match->key,
+				 ETH_SMAC_0, &match.key->src[0], 4);
+		rule_match_set_n(r_match->key,
+				 ETH_SMAC_1, &match.key->src[4], 2);
+
+		rule_match_set_n(r_match->mask,
+				 ETH_SMAC_0, &match.mask->src[0], 4);
+		rule_match_set_n(r_match->mask,
+				 ETH_SMAC_1, &match.mask->src[4], 2);
 	}
 
 	if (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {
@@ -233,27 +324,11 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 
 		flow_rule_match_ipv4_addrs(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC;
-		memcpy(&m_entry->keymask.u32.key,
-		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry->keymask.u32.mask,
-		       &match.mask->src, sizeof(match.mask->src));
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST;
-		memcpy(&m_entry->keymask.u32.key,
-		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry->keymask.u32.mask,
-		       &match.mask->dst, sizeof(match.mask->dst));
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, IP_SRC, match.key->src);
+		rule_match_set(r_match->mask, IP_SRC, match.mask->src);
+
+		rule_match_set(r_match->key, IP_DST, match.key->dst);
+		rule_match_set(r_match->mask, IP_DST, match.mask->dst);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_PORTS)) {
@@ -268,49 +343,34 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 
 		flow_rule_match_ports(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC;
-		m_entry->keymask.u16.key = ntohs(match.key->src);
-		m_entry->keymask.u16.mask = ntohs(match.mask->src);
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST;
-		m_entry->keymask.u16.key = ntohs(match.key->dst);
-		m_entry->keymask.u16.mask = ntohs(match.mask->dst);
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, L4_PORT_SRC, match.key->src);
+		rule_match_set(r_match->mask, L4_PORT_SRC, match.mask->src);
+
+		rule_match_set(r_match->key, L4_PORT_DST, match.key->dst);
+		rule_match_set(r_match->mask, L4_PORT_DST, match.mask->dst);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_PORTS_RANGE)) {
 		struct flow_match_ports_range match;
+		__be32 tp_key, tp_mask;
 
 		flow_rule_match_ports_range(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->type =
-			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC;
-		m_entry->keymask.u32.key = ntohs(match.key->tp_min.src) |
-				(u32)ntohs(match.key->tp_max.src) << 16;
-		m_entry->keymask.u32.mask = ntohs(match.mask->tp_min.src) |
-				(u32)ntohs(match.mask->tp_max.src) << 16;
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->type =
-			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST;
-		m_entry->keymask.u32.key = ntohs(match.key->tp_min.dst) |
-				(u32)ntohs(match.key->tp_max.dst) << 16;
-		m_entry->keymask.u32.mask = ntohs(match.mask->tp_min.dst) |
-				(u32)ntohs(match.mask->tp_max.dst) << 16;
-		prestera_acl_rule_match_add(rule, m_entry);
+		/* src port range (min, max) */
+		tp_key = htonl(ntohs(match.key->tp_min.src) |
+			       (ntohs(match.key->tp_max.src) << 16));
+		tp_mask = htonl(ntohs(match.mask->tp_min.src) |
+				(ntohs(match.mask->tp_max.src) << 16));
+		rule_match_set(r_match->key, L4_PORT_RANGE_SRC, tp_key);
+		rule_match_set(r_match->mask, L4_PORT_RANGE_SRC, tp_mask);
+
+		/* dst port range (min, max) */
+		tp_key = htonl(ntohs(match.key->tp_min.dst) |
+			       (ntohs(match.key->tp_max.dst) << 16));
+		tp_mask = htonl(ntohs(match.mask->tp_min.dst) |
+				(ntohs(match.mask->tp_max.dst) << 16));
+		rule_match_set(r_match->key, L4_PORT_RANGE_DST, tp_key);
+		rule_match_set(r_match->mask, L4_PORT_RANGE_DST, tp_mask);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_VLAN)) {
@@ -319,22 +379,15 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		flow_rule_match_vlan(f_rule, &match);
 
 		if (match.mask->vlan_id != 0) {
-			m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-			if (!m_entry)
-				return -ENOMEM;
-			m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID;
-			m_entry->keymask.u16.key = match.key->vlan_id;
-			m_entry->keymask.u16.mask = match.mask->vlan_id;
-			prestera_acl_rule_match_add(rule, m_entry);
+			__be16 key = cpu_to_be16(match.key->vlan_id);
+			__be16 mask = cpu_to_be16(match.mask->vlan_id);
+
+			rule_match_set(r_match->key, VLAN_ID, key);
+			rule_match_set(r_match->mask, VLAN_ID, mask);
 		}
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID;
-		m_entry->keymask.u16.key = ntohs(match.key->vlan_tpid);
-		m_entry->keymask.u16.mask = ntohs(match.mask->vlan_tpid);
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, VLAN_TPID, match.key->vlan_tpid);
+		rule_match_set(r_match->mask, VLAN_TPID, match.mask->vlan_tpid);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_ICMP)) {
@@ -342,89 +395,231 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 
 		flow_rule_match_icmp(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE;
-		m_entry->keymask.u8.key = match.key->type;
-		m_entry->keymask.u8.mask = match.mask->type;
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE;
-		m_entry->keymask.u8.key = match.key->code;
-		m_entry->keymask.u8.mask = match.mask->code;
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, ICMP_TYPE, match.key->type);
+		rule_match_set(r_match->mask, ICMP_TYPE, match.mask->type);
+
+		rule_match_set(r_match->key, ICMP_CODE, match.key->code);
+		rule_match_set(r_match->mask, ICMP_CODE, match.mask->code);
 	}
 
-	return mvsw_pr_flower_parse_actions(sw, block, rule,
-					    &f->rule->action,
+	return mvsw_pr_flower_parse_actions(block, rule, &f->rule->action,
+					    f->common.chain_index,
 					    f->common.extack);
 }
 
-int mvsw_pr_flower_replace(struct mvsw_pr_switch *sw,
-			   struct prestera_acl_block *block,
-			   struct flow_cls_offload *f)
+static int prestera_flower_prio_check(struct prestera_flow_block *block,
+				      struct flow_cls_offload *f)
+{
+	u32 mall_prio;
+	int err;
+
+	err = prestera_mall_prio_get(block, &mall_prio);
+	if (err == -ENOENT)
+		return 0;
+	if (err)
+		return err;
+
+	if (f->common.prio <= mall_prio)
+		return -EOPNOTSUPP;
+
+	return 0;
+}
+
+int prestera_flower_prio_get(struct prestera_flow_block *block,
+			     u32 *prio)
 {
+	if (!prestera_acl_block_rule_count(block))
+		return -ENOENT;
+
+	*prio = block->flower_min_prio;
+	return 0;
+}
+
+static void prestera_flower_prio_update(struct prestera_flow_block *block,
+					u32 prio)
+{
+	if (prio < block->flower_min_prio)
+		block->flower_min_prio = prio;
+}
+
+int prestera_flower_replace(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
+			    struct flow_cls_offload *f)
+{
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl *acl = sw->acl;
 	struct prestera_acl_rule *rule;
 	int err;
 
-	rule = prestera_acl_rule_create(block, f->cookie);
-	if (IS_ERR(rule))
-		return PTR_ERR(rule);
+	err = prestera_flower_prio_check(block, f);
+	if (err)
+		return err;
+
+	ruleset = prestera_acl_ruleset_get(acl, block, f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	/* increments the ruleset reference */
+	rule = prestera_acl_rule_create(ruleset, f->cookie,
+					f->common.chain_index);
+	if (IS_ERR(rule)) {
+		err = PTR_ERR(rule);
+		goto err_rule_create;
+	}
 
-	err = mvsw_pr_flower_parse(sw, block, rule, f);
+	err = mvsw_pr_flower_parse(block, rule, f);
 	if (err)
-		goto err_flower_parse;
+		goto err_rule_add;
+
+	if (!prestera_acl_ruleset_is_offload(ruleset)) {
+		err = prestera_acl_ruleset_offload(ruleset);
+		if (err)
+			goto err_ruleset_offload;
+	}
 
 	err = prestera_acl_rule_add(sw, rule);
 	if (err)
 		goto err_rule_add;
 
+	prestera_flower_prio_update(block, f->common.prio);
+
+	prestera_acl_ruleset_put(ruleset);
 	return 0;
 
+err_ruleset_offload:
 err_rule_add:
-err_flower_parse:
 	prestera_acl_rule_destroy(rule);
+err_rule_create:
+	prestera_acl_ruleset_put(ruleset);
 	return err;
 }
 
-void mvsw_pr_flower_destroy(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
-			    struct flow_cls_offload *f)
+void prestera_flower_destroy(struct prestera_switch *sw,
+			     struct prestera_flow_block *block,
+			     struct flow_cls_offload *f)
 {
+	struct prestera_acl_ruleset *ruleset;
 	struct prestera_acl_rule *rule;
 
-	rule = prestera_acl_rule_lookup(prestera_acl_block_ruleset_get(block),
-					f->cookie);
+	ruleset = prestera_acl_ruleset_lookup(sw->acl, block,
+					      f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return;
+
+	rule = prestera_acl_rule_lookup(ruleset, f->cookie);
 	if (rule) {
 		prestera_acl_rule_del(sw, rule);
 		prestera_acl_rule_destroy(rule);
 	}
+	prestera_acl_ruleset_put(ruleset);
 }
 
-int mvsw_pr_flower_stats(struct mvsw_pr_switch *sw,
-			 struct prestera_acl_block *block,
-			 struct flow_cls_offload *f)
+int prestera_flower_tmplt_create(struct prestera_switch *sw,
+				 struct prestera_flow_block *block,
+				 struct flow_cls_offload *f)
 {
+	struct prestera_flower_template *template;
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl_rule rule;
+	int err;
+
+	memset(&rule, 0, sizeof(rule));
+	err = mvsw_pr_flower_parse(block, &rule, f);
+	if (err)
+		return err;
+
+	template = kmalloc(sizeof(*template), GFP_KERNEL);
+	if (!template) {
+		err = -ENOMEM;
+		goto err_malloc;
+	}
+
+	prestera_acl_rule_keymask_pcl_id_set(&rule, 0);
+	ruleset = prestera_acl_ruleset_get(sw->acl, block,
+					   f->common.chain_index);
+	if (IS_ERR_OR_NULL(ruleset)) {
+		err = -EINVAL;
+		goto err_ruleset_get;
+	}
+
+	/* preserve keymask/template to this ruleset */
+	err = prestera_acl_ruleset_keymask_set(ruleset, rule.re_key.match.mask);
+	if (err)
+		goto err_ruleset_offload;
+
+	/* skip error, as it is not possible to reject template operation,
+	 * so, keep the reference to the ruleset for rules to be added
+	 * to that ruleset later. In case of offload fail, the ruleset
+	 * will be offloaded again during adding a new rule. Also,
+	 * unlikly possble that ruleset is already offloaded at this staage.
+	 */
+	prestera_acl_ruleset_offload(ruleset);
+
+	/* keep the reference to the ruleset */
+	template->ruleset = ruleset;
+	template->chain_index = f->common.chain_index;
+	list_add_rcu(&template->list, &block->template_list);
+	return 0;
+
+err_ruleset_offload:
+	prestera_acl_ruleset_put(ruleset);
+err_ruleset_get:
+	kfree(template);
+err_malloc:
+	MVSW_LOG_ERROR("Create chain template failed");
+	return err;
+}
+
+void prestera_flower_tmplt_destroy(struct prestera_switch *sw,
+				   struct prestera_flow_block *block,
+				   struct flow_cls_offload *f)
+{
+	struct prestera_flower_template *template;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &block->template_list) {
+		template = list_entry(pos, typeof(*template), list);
+		if (template->chain_index == f->common.chain_index) {
+			/* put the reference to the ruleset kept in create */
+			prestera_acl_ruleset_put(template->ruleset);
+			list_del(&template->list);
+			kfree(template);
+			return;
+		}
+	}
+}
+
+int prestera_flower_stats(struct prestera_switch *sw,
+			  struct prestera_flow_block *block,
+			  struct flow_cls_offload *f)
+{
+	struct prestera_acl_ruleset *ruleset;
 	struct prestera_acl_rule *rule;
 	u64 packets;
 	u64 lastuse;
 	u64 bytes;
 	int err;
 
-	rule = prestera_acl_rule_lookup(prestera_acl_block_ruleset_get(block),
-					f->cookie);
-	if (!rule)
-		return -EINVAL;
+	ruleset = prestera_acl_ruleset_lookup(sw->acl, block,
+					      f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
 
-	err = prestera_acl_rule_get_stats(sw, rule, &packets, &bytes, &lastuse);
+	rule = prestera_acl_rule_lookup(ruleset, f->cookie);
+	if (!rule) {
+		err = -EINVAL;
+		goto err_rule_get_stats;
+	}
+
+	err = prestera_acl_rule_get_stats(sw->acl, rule, &packets,
+					  &bytes, &lastuse);
 	if (err)
-		return err;
+		goto err_rule_get_stats;
 
 	flow_stats_update(&f->stats, bytes, packets, 0, lastuse,
-			  FLOW_ACTION_HW_STATS_IMMEDIATE);
-	return 0;
+			  FLOW_ACTION_HW_STATS_DELAYED);
+
+err_rule_get_stats:
+	prestera_acl_ruleset_put(ruleset);
+	return err;
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
index e1c9f6a..5369bbc 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
@@ -1,8 +1,6 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
 #include <linux/sysfs.h>
 #include <linux/fs.h>
 #include <linux/etherdevice.h>
@@ -28,8 +26,8 @@
 
 #define mvsw_dev(sw)		((sw)->dev->dev)
 
-static void mvsw_pr_fw_log_evt_handler(struct mvsw_pr_switch *,
-				       struct mvsw_pr_event *,
+static void mvsw_pr_fw_log_evt_handler(struct prestera_switch *,
+				       struct prestera_event *,
 				       void *);
 static ssize_t mvsw_pr_fw_log_debugfs_read(struct file *file,
 					   char __user *ubuf,
@@ -40,8 +38,8 @@ static ssize_t mvsw_pr_fw_log_debugfs_write(struct file *file,
 static inline int mvsw_pr_fw_log_get_type_from_str(const char *str);
 static inline int mvsw_pr_fw_log_get_lib_from_str(const char *str);
 
-static int mvsw_pr_fw_log_event_handler_register(struct mvsw_pr_switch *sw);
-static void mvsw_pr_fw_log_event_handler_unregister(struct mvsw_pr_switch *sw);
+static int mvsw_pr_fw_log_event_handler_register(struct prestera_switch *sw);
+static void mvsw_pr_fw_log_event_handler_unregister(struct prestera_switch *sw);
 
 struct mvsw_pr_fw_log_prv_debugfs {
 	struct dentry *cfg_dir;
@@ -126,8 +124,8 @@ static const char *mvsw_pr_fw_log_prv_type_id2name[MVSW_FW_LOG_TYPE_MAX] = {
 	[MVSW_FW_LOG_TYPE_NONE]  = "none",
 };
 
-static void mvsw_pr_fw_log_evt_handler(struct mvsw_pr_switch *sw,
-				       struct mvsw_pr_event *evt, void *arg)
+static void mvsw_pr_fw_log_evt_handler(struct prestera_switch *sw,
+				       struct prestera_event *evt, void *arg)
 {
 	u32 log_len = evt->fw_log_evt.log_len;
 	u8 *buf = evt->fw_log_evt.data;
@@ -269,7 +267,7 @@ static ssize_t mvsw_pr_fw_log_debugfs_write(struct file *file,
 					    const char __user *ubuf,
 					    size_t count, loff_t *ppos)
 {
-	struct mvsw_pr_switch *sw = file->private_data;
+	struct prestera_switch *sw = file->private_data;
 	int lib, type;
 	int i, j;
 	int err;
@@ -358,19 +356,19 @@ static inline int mvsw_pr_fw_log_get_lib_from_str(const char *str)
 	return MVSW_FW_LOG_LIB_MAX;
 }
 
-static int mvsw_pr_fw_log_event_handler_register(struct mvsw_pr_switch *sw)
+static int mvsw_pr_fw_log_event_handler_register(struct prestera_switch *sw)
 {
 	return mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_FW_LOG,
 						 mvsw_pr_fw_log_evt_handler,
 						 NULL);
 }
 
-static void mvsw_pr_fw_log_event_handler_unregister(struct mvsw_pr_switch *sw)
+static void mvsw_pr_fw_log_event_handler_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_FW_LOG);
 }
 
-int mvsw_pr_fw_log_init(struct mvsw_pr_switch *sw)
+int mvsw_pr_fw_log_init(struct prestera_switch *sw)
 {
 	fw_log_debugfs_handle.cfg_dir =
 		debugfs_create_dir(FW_LOG_DBGFS_CFG_DIR, NULL);
@@ -411,7 +409,7 @@ int mvsw_pr_fw_log_init(struct mvsw_pr_switch *sw)
 	return -1;
 }
 
-void mvsw_pr_fw_log_fini(struct mvsw_pr_switch *sw)
+void mvsw_pr_fw_log_fini(struct prestera_switch *sw)
 {
 	mvsw_pr_fw_log_event_handler_unregister(sw);
 
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
index ccd5514..ac5f64f 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
@@ -1,15 +1,12 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _MVSW_PRESTERA_FW_LOG_H_
 #define _MVSW_PRESTERA_FW_LOG_H_
 
 #include "prestera.h"
 
-int  mvsw_pr_fw_log_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_fw_log_fini(struct mvsw_pr_switch *sw);
+int  mvsw_pr_fw_log_init(struct prestera_switch *sw);
+void mvsw_pr_fw_log_fini(struct prestera_switch *sw);
 
 #endif /* _MVSW_PRESTERA_FW_LOG_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.c b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
index eb0a544..25eb50b 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
@@ -1,30 +1,42 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
 #include <linux/etherdevice.h>
 #include <linux/ethtool.h>
 #include <linux/netdevice.h>
 #include <linux/list.h>
 
-#include "prestera_hw.h"
 #include "prestera.h"
+#include "prestera_hw.h"
+#include "prestera_acl.h"
 #include "prestera_log.h"
 #include "prestera_fw_log.h"
+#include "prestera_counter.h"
 #include "prestera_rxtx.h"
 
 #define MVSW_PR_INIT_TIMEOUT 30000000	/* 30sec */
 #define MVSW_PR_MIN_MTU 64
 #define MVSW_PR_MSG_BUFF_CHUNK_SIZE	32	/* bytes */
 
+#ifndef MVSW_FW_WD_KICK_TIMEOUT
+#define MVSW_FW_WD_KICK_TIMEOUT		1000
+#endif /* MVSW_FW_WD_KICK_TIMEOUT */
+
+#ifndef MVSW_FW_KEEPALIVE_WD_MAX_KICKS
+#define MVSW_FW_KEEPALIVE_WD_MAX_KICKS			15
+#endif /* MVSW_FW_KEEPALIVE_WD_MAX_KICKS */
+
 enum mvsw_msg_type {
 	MVSW_MSG_TYPE_SWITCH_INIT = 0x1,
 	MVSW_MSG_TYPE_SWITCH_ATTR_SET = 0x2,
 
+	MVSW_MSG_TYPE_KEEPALIVE_INIT = 0x3,
+	MVSW_MSG_TYPE_SWITCH_RESET = 0x4,
+
 	MVSW_MSG_TYPE_PORT_ATTR_SET = 0x100,
 	MVSW_MSG_TYPE_PORT_ATTR_GET = 0x101,
 	MVSW_MSG_TYPE_PORT_INFO_GET = 0x110,
+	MVSW_MSG_TYPE_PORT_RATE_LIMIT_MODE_SET = 0x111,
 
 	MVSW_MSG_TYPE_VLAN_CREATE = 0x200,
 	MVSW_MSG_TYPE_VLAN_DELETE = 0x201,
@@ -46,13 +58,19 @@ enum mvsw_msg_type {
 	MVSW_MSG_TYPE_BRIDGE_PORT_ADD = 0x402,
 	MVSW_MSG_TYPE_BRIDGE_PORT_DELETE = 0x403,
 
-	MVSW_MSG_TYPE_ACL_RULE_ADD = 0x500,
-	MVSW_MSG_TYPE_ACL_RULE_DELETE = 0x501,
-	MVSW_MSG_TYPE_ACL_RULE_STATS_GET = 0x510,
-	MVSW_MSG_TYPE_ACL_RULESET_CREATE = 0x520,
-	MVSW_MSG_TYPE_ACL_RULESET_DELETE = 0x521,
-	MVSW_MSG_TYPE_ACL_PORT_BIND = 0x530,
-	MVSW_MSG_TYPE_ACL_PORT_UNBIND = 0x531,
+	MVSW_MSG_TYPE_COUNTER_GET = 0x510,
+	MVSW_MSG_TYPE_COUNTER_ABORT = 0x511,
+	MVSW_MSG_TYPE_COUNTER_TRIGGER = 0x512,
+	MVSW_MSG_TYPE_COUNTER_BLOCK_GET = 0x513,
+	MVSW_MSG_TYPE_COUNTER_BLOCK_RELEASE = 0x514,
+	MVSW_MSG_TYPE_COUNTER_CLEAR = 0x515,
+
+	MVSW_MSG_TYPE_VTCAM_CREATE = 0x540,
+	MVSW_MSG_TYPE_VTCAM_DESTROY = 0x541,
+	MVSW_MSG_TYPE_VTCAM_RULE_ADD = 0x550,
+	MVSW_MSG_TYPE_VTCAM_RULE_DELETE = 0x551,
+	MVSW_MSG_TYPE_VTCAM_IFACE_BIND = 0x560,
+	MVSW_MSG_TYPE_VTCAM_IFACE_UNBIND = 0x561,
 
 	MVSW_MSG_TYPE_ROUTER_RIF_CREATE = 0x600,
 	MVSW_MSG_TYPE_ROUTER_RIF_DELETE = 0x601,
@@ -61,6 +79,7 @@ enum mvsw_msg_type {
 	MVSW_MSG_TYPE_ROUTER_LPM_DELETE = 0x611,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_SET = 0x622,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_GET = 0x644,
+	MVSW_MSG_TYPE_ROUTER_NH_GRP_BLK_GET = 0x645,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_ADD = 0x623,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_DELETE = 0x624,
 	MVSW_MSG_TYPE_ROUTER_VR_CREATE = 0x630,
@@ -78,30 +97,41 @@ enum mvsw_msg_type {
 
 	MVSW_MSG_TYPE_STP_PORT_SET = 0x1000,
 
+	MVSW_MSG_TYPE_SPAN_GET = 0X1100,
+	MVSW_MSG_TYPE_SPAN_BIND = 0X1101,
+	MVSW_MSG_TYPE_SPAN_UNBIND = 0X1102,
+	MVSW_MSG_TYPE_SPAN_RELEASE = 0X1103,
+
+	MVSW_MSG_TYPE_NAT_PORT_NEIGH_UPDATE = 0X1200,
+
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_ADD = 0X1211,
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_SET = 0X1212,
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_DEL = 0X1213,
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_GET = 0X1214,
+
+	MVSW_MSG_TYPE_CPU_CODE_COUNTERS_GET = 0x2000,
+
 	MVSW_MSG_TYPE_ACK = 0x10000,
 	MVSW_MSG_TYPE_MAX
 };
 
 enum mvsw_msg_port_attr {
-	MVSW_MSG_PORT_ATTR_ADMIN_STATE = 1,
 	MVSW_MSG_PORT_ATTR_OPER_STATE = 2,
 	MVSW_MSG_PORT_ATTR_MTU = 3,
 	MVSW_MSG_PORT_ATTR_MAC = 4,
-	MVSW_MSG_PORT_ATTR_SPEED = 5,
 	MVSW_MSG_PORT_ATTR_ACCEPT_FRAME_TYPE = 6,
 	MVSW_MSG_PORT_ATTR_LEARNING = 7,
 	MVSW_MSG_PORT_ATTR_FLOOD = 8,
 	MVSW_MSG_PORT_ATTR_CAPABILITY = 9,
 	MVSW_MSG_PORT_ATTR_REMOTE_CAPABILITY = 10,
-	MVSW_MSG_PORT_ATTR_REMOTE_FC = 11,
-	MVSW_MSG_PORT_ATTR_LINK_MODE = 12,
+	MVSW_MSG_PORT_ATTR_PHY_MODE = 12,
 	MVSW_MSG_PORT_ATTR_TYPE = 13,
-	MVSW_MSG_PORT_ATTR_FEC = 14,
-	MVSW_MSG_PORT_ATTR_AUTONEG = 15,
-	MVSW_MSG_PORT_ATTR_DUPLEX = 16,
 	MVSW_MSG_PORT_ATTR_STATS = 17,
 	MVSW_MSG_PORT_ATTR_MDIX = 18,
 	MVSW_MSG_PORT_ATTR_AUTONEG_RESTART = 19,
+	MVSW_MSG_PORT_ATTR_SOURCE_ID_DEFAULT = 20,
+	MVSW_MSG_PORT_ATTR_SOURCE_ID_FILTER = 21,
+	MVSW_MSG_PORT_ATTR_MAC_MODE = 22,
 	MVSW_MSG_PORT_ATTR_MAX
 };
 
@@ -177,6 +207,12 @@ enum {
 	MVSW_PORT_FLOOD_TYPE_BC = 2,
 };
 
+enum {
+	MVSW_COUNTER_CLIENT_LOOKUP_0 = 0,
+	MVSW_COUNTER_CLIENT_LOOKUP_1 = 1,
+	MVSW_COUNTER_CLIENT_LOOKUP_2 = 2,
+};
+
 struct mvsw_msg_buff {
 	u32 free;
 	u32 total;
@@ -220,6 +256,7 @@ struct mvsw_msg_switch_init_ret {
 	u8  switch_id;
 	u8  lag_max;
 	u8  lag_member_max;
+	u32 size_tbl_router_nexthop;
 } __packed __aligned(4);
 
 struct mvsw_msg_port_autoneg_param {
@@ -232,6 +269,7 @@ struct mvsw_msg_port_cap_param {
 	u64 link_mode;
 	u8  type;
 	u8  fec;
+	u8  fc;
 	u8  transceiver;
 };
 
@@ -246,22 +284,38 @@ struct mvsw_msg_port_flood_param {
 };
 
 union mvsw_msg_port_param {
-	u8  admin_state;
 	u8  oper_state;
 	u32 mtu;
 	u8  mac[ETH_ALEN];
 	u8  accept_frm_type;
 	u8  learning;
-	u32 speed;
-	u32 link_mode;
+	union {
+		struct {
+			/* TODO: merge it with "mode" */
+			u8 admin:1;
+			u32 mode;
+			u8  inband:1;
+			u32 speed;
+			u8  duplex;
+			u8  fec;
+			u8  fc;
+		} mac;
+		struct {
+			/* TODO: merge it with "mode" */
+			u8 admin:1;
+			u8 adv_enable;
+			u64 modes;
+			/* TODO: merge it with modes */
+			u32 mode;
+		} phy;
+	} link;
 	u8  type;
-	u8  duplex;
-	u8  fec;
-	u8  fc;
 	struct mvsw_msg_port_mdix_param mdix;
 	struct mvsw_msg_port_autoneg_param autoneg;
 	struct mvsw_msg_port_cap_param cap;
 	struct mvsw_msg_port_flood_param flood;
+	u32 source_id_default;
+	u32 source_id_filter;
 };
 
 struct mvsw_msg_port_attr_cmd {
@@ -294,6 +348,14 @@ struct mvsw_msg_port_info_ret {
 	u16 fp_id;
 } __packed __aligned(4);
 
+struct mvsw_msg_port_storm_control_cfg_set_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 port;
+	u32 dev;
+	u32 storm_type;
+	u32 kbyte_per_sec_rate;
+} __packed __aligned(4);
+
 struct mvsw_msg_vlan_cmd {
 	struct mvsw_msg_cmd cmd;
 	u32 port;
@@ -325,38 +387,161 @@ struct mvsw_msg_log_lvl_set_cmd {
 	u32 type;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_rule_cmd {
+struct mvsw_msg_iface {
+	u8 type;
+	u16 vid;
+	u16 vr_id;
+	union {
+		struct {
+			u32 dev;
+			u32 port;
+		} __packed;
+		u16 lag_id;
+	};
+} __packed;
+
+struct mvsw_msg_nh {
+	struct mvsw_msg_iface oif;
+	u8 is_active;
+	u32 hw_id;
+	u8 mac[ETH_ALEN];
+} __packed;
+
+struct mvsw_msg_nh_mangle_info {
+	u8 l4_src_valid:1, l4_dst_valid:1,
+	   sip_valid:1, dip_valid:1;
+	__be16 l4_src;
+	__be16 l4_dst;
+	__be32 sip;
+	__be32 dip;
+	struct mvsw_msg_nh nh;
+} __packed __aligned(4);
+
+struct mvsw_msg_nh_mangle_cmd {
 	struct mvsw_msg_cmd cmd;
-	u32 id;
-	u16 ruleset_id;
+	u32 nh_id;
+	struct mvsw_msg_nh_mangle_info info;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_rule_ret {
+struct mvsw_msg_nh_mangle_ret {
 	struct mvsw_msg_ret ret;
+	u32 nh_id;
+	struct mvsw_msg_nh_mangle_info info;
+} __packed __aligned(4);
+
+struct mvsw_msg_acl_action {
+	u32 id;
+	union {
+		struct {
+			u8 hw_tc;
+		} __packed trap;
+		struct {
+			u64 rate;
+			u64 burst;
+		} __packed police;
+		struct {
+			u32 nh_id;
+		} __packed nh;
+		struct {
+			__be32 old_addr;
+			__be32 new_addr;
+			u32 port;
+			u32 dev;
+			u32 flags;
+		} __packed nat;
+		struct {
+			u32 index;
+		} __packed jump;
+		struct {
+			u32 id;
+		} __packed count;
+	};
+} __packed __aligned(4);
+
+struct mvsw_msg_vtcam_create_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	u8 lookup;
+} __packed __aligned(4);
+
+struct mvsw_msg_vtcam_destroy_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 vtcam_id;
+} __packed __aligned(4);
+
+struct mvsw_msg_vtcam_rule_add_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 key[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	u32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	u32 vtcam_id;
+	u32 prio;
+	u8 n_act;
+} __packed __aligned(4);
+
+struct mvsw_msg_vtcam_rule_del_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 vtcam_id;
 	u32 id;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_rule_stats_ret {
+struct mvsw_msg_vtcam_bind_cmd {
+	struct mvsw_msg_cmd cmd;
+	union {
+		struct {
+			u32 hw_id;
+			u32 dev_id;
+		} __packed port;
+		u32 index;
+	};
+	u32 vtcam_id;
+	u16 pcl_id;
+	u8 type;
+} __packed __aligned(4);
+
+struct mvsw_msg_vtcam_ret {
 	struct mvsw_msg_ret ret;
+	u32 vtcam_id;
+	u32 rule_id;
+} __packed __aligned(4);
+
+struct mvsw_msg_counter_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 client;
+	u32 block_id;
+	u32 num_counters;
+} __packed __aligned(4);
+
+struct mvsw_msg_counter_stats {
 	u64 packets;
 	u64 bytes;
+} __packed;
+
+struct mvsw_msg_counter_ret {
+	struct mvsw_msg_ret ret;
+	u32 block_id;
+	u32 offset;
+	u32 num_counters;
+	u32 done;
+	struct mvsw_msg_counter_stats stats[0];
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_ruleset_bind_cmd {
+struct mvsw_msg_nat_port_cmd {
 	struct mvsw_msg_cmd cmd;
+	u8 neigh_mac[ETH_ALEN];
 	u32 port;
 	u32 dev;
-	u16 ruleset_id;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_ruleset_cmd {
+struct mvsw_msg_span_cmd {
 	struct mvsw_msg_cmd cmd;
-	u16 id;
+	u32 port;
+	u32 dev;
+	u8 id;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_ruleset_ret {
+struct mvsw_msg_span_ret {
 	struct mvsw_msg_ret ret;
-	u16 id;
+	u8 id;
 } __packed __aligned(4);
 
 struct mvsw_msg_event {
@@ -386,9 +571,12 @@ struct mvsw_msg_event_fdb {
 } __packed __aligned(4);
 
 struct mvsw_msg_event_port_param {
+	u64 lmode_bmap;
+	u32 link_mode;
 	u8 oper_state;
-	u8 duplex;
-	u32 speed;
+	u8 fc;
+	u8 status;
+	u8 admin_mode;
 } __packed __aligned(4);
 
 struct mvsw_msg_event_port {
@@ -424,19 +612,6 @@ struct mvsw_msg_stp_cmd {
 	u8  state;
 } __packed __aligned(4);
 
-struct mvsw_msg_iface {
-	u8 type;
-	u16 vid;
-	u16 vr_id;
-	union {
-		struct {
-			u32 dev;
-			u32 port;
-		};
-		u16 lag_id;
-	};
-} __packed __aligned(4);
-
 struct mvsw_msg_rif_cmd {
 	struct mvsw_msg_cmd cmd;
 	struct mvsw_msg_iface iif;
@@ -458,23 +633,26 @@ struct mvsw_msg_lpm_cmd {
 	u16 vr_id;
 } __packed __aligned(4);
 
-struct mvsw_msg_nh {
-	struct mvsw_msg_iface oif;
-	u8 is_active;
-	u32 hw_id;
-	u8 mac[ETH_ALEN];
-} __packed __aligned(4);
-
 struct mvsw_msg_nh_cmd {
 	struct mvsw_msg_cmd cmd;
 	u32 size;
 	u32 grp_id;
-	struct mvsw_msg_nh nh[MVSW_PR_NHGR_SIZE_MAX];
+	struct mvsw_msg_nh nh[PRESTERA_NHGR_SIZE_MAX];
 } __packed __aligned(4);
 
 struct mvsw_msg_nh_ret {
 	struct mvsw_msg_ret ret;
-	struct mvsw_msg_nh nh[MVSW_PR_NHGR_SIZE_MAX];
+	struct mvsw_msg_nh nh[PRESTERA_NHGR_SIZE_MAX];
+} __packed __aligned(4);
+
+struct mvsw_msg_nh_chunk_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 offset;
+} __packed __aligned(4);
+
+struct mvsw_msg_nh_chunk_ret {
+	struct mvsw_msg_ret ret;
+	u8 hw_state[PRESTERA_MSG_CHUNK_SIZE];
 } __packed __aligned(4);
 
 struct mvsw_msg_nh_grp_cmd {
@@ -521,6 +699,39 @@ struct mvsw_msg_lag_cmd {
 	u16 vr_id;
 } __packed __aligned(4);
 
+struct mvsw_msg_keepalive_init_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 pulse_timeout_ms;
+} __packed __aligned(4);
+
+struct mvsw_msg_cpu_code_counter_cmd {
+	struct mvsw_msg_cmd cmd;
+	u8 counter_type;
+	u8 code;
+} __packed __aligned(4);
+
+struct mvsw_msg_cpu_code_counter_ret {
+	struct mvsw_msg_ret ret;
+	u64 packet_count;
+} __packed __aligned(4);
+
+static void fw_reset_wdog(struct prestera_device *dev);
+
+static int mvsw_pr_cmd_qid_by_req_type(enum mvsw_msg_type type)
+{
+	switch (type) {
+	case MVSW_MSG_TYPE_COUNTER_GET:
+	case MVSW_MSG_TYPE_COUNTER_ABORT:
+	case MVSW_MSG_TYPE_COUNTER_TRIGGER:
+	case MVSW_MSG_TYPE_COUNTER_BLOCK_GET:
+	case MVSW_MSG_TYPE_COUNTER_BLOCK_RELEASE:
+	case MVSW_MSG_TYPE_COUNTER_CLEAR:
+		return 1;
+	default:
+		return 0;
+	}
+}
+
 #define fw_check_resp(_response)	\
 ({								\
 	int __er = 0;						\
@@ -532,31 +743,52 @@ struct mvsw_msg_lag_cmd {
 	(__er);							\
 })
 
-#define __fw_send_req_resp(_switch, _type, _req, _req_size,	\
-_response, _wait)						\
+#define __fw_send_req_resp(_switch, _type, _request, _req_size,	\
+_response, _resp_size, _wait)					\
 ({								\
 	int __e;						\
 	typeof(_switch) __sw = (_switch);			\
-	typeof(_req) __req = (_req);				\
+	typeof(_request) __req = (_request);			\
 	typeof(_response) __resp = (_response);			\
-	__req->cmd.type = (_type);				\
+	typeof(_type) __type = (_type);				\
+	__req->cmd.type = (__type);				\
 	__e = __sw->dev->send_req(__sw->dev,			\
+		mvsw_pr_cmd_qid_by_req_type(__type),		\
 		(u8 *)__req, _req_size,				\
-		(u8 *)__resp, sizeof(*__resp),			\
+		(u8 *)__resp, _resp_size,			\
 		_wait);						\
+	if (__e != -EBUSY && __e != -ENODEV)			\
+		fw_reset_wdog(_switch->dev);			\
 	if (!__e)						\
 		__e = fw_check_resp(__resp);			\
 	(__e);							\
 })
 
+#define fw_send_nreq_nresp(_sw, _t, _req, _req_size, _resp, _resp_size)	\
+	__fw_send_req_resp(_sw, _t, _req, _req_size, _resp, _resp_size, 0)
+
 #define fw_send_nreq_resp(_sw, _t, _req, _req_size, _resp)	\
-	__fw_send_req_resp(_sw, _t, _req, _req_size, _resp, 0)
+({								\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _req, _req_size,		\
+			    _res, sizeof(*_res), 0));		\
+})
 
-#define fw_send_req_resp(_sw, _t, _req, _resp)	\
-	__fw_send_req_resp(_sw, _t, _req, sizeof(*_req), _resp, 0)
+#define fw_send_req_resp(_sw, _t, _req, _resp)			\
+({								\
+	typeof(_req) _re = (_req);				\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _re, sizeof(*_re),		\
+			    _res, sizeof(*_res), 0));		\
+})
 
 #define fw_send_req_resp_wait(_sw, _t, _req, _resp, _wait)	\
-	__fw_send_req_resp(_sw, _t, _req, sizeof(*_req), _resp, _wait)
+({								\
+	typeof(_req) _re = (_req);				\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _re, sizeof(*_re),		\
+			    _res, sizeof(*_res), _wait));	\
+})
 
 #define fw_send_req(_sw, _t, _req)	\
 ({							\
@@ -566,14 +798,39 @@ _response, _wait)						\
 
 struct mvsw_fw_event_handler {
 	struct list_head list;
-	enum mvsw_pr_event_type type;
-	void (*func)(struct mvsw_pr_switch *sw,
-		     struct mvsw_pr_event *evt,
+	enum prestera_event_type type;
+	void (*func)(struct prestera_switch *sw,
+		     struct prestera_event *evt,
 		     void *arg);
 	void *arg;
 };
 
-static int fw_parse_port_evt(u8 *msg, struct mvsw_pr_event *evt)
+static void prestera_hw_remote_fc_to_eth(u8 fc, bool *pause, bool *asym_pause);
+static u8 mvsw_mdix_to_eth(u8 mode);
+
+static void mvsw_pr_fw_keepalive_wd_work_fn(struct work_struct *work)
+{
+	struct delayed_work *dl_work =
+		container_of(work, struct delayed_work, work);
+	struct prestera_device *dev =
+		container_of(dl_work, struct prestera_device,
+			     keepalive_wdog_work);
+
+	atomic_t *ctr = &dev->keepalive_wdog_counter;
+
+	if (atomic_add_unless(ctr, 1, MVSW_FW_KEEPALIVE_WD_MAX_KICKS)) {
+		queue_delayed_work(system_long_wq,
+				   &dev->keepalive_wdog_work,
+				   msecs_to_jiffies(MVSW_FW_WD_KICK_TIMEOUT));
+		return;
+	}
+
+	pr_err("fw_keepalive_wdog: Fw is stuck and became non-operational\n");
+
+	dev->running = false;
+}
+
+static int fw_parse_port_evt(u8 *msg, struct prestera_event *evt)
 {
 	struct mvsw_msg_event_port *hw_evt = (struct mvsw_msg_event_port *)msg;
 
@@ -581,15 +838,21 @@ static int fw_parse_port_evt(u8 *msg, struct mvsw_pr_event *evt)
 
 	if (evt->id == MVSW_PORT_EVENT_STATE_CHANGED) {
 		evt->port_evt.data.oper_state = hw_evt->param.oper_state;
-		evt->port_evt.data.duplex = hw_evt->param.duplex;
-		evt->port_evt.data.speed = hw_evt->param.speed;
+		evt->port_evt.data.lmode_bmap = hw_evt->param.lmode_bmap;
+		prestera_hw_remote_fc_to_eth(hw_evt->param.fc,
+					     &evt->port_evt.data.pause,
+					     &evt->port_evt.data.asym_pause);
+		evt->port_evt.data.status = hw_evt->param.status;
+		evt->port_evt.data.admin_mode = hw_evt->param.admin_mode;
+		evt->port_evt.data.link_mode = hw_evt->param.link_mode;
 	} else {
 		return -EINVAL;
 	}
+
 	return 0;
 }
 
-static int fw_parse_fdb_evt(u8 *msg, struct mvsw_pr_event *evt)
+static int fw_parse_fdb_evt(u8 *msg, struct prestera_event *evt)
 {
 	struct mvsw_msg_event_fdb *hw_evt = (struct mvsw_msg_event_fdb *)msg;
 
@@ -613,7 +876,7 @@ static int fw_parse_fdb_evt(u8 *msg, struct mvsw_pr_event *evt)
 	return 0;
 }
 
-static int fw_parse_log_evt(u8 *msg, struct mvsw_pr_event *evt)
+static int fw_parse_log_evt(u8 *msg, struct prestera_event *evt)
 {
 	struct mvsw_msg_event_log *hw_evt = (struct mvsw_msg_event_log *)msg;
 
@@ -624,7 +887,7 @@ static int fw_parse_log_evt(u8 *msg, struct mvsw_pr_event *evt)
 }
 
 struct mvsw_fw_evt_parser {
-	int (*func)(u8 *msg, struct mvsw_pr_event *evt);
+	int (*func)(u8 *msg, struct prestera_event *evt);
 };
 
 static struct mvsw_fw_evt_parser fw_event_parsers[MVSW_EVENT_TYPE_MAX] = {
@@ -634,8 +897,8 @@ static struct mvsw_fw_evt_parser fw_event_parsers[MVSW_EVENT_TYPE_MAX] = {
 };
 
 static struct mvsw_fw_event_handler *
-__find_event_handler(const struct mvsw_pr_switch *sw,
-		     enum mvsw_pr_event_type type)
+__find_event_handler(const struct prestera_switch *sw,
+		     enum prestera_event_type type)
 {
 	struct mvsw_fw_event_handler *eh;
 
@@ -647,8 +910,8 @@ __find_event_handler(const struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static int mvsw_find_event_handler(const struct mvsw_pr_switch *sw,
-				   enum mvsw_pr_event_type type,
+static int mvsw_find_event_handler(const struct prestera_switch *sw,
+				   enum prestera_event_type type,
 				   struct mvsw_fw_event_handler *eh)
 {
 	struct mvsw_fw_event_handler *tmp;
@@ -665,14 +928,22 @@ static int mvsw_find_event_handler(const struct mvsw_pr_switch *sw,
 	return err;
 }
 
+static void fw_reset_wdog(struct prestera_device *dev)
+{
+	if (dev->running)
+		atomic_set(&dev->keepalive_wdog_counter, 0);
+}
+
 static int fw_event_recv(struct prestera_device *dev, u8 *buf, size_t size)
 {
 	struct mvsw_msg_event *msg = (struct mvsw_msg_event *)buf;
-	struct mvsw_pr_switch *sw = dev->priv;
+	struct prestera_switch *sw = dev->priv;
 	struct mvsw_fw_event_handler eh;
-	struct mvsw_pr_event evt;
+	struct prestera_event evt;
 	int err;
 
+	fw_reset_wdog(dev);
+
 	if (msg->type >= MVSW_EVENT_TYPE_MAX)
 		return -EINVAL;
 
@@ -692,9 +963,9 @@ static int fw_event_recv(struct prestera_device *dev, u8 *buf, size_t size)
 
 static void fw_pkt_recv(struct prestera_device *dev)
 {
-	struct mvsw_pr_switch *sw = dev->priv;
+	struct prestera_switch *sw = dev->priv;
 	struct mvsw_fw_event_handler eh;
-	struct mvsw_pr_event ev;
+	struct prestera_event ev;
 	int err;
 
 	ev.id = MVSW_RXTX_EVENT_RCV_PKT;
@@ -706,112 +977,7 @@ static void fw_pkt_recv(struct prestera_device *dev)
 	eh.func(sw, &ev, eh.arg);
 }
 
-static struct mvsw_msg_buff *mvsw_msg_buff_create(u16 head_size)
-{
-	struct mvsw_msg_buff *msg_buff;
-
-	msg_buff = kzalloc(sizeof(*msg_buff), GFP_KERNEL);
-	if (!msg_buff)
-		return NULL;
-
-	msg_buff->data = kzalloc(MVSW_PR_MSG_BUFF_CHUNK_SIZE + head_size,
-				 GFP_KERNEL);
-	if (!msg_buff->data) {
-		kfree(msg_buff);
-		return NULL;
-	}
-
-	msg_buff->total = MVSW_PR_MSG_BUFF_CHUNK_SIZE + head_size;
-	msg_buff->free = MVSW_PR_MSG_BUFF_CHUNK_SIZE;
-	msg_buff->used = head_size;
-
-	return msg_buff;
-}
-
-static void *mvsw_msg_buff_data(struct mvsw_msg_buff *msg_buff)
-{
-	return msg_buff->data;
-}
-
-static u32 mvsw_msg_buff_size(const struct mvsw_msg_buff *msg_buff)
-{
-	return msg_buff->used;
-}
-
-static int mvsw_msg_buff_resize(struct mvsw_msg_buff *msg_buff)
-{
-	void *data;
-
-	data = krealloc(msg_buff->data,
-			msg_buff->total + MVSW_PR_MSG_BUFF_CHUNK_SIZE,
-			GFP_KERNEL);
-	if (!data)
-		return -ENOMEM;
-
-	msg_buff->total += MVSW_PR_MSG_BUFF_CHUNK_SIZE;
-	msg_buff->free += MVSW_PR_MSG_BUFF_CHUNK_SIZE;
-	msg_buff->data = data;
-
-	return 0;
-}
-
-static int mvsw_msg_buff_put(struct mvsw_msg_buff *msg_buff,
-			     void *data, u16 size)
-{
-	void *data_ptr;
-	int err;
-
-	if (size > msg_buff->free) {
-		err = mvsw_msg_buff_resize(msg_buff);
-		if (err)
-			return err;
-	}
-	/* point to unused data */
-	data_ptr = msg_buff->data + msg_buff->used;
-
-	/* set the data */
-	memcpy(data_ptr, data, size);
-	msg_buff->used += size;
-	msg_buff->free -= size;
-
-	return 0;
-}
-
-static int mvsw_msg_buff_terminate(struct mvsw_msg_buff *msg_buff)
-{
-	u16 padding_size;
-	void *data_ptr;
-	int err;
-
-	/* the data should be aligned to 4 byte, so calculate
-	 * the padding leaving at least one byte for termination
-	 */
-	padding_size = ALIGN(msg_buff->used + sizeof(u8),
-			     sizeof(u32)) - msg_buff->used;
-	if (msg_buff->free < padding_size) {
-		err = mvsw_msg_buff_resize(msg_buff);
-		if (err)
-			return err;
-	}
-	/* point to unused data */
-	data_ptr = msg_buff->data + msg_buff->used;
-
-	/* terminate buffer by zero byte */
-	memset(data_ptr, 0, padding_size);
-	msg_buff->used += padding_size;
-	msg_buff->free -= padding_size;
-	data_ptr += padding_size;
-
-	return 0;
-}
-
-static void mvsw_msg_buff_destroy(struct mvsw_msg_buff *msg_buff)
-{
-	kfree(msg_buff->data);
-	kfree(msg_buff);
-}
-
-int mvsw_pr_hw_port_info_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_info_get(const struct prestera_port *port,
 			     u16 *fp_id, u32 *hw_id, u32 *dev_id)
 {
 	struct mvsw_msg_port_info_ret resp;
@@ -832,8 +998,11 @@ int mvsw_pr_hw_port_info_get(const struct mvsw_pr_port *port,
 	return 0;
 }
 
-int mvsw_pr_hw_switch_init(struct mvsw_pr_switch *sw)
+int mvsw_pr_hw_switch_init(struct prestera_switch *sw)
 {
+	struct mvsw_msg_keepalive_init_cmd keepalive_init_req = {
+		.pulse_timeout_ms = MVSW_FW_WD_KICK_TIMEOUT
+	};
 	struct mvsw_msg_switch_init_ret resp;
 	struct mvsw_msg_common_request req;
 	int err = 0;
@@ -851,13 +1020,32 @@ int mvsw_pr_hw_switch_init(struct mvsw_pr_switch *sw)
 	sw->mtu_max = resp.mtu_max;
 	sw->lag_max = resp.lag_max;
 	sw->lag_member_max = resp.lag_member_max;
+	sw->size_tbl_router_nexthop = resp.size_tbl_router_nexthop;
 	sw->dev->recv_msg = fw_event_recv;
 	sw->dev->recv_pkt = fw_pkt_recv;
 
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_KEEPALIVE_INIT,
+			       &keepalive_init_req, &resp);
+	if (err)
+		return err;
+
+	INIT_DELAYED_WORK(&sw->dev->keepalive_wdog_work,
+			  mvsw_pr_fw_keepalive_wd_work_fn);
+
+	queue_delayed_work(system_long_wq,
+			   &sw->dev->keepalive_wdog_work,
+			   msecs_to_jiffies(MVSW_FW_WD_KICK_TIMEOUT));
+
 	return err;
 }
 
-int mvsw_pr_hw_switch_ageing_set(const struct mvsw_pr_switch *sw,
+void mvsw_pr_hw_keepalive_fini(const struct prestera_switch *sw)
+{
+	if (sw->dev->running)
+		cancel_delayed_work_sync(&sw->dev->keepalive_wdog_work);
+}
+
+int mvsw_pr_hw_switch_ageing_set(const struct prestera_switch *sw,
 				 u32 ageing_time)
 {
 	struct mvsw_msg_switch_attr_cmd req = {
@@ -868,7 +1056,7 @@ int mvsw_pr_hw_switch_ageing_set(const struct mvsw_pr_switch *sw,
 	return fw_send_req(sw, MVSW_MSG_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_switch_mac_set(const struct mvsw_pr_switch *sw, const u8 *mac)
+int mvsw_pr_hw_switch_mac_set(const struct prestera_switch *sw, const u8 *mac)
 {
 	struct mvsw_msg_switch_attr_cmd req = {
 		.attr = MVSW_MSG_SWITCH_ATTR_MAC,
@@ -879,7 +1067,7 @@ int mvsw_pr_hw_switch_mac_set(const struct mvsw_pr_switch *sw, const u8 *mac)
 	return fw_send_req(sw, MVSW_MSG_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_switch_trap_policer_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_switch_trap_policer_set(const struct prestera_switch *sw,
 				       u8 profile)
 {
 	struct mvsw_msg_switch_attr_cmd req = {
@@ -890,51 +1078,7 @@ int mvsw_pr_hw_switch_trap_policer_set(const struct mvsw_pr_switch *sw,
 	return fw_send_req(sw, MVSW_MSG_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_state_set(const struct mvsw_pr_port *port,
-			      bool admin_state)
-{
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_ADMIN_STATE,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {.admin_state = admin_state ? 1 : 0}
-	};
-
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
-}
-
-int mvsw_pr_hw_port_state_get(const struct mvsw_pr_port *port,
-			      bool *admin_state, bool *oper_state)
-{
-	struct mvsw_msg_port_attr_ret resp;
-	struct mvsw_msg_port_attr_cmd req = {
-		.port = port->hw_id,
-		.dev = port->dev_id
-	};
-	int err;
-
-	if (admin_state) {
-		req.attr = MVSW_MSG_PORT_ATTR_ADMIN_STATE;
-		err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-				       &req, &resp);
-		if (err)
-			return err;
-		*admin_state = resp.param.admin_state != 0;
-	}
-
-	if (oper_state) {
-		req.attr = MVSW_MSG_PORT_ATTR_OPER_STATE;
-		err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-				       &req, &resp);
-		if (err)
-			return err;
-		*oper_state = resp.param.oper_state != 0;
-	}
-
-	return 0;
-}
-
-int mvsw_pr_hw_port_mtu_set(const struct mvsw_pr_port *port, u32 mtu)
+int mvsw_pr_hw_port_mtu_set(const struct prestera_port *port, u32 mtu)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_MTU,
@@ -946,7 +1090,7 @@ int mvsw_pr_hw_port_mtu_set(const struct mvsw_pr_port *port, u32 mtu)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_mtu_get(const struct mvsw_pr_port *port, u32 *mtu)
+int mvsw_pr_hw_port_mtu_get(const struct prestera_port *port, u32 *mtu)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -966,7 +1110,7 @@ int mvsw_pr_hw_port_mtu_get(const struct mvsw_pr_port *port, u32 *mtu)
 	return err;
 }
 
-int mvsw_pr_hw_port_mac_set(const struct mvsw_pr_port *port, char *mac)
+int mvsw_pr_hw_port_mac_set(const struct prestera_port *port, char *mac)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_MAC,
@@ -978,7 +1122,7 @@ int mvsw_pr_hw_port_mac_set(const struct mvsw_pr_port *port, char *mac)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_mac_get(const struct mvsw_pr_port *port, char *mac)
+int mvsw_pr_hw_port_mac_get(const struct prestera_port *port, char *mac)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -998,7 +1142,7 @@ int mvsw_pr_hw_port_mac_get(const struct mvsw_pr_port *port, char *mac)
 	return err;
 }
 
-int mvsw_pr_hw_port_accept_frame_type_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_accept_frame_type_set(const struct prestera_port *port,
 					  enum mvsw_pr_accept_frame_type type)
 {
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1011,7 +1155,7 @@ int mvsw_pr_hw_port_accept_frame_type_set(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_learning_set(const struct mvsw_pr_port *port, bool enable)
+int mvsw_pr_hw_port_learning_set(const struct prestera_port *port, bool enable)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_LEARNING,
@@ -1023,10 +1167,10 @@ int mvsw_pr_hw_port_learning_set(const struct mvsw_pr_port *port, bool enable)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_event_handler_register(struct mvsw_pr_switch *sw,
-				      enum mvsw_pr_event_type type,
-				      void (*cb)(struct mvsw_pr_switch *sw,
-						 struct mvsw_pr_event *evt,
+int mvsw_pr_hw_event_handler_register(struct prestera_switch *sw,
+				      enum prestera_event_type type,
+				      void (*cb)(struct prestera_switch *sw,
+						 struct prestera_event *evt,
 						 void *arg),
 				      void *arg)
 {
@@ -1050,8 +1194,8 @@ int mvsw_pr_hw_event_handler_register(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-void mvsw_pr_hw_event_handler_unregister(struct mvsw_pr_switch *sw,
-					 enum mvsw_pr_event_type type)
+void mvsw_pr_hw_event_handler_unregister(struct prestera_switch *sw,
+					 enum prestera_event_type type)
 {
 	struct mvsw_fw_event_handler *eh;
 
@@ -1064,7 +1208,7 @@ void mvsw_pr_hw_event_handler_unregister(struct mvsw_pr_switch *sw,
 	kfree(eh);
 }
 
-int mvsw_pr_hw_vlan_create(const struct mvsw_pr_switch *sw, u16 vid)
+int mvsw_pr_hw_vlan_create(const struct prestera_switch *sw, u16 vid)
 {
 	struct mvsw_msg_vlan_cmd req = {
 		.vid = vid,
@@ -1073,7 +1217,7 @@ int mvsw_pr_hw_vlan_create(const struct mvsw_pr_switch *sw, u16 vid)
 	return fw_send_req(sw, MVSW_MSG_TYPE_VLAN_CREATE, &req);
 }
 
-int mvsw_pr_hw_vlan_delete(const struct mvsw_pr_switch *sw, u16 vid)
+int mvsw_pr_hw_vlan_delete(const struct prestera_switch *sw, u16 vid)
 {
 	struct mvsw_msg_vlan_cmd req = {
 		.vid = vid,
@@ -1082,7 +1226,7 @@ int mvsw_pr_hw_vlan_delete(const struct mvsw_pr_switch *sw, u16 vid)
 	return fw_send_req(sw, MVSW_MSG_TYPE_VLAN_DELETE, &req);
 }
 
-int mvsw_pr_hw_vlan_port_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_vlan_port_set(const struct prestera_port *port,
 			     u16 vid, bool is_member, bool untagged)
 {
 	struct mvsw_msg_vlan_cmd req = {
@@ -1096,7 +1240,7 @@ int mvsw_pr_hw_vlan_port_set(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_VLAN_PORT_SET, &req);
 }
 
-int mvsw_pr_hw_vlan_port_vid_set(const struct mvsw_pr_port *port, u16 vid)
+int mvsw_pr_hw_vlan_port_vid_set(const struct prestera_port *port, u16 vid)
 {
 	struct mvsw_msg_vlan_cmd req = {
 		.port = port->hw_id,
@@ -1107,7 +1251,7 @@ int mvsw_pr_hw_vlan_port_vid_set(const struct mvsw_pr_port *port, u16 vid)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_VLAN_PVID_SET, &req);
 }
 
-int mvsw_pr_hw_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
+int mvsw_pr_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state)
 {
 	struct mvsw_msg_stp_cmd req = {
 		.port = port->hw_id,
@@ -1119,27 +1263,24 @@ int mvsw_pr_hw_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_STP_PORT_SET, &req);
 }
 
-int mvsw_pr_hw_port_speed_get(const struct mvsw_pr_port *port, u32 *speed)
+int mvsw_pr_hw_port_uc_flood_set(const struct prestera_port *port, bool flood)
 {
-	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_SPEED,
+		.attr = MVSW_MSG_PORT_ATTR_FLOOD,
 		.port = port->hw_id,
-		.dev = port->dev_id
+		.dev = port->dev_id,
+		.param = {
+			.flood = {
+				.type = MVSW_PORT_FLOOD_TYPE_UC,
+				.enable = flood ? 1 : 0,
+			}
+		}
 	};
-	int err;
 
-	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-			       &req, &resp);
-	if (err)
-		return err;
-
-	*speed = resp.param.speed;
-
-	return err;
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_uc_flood_set(const struct mvsw_pr_port *port, bool flood)
+int mvsw_pr_hw_port_mc_flood_set(const struct prestera_port *port, bool flood)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_FLOOD,
@@ -1147,7 +1288,7 @@ int mvsw_pr_hw_port_uc_flood_set(const struct mvsw_pr_port *port, bool flood)
 		.dev = port->dev_id,
 		.param = {
 			.flood = {
-				.type = MVSW_PORT_FLOOD_TYPE_UC,
+				.type = MVSW_PORT_FLOOD_TYPE_MC,
 				.enable = flood ? 1 : 0,
 			}
 		}
@@ -1156,24 +1297,37 @@ int mvsw_pr_hw_port_uc_flood_set(const struct mvsw_pr_port *port, bool flood)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_mc_flood_set(const struct mvsw_pr_port *port, bool flood)
+int prestera_hw_port_srcid_default_set(const struct prestera_port *port,
+				       u32 sourceid)
 {
 	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_FLOOD,
+		.attr = MVSW_MSG_PORT_ATTR_SOURCE_ID_DEFAULT,
 		.port = port->hw_id,
 		.dev = port->dev_id,
 		.param = {
-			.flood = {
-				.type = MVSW_PORT_FLOOD_TYPE_MC,
-				.enable = flood ? 1 : 0,
-			}
+			.source_id_default = sourceid
 		}
 	};
 
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_fdb_add(const struct mvsw_pr_port *port,
+int prestera_hw_port_srcid_filter_set(const struct prestera_port *port,
+				      u32 sourceid)
+{
+	struct mvsw_msg_port_attr_cmd req = {
+		.attr = MVSW_MSG_PORT_ATTR_SOURCE_ID_FILTER,
+		.port = port->hw_id,
+		.dev = port->dev_id,
+		.param = {
+			.source_id_filter = sourceid
+		}
+	};
+
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
+}
+
+int mvsw_pr_hw_fdb_add(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid, bool dynamic)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1191,7 +1345,7 @@ int mvsw_pr_hw_fdb_add(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_ADD, &req);
 }
 
-int mvsw_pr_hw_lag_fdb_add(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_add(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid, bool dynamic)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1206,7 +1360,7 @@ int mvsw_pr_hw_lag_fdb_add(const struct mvsw_pr_switch *sw, u16 lag_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_ADD, &req);
 }
 
-int mvsw_pr_hw_fdb_del(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_fdb_del(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1223,7 +1377,7 @@ int mvsw_pr_hw_fdb_del(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_DELETE, &req);
 }
 
-int mvsw_pr_hw_lag_fdb_del(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_del(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1237,8 +1391,8 @@ int mvsw_pr_hw_lag_fdb_del(const struct mvsw_pr_switch *sw, u16 lag_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_DELETE, &req);
 }
 
-int mvsw_pr_hw_port_cap_get(const struct mvsw_pr_port *port,
-			    struct mvsw_pr_port_caps *caps)
+int mvsw_pr_hw_port_cap_get(const struct prestera_port *port,
+			    struct prestera_port_caps *caps)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1261,8 +1415,10 @@ int mvsw_pr_hw_port_cap_get(const struct mvsw_pr_port *port,
 	return err;
 }
 
-int mvsw_pr_hw_port_remote_cap_get(const struct mvsw_pr_port *port,
-				   u64 *link_mode_bitmap)
+/* TODO: make name, that explicity show relation to PHY */
+int mvsw_pr_hw_port_remote_cap_get(const struct prestera_port *port,
+				   u64 *link_mode_bitmap,
+				   bool *pause, bool *asym_pause)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1278,6 +1434,7 @@ int mvsw_pr_hw_port_remote_cap_get(const struct mvsw_pr_port *port,
 		return err;
 
 	*link_mode_bitmap = resp.param.cap.link_mode;
+	prestera_hw_remote_fc_to_eth(resp.param.cap.fc, pause, asym_pause);
 
 	return err;
 }
@@ -1310,7 +1467,28 @@ static u8 mvsw_mdix_from_eth(u8 mode)
 	return MVSW_PORT_TP_NA;
 }
 
-int mvsw_pr_hw_port_mdix_get(const struct mvsw_pr_port *port, u8 *status,
+static void prestera_hw_remote_fc_to_eth(u8 fc, bool *pause, bool *asym_pause)
+{
+	switch (fc) {
+	case MVSW_FC_SYMMETRIC:
+		*pause = true;
+		*asym_pause = false;
+		break;
+	case MVSW_FC_ASYMMETRIC:
+		*pause = false;
+		*asym_pause = true;
+		break;
+	case MVSW_FC_SYMM_ASYMM:
+		*pause = true;
+		*asym_pause = true;
+		break;
+	default:
+		*pause = false;
+		*asym_pause = false;
+	};
+}
+
+int mvsw_pr_hw_port_mdix_get(const struct prestera_port *port, u8 *status,
 			     u8 *admin_mode)
 {
 	struct mvsw_msg_port_attr_ret resp;
@@ -1332,7 +1510,7 @@ int mvsw_pr_hw_port_mdix_get(const struct mvsw_pr_port *port, u8 *status,
 	return 0;
 }
 
-int mvsw_pr_hw_port_mdix_set(const struct mvsw_pr_port *port, u8 mode)
+int mvsw_pr_hw_port_mdix_set(const struct prestera_port *port, u8 mode)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_MDIX,
@@ -1345,7 +1523,7 @@ int mvsw_pr_hw_port_mdix_set(const struct mvsw_pr_port *port, u8 mode)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_type_get(const struct mvsw_pr_port *port, u8 *type)
+int mvsw_pr_hw_port_type_get(const struct prestera_port *port, u8 *type)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1365,39 +1543,7 @@ int mvsw_pr_hw_port_type_get(const struct mvsw_pr_port *port, u8 *type)
 	return err;
 }
 
-int mvsw_pr_hw_port_fec_get(const struct mvsw_pr_port *port, u8 *fec)
-{
-	struct mvsw_msg_port_attr_ret resp;
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_FEC,
-		.port = port->hw_id,
-		.dev = port->dev_id
-	};
-	int err;
-
-	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-			       &req, &resp);
-	if (err)
-		return err;
-
-	*fec = resp.param.fec;
-
-	return err;
-}
-
-int mvsw_pr_hw_port_fec_set(const struct mvsw_pr_port *port, u8 fec)
-{
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_FEC,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {.fec = fec}
-	};
-
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
-}
-
-int mvsw_pr_hw_fw_log_level_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_fw_log_level_set(const struct prestera_switch *sw,
 				u32 lib, u32 type)
 {
 	struct mvsw_msg_log_lvl_set_cmd req = {
@@ -1413,44 +1559,8 @@ int mvsw_pr_hw_fw_log_level_set(const struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-int mvsw_pr_hw_port_autoneg_set(const struct mvsw_pr_port *port,
-				bool autoneg, u64 link_modes, u8 fec)
-{
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_AUTONEG,
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.param = {.autoneg = {.link_mode = link_modes,
-				      .enable = autoneg ? 1 : 0,
-				      .fec = fec}
-		}
-	};
-
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
-}
-
-int mvsw_pr_hw_port_duplex_get(const struct mvsw_pr_port *port, u8 *duplex)
-{
-	struct mvsw_msg_port_attr_ret resp;
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_DUPLEX,
-		.port = port->hw_id,
-		.dev = port->dev_id
-	};
-	int err;
-
-	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-			       &req, &resp);
-	if (err)
-		return err;
-
-	*duplex = resp.param.duplex;
-
-	return err;
-}
-
-int mvsw_pr_hw_port_stats_get(const struct mvsw_pr_port *port,
-			      struct mvsw_pr_port_stats *stats)
+int mvsw_pr_hw_port_stats_get(const struct prestera_port *port,
+			      struct prestera_port_stats *stats)
 {
 	struct mvsw_msg_port_stats_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1505,7 +1615,7 @@ int mvsw_pr_hw_port_stats_get(const struct mvsw_pr_port *port,
 	return 0;
 }
 
-int mvsw_pr_hw_bridge_create(const struct mvsw_pr_switch *sw, u16 *bridge_id)
+int mvsw_pr_hw_bridge_create(const struct prestera_switch *sw, u16 *bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req;
 	struct mvsw_msg_bridge_ret resp;
@@ -1519,7 +1629,7 @@ int mvsw_pr_hw_bridge_create(const struct mvsw_pr_switch *sw, u16 *bridge_id)
 	return err;
 }
 
-int mvsw_pr_hw_bridge_delete(const struct mvsw_pr_switch *sw, u16 bridge_id)
+int mvsw_pr_hw_bridge_delete(const struct prestera_switch *sw, u16 bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req = {
 		.bridge = bridge_id
@@ -1528,7 +1638,7 @@ int mvsw_pr_hw_bridge_delete(const struct mvsw_pr_switch *sw, u16 bridge_id)
 	return fw_send_req(sw, MVSW_MSG_TYPE_BRIDGE_DELETE, &req);
 }
 
-int mvsw_pr_hw_bridge_port_add(const struct mvsw_pr_port *port, u16 bridge_id)
+int mvsw_pr_hw_bridge_port_add(const struct prestera_port *port, u16 bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req = {
 		.bridge = bridge_id,
@@ -1539,7 +1649,7 @@ int mvsw_pr_hw_bridge_port_add(const struct mvsw_pr_port *port, u16 bridge_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_BRIDGE_PORT_ADD, &req);
 }
 
-int mvsw_pr_hw_bridge_port_delete(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_bridge_port_delete(const struct prestera_port *port,
 				  u16 bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req = {
@@ -1551,7 +1661,7 @@ int mvsw_pr_hw_bridge_port_delete(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_BRIDGE_PORT_DELETE, &req);
 }
 
-int mvsw_pr_hw_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid)
 {
 	struct mvsw_msg_macvlan_cmd req = {
@@ -1564,7 +1674,7 @@ int mvsw_pr_hw_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_MACVLAN_ADD, &req);
 }
 
-int mvsw_pr_hw_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid)
 {
 	struct mvsw_msg_macvlan_cmd req = {
@@ -1577,7 +1687,7 @@ int mvsw_pr_hw_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_MACVLAN_DEL, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_port(const struct mvsw_pr_port *port, u32 mode)
+int mvsw_pr_hw_fdb_flush_port(const struct prestera_port *port, u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
 		.dest_type = MVSW_HW_FDB_ENTRY_TYPE_REG_PORT,
@@ -1591,7 +1701,7 @@ int mvsw_pr_hw_fdb_flush_port(const struct mvsw_pr_port *port, u32 mode)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_lag(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_fdb_flush_lag(const struct prestera_switch *sw, u16 lag_id,
 			     u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1603,7 +1713,7 @@ int mvsw_pr_hw_fdb_flush_lag(const struct mvsw_pr_switch *sw, u16 lag_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_vlan(const struct mvsw_pr_switch *sw, u16 vid,
+int mvsw_pr_hw_fdb_flush_vlan(const struct prestera_switch *sw, u16 vid,
 			      u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1614,7 +1724,7 @@ int mvsw_pr_hw_fdb_flush_vlan(const struct mvsw_pr_switch *sw, u16 vid,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_FLUSH_VLAN, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_port_vlan(const struct mvsw_pr_port *port, u16 vid,
+int mvsw_pr_hw_fdb_flush_port_vlan(const struct prestera_port *port, u16 vid,
 				   u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1630,7 +1740,7 @@ int mvsw_pr_hw_fdb_flush_port_vlan(const struct mvsw_pr_port *port, u16 vid,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT_VLAN, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_lag_vlan(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_fdb_flush_lag_vlan(const struct prestera_switch *sw,
 				  u16 lag_id, u16 vid, u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1643,12 +1753,12 @@ int mvsw_pr_hw_fdb_flush_lag_vlan(const struct mvsw_pr_switch *sw,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT_VLAN, &req);
 }
 
-int mvsw_pr_hw_port_link_mode_get(const struct mvsw_pr_port *port,
-				  u32 *mode)
+int mvsw_pr_hw_port_mac_mode_get(const struct prestera_port *port,
+				 u32 *mode, u32 *speed, u8 *duplex, u8 *fec)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_LINK_MODE,
+		.attr = MVSW_MSG_PORT_ATTR_MAC_MODE,
 		.port = port->hw_id,
 		.dev = port->dev_id
 	};
@@ -1659,25 +1769,84 @@ int mvsw_pr_hw_port_link_mode_get(const struct mvsw_pr_port *port,
 	if (err)
 		return err;
 
-	*mode = resp.param.link_mode;
+	if (mode)
+		*mode = resp.param.link.mac.mode;
+
+	if (speed)
+		*speed = resp.param.link.mac.speed;
+
+	if (duplex)
+		*duplex = resp.param.link.mac.duplex;
+
+	if (fec)
+		*fec = resp.param.link.mac.fec;
 
 	return err;
 }
 
-int mvsw_pr_hw_port_link_mode_set(const struct mvsw_pr_port *port,
-				  u32 mode)
+int mvsw_pr_hw_port_mac_mode_set(const struct prestera_port *port,
+				 bool admin, u32 mode, u8 inband,
+				 u32 speed, u8 duplex, u8 fec)
 {
 	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_LINK_MODE,
+		.attr = MVSW_MSG_PORT_ATTR_MAC_MODE,
 		.port = port->hw_id,
 		.dev = port->dev_id,
-		.param = {.link_mode = mode}
+		.param = {
+			.link = {
+				.mac = {
+					.admin = admin,
+					.mode = mode,
+					.inband = inband,
+					.speed = speed,
+					.duplex = duplex,
+					.fec = fec
+				}
+			}
+		}
 	};
 
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-static int mvsw_pr_iface_to_msg(struct mvsw_pr_iface *iface,
+int mvsw_pr_hw_port_phy_mode_set(const struct prestera_port *port,
+				 bool admin, bool adv, u32 mode, u64 modes)
+{
+	struct mvsw_msg_port_attr_cmd req = {
+		.attr = MVSW_MSG_PORT_ATTR_PHY_MODE,
+		.port = port->hw_id,
+		.dev = port->dev_id,
+		.param = {
+			.link = {
+				.phy = {
+					.admin = admin,
+					.adv_enable = adv ? 1 : 0,
+					.mode = mode,
+					.modes = modes
+				}
+			}
+		}
+	};
+
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
+}
+
+int mvsw_pr_hw_port_storm_control_cfg_set(const struct prestera_port *port,
+					  u32 storm_type,
+					  u32 kbyte_per_sec_rate)
+{
+	struct mvsw_msg_port_storm_control_cfg_set_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
+		.storm_type = storm_type,
+		.kbyte_per_sec_rate = kbyte_per_sec_rate
+	};
+
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_RATE_LIMIT_MODE_SET,
+			   &req);
+}
+
+static int mvsw_pr_iface_to_msg(struct prestera_iface *iface,
 				struct mvsw_msg_iface *msg_if)
 {
 	switch (iface->type) {
@@ -1699,8 +1868,8 @@ static int mvsw_pr_iface_to_msg(struct mvsw_pr_iface *iface,
 	return 0;
 }
 
-int mvsw_pr_hw_rif_create(const struct mvsw_pr_switch *sw,
-			  struct mvsw_pr_iface *iif, u8 *mac, u16 *rif_id)
+int mvsw_pr_hw_rif_create(const struct prestera_switch *sw,
+			  struct prestera_iface *iif, u8 *mac, u16 *rif_id)
 {
 	struct mvsw_msg_rif_cmd req;
 	struct mvsw_msg_rif_ret resp;
@@ -1721,8 +1890,8 @@ int mvsw_pr_hw_rif_create(const struct mvsw_pr_switch *sw,
 	return err;
 }
 
-int mvsw_pr_hw_rif_delete(const struct mvsw_pr_switch *sw, u16 rif_id,
-			  struct mvsw_pr_iface *iif)
+int mvsw_pr_hw_rif_delete(const struct prestera_switch *sw, u16 rif_id,
+			  struct prestera_iface *iif)
 {
 	struct mvsw_msg_rif_cmd req = {
 		.rif_id = rif_id,
@@ -1736,8 +1905,8 @@ int mvsw_pr_hw_rif_delete(const struct mvsw_pr_switch *sw, u16 rif_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_RIF_DELETE, &req);
 }
 
-int mvsw_pr_hw_rif_set(const struct mvsw_pr_switch *sw, u16 *rif_id,
-		       struct mvsw_pr_iface *iif, u8 *mac)
+int mvsw_pr_hw_rif_set(const struct prestera_switch *sw, u16 *rif_id,
+		       struct prestera_iface *iif, u8 *mac)
 {
 	struct mvsw_msg_rif_ret resp;
 	struct mvsw_msg_rif_cmd req = {
@@ -1759,7 +1928,7 @@ int mvsw_pr_hw_rif_set(const struct mvsw_pr_switch *sw, u16 *rif_id,
 	return err;
 }
 
-int mvsw_pr_hw_vr_create(const struct mvsw_pr_switch *sw, u16 *vr_id)
+int mvsw_pr_hw_vr_create(const struct prestera_switch *sw, u16 *vr_id)
 {
 	int err;
 	struct mvsw_msg_vr_ret resp;
@@ -1773,7 +1942,7 @@ int mvsw_pr_hw_vr_create(const struct mvsw_pr_switch *sw, u16 *vr_id)
 	return err;
 }
 
-int mvsw_pr_hw_vr_delete(const struct mvsw_pr_switch *sw, u16 vr_id)
+int mvsw_pr_hw_vr_delete(const struct prestera_switch *sw, u16 vr_id)
 {
 	struct mvsw_msg_vr_cmd req = {
 		.vr_id = vr_id,
@@ -1782,7 +1951,7 @@ int mvsw_pr_hw_vr_delete(const struct mvsw_pr_switch *sw, u16 vr_id)
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_VR_DELETE, &req);
 }
 
-int mvsw_pr_hw_vr_abort(const struct mvsw_pr_switch *sw, u16 vr_id)
+int mvsw_pr_hw_vr_abort(const struct prestera_switch *sw, u16 vr_id)
 {
 	struct mvsw_msg_vr_cmd req = {
 		.vr_id = vr_id,
@@ -1791,7 +1960,7 @@ int mvsw_pr_hw_vr_abort(const struct mvsw_pr_switch *sw, u16 vr_id)
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_VR_ABORT, &req);
 }
 
-int mvsw_pr_hw_lpm_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_lpm_add(const struct prestera_switch *sw, u16 vr_id,
 		       __be32 dst, u32 dst_len, u32 grp_id)
 {
 	struct mvsw_msg_lpm_cmd req = {
@@ -1804,7 +1973,7 @@ int mvsw_pr_hw_lpm_add(const struct mvsw_pr_switch *sw, u16 vr_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_LPM_ADD, &req);
 }
 
-int mvsw_pr_hw_lpm_del(const struct mvsw_pr_switch *sw, u16 vr_id, __be32 dst,
+int mvsw_pr_hw_lpm_del(const struct prestera_switch *sw, u16 vr_id, __be32 dst,
 		       u32 dst_len)
 {
 	struct mvsw_msg_lpm_cmd req = {
@@ -1816,8 +1985,8 @@ int mvsw_pr_hw_lpm_del(const struct mvsw_pr_switch *sw, u16 vr_id, __be32 dst,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_LPM_DELETE, &req);
 }
 
-int mvsw_pr_hw_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
-			      struct mvsw_pr_neigh_info *nhs, u32 grp_id)
+int mvsw_pr_hw_nh_entries_set(const struct prestera_switch *sw, int count,
+			      struct prestera_neigh_info *nhs, u32 grp_id)
 {
 	struct mvsw_msg_nh_cmd req = { .size = count, .grp_id = grp_id };
 	int i, err;
@@ -1835,8 +2004,8 @@ int mvsw_pr_hw_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
 
 /* TODO: more than one nh */
 /* For now "count = 1" supported only */
-int mvsw_pr_hw_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
-			      struct mvsw_pr_neigh_info *nhs, u32 grp_id)
+int mvsw_pr_hw_nh_entries_get(const struct prestera_switch *sw, int count,
+			      struct prestera_neigh_info *nhs, u32 grp_id)
 {
 	struct mvsw_msg_nh_cmd req = { .size = count, .grp_id = grp_id };
 	struct mvsw_msg_nh_ret resp;
@@ -1853,7 +2022,37 @@ int mvsw_pr_hw_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
 	return err;
 }
 
-int mvsw_pr_hw_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nhgrp_blk_get(const struct prestera_switch *sw,
+			     u8 *hw_state, u32 buf_size /* Buffer in bytes */)
+{
+	struct mvsw_msg_nh_chunk_cmd req;
+	static struct mvsw_msg_nh_chunk_ret resp;
+	int err;
+	u32 buf_offset;
+
+	memset(&hw_state[0], 0, buf_size);
+	buf_offset = 0;
+	while (1) {
+		if (buf_offset >= buf_size)
+			break;
+
+		memset(&req, 0, sizeof(req));
+		req.offset = buf_offset * 8; /* 8 bits in u8 */
+		err = fw_send_req_resp(sw, MVSW_MSG_TYPE_ROUTER_NH_GRP_BLK_GET,
+				       &req, &resp);
+		if (err)
+			return err;
+
+		memcpy(&hw_state[buf_offset], &resp.hw_state[0],
+		       buf_offset + PRESTERA_MSG_CHUNK_SIZE > buf_size ?
+			buf_size - buf_offset : PRESTERA_MSG_CHUNK_SIZE);
+		buf_offset += PRESTERA_MSG_CHUNK_SIZE;
+	}
+
+	return err;
+}
+
+int mvsw_pr_hw_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
 			       u32 *grp_id)
 {
 	struct mvsw_msg_nh_grp_cmd req = { .size = nh_count };
@@ -1869,7 +2068,7 @@ int mvsw_pr_hw_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return err;
 }
 
-int mvsw_pr_hw_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
 			       u32 grp_id)
 {
 	struct mvsw_msg_nh_grp_cmd req = {
@@ -1880,14 +2079,14 @@ int mvsw_pr_hw_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_NH_GRP_DELETE, &req);
 }
 
-int mvsw_pr_hw_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy)
+int mvsw_pr_hw_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy)
 {
 	struct mvsw_msg_mp_cmd req = { .hash_policy = hash_policy};
 
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_MP_HASH_SET, &req);
 }
 
-int mvsw_pr_hw_rxtx_init(const struct mvsw_pr_switch *sw, bool use_sdma,
+int mvsw_pr_hw_rxtx_init(const struct prestera_switch *sw, bool use_sdma,
 			 u32 *map_addr)
 {
 	struct mvsw_msg_rxtx_ret resp;
@@ -1906,7 +2105,7 @@ int mvsw_pr_hw_rxtx_init(const struct mvsw_pr_switch *sw, bool use_sdma,
 	return 0;
 }
 
-int mvsw_pr_hw_port_autoneg_restart(struct mvsw_pr_port *port)
+int mvsw_pr_hw_port_autoneg_restart(struct prestera_port *port)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_AUTONEG_RESTART,
@@ -1917,290 +2116,297 @@ int mvsw_pr_hw_port_autoneg_restart(struct mvsw_pr_port *port)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_remote_fc_get(const struct mvsw_pr_port *port,
-				  bool *pause, bool *asym_pause)
+/* ACL API */
+static int acl_rule_add_put_action(struct mvsw_msg_acl_action *action,
+				   struct prestera_acl_hw_action_info *info)
 {
-	struct mvsw_msg_port_attr_ret resp;
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_REMOTE_FC,
-		.port = port->hw_id,
-		.dev = port->dev_id
-	};
-	int err;
-
-	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-			       &req, &resp);
-	if (err)
-		return err;
+	action->id = info->id;
 
-	switch (resp.param.fc) {
-	case MVSW_FC_SYMMETRIC:
-		*pause = true;
-		*asym_pause = false;
+	switch (info->id) {
+	case MVSW_ACL_RULE_ACTION_ACCEPT:
+	case MVSW_ACL_RULE_ACTION_DROP:
+		/* just rule action id, no specific data */
 		break;
-	case MVSW_FC_ASYMMETRIC:
-		*pause = false;
-		*asym_pause = true;
+	case MVSW_ACL_RULE_ACTION_TRAP:
+		action->trap.hw_tc = info->trap.hw_tc;
 		break;
-	case MVSW_FC_SYMM_ASYMM:
-		*pause = true;
-		*asym_pause = true;
+	case MVSW_ACL_RULE_ACTION_JUMP:
+		action->jump.index = info->jump.index;
+		break;
+	case MVSW_ACL_RULE_ACTION_POLICE:
+		action->police.rate = info->police.rate;
+		action->police.burst = info->police.burst;
+		break;
+	case MVSW_ACL_RULE_ACTION_NH:
+		action->nh.nh_id = info->nh;
+		break;
+	case MVSW_ACL_RULE_ACTION_NAT:
+		action->nat.old_addr = info->nat.old_addr;
+		action->nat.new_addr = info->nat.new_addr;
+		action->nat.flags = info->nat.flags;
+		action->nat.port = info->nat.port;
+		action->nat.dev = info->nat.dev;
+		break;
+	case MVSW_ACL_RULE_ACTION_COUNT:
+		action->count.id = info->count.id;
 		break;
 	default:
-		*pause = false;
-		*asym_pause = false;
-	};
+		return -EINVAL;
+	}
 
-	return err;
+	return 0;
 }
 
-/* ACL API */
-int mvsw_pr_hw_acl_ruleset_create(const struct mvsw_pr_switch *sw,
-				  u16 *ruleset_id)
+int prestera_hw_counter_trigger(const struct prestera_switch *sw, u32 block_id)
 {
-	int err;
-	struct mvsw_msg_acl_ruleset_ret resp;
-	struct mvsw_msg_acl_ruleset_cmd req;
+	struct mvsw_msg_counter_cmd req = {
+		.block_id = block_id
+	};
 
-	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_ACL_RULESET_CREATE,
-			       &req, &resp);
-	if (err)
-		return err;
+	return fw_send_req(sw, MVSW_MSG_TYPE_COUNTER_TRIGGER, &req);
+}
 
-	*ruleset_id = resp.id;
-	return 0;
+int prestera_hw_counter_abort(const struct prestera_switch *sw)
+{
+	struct mvsw_msg_counter_cmd req;
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_COUNTER_ABORT, &req);
 }
 
-int mvsw_pr_hw_acl_ruleset_del(const struct mvsw_pr_switch *sw,
-			       u16 ruleset_id)
+int prestera_hw_counters_get(const struct prestera_switch *sw, u32 idx,
+			     u32 *len, bool *done,
+			     struct prestera_counter_stats *stats)
 {
-	struct mvsw_msg_acl_ruleset_cmd req = {
-		.id = ruleset_id,
+	struct mvsw_msg_counter_ret *resp;
+	struct mvsw_msg_counter_cmd req = {
+		.block_id = idx,
+		.num_counters = *len,
 	};
+	size_t size = sizeof(*resp) + sizeof(*resp->stats) * (*len);
+	int err, i;
+
+	resp = kmalloc(size, GFP_KERNEL);
+	if (!resp)
+		return -ENOMEM;
+
+	err = fw_send_nreq_nresp(sw, MVSW_MSG_TYPE_COUNTER_GET,
+				 &req, sizeof(req), resp, size);
+	if (err)
+		goto free_buff;
+
+	for (i = 0; i < resp->num_counters; i++) {
+		stats[i].packets += resp->stats[i].packets;
+		stats[i].bytes += resp->stats[i].bytes;
+	}
+
+	*len = resp->num_counters;
+	*done = resp->done;
 
-	return fw_send_req(sw, MVSW_MSG_TYPE_ACL_RULESET_DELETE, &req);
+free_buff:
+	kfree(resp);
+	return err;
 }
 
-static int acl_rule_add_put_actions(struct mvsw_msg_buff *msg,
-				    struct prestera_acl_rule *rule)
+static u32 prestera_client_to_agent(enum prestera_counter_client client)
 {
-	struct list_head *a_list = prestera_acl_rule_action_list_get(rule);
-	u8 n_actions = prestera_acl_rule_action_len(rule);
-	struct prestera_acl_rule_action_entry *a_entry;
-	__be64 be64;
-	int err;
+	switch (client) {
+	case PRESTERA_COUNTER_CLIENT_LOOKUP_0:
+		return MVSW_COUNTER_CLIENT_LOOKUP_0;
+	case PRESTERA_COUNTER_CLIENT_LOOKUP_1:
+		return MVSW_COUNTER_CLIENT_LOOKUP_1;
+	case PRESTERA_COUNTER_CLIENT_LOOKUP_2:
+		return MVSW_COUNTER_CLIENT_LOOKUP_2;
+	case PRESTERA_COUNTER_CLIENT_LOOKUP_LAST:
+	default:
+		return -ENOTSUPP;
+	}
+}
 
-	err = mvsw_msg_buff_put(msg, &n_actions, sizeof(n_actions));
+int prestera_hw_counter_block_get(const struct prestera_switch *sw,
+				  enum prestera_counter_client client,
+				  u32 *block_id, u32 *offset,
+				  u32 *num_counters)
+{
+	struct mvsw_msg_counter_ret resp;
+	struct mvsw_msg_counter_cmd req = {
+		.client = prestera_client_to_agent(client)
+	};
+	int err = 0;
+
+	if (req.client == -ENOTSUPP)
+		return -ENOTSUPP;
+
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_COUNTER_BLOCK_GET,
+			       &req, &resp);
 	if (err)
 		return err;
 
-	list_for_each_entry(a_entry, a_list, list) {
-		err = mvsw_msg_buff_put(msg, (u8 *)&a_entry->id, sizeof(u8));
-		if (err)
-			return err;
-
-		switch (a_entry->id) {
-		case MVSW_ACL_RULE_ACTION_ACCEPT:
-		case MVSW_ACL_RULE_ACTION_DROP:
-		case MVSW_ACL_RULE_ACTION_TRAP:
-			/* just rule action id, no specific data */
-			break;
-		case MVSW_ACL_RULE_ACTION_POLICE:
-			be64 = cpu_to_be64(a_entry->police.rate);
-			err = mvsw_msg_buff_put(msg, &be64, sizeof(be64));
-			be64 = cpu_to_be64(a_entry->police.burst);
-			err = mvsw_msg_buff_put(msg, &be64, sizeof(be64));
-			break;
-		default:
-			err = -EINVAL;
-		}
-		if (err)
-			return err;
-	}
+	*block_id = resp.block_id;
+	*offset = resp.offset;
+	*num_counters = resp.num_counters;
 
 	return 0;
 }
 
-static int acl_rule_add_put_matches(struct mvsw_msg_buff *msg,
-				    struct prestera_acl_rule *rule)
+int prestera_hw_counter_block_release(const struct prestera_switch *sw,
+				      u32 block_id)
 {
-	struct list_head *m_list = prestera_acl_rule_match_list_get(rule);
-	struct prestera_acl_rule_match_entry *m_entry;
-	int err;
+	struct mvsw_msg_counter_cmd req = {
+		.block_id = block_id
+	};
 
-	list_for_each_entry(m_entry, m_list, list) {
-		err = mvsw_msg_buff_put(msg, (u8 *)&m_entry->type, sizeof(u8));
-		if (err)
-			return err;
+	return fw_send_req(sw, MVSW_MSG_TYPE_COUNTER_BLOCK_RELEASE, &req);
+}
 
-		switch (m_entry->type) {
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u16.key,
-				 sizeof(m_entry->keymask.u16.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u16.mask,
-				 sizeof(m_entry->keymask.u16.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u8.key,
-				 sizeof(m_entry->keymask.u8.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u8.mask,
-				 sizeof(m_entry->keymask.u8.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.mac.key,
-				 sizeof(m_entry->keymask.mac.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.mac.mask,
-				 sizeof(m_entry->keymask.mac.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u32.key,
-				 sizeof(m_entry->keymask.u32.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u32.mask,
-				 sizeof(m_entry->keymask.u32.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u64.key,
-				 sizeof(m_entry->keymask.u64.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u64.mask,
-				 sizeof(m_entry->keymask.u64.mask));
-			break;
-		default:
-			err = -EINVAL;
-		}
-		if (err)
-			return err;
-	}
+int prestera_hw_counter_clear(const struct prestera_switch *sw, u32 block_id,
+			      u32 counter_id)
+{
+	struct mvsw_msg_counter_cmd req = {
+		.block_id = block_id,
+		.num_counters = counter_id,
+	};
 
-	return 0;
+	return fw_send_req(sw, MVSW_MSG_TYPE_COUNTER_CLEAR, &req);
 }
 
-int mvsw_pr_hw_acl_rule_add(const struct mvsw_pr_switch *sw,
-			    struct prestera_acl_rule *rule,
-			    u32 *rule_id)
+int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
+				      unsigned char *mac)
 {
-	int err;
-	struct mvsw_msg_acl_rule_ret resp;
-	u8 hw_tc = prestera_acl_rule_hw_tc_get(rule);
-	u32 priority = prestera_acl_rule_priority_get(rule);
-	u16 ruleset_id = prestera_acl_rule_ruleset_id_get(rule);
-	struct mvsw_msg_acl_rule_cmd *req;
-	struct mvsw_msg_buff *msg;
-
-	msg = mvsw_msg_buff_create(sizeof(*req));
-	if (!msg)
-		return -ENOMEM;
+	struct mvsw_msg_nat_port_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
+	};
+	memcpy(req.neigh_mac, mac, sizeof(req.neigh_mac));
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_NAT_PORT_NEIGH_UPDATE,
+			   &req);
+}
 
-	/* put priority first */
-	err = mvsw_msg_buff_put(msg, &priority, sizeof(priority));
-	if (err)
-		goto free_msg;
+int prestera_hw_nh_mangle_add(const struct prestera_switch *sw, u32 *nh_id)
+{
+	struct mvsw_msg_nh_mangle_cmd req;
+	struct mvsw_msg_nh_mangle_ret resp;
+	int err;
 
-	/* put hw_tc into the message */
-	err = mvsw_msg_buff_put(msg, &hw_tc, sizeof(hw_tc));
+	memset(&req, 0, sizeof(req));
+	memset(&resp, 0, sizeof(resp));
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_ADD, &req,
+			       &resp);
 	if (err)
-		goto free_msg;
+		return err;
 
-	/* put acl actions into the message */
-	err = acl_rule_add_put_actions(msg, rule);
-	if (err)
-		goto free_msg;
+	*nh_id = resp.nh_id;
+	return 0;
+}
 
-	/* put acl matches into the message */
-	err = acl_rule_add_put_matches(msg, rule);
-	if (err)
-		goto free_msg;
+int prestera_hw_nh_mangle_del(const struct prestera_switch *sw, u32 nh_id)
+{
+	struct mvsw_msg_nh_mangle_cmd req;
 
-	/* terminate message */
-	err = mvsw_msg_buff_terminate(msg);
-	if (err)
-		goto free_msg;
+	memset(&req, 0, sizeof(req));
+	req.nh_id = nh_id;
+	return fw_send_req(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_DEL, &req);
+}
 
-	req = (struct mvsw_msg_acl_rule_cmd *)mvsw_msg_buff_data(msg);
+int prestera_hw_nh_mangle_set(const struct prestera_switch *sw, u32 nh_id,
+			      bool l4_src_valid, __be16 l4_src,
+			      bool l4_dst_valid, __be16 l4_dst,
+			      bool sip_valid, struct prestera_ip_addr sip,
+			      bool dip_valid, struct prestera_ip_addr dip,
+			      struct prestera_neigh_info nh)
+{
+	struct mvsw_msg_nh_mangle_cmd req;
+	int err;
 
-	req->ruleset_id = ruleset_id;
+	if (sip.v != MVSW_PR_IPV4 || dip.v != MVSW_PR_IPV4)
+		return -EINVAL;
 
-	err = fw_send_nreq_resp(sw, MVSW_MSG_TYPE_ACL_RULE_ADD, req,
-				mvsw_msg_buff_size(msg), &resp);
+	memset(&req, 0, sizeof(req));
+	req.nh_id = nh_id;
+	req.info.l4_src_valid = l4_src_valid;
+	req.info.l4_dst_valid = l4_dst_valid;
+	req.info.sip_valid = sip_valid;
+	req.info.dip_valid = dip_valid;
+	req.info.l4_src = l4_src;
+	req.info.l4_dst = l4_dst;
+	req.info.sip = sip.u.ipv4;
+	req.info.dip = dip.u.ipv4;
+	req.info.nh.is_active = nh.connected;
+	memcpy(&req.info.nh.mac, nh.ha, ETH_ALEN);
+	err = mvsw_pr_iface_to_msg(&nh.iface, &req.info.nh.oif);
 	if (err)
-		goto free_msg;
+		return err;
 
-	*rule_id = resp.id;
-free_msg:
-	mvsw_msg_buff_destroy(msg);
-	return err;
+	return fw_send_req(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_SET, &req);
 }
 
-int mvsw_pr_hw_acl_rule_del(const struct mvsw_pr_switch *sw, u32 rule_id)
+int prestera_hw_nh_mangle_get(const struct prestera_switch *sw, u32 nh_id,
+			      bool *is_active)
 {
-	struct mvsw_msg_acl_rule_cmd req = {
-		.id = rule_id
-	};
+	struct mvsw_msg_nh_mangle_cmd req;
+	struct mvsw_msg_nh_mangle_ret resp;
+	int err;
+
+	memset(&req, 0, sizeof(req));
+	req.nh_id = nh_id;
+	memset(&resp, 0, sizeof(resp));
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_GET, &req,
+			       &resp);
+	if (err)
+		return err;
 
-	return fw_send_req(sw, MVSW_MSG_TYPE_ACL_RULE_DELETE, &req);
+	*is_active = resp.info.nh.is_active;
+	return 0;
 }
 
-int mvsw_pr_hw_acl_rule_stats_get(const struct mvsw_pr_switch *sw, u32 rule_id,
-				  u64 *packets, u64 *bytes)
+int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id)
 {
 	int err;
-	struct mvsw_msg_acl_rule_stats_ret resp;
-	struct mvsw_msg_acl_rule_cmd req = {
-		.id = rule_id
+	struct mvsw_msg_span_ret resp;
+	struct mvsw_msg_span_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
 	};
 
-	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_ACL_RULE_STATS_GET,
-			       &req, &resp);
+	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_SPAN_GET, &req, &resp);
 	if (err)
 		return err;
 
-	*packets = resp.packets;
-	*bytes = resp.bytes;
+	*span_id = resp.id;
+
 	return 0;
 }
 
-int mvsw_pr_hw_acl_port_bind(const struct mvsw_pr_port *port, u16 ruleset_id)
+int prestera_hw_span_bind(const struct prestera_port *port, u8 span_id)
 {
-	struct mvsw_msg_acl_ruleset_bind_cmd req = {
+	struct mvsw_msg_span_cmd req = {
 		.port = port->hw_id,
 		.dev = port->dev_id,
-		.ruleset_id = ruleset_id,
+		.id = span_id,
 	};
 
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_ACL_PORT_BIND, &req);
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_SPAN_BIND, &req);
 }
 
-int mvsw_pr_hw_acl_port_unbind(const struct mvsw_pr_port *port, u16 ruleset_id)
+int prestera_hw_span_unbind(const struct prestera_port *port)
 {
-	struct mvsw_msg_acl_ruleset_bind_cmd req = {
+	struct mvsw_msg_span_cmd req = {
 		.port = port->hw_id,
 		.dev = port->dev_id,
-		.ruleset_id = ruleset_id,
 	};
 
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_ACL_PORT_UNBIND, &req);
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_SPAN_UNBIND, &req);
 }
 
-int mvsw_pr_hw_lag_member_add(struct mvsw_pr_port *port, u16 lag_id)
+int prestera_hw_span_release(const struct prestera_switch *sw, u8 span_id)
+{
+	struct mvsw_msg_span_cmd req = {
+		.id = span_id
+	};
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_SPAN_RELEASE, &req);
+}
+
+int mvsw_pr_hw_lag_member_add(struct prestera_port *port, u16 lag_id)
 {
 	struct mvsw_msg_lag_cmd req = {
 		.port = port->hw_id,
@@ -2211,7 +2417,7 @@ int mvsw_pr_hw_lag_member_add(struct mvsw_pr_port *port, u16 lag_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_LAG_ADD, &req);
 }
 
-int mvsw_pr_hw_lag_member_del(struct mvsw_pr_port *port, u16 lag_id)
+int mvsw_pr_hw_lag_member_del(struct prestera_port *port, u16 lag_id)
 {
 	struct mvsw_msg_lag_cmd req = {
 		.port = port->hw_id,
@@ -2222,7 +2428,7 @@ int mvsw_pr_hw_lag_member_del(struct mvsw_pr_port *port, u16 lag_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_LAG_DELETE, &req);
 }
 
-int mvsw_pr_hw_lag_member_enable(struct mvsw_pr_port *port, u16 lag_id,
+int mvsw_pr_hw_lag_member_enable(struct prestera_port *port, u16 lag_id,
 				 bool enable)
 {
 	u32 cmd;
@@ -2236,7 +2442,7 @@ int mvsw_pr_hw_lag_member_enable(struct mvsw_pr_port *port, u16 lag_id,
 	return fw_send_req(port->sw, cmd, &req);
 }
 
-int mvsw_pr_hw_lag_member_rif_leave(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_lag_member_rif_leave(const struct prestera_port *port,
 				    u16 lag_id, u16 vr_id)
 {
 	struct mvsw_msg_lag_cmd req = {
@@ -2248,3 +2454,161 @@ int mvsw_pr_hw_lag_member_rif_leave(const struct mvsw_pr_port *port,
 
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_LAG_ROUTER_LEAVE, &req);
 }
+
+int
+prestera_hw_cpu_code_counters_get(const struct prestera_switch *sw, u8 code,
+				  enum prestera_hw_cpu_code_cnt_t counter_type,
+				  u64 *packet_count)
+{
+	struct mvsw_msg_cpu_code_counter_cmd req = {
+		.counter_type = counter_type,
+		.code = code,
+	};
+	struct mvsw_msg_cpu_code_counter_ret resp;
+	int err;
+
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_CPU_CODE_COUNTERS_GET,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	*packet_count = resp.packet_count;
+
+	return 0;
+}
+
+int prestera_hw_vtcam_create(const struct prestera_switch *sw,
+			     u8 lookup, const u32 *keymask, u32 *vtcam_id)
+{
+	int err;
+	struct mvsw_msg_vtcam_ret resp;
+	struct mvsw_msg_vtcam_create_cmd req = {
+		.lookup = lookup,
+	};
+
+	if (keymask)
+		memcpy(req.keymask, keymask, sizeof(req.keymask));
+	else
+		memset(req.keymask, 0, sizeof(req.keymask));
+
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_VTCAM_CREATE, &req, &resp);
+	if (err)
+		return err;
+
+	*vtcam_id = resp.vtcam_id;
+	return 0;
+}
+
+int prestera_hw_vtcam_destroy(const struct prestera_switch *sw, u32 vtcam_id)
+{
+	struct mvsw_msg_vtcam_destroy_cmd req = {
+		.vtcam_id = vtcam_id,
+	};
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_DESTROY, &req);
+}
+
+int prestera_hw_vtcam_rule_add(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 prio, void *key, void *keymask,
+			       struct prestera_acl_hw_action_info *act,
+			       u8 n_act, u32 *rule_id)
+{
+	struct mvsw_msg_acl_action *actions_msg;
+	struct mvsw_msg_vtcam_rule_add_cmd *req;
+	struct mvsw_msg_vtcam_ret resp;
+	void *buff;
+	u32 size;
+	int err;
+	u8 i;
+
+	size = sizeof(*req) + sizeof(*actions_msg) * n_act;
+
+	buff = kzalloc(size, GFP_KERNEL);
+	if (!buff)
+		return -ENOMEM;
+
+	req = buff;
+	req->n_act = n_act;
+	actions_msg = buff + sizeof(*req);
+
+	/* put acl matches into the message */
+	memcpy(req->key, key, sizeof(req->key));
+	memcpy(req->keymask, keymask, sizeof(req->keymask));
+
+	/* put acl actions into the message */
+	for (i = 0; i < n_act; i++) {
+		err = acl_rule_add_put_action(&actions_msg[i], &act[i]);
+		if (err)
+			goto free_buff;
+	}
+
+	req->vtcam_id = vtcam_id;
+	req->prio = prio;
+
+	err = fw_send_nreq_resp(sw, MVSW_MSG_TYPE_VTCAM_RULE_ADD, req,
+				size, &resp);
+	if (err)
+		goto free_buff;
+
+	*rule_id = resp.rule_id;
+free_buff:
+	kfree(buff);
+	return err;
+}
+
+int prestera_hw_vtcam_rule_del(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id)
+{
+	struct mvsw_msg_vtcam_rule_del_cmd req = {
+		.vtcam_id = vtcam_id,
+		.id = rule_id
+	};
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_RULE_DELETE, &req);
+}
+
+int prestera_hw_vtcam_iface_bind(const struct prestera_switch *sw,
+				 struct prestera_acl_iface *iface,
+				 u32 vtcam_id, u16 pcl_id)
+{
+	struct mvsw_msg_vtcam_bind_cmd req = {
+		.vtcam_id = vtcam_id,
+		.type = iface->type,
+		.pcl_id = pcl_id
+	};
+
+	if (iface->type == PRESTERA_ACL_IFACE_TYPE_PORT) {
+		req.port.dev_id = iface->port->dev_id;
+		req.port.hw_id = iface->port->hw_id;
+	} else {
+		req.index = iface->index;
+	}
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_IFACE_BIND, &req);
+}
+
+int prestera_hw_vtcam_iface_unbind(const struct prestera_switch *sw,
+				   struct prestera_acl_iface *iface,
+				   u32 vtcam_id)
+{
+	struct mvsw_msg_vtcam_bind_cmd req = {
+		.vtcam_id = vtcam_id,
+		.type = iface->type,
+	};
+
+	if (iface->type == PRESTERA_ACL_IFACE_TYPE_PORT) {
+		req.port.dev_id = iface->port->dev_id;
+		req.port.hw_id = iface->port->hw_id;
+	} else {
+		req.index = iface->index;
+	}
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_IFACE_UNBIND, &req);
+}
+
+int prestera_hw_switch_reset(struct prestera_switch *sw)
+{
+	struct mvsw_msg_common_request req;
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_SWITCH_RESET, &req);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.h b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
index ad6c4da..be6636a 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
@@ -1,8 +1,5 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _MVSW_PRESTERA_HW_H_
 #define _MVSW_PRESTERA_HW_H_
@@ -16,6 +13,22 @@ enum mvsw_pr_accept_frame_type {
 };
 
 enum {
+	PRESTERA_MAC_MODE_INTERNAL,
+	PRESTERA_MAC_MODE_SGMII,
+	PRESTERA_MAC_MODE_1000BASE_X,
+	PRESTERA_MAC_MODE_KR,
+	PRESTERA_MAC_MODE_KR2,
+	PRESTERA_MAC_MODE_KR4,
+	PRESTERA_MAC_MODE_CR,
+	PRESTERA_MAC_MODE_CR2,
+	PRESTERA_MAC_MODE_CR4,
+	PRESTERA_MAC_MODE_SR_LR,
+	PRESTERA_MAC_MODE_SR_LR2,
+	PRESTERA_MAC_MODE_SR_LR4,
+	PRESTERA_MAC_MODE_MAX
+};
+
+enum {
 	MVSW_LINK_MODE_10baseT_Half_BIT,
 	MVSW_LINK_MODE_10baseT_Full_BIT,
 	MVSW_LINK_MODE_100baseT_Half_BIT,
@@ -71,7 +84,8 @@ enum {
 
 enum {
 	MVSW_PORT_DUPLEX_HALF,
-	MVSW_PORT_DUPLEX_FULL
+	MVSW_PORT_DUPLEX_FULL,
+	MVSW_PORT_DUPLEX_MAX
 };
 
 enum {
@@ -135,6 +149,8 @@ enum {
 	MVSW_FW_LOG_LIB_PPU,
 	MVSW_FW_LOG_LIB_EXACT_MATCH_MANAGER,
 	MVSW_FW_LOG_LIB_MAC_SEC,
+	MVSW_FW_LOG_LIB_PTP_MANAGER,
+	MVSW_FW_LOG_LIB_HSR_PRP,
 	MVSW_FW_LOG_LIB_ALL,
 
 	MVSW_FW_LOG_LIB_MAX
@@ -150,175 +166,240 @@ enum {
 	MVSW_FW_LOG_TYPE_MAX
 };
 
-struct mvsw_pr_switch;
-struct mvsw_pr_port;
-struct mvsw_pr_port_stats;
-struct mvsw_pr_port_caps;
+enum {
+	MVSW_PORT_STORM_CTL_TYPE_BC = 0,
+	MVSW_PORT_STORM_CTL_TYPE_UC_UNK = 1,
+	MVSW_PORT_STORM_CTL_TYPE_MC = 2
+};
+
+enum prestera_hw_cpu_code_cnt_t {
+	PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP = 0,
+	PRESTERA_HW_CPU_CODE_CNT_TYPE_TRAP = 1,
+};
+
+struct prestera_switch;
+struct prestera_port;
+struct prestera_port_stats;
+struct prestera_port_caps;
 struct prestera_acl_rule;
-struct mvsw_pr_iface;
-struct mvsw_pr_neigh_info;
 
-enum mvsw_pr_event_type;
-struct mvsw_pr_event;
+struct prestera_iface;
+struct prestera_neigh_info;
+struct prestera_counter_stats;
+struct prestera_acl_iface;
+
+enum prestera_counter_client;
+enum prestera_event_type;
+struct prestera_event;
 
 /* Switch API */
-int mvsw_pr_hw_switch_init(struct mvsw_pr_switch *sw);
-int mvsw_pr_hw_switch_ageing_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_switch_init(struct prestera_switch *sw);
+int prestera_hw_switch_reset(struct prestera_switch *sw);
+int mvsw_pr_hw_switch_ageing_set(const struct prestera_switch *sw,
 				 u32 ageing_time);
-int mvsw_pr_hw_switch_mac_set(const struct mvsw_pr_switch *sw, const u8 *mac);
-int mvsw_pr_hw_switch_trap_policer_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_switch_mac_set(const struct prestera_switch *sw, const u8 *mac);
+int mvsw_pr_hw_switch_trap_policer_set(const struct prestera_switch *sw,
 				       u8 profile);
 
 /* Port API */
-int mvsw_pr_hw_port_info_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_info_get(const struct prestera_port *port,
 			     u16 *fp_id, u32 *hw_id, u32 *dev_id);
-int mvsw_pr_hw_port_state_set(const struct mvsw_pr_port *port,
-			      bool admin_state);
-int mvsw_pr_hw_port_state_get(const struct mvsw_pr_port *port,
-			      bool *admin_state, bool *oper_state);
-int mvsw_pr_hw_port_mtu_set(const struct mvsw_pr_port *port, u32 mtu);
-int mvsw_pr_hw_port_mtu_get(const struct mvsw_pr_port *port, u32 *mtu);
-int mvsw_pr_hw_port_mac_set(const struct mvsw_pr_port *port, char *mac);
-int mvsw_pr_hw_port_mac_get(const struct mvsw_pr_port *port, char *mac);
-int mvsw_pr_hw_port_accept_frame_type_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_mtu_set(const struct prestera_port *port, u32 mtu);
+int mvsw_pr_hw_port_mtu_get(const struct prestera_port *port, u32 *mtu);
+int mvsw_pr_hw_port_mac_set(const struct prestera_port *port, char *mac);
+int mvsw_pr_hw_port_mac_get(const struct prestera_port *port, char *mac);
+int mvsw_pr_hw_port_accept_frame_type_set(const struct prestera_port *port,
 					  enum mvsw_pr_accept_frame_type type);
-int mvsw_pr_hw_port_learning_set(const struct mvsw_pr_port *port, bool enable);
-int mvsw_pr_hw_port_speed_get(const struct mvsw_pr_port *port, u32 *speed);
-int mvsw_pr_hw_port_uc_flood_set(const struct mvsw_pr_port *port, bool flood);
-int mvsw_pr_hw_port_mc_flood_set(const struct mvsw_pr_port *port, bool flood);
-int mvsw_pr_hw_port_cap_get(const struct mvsw_pr_port *port,
-			    struct mvsw_pr_port_caps *caps);
-int mvsw_pr_hw_port_remote_cap_get(const struct mvsw_pr_port *port,
-				   u64 *link_mode_bitmap);
-int mvsw_pr_hw_port_remote_fc_get(const struct mvsw_pr_port *port,
-				  bool *pause, bool *asym_pause);
-int mvsw_pr_hw_port_type_get(const struct mvsw_pr_port *port, u8 *type);
-int mvsw_pr_hw_port_fec_get(const struct mvsw_pr_port *port, u8 *fec);
-int mvsw_pr_hw_port_fec_set(const struct mvsw_pr_port *port, u8 fec);
-int mvsw_pr_hw_port_autoneg_set(const struct mvsw_pr_port *port,
-				bool autoneg, u64 link_modes, u8 fec);
-int mvsw_pr_hw_port_duplex_get(const struct mvsw_pr_port *port, u8 *duplex);
-int mvsw_pr_hw_port_stats_get(const struct mvsw_pr_port *port,
-			      struct mvsw_pr_port_stats *stats);
-int mvsw_pr_hw_port_link_mode_get(const struct mvsw_pr_port *port,
-				  u32 *mode);
-int mvsw_pr_hw_port_link_mode_set(const struct mvsw_pr_port *port,
-				  u32 mode);
-int mvsw_pr_hw_port_mdix_get(const struct mvsw_pr_port *port, u8 *status,
+int mvsw_pr_hw_port_learning_set(const struct prestera_port *port, bool enable);
+int mvsw_pr_hw_port_uc_flood_set(const struct prestera_port *port, bool flood);
+int mvsw_pr_hw_port_mc_flood_set(const struct prestera_port *port, bool flood);
+int prestera_hw_port_srcid_default_set(const struct prestera_port *port,
+				       u32 sourceid);
+int prestera_hw_port_srcid_filter_set(const struct prestera_port *port,
+				      u32 sourceid);
+int mvsw_pr_hw_port_cap_get(const struct prestera_port *port,
+			    struct prestera_port_caps *caps);
+int mvsw_pr_hw_port_remote_cap_get(const struct prestera_port *port,
+				   u64 *link_mode_bitmap,
+				   bool *pause, bool *asym_pause);
+int mvsw_pr_hw_port_type_get(const struct prestera_port *port, u8 *type);
+int mvsw_pr_hw_port_stats_get(const struct prestera_port *port,
+			      struct prestera_port_stats *stats);
+int mvsw_pr_hw_port_mac_mode_get(const struct prestera_port *port,
+				 u32 *mode, u32 *speed, u8 *duplex, u8 *fec);
+int mvsw_pr_hw_port_mac_mode_set(const struct prestera_port *port,
+				 bool admin, u32 mode, u8 inband,
+				 u32 speed, u8 duplex, u8 fec);
+int mvsw_pr_hw_port_phy_mode_set(const struct prestera_port *port,
+				 bool admin, bool adv, u32 mode, u64 modes);
+int mvsw_pr_hw_port_mdix_get(const struct prestera_port *port, u8 *status,
 			     u8 *admin_mode);
-int mvsw_pr_hw_port_mdix_set(const struct mvsw_pr_port *port, u8 mode);
-int mvsw_pr_hw_port_autoneg_restart(struct mvsw_pr_port *port);
+int mvsw_pr_hw_port_mdix_set(const struct prestera_port *port, u8 mode);
+int mvsw_pr_hw_port_autoneg_restart(struct prestera_port *port);
+
+int mvsw_pr_hw_port_storm_control_cfg_set(const struct prestera_port *port,
+					  u32 storm_type,
+					  u32 kbyte_per_sec_rate);
 
 /* Vlan API */
-int mvsw_pr_hw_vlan_create(const struct mvsw_pr_switch *sw, u16 vid);
-int mvsw_pr_hw_vlan_delete(const struct mvsw_pr_switch *sw, u16 vid);
-int mvsw_pr_hw_vlan_port_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_vlan_create(const struct prestera_switch *sw, u16 vid);
+int mvsw_pr_hw_vlan_delete(const struct prestera_switch *sw, u16 vid);
+int mvsw_pr_hw_vlan_port_set(const struct prestera_port *port,
 			     u16 vid, bool is_member, bool untagged);
-int mvsw_pr_hw_vlan_port_vid_set(const struct mvsw_pr_port *port, u16 vid);
+int mvsw_pr_hw_vlan_port_vid_set(const struct prestera_port *port, u16 vid);
 
 /* FDB API */
-int mvsw_pr_hw_fdb_add(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_fdb_add(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid, bool dynamic);
-int mvsw_pr_hw_fdb_del(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_fdb_del(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid);
-int mvsw_pr_hw_fdb_flush_port(const struct mvsw_pr_port *port, u32 mode);
-int mvsw_pr_hw_fdb_flush_vlan(const struct mvsw_pr_switch *sw, u16 vid,
+int mvsw_pr_hw_fdb_flush_port(const struct prestera_port *port, u32 mode);
+int mvsw_pr_hw_fdb_flush_vlan(const struct prestera_switch *sw, u16 vid,
 			      u32 mode);
-int mvsw_pr_hw_fdb_flush_port_vlan(const struct mvsw_pr_port *port, u16 vid,
+int mvsw_pr_hw_fdb_flush_port_vlan(const struct prestera_port *port, u16 vid,
 				   u32 mode);
-int mvsw_pr_hw_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid);
-int mvsw_pr_hw_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid);
 
 /* Bridge API */
-int mvsw_pr_hw_bridge_create(const struct mvsw_pr_switch *sw, u16 *bridge_id);
-int mvsw_pr_hw_bridge_delete(const struct mvsw_pr_switch *sw, u16 bridge_id);
-int mvsw_pr_hw_bridge_port_add(const struct mvsw_pr_port *port, u16 bridge_id);
-int mvsw_pr_hw_bridge_port_delete(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_bridge_create(const struct prestera_switch *sw, u16 *bridge_id);
+int mvsw_pr_hw_bridge_delete(const struct prestera_switch *sw, u16 bridge_id);
+int mvsw_pr_hw_bridge_port_add(const struct prestera_port *port, u16 bridge_id);
+int mvsw_pr_hw_bridge_port_delete(const struct prestera_port *port,
 				  u16 bridge_id);
 
 /* STP API */
-int mvsw_pr_hw_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state);
-
-/* ACL API */
-int mvsw_pr_hw_acl_ruleset_create(const struct mvsw_pr_switch *sw,
-				  u16 *ruleset_id);
-int mvsw_pr_hw_acl_ruleset_del(const struct mvsw_pr_switch *sw,
-			       u16 ruleset_id);
-int mvsw_pr_hw_acl_rule_add(const struct mvsw_pr_switch *sw,
-			    struct prestera_acl_rule *rule,
-			    u32 *rule_id);
-int mvsw_pr_hw_acl_rule_del(const struct mvsw_pr_switch *sw, u32 rule_id);
-int mvsw_pr_hw_acl_rule_stats_get(const struct mvsw_pr_switch *sw, u32 rule_id,
-				  u64 *packets, u64 *bytes);
-int mvsw_pr_hw_acl_port_bind(const struct mvsw_pr_port *port, u16 ruleset_id);
-int mvsw_pr_hw_acl_port_unbind(const struct mvsw_pr_port *port, u16 ruleset_id);
+int mvsw_pr_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state);
+
+/* Counter API */
+int prestera_hw_counter_trigger(const struct prestera_switch *sw, u32 block_id);
+int prestera_hw_counter_abort(const struct prestera_switch *sw);
+int prestera_hw_counters_get(const struct prestera_switch *sw, u32 idx,
+			     u32 *len, bool *done,
+			     struct prestera_counter_stats *stats);
+int prestera_hw_counter_block_get(const struct prestera_switch *sw,
+				  enum prestera_counter_client client,
+				  u32 *block_id, u32 *offset,
+				  u32 *num_counters);
+int prestera_hw_counter_block_release(const struct prestera_switch *sw,
+				      u32 block_id);
+int prestera_hw_counter_clear(const struct prestera_switch *sw, u32 block_id,
+			      u32 counter_id);
+
+/* vTCAM API */
+int prestera_hw_vtcam_create(const struct prestera_switch *sw,
+			     u8 lookup, const u32 *keymask, u32 *vtcam_id);
+int prestera_hw_vtcam_rule_add(const struct prestera_switch *sw, u32 vtcam_id,
+			       u32 prio, void *key, void *keymask,
+			       struct prestera_acl_hw_action_info *act,
+			       u8 n_act, u32 *rule_id);
+int prestera_hw_vtcam_rule_del(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id);
+int prestera_hw_vtcam_destroy(const struct prestera_switch *sw, u32 vtcam_id);
+int prestera_hw_vtcam_iface_bind(const struct prestera_switch *sw,
+				 struct prestera_acl_iface *iface,
+				 u32 vtcam_id, u16 pcl_id);
+int prestera_hw_vtcam_iface_unbind(const struct prestera_switch *sw,
+				   struct prestera_acl_iface *iface,
+				   u32 vtcam_id);
+
+/* NAT API */
+int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
+				      unsigned char *mac);
+int prestera_hw_nh_mangle_add(const struct prestera_switch *sw, u32 *nh_id);
+int prestera_hw_nh_mangle_del(const struct prestera_switch *sw, u32 nh_id);
+int prestera_hw_nh_mangle_set(const struct prestera_switch *sw, u32 nh_id,
+			      bool l4_src_valid, __be16 l4_src,
+			      bool l4_dst_valid, __be16 l4_dst,
+			      bool sip_valid, struct prestera_ip_addr sip,
+			      bool dip_valid, struct prestera_ip_addr dip,
+			      struct prestera_neigh_info nh);
+int prestera_hw_nh_mangle_get(const struct prestera_switch *sw, u32 nh_id,
+			      bool *is_active);
+
+/* SPAN API */
+int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id);
+int prestera_hw_span_bind(const struct prestera_port *port, u8 span_id);
+int prestera_hw_span_unbind(const struct prestera_port *port);
+int prestera_hw_span_release(const struct prestera_switch *sw, u8 span_id);
 
 /* Router API */
-int mvsw_pr_hw_rif_create(const struct mvsw_pr_switch *sw,
-			  struct mvsw_pr_iface *iif, u8 *mac, u16 *rif_id);
-int mvsw_pr_hw_rif_delete(const struct mvsw_pr_switch *sw, u16 rif_id,
-			  struct mvsw_pr_iface *iif);
-int mvsw_pr_hw_rif_set(const struct mvsw_pr_switch *sw, u16 *rif_id,
-		       struct mvsw_pr_iface *iif, u8 *mac);
+int mvsw_pr_hw_rif_create(const struct prestera_switch *sw,
+			  struct prestera_iface *iif, u8 *mac, u16 *rif_id);
+int mvsw_pr_hw_rif_delete(const struct prestera_switch *sw, u16 rif_id,
+			  struct prestera_iface *iif);
+int mvsw_pr_hw_rif_set(const struct prestera_switch *sw, u16 *rif_id,
+		       struct prestera_iface *iif, u8 *mac);
 
 /* Virtual Router API */
-int mvsw_pr_hw_vr_create(const struct mvsw_pr_switch *sw, u16 *vr_id);
-int mvsw_pr_hw_vr_delete(const struct mvsw_pr_switch *sw, u16 vr_id);
-int mvsw_pr_hw_vr_abort(const struct mvsw_pr_switch *sw, u16 vr_id);
+int mvsw_pr_hw_vr_create(const struct prestera_switch *sw, u16 *vr_id);
+int mvsw_pr_hw_vr_delete(const struct prestera_switch *sw, u16 vr_id);
+int mvsw_pr_hw_vr_abort(const struct prestera_switch *sw, u16 vr_id);
 
 /* LPM API */
-int mvsw_pr_hw_lpm_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_lpm_add(const struct prestera_switch *sw, u16 vr_id,
 		       __be32 dst, u32 dst_len, u32 grp_id);
-int mvsw_pr_hw_lpm_del(const struct mvsw_pr_switch *sw, u16 vr_id, __be32 dst,
+int mvsw_pr_hw_lpm_del(const struct prestera_switch *sw, u16 vr_id, __be32 dst,
 		       u32 dst_len);
 
 /* NH API */
-int mvsw_pr_hw_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
-			      struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_hw_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
-			      struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_hw_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nh_entries_set(const struct prestera_switch *sw, int count,
+			      struct prestera_neigh_info *nhs, u32 grp_id);
+int mvsw_pr_hw_nh_entries_get(const struct prestera_switch *sw, int count,
+			      struct prestera_neigh_info *nhs, u32 grp_id);
+int mvsw_pr_hw_nhgrp_blk_get(const struct prestera_switch *sw,
+			     u8 *hw_state, u32 buf_size /* Buffer in bytes */);
+int mvsw_pr_hw_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
 			       u32 *grp_id);
-int mvsw_pr_hw_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
 			       u32 grp_id);
 
 /* MP API */
-int mvsw_pr_hw_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy);
+int mvsw_pr_hw_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy);
 
 /* LAG API */
-int mvsw_pr_hw_lag_member_add(struct mvsw_pr_port *port, u16 lag_id);
-int mvsw_pr_hw_lag_member_del(struct mvsw_pr_port *port, u16 lag_id);
-int mvsw_pr_hw_lag_member_enable(struct mvsw_pr_port *port, u16 lag_id,
+int mvsw_pr_hw_lag_member_add(struct prestera_port *port, u16 lag_id);
+int mvsw_pr_hw_lag_member_del(struct prestera_port *port, u16 lag_id);
+int mvsw_pr_hw_lag_member_enable(struct prestera_port *port, u16 lag_id,
 				 bool enable);
-int mvsw_pr_hw_lag_fdb_add(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_add(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid, bool dynamic);
-int mvsw_pr_hw_lag_fdb_del(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_del(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid);
-int mvsw_pr_hw_fdb_flush_lag(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_fdb_flush_lag(const struct prestera_switch *sw, u16 lag_id,
 			     u32 mode);
-int mvsw_pr_hw_fdb_flush_lag_vlan(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_fdb_flush_lag_vlan(const struct prestera_switch *sw,
 				  u16 lag_id, u16 vid, u32 mode);
-int mvsw_pr_hw_lag_member_rif_leave(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_lag_member_rif_leave(const struct prestera_port *port,
 				    u16 lag_id, u16 vr_id);
 
 /* Event handlers */
-int mvsw_pr_hw_event_handler_register(struct mvsw_pr_switch *sw,
-				      enum mvsw_pr_event_type type,
-				      void (*cb)(struct mvsw_pr_switch *sw,
-						 struct mvsw_pr_event *evt,
+int mvsw_pr_hw_event_handler_register(struct prestera_switch *sw,
+				      enum prestera_event_type type,
+				      void (*cb)(struct prestera_switch *sw,
+						 struct prestera_event *evt,
 						 void *arg),
 				      void *arg);
 
-void mvsw_pr_hw_event_handler_unregister(struct mvsw_pr_switch *sw,
-					 enum mvsw_pr_event_type type);
+void mvsw_pr_hw_event_handler_unregister(struct prestera_switch *sw,
+					 enum prestera_event_type type);
 
 /* FW Log API */
-int mvsw_pr_hw_fw_log_level_set(const struct mvsw_pr_switch *sw, u32 lib,
+int mvsw_pr_hw_fw_log_level_set(const struct prestera_switch *sw, u32 lib,
 				u32 type);
 
-int mvsw_pr_hw_rxtx_init(const struct mvsw_pr_switch *sw, bool use_sdma,
+int mvsw_pr_hw_rxtx_init(const struct prestera_switch *sw, bool use_sdma,
 			 u32 *map_addr);
 
+/* FW Keepalive/ Watchdog API */
+void mvsw_pr_hw_keepalive_fini(const struct prestera_switch *sw);
+
+/* HW trap/drop counters API */
+int
+prestera_hw_cpu_code_counters_get(const struct prestera_switch *sw, u8 code,
+				  enum prestera_hw_cpu_code_cnt_t counter_type,
+				  u64 *packet_count);
+
 #endif /* _MVSW_PRESTERA_HW_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_log.c b/drivers/net/ethernet/marvell/prestera/prestera_log.c
index bf2fb60..19f9bdd 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_log.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_log.c
@@ -1,8 +1,6 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
 #include "prestera_log.h"
 
 static const char unknown[] = "UNKNOWN";
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_log.h b/drivers/net/ethernet/marvell/prestera/prestera_log.h
index aacb296..6fc8aa2 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_log.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_log.h
@@ -1,8 +1,5 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _MVSW_PRESTERA_LOG_H_
 #define _MVSW_PRESTERA_LOG_H_
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_main.c b/drivers/net/ethernet/marvell/prestera/prestera_main.c
index 05c9dc8..32d90db 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_main.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_main.c
@@ -1,8 +1,6 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/list.h>
@@ -24,323 +22,52 @@
 #include "prestera_hw.h"
 #include "prestera_debugfs.h"
 #include "prestera_devlink.h"
+#include "prestera_ethtool.h"
 #include "prestera_dsa.h"
 #include "prestera_rxtx.h"
 #include "prestera_drv_ver.h"
+#include "prestera_counter.h"
 
 static u8 trap_policer_profile = 1;
 
-#define MVSW_PR_MTU_DEFAULT 1536
-#define MVSW_PR_MAC_ADDR_OFFSET 4
+#define PRESTERA_MTU_DEFAULT 1536
+#define PRESTERA_MAC_ADDR_OFFSET 4
 
 #define PORT_STATS_CACHE_TIMEOUT_MS	(msecs_to_jiffies(1000))
-#define PORT_STATS_CNT	(sizeof(struct mvsw_pr_port_stats) / sizeof(u64))
-#define PORT_STATS_IDX(name) \
-	(offsetof(struct mvsw_pr_port_stats, name) / sizeof(u64))
-#define PORT_STATS_FIELD(name)	\
-	[PORT_STATS_IDX(name)] = __stringify(name)
 
 static struct list_head switches_registered;
 
-static const char mvsw_driver_kind[] = "prestera_sw";
-static const char mvsw_driver_name[] = "mvsw_switchdev";
-static const char mvsw_driver_version[] = PRESTERA_DRV_VER;
-
-#define mvsw_dev(sw)		((sw)->dev->dev)
-#define mvsw_dev_name(sw)	dev_name((sw)->dev->dev)
+static const char prestera_driver_name[] = "mvsw_switchdev";
 
-static struct workqueue_struct *mvsw_pr_wq;
+#define prestera_dev(sw)	((sw)->dev->dev)
 
-struct mvsw_pr_link_mode {
-	enum ethtool_link_mode_bit_indices eth_mode;
-	u32 speed;
-	u64 pr_mask;
-	u8 duplex;
-	u8 port_type;
-};
+static struct workqueue_struct *prestera_wq;
 
-static const struct mvsw_pr_link_mode
-mvsw_pr_link_modes[MVSW_LINK_MODE_MAX] = {
-	[MVSW_LINK_MODE_10baseT_Half_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Half_BIT,
-		.speed = 10,
-		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Half_BIT,
-		.duplex = MVSW_PORT_DUPLEX_HALF,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_10baseT_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Full_BIT,
-		.speed = 10,
-		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_100baseT_Half_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Half_BIT,
-		.speed = 100,
-		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Half_BIT,
-		.duplex = MVSW_PORT_DUPLEX_HALF,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_100baseT_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Full_BIT,
-		.speed = 100,
-		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_1000baseT_Half_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Half_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Half_BIT,
-		.duplex = MVSW_PORT_DUPLEX_HALF,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_1000baseT_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Full_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_1000baseX_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_1000baseX_Full_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseX_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_1000baseKX_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_1000baseKX_Full_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseKX_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_2500baseX_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_2500baseX_Full_BIT,
-		.speed = 2500,
-		.pr_mask = 1 << MVSW_LINK_MODE_2500baseX_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-	},
-	[MVSW_LINK_MODE_10GbaseKR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_10000baseKR_Full_BIT,
-		.speed = 10000,
-		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseKR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_10GbaseSR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_10000baseSR_Full_BIT,
-		.speed = 10000,
-		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseSR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_10GbaseLR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_10000baseLR_Full_BIT,
-		.speed = 10000,
-		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseLR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_20GbaseKR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_20000baseKR2_Full_BIT,
-		.speed = 20000,
-		.pr_mask = 1 << MVSW_LINK_MODE_20GbaseKR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_25GbaseCR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_25000baseCR_Full_BIT,
-		.speed = 25000,
-		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseCR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	},
-	[MVSW_LINK_MODE_25GbaseKR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_25000baseKR_Full_BIT,
-		.speed = 25000,
-		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseKR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_25GbaseSR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_25000baseSR_Full_BIT,
-		.speed = 25000,
-		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseSR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_40GbaseKR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_40000baseKR4_Full_BIT,
-		.speed = 40000,
-		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseKR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_40GbaseCR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_40000baseCR4_Full_BIT,
-		.speed = 40000,
-		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseCR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	},
-	[MVSW_LINK_MODE_40GbaseSR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_40000baseSR4_Full_BIT,
-		.speed = 40000,
-		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseSR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_50GbaseCR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_50000baseCR2_Full_BIT,
-		.speed = 50000,
-		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseCR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	},
-	[MVSW_LINK_MODE_50GbaseKR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_50000baseKR2_Full_BIT,
-		.speed = 50000,
-		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseKR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_50GbaseSR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_50000baseSR2_Full_BIT,
-		.speed = 50000,
-		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseSR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_100GbaseKR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_100000baseKR4_Full_BIT,
-		.speed = 100000,
-		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseKR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_100GbaseSR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_100000baseSR4_Full_BIT,
-		.speed = 100000,
-		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseSR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_100GbaseCR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_100000baseCR4_Full_BIT,
-		.speed = 100000,
-		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseCR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	}
+struct prestera_span_entry {
+	struct list_head list;
+	struct prestera_port *port;
+	refcount_t ref_count;
+	u8 id;
 };
 
-struct mvsw_pr_fec {
-	u32 eth_fec;
-	enum ethtool_link_mode_bit_indices eth_mode;
-	u8 pr_fec;
+struct prestera_span {
+	struct prestera_switch *sw;
+	struct list_head entries;
 };
 
-static const struct mvsw_pr_fec mvsw_pr_fec_caps[MVSW_PORT_FEC_MAX] = {
-	[MVSW_PORT_FEC_OFF_BIT] = {
-		.eth_fec = ETHTOOL_FEC_OFF,
-		.eth_mode = ETHTOOL_LINK_MODE_FEC_NONE_BIT,
-		.pr_fec = 1 << MVSW_PORT_FEC_OFF_BIT,
-	},
-	[MVSW_PORT_FEC_BASER_BIT] = {
-		.eth_fec = ETHTOOL_FEC_BASER,
-		.eth_mode = ETHTOOL_LINK_MODE_FEC_BASER_BIT,
-		.pr_fec = 1 << MVSW_PORT_FEC_BASER_BIT,
-	},
-	[MVSW_PORT_FEC_RS_BIT] = {
-		.eth_fec = ETHTOOL_FEC_RS,
-		.eth_mode = ETHTOOL_LINK_MODE_FEC_RS_BIT,
-		.pr_fec = 1 << MVSW_PORT_FEC_RS_BIT,
-	}
-};
-
-struct mvsw_pr_port_type {
-	enum ethtool_link_mode_bit_indices eth_mode;
-	u8 eth_type;
-};
-
-static const struct mvsw_pr_port_type
-mvsw_pr_port_types[MVSW_PORT_TYPE_MAX] = {
-	[MVSW_PORT_TYPE_NONE] = {
-		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
-		.eth_type = PORT_NONE,
-	},
-	[MVSW_PORT_TYPE_TP] = {
-		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
-		.eth_type = PORT_TP,
-	},
-	[MVSW_PORT_TYPE_AUI] = {
-		.eth_mode = ETHTOOL_LINK_MODE_AUI_BIT,
-		.eth_type = PORT_AUI,
-	},
-	[MVSW_PORT_TYPE_MII] = {
-		.eth_mode = ETHTOOL_LINK_MODE_MII_BIT,
-		.eth_type = PORT_MII,
-	},
-	[MVSW_PORT_TYPE_FIBRE] = {
-		.eth_mode = ETHTOOL_LINK_MODE_FIBRE_BIT,
-		.eth_type = PORT_FIBRE,
-	},
-	[MVSW_PORT_TYPE_BNC] = {
-		.eth_mode = ETHTOOL_LINK_MODE_BNC_BIT,
-		.eth_type = PORT_BNC,
-	},
-	[MVSW_PORT_TYPE_DA] = {
-		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
-		.eth_type = PORT_TP,
-	},
-	[MVSW_PORT_TYPE_OTHER] = {
-		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
-		.eth_type = PORT_OTHER,
-	}
-};
+struct prestera_port *dev_to_prestera_port(struct device *dev)
+{
+	struct net_device *net_dev;
 
-static const char mvsw_pr_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
-	PORT_STATS_FIELD(good_octets_received),
-	PORT_STATS_FIELD(bad_octets_received),
-	PORT_STATS_FIELD(mac_trans_error),
-	PORT_STATS_FIELD(broadcast_frames_received),
-	PORT_STATS_FIELD(multicast_frames_received),
-	PORT_STATS_FIELD(frames_64_octets),
-	PORT_STATS_FIELD(frames_65_to_127_octets),
-	PORT_STATS_FIELD(frames_128_to_255_octets),
-	PORT_STATS_FIELD(frames_256_to_511_octets),
-	PORT_STATS_FIELD(frames_512_to_1023_octets),
-	PORT_STATS_FIELD(frames_1024_to_max_octets),
-	PORT_STATS_FIELD(excessive_collision),
-	PORT_STATS_FIELD(multicast_frames_sent),
-	PORT_STATS_FIELD(broadcast_frames_sent),
-	PORT_STATS_FIELD(fc_sent),
-	PORT_STATS_FIELD(fc_received),
-	PORT_STATS_FIELD(buffer_overrun),
-	PORT_STATS_FIELD(undersize),
-	PORT_STATS_FIELD(fragments),
-	PORT_STATS_FIELD(oversize),
-	PORT_STATS_FIELD(jabber),
-	PORT_STATS_FIELD(rx_error_frame_received),
-	PORT_STATS_FIELD(bad_crc),
-	PORT_STATS_FIELD(collisions),
-	PORT_STATS_FIELD(late_collision),
-	PORT_STATS_FIELD(unicast_frames_received),
-	PORT_STATS_FIELD(unicast_frames_sent),
-	PORT_STATS_FIELD(sent_multiple),
-	PORT_STATS_FIELD(sent_deferred),
-	PORT_STATS_FIELD(good_octets_sent),
-};
+	net_dev = container_of(dev, struct net_device, dev);
 
-static LIST_HEAD(mvsw_pr_block_cb_list);
+	return netdev_priv(net_dev);
+}
 
-static struct mvsw_pr_port *__find_pr_port(const struct mvsw_pr_switch *sw,
-					   u32 port_id)
+static struct prestera_port *__find_pr_port(const struct prestera_switch *sw,
+					    u32 port_id)
 {
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
 	list_for_each_entry(port, &sw->port_list, list) {
 		if (port->id == port_id)
@@ -350,229 +77,86 @@ static struct mvsw_pr_port *__find_pr_port(const struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static int mvsw_pr_port_state_set(struct net_device *dev, bool is_up)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	int err;
-
-	if (!is_up)
-		netif_stop_queue(dev);
-
-	err = mvsw_pr_hw_port_state_set(port, is_up);
-
-	if (is_up && !err)
-		netif_start_queue(dev);
-
-	return err;
-}
-
-static int mvsw_pr_port_open(struct net_device *dev)
+static int prestera_port_open(struct net_device *dev)
 {
+	int err = 0;
 #ifdef CONFIG_PHYLINK
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
+	if (port->phy_link) {
 		phylink_start(port->phy_link);
-#endif
-	return mvsw_pr_port_state_set(dev, true);
-}
-
-static int mvsw_pr_port_close(struct net_device *dev)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-
-	mvsw_pr_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_DYNAMIC);
-
-#ifdef CONFIG_PHYLINK
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
-		phylink_stop(port->phy_link);
-#endif
-	return mvsw_pr_port_state_set(dev, false);
-}
-
-static netdev_tx_t mvsw_pr_port_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	struct mvsw_pr_rxtx_info rxtx_info = {
-		.port_id = port->id
-	};
-
-	return mvsw_pr_rxtx_xmit(skb, &rxtx_info);
-}
-
-/* TC flower */
-static int
-mvsw_pr_setup_tc_cls_flower(struct prestera_acl_block *acl_block,
-			    struct flow_cls_offload *f)
-{
-	struct mvsw_pr_switch *sw = prestera_acl_block_sw(acl_block);
-
-	if (f->common.chain_index != 0)
-		return -EOPNOTSUPP;
-
-	switch (f->command) {
-	case FLOW_CLS_REPLACE:
-		return mvsw_pr_flower_replace(sw, acl_block, f);
-	case FLOW_CLS_DESTROY:
-		mvsw_pr_flower_destroy(sw, acl_block, f);
-		return 0;
-	case FLOW_CLS_STATS:
-		return mvsw_pr_flower_stats(sw, acl_block, f);
-	default:
-		return -EOPNOTSUPP;
+		/* port became up once mac_config called */
+	} else {
+		port->cfg_phy.admin = true;
+		err = mvsw_pr_hw_port_phy_mode_set(port, true, port->autoneg,
+						   port->cfg_phy.mode,
+						   port->adver_link_modes);
 	}
-}
-
-static int mvsw_pr_setup_tc_block_cb_flower(enum tc_setup_type type,
-					    void *type_data, void *cb_priv)
-{
-	struct prestera_acl_block *acl_block = cb_priv;
+#else
+	pr_err("Can't operate without phylink");
+#endif
 
-	switch (type) {
-	case TC_SETUP_CLSFLOWER:
-		if (prestera_acl_block_disabled(acl_block))
-			return -EOPNOTSUPP;
-		return mvsw_pr_setup_tc_cls_flower(acl_block, type_data);
-	default:
-		return -EOPNOTSUPP;
-	}
+	netif_start_queue(dev);
+	return err;
 }
 
-static void mvsw_pr_tc_block_flower_release(void *cb_priv)
+static int prestera_port_close(struct net_device *dev)
 {
-	struct prestera_acl_block *acl_block = cb_priv;
-
-	prestera_acl_block_destroy(acl_block);
-}
-
-static int
-mvsw_pr_setup_tc_block_flower_bind(struct mvsw_pr_port *port,
-				   struct flow_block_offload *f)
-{
-	struct mvsw_pr_switch *sw = port->sw;
-	struct prestera_acl_block *acl_block;
-	struct flow_block_cb *block_cb;
-	bool register_block = false;
-	bool disable_block = false;
-	int err;
+	int err = 0;
+	struct prestera_port *port = netdev_priv(dev);
+#ifdef CONFIG_PHYLINK
+	struct prestera_port_mac_config cfg_mac;
 
-	block_cb = flow_block_cb_lookup(f->block,
-					mvsw_pr_setup_tc_block_cb_flower, sw);
-	if (!block_cb) {
-		acl_block = prestera_acl_block_create(sw, f->net);
-		if (!acl_block)
-			return -ENOMEM;
-		block_cb = flow_block_cb_alloc(mvsw_pr_setup_tc_block_cb_flower,
-					       sw, acl_block,
-					       mvsw_pr_tc_block_flower_release);
-		if (IS_ERR(block_cb)) {
-			prestera_acl_block_destroy(acl_block);
-			err = PTR_ERR(block_cb);
-			goto err_cb_register;
-		}
-		register_block = true;
+	if (port->phy_link) {
+		phylink_stop(port->phy_link);
+		phylink_disconnect_phy(port->phy_link);
+		/* TODO: can we use somethink, like phylink callback ? */
+		/* ensure, that link is down */
+		/* TODO: use macros for operations like admin down-up ? */
+		prestera_port_cfg_mac_read(port, &cfg_mac);
+		cfg_mac.admin = false;
+		prestera_port_cfg_mac_write(port, &cfg_mac);
 	} else {
-		acl_block = flow_block_cb_priv(block_cb);
-	}
-	flow_block_cb_incref(block_cb);
-
-	if (!tc_can_offload(port->net_dev)) {
-		if (prestera_acl_block_rule_count(acl_block)) {
-			err = -EOPNOTSUPP;
-			goto err_block_bind;
-		}
-
-		disable_block = true;
-	}
-
-	err = prestera_acl_block_bind(sw, acl_block, port);
-	if (err)
-		goto err_block_bind;
-
-	if (register_block) {
-		flow_block_cb_add(block_cb, f);
-		list_add_tail(&block_cb->driver_list, &mvsw_pr_block_cb_list);
+		port->cfg_phy.admin = false;
+		err = mvsw_pr_hw_port_phy_mode_set(port, false, port->autoneg,
+						   port->cfg_phy.mode,
+						   port->adver_link_modes);
 	}
+#else
+	pr_err("Can't operate without phylink");
+#endif
 
-	if (disable_block)
-		prestera_acl_block_disable_inc(acl_block);
-
-	port->acl_block = acl_block;
-	return 0;
+	prestera_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_DYNAMIC);
 
-err_block_bind:
-	if (!flow_block_cb_decref(block_cb))
-		flow_block_cb_free(block_cb);
-err_cb_register:
+	netif_stop_queue(dev);
 	return err;
 }
 
-static void
-mvsw_pr_setup_tc_block_flower_unbind(struct mvsw_pr_port *port,
-				     struct flow_block_offload *f)
+static netdev_tx_t prestera_port_xmit(struct sk_buff *skb,
+				      struct net_device *dev)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct prestera_acl_block *acl_block;
-	struct flow_block_cb *block_cb;
-	int err;
-
-	block_cb = flow_block_cb_lookup(f->block,
-					mvsw_pr_setup_tc_block_cb_flower, sw);
-	if (!block_cb)
-		return;
-
-	acl_block = flow_block_cb_priv(block_cb);
-
-	if (!tc_can_offload(port->net_dev))
-		prestera_acl_block_disable_dec(acl_block);
-
-	err = prestera_acl_block_unbind(sw, acl_block, port);
-	if (!err && !flow_block_cb_decref(block_cb)) {
-		flow_block_cb_remove(block_cb, f);
-		list_del(&block_cb->driver_list);
-	}
-	port->acl_block = NULL;
+	return prestera_rxtx_xmit(skb, netdev_priv(dev));
 }
 
-static int mvsw_sp_setup_tc_block(struct mvsw_pr_port *port,
-				  struct flow_block_offload *f)
+static int prestera_setup_tc(struct net_device *dev, enum tc_setup_type type,
+			     void *type_data)
 {
-	if (f->binder_type != FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS)
-		return -EOPNOTSUPP;
-
-	f->driver_block_list = &mvsw_pr_block_cb_list;
-
-	switch (f->command) {
-	case FLOW_BLOCK_BIND:
-		return mvsw_pr_setup_tc_block_flower_bind(port, f);
-	case FLOW_BLOCK_UNBIND:
-		mvsw_pr_setup_tc_block_flower_unbind(port, f);
-		return 0;
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static int mvsw_pr_setup_tc(struct net_device *dev, enum tc_setup_type type,
-			    void *type_data)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	switch (type) {
 	case TC_SETUP_BLOCK:
-		return mvsw_sp_setup_tc_block(port, type_data);
+		return prestera_setup_tc_block(port, type_data);
 	default:
 		return -EOPNOTSUPP;
 	}
 }
 
-static void mvsw_pr_set_rx_mode(struct net_device *dev)
+static void prestera_set_rx_mode(struct net_device *dev)
 {
 	/* TO DO: add implementation */
 }
 
-static int mvsw_is_valid_mac_addr(struct mvsw_pr_port *port, u8 *addr)
+static int prestera_valid_mac_addr(struct prestera_port *port, u8 *addr)
 {
 	int err;
 
@@ -586,13 +170,13 @@ static int mvsw_is_valid_mac_addr(struct mvsw_pr_port *port, u8 *addr)
 	return 0;
 }
 
-static int mvsw_pr_port_set_mac_address(struct net_device *dev, void *p)
+static int prestera_port_set_mac_address(struct net_device *dev, void *p)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	struct sockaddr *addr = p;
 	int err;
 
-	err = mvsw_is_valid_mac_addr(port, addr->sa_data);
+	err = prestera_valid_mac_addr(port, addr->sa_data);
 	if (err)
 		return err;
 
@@ -603,9 +187,9 @@ static int mvsw_pr_port_set_mac_address(struct net_device *dev, void *p)
 	return err;
 }
 
-static int mvsw_pr_port_change_mtu(struct net_device *dev, int mtu)
+static int prestera_port_change_mtu(struct net_device *dev, int mtu)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	int err;
 
 	if (port->sw->mtu_min <= mtu && mtu <= port->sw->mtu_max)
@@ -619,11 +203,11 @@ static int mvsw_pr_port_change_mtu(struct net_device *dev, int mtu)
 	return err;
 }
 
-static void mvsw_pr_port_get_stats64(struct net_device *dev,
-				     struct rtnl_link_stats64 *stats)
+static void prestera_port_get_stats64(struct net_device *dev,
+				      struct rtnl_link_stats64 *stats)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	struct mvsw_pr_port_stats *port_stats = &port->cached_hw_stats.stats;
+	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_port_stats *port_stats = &port->cached_hw_stats.stats;
 
 	stats->rx_packets =	port_stats->broadcast_frames_received +
 				port_stats->multicast_frames_received +
@@ -649,62 +233,94 @@ static void mvsw_pr_port_get_stats64(struct net_device *dev,
 	stats->rx_crc_errors = port_stats->bad_crc;
 }
 
-static void mvsw_pr_port_get_hw_stats(struct mvsw_pr_port *port)
+static void prestera_port_get_hw_stats(struct prestera_port *port)
 {
 	mvsw_pr_hw_port_stats_get(port, &port->cached_hw_stats.stats);
 }
 
 static void update_stats_cache(struct work_struct *work)
 {
-	struct mvsw_pr_port *port =
-		container_of(work, struct mvsw_pr_port,
+	struct prestera_port *port =
+		container_of(work, struct prestera_port,
 			     cached_hw_stats.caching_dw.work);
 
 	rtnl_lock();
-	mvsw_pr_port_get_hw_stats(port);
+	prestera_port_get_hw_stats(port);
 	rtnl_unlock();
 
-	queue_delayed_work(mvsw_pr_wq, &port->cached_hw_stats.caching_dw,
+	queue_delayed_work(prestera_wq, &port->cached_hw_stats.caching_dw,
 			   PORT_STATS_CACHE_TIMEOUT_MS);
 }
 
-static bool mvsw_pr_port_has_offload_stats(const struct net_device *dev,
-					   int attr_id)
+static int prestera_port_get_stats_cpu_hit(const struct net_device *dev,
+					   struct rtnl_link_stats64 *stats)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	u64 rx_packets, rx_bytes, tx_packets, tx_bytes;
+	struct prestera_rxtx_stats *p;
+	u32 tx_dropped = 0;
+	unsigned int start;
+	int i;
+
+	for_each_possible_cpu(i) {
+		p = per_cpu_ptr(port->rxtx_stats, i);
+		do {
+			start = u64_stats_fetch_begin_irq(&p->syncp);
+			rx_packets = p->rx_packets;
+			rx_bytes = p->rx_bytes;
+			tx_packets = p->tx_packets;
+			tx_bytes = p->tx_bytes;
+		} while (u64_stats_fetch_retry_irq(&p->syncp, start));
+
+		stats->rx_packets += rx_packets;
+		stats->rx_bytes += rx_bytes;
+		stats->tx_packets += tx_packets;
+		stats->tx_bytes += tx_bytes;
+		/* tx_dropped is u32, updated without syncp protection. */
+		tx_dropped += p->tx_dropped;
+	}
+	stats->tx_dropped = tx_dropped;
+	return 0;
+}
+
+static bool prestera_port_has_offload_stats(const struct net_device *dev,
+					    int attr_id)
 {
-	/* TO DO: add implementation */
-	return false;
+	return attr_id == IFLA_OFFLOAD_XSTATS_CPU_HIT;
 }
 
-static int mvsw_pr_port_get_offload_stats(int attr_id,
-					  const struct net_device *dev,
-					  void *sp)
+static int prestera_port_get_offload_stats(int attr_id,
+					   const struct net_device *dev,
+					   void *sp)
 {
-	/* TO DO: add implementation */
-	return 0;
+	if (attr_id == IFLA_OFFLOAD_XSTATS_CPU_HIT)
+		return prestera_port_get_stats_cpu_hit(dev, sp);
+
+	return -EINVAL;
 }
 
-static int mvsw_pr_feature_hw_tc(struct net_device *dev, bool enable)
+static int prestera_feature_hw_tc(struct net_device *dev, bool enable)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	if (!enable) {
-		if (prestera_acl_block_rule_count(port->acl_block)) {
+		if (prestera_acl_block_rule_count(port->flow_block)) {
 			netdev_err(dev, "Active offloaded tc filters, can't turn hw_tc_offload off\n");
 			return -EINVAL;
 		}
-		prestera_acl_block_disable_inc(port->acl_block);
+		prestera_acl_block_disable_inc(port->flow_block);
 	} else {
-		prestera_acl_block_disable_dec(port->acl_block);
+		prestera_acl_block_disable_dec(port->flow_block);
 	}
 	return 0;
 }
 
 static int
-mvsw_pr_handle_feature(struct net_device *dev,
-		       netdev_features_t wanted_features,
-		       netdev_features_t feature,
-		       int (*feature_handler)(struct net_device *dev,
-					      bool enable))
+prestera_handle_feature(struct net_device *dev,
+			netdev_features_t wanted_features,
+			netdev_features_t feature,
+			int (*feature_handler)(struct net_device *dev,
+					       bool enable))
 {
 	netdev_features_t changes = wanted_features ^ dev->features;
 	bool enable = !!(wanted_features & feature);
@@ -728,14 +344,14 @@ mvsw_pr_handle_feature(struct net_device *dev,
 	return 0;
 }
 
-static int mvsw_pr_set_features(struct net_device *dev,
-				netdev_features_t features)
+static int prestera_set_features(struct net_device *dev,
+				 netdev_features_t features)
 {
 	netdev_features_t oper_features = dev->features;
 	int err = 0;
 
-	err |= mvsw_pr_handle_feature(dev, features, NETIF_F_HW_TC,
-				       mvsw_pr_feature_hw_tc);
+	err |= prestera_handle_feature(dev, features, NETIF_F_HW_TC,
+				       prestera_feature_hw_tc);
 
 	if (err) {
 		dev->features = oper_features;
@@ -745,57 +361,42 @@ static int mvsw_pr_set_features(struct net_device *dev,
 	return 0;
 }
 
-static void mvsw_pr_port_get_drvinfo(struct net_device *dev,
-				     struct ethtool_drvinfo *drvinfo)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	struct mvsw_pr_switch *sw = port->sw;
-
-	strlcpy(drvinfo->driver, mvsw_driver_kind, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->bus_info, mvsw_dev_name(sw), sizeof(drvinfo->bus_info));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),
-		 "%d.%d.%d",
-		 sw->dev->fw_rev.maj,
-		 sw->dev->fw_rev.min,
-		 sw->dev->fw_rev.sub);
-}
-
-static const struct net_device_ops mvsw_pr_netdev_ops = {
-	.ndo_open = mvsw_pr_port_open,
-	.ndo_stop = mvsw_pr_port_close,
-	.ndo_start_xmit = mvsw_pr_port_xmit,
-	.ndo_setup_tc = mvsw_pr_setup_tc,
-	.ndo_change_mtu = mvsw_pr_port_change_mtu,
-	.ndo_set_rx_mode = mvsw_pr_set_rx_mode,
-	.ndo_get_stats64 = mvsw_pr_port_get_stats64,
-	.ndo_set_features = mvsw_pr_set_features,
-	.ndo_set_mac_address = mvsw_pr_port_set_mac_address,
-	.ndo_has_offload_stats = mvsw_pr_port_has_offload_stats,
-	.ndo_get_offload_stats = mvsw_pr_port_get_offload_stats,
+static const struct net_device_ops prestera_netdev_ops = {
+	.ndo_open = prestera_port_open,
+	.ndo_stop = prestera_port_close,
+	.ndo_start_xmit = prestera_port_xmit,
+	.ndo_setup_tc = prestera_setup_tc,
+	.ndo_change_mtu = prestera_port_change_mtu,
+	.ndo_set_rx_mode = prestera_set_rx_mode,
+	.ndo_get_stats64 = prestera_port_get_stats64,
+	.ndo_set_features = prestera_set_features,
+	.ndo_set_mac_address = prestera_port_set_mac_address,
+	.ndo_has_offload_stats = prestera_port_has_offload_stats,
+	.ndo_get_offload_stats = prestera_port_get_offload_stats,
 	.ndo_get_devlink_port = prestera_devlink_get_port,
 };
 
-bool mvsw_pr_netdev_check(const struct net_device *dev)
+bool prestera_netdev_check(const struct net_device *dev)
 {
-	return dev->netdev_ops == &mvsw_pr_netdev_ops;
+	return dev->netdev_ops == &prestera_netdev_ops;
 }
 
-static int mvsw_pr_lower_dev_walk(struct net_device *lower_dev,
-	struct netdev_nested_priv  *priv)
+static int prestera_lower_dev_walk(struct net_device *dev,
+				   struct netdev_nested_priv *priv)
 {
-	struct mvsw_pr_port **pport = (struct mvsw_pr_port **)priv->data;
+	struct prestera_port **pport = (struct prestera_port **)priv->data;
 
-	if (mvsw_pr_netdev_check(lower_dev)) {
-		*pport = netdev_priv(lower_dev);
+	if (prestera_netdev_check(dev)) {
+		*pport = netdev_priv(dev);
 		return 1;
 	}
 
 	return 0;
 }
 
-struct mvsw_pr_port *mvsw_pr_port_dev_lower_find(struct net_device *dev)
+struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev)
 {
-	struct mvsw_pr_port *port = NULL;
+	struct prestera_port *port = NULL;
 	struct netdev_nested_priv priv = {
 		.data = (void *)&port,
 	};
@@ -803,568 +404,108 @@ struct mvsw_pr_port *mvsw_pr_port_dev_lower_find(struct net_device *dev)
 	if (!dev)
 		return NULL;
 
-	if (mvsw_pr_netdev_check(dev))
+	if (prestera_netdev_check(dev))
 		return netdev_priv(dev);
 
-	port = NULL;
-	netdev_walk_all_lower_dev(dev, mvsw_pr_lower_dev_walk, &priv);
+	netdev_walk_all_lower_dev(dev, prestera_lower_dev_walk, &priv);
 
 	return port;
 }
 
-struct mvsw_pr_switch *mvsw_pr_switch_get(struct net_device *dev)
+struct prestera_switch *prestera_switch_get(struct net_device *dev)
 {
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
-	port = mvsw_pr_port_dev_lower_find(dev);
+	port = prestera_port_dev_lower_find(dev);
 	return port ? port->sw : NULL;
 }
 
-static void mvsw_modes_to_eth(unsigned long *eth_modes, u64 link_modes, u8 fec,
-			      u8 type)
-{
-	u32 mode;
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((mvsw_pr_link_modes[mode].pr_mask & link_modes) == 0)
-			continue;
-		if (type != MVSW_PORT_TYPE_NONE &&
-		    mvsw_pr_link_modes[mode].port_type != type)
-			continue;
-		__set_bit(mvsw_pr_link_modes[mode].eth_mode, eth_modes);
-	}
-
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((mvsw_pr_fec_caps[mode].pr_fec & fec) == 0)
-			continue;
-		__set_bit(mvsw_pr_fec_caps[mode].eth_mode, eth_modes);
-	}
-}
-
-static void mvsw_pr_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
-				     struct mvsw_pr_port *port)
-{
-	ecmd->base.autoneg = port->autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
-
-	mvsw_modes_to_eth(ecmd->link_modes.supported,
-			  port->caps.supp_link_modes,
-			  port->caps.supp_fec,
-			  port->caps.type);
-
-	if (port->caps.type != MVSW_PORT_TYPE_TP)
-		return;
-
-	ethtool_link_ksettings_add_link_mode(ecmd, supported, Autoneg);
-
-	if (!netif_running(port->net_dev))
-		return;
-
-	if (port->autoneg) {
-		mvsw_modes_to_eth(ecmd->link_modes.advertising,
-				  port->adver_link_modes,
-				  port->adver_fec,
-				  port->caps.type);
-		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
-						     Autoneg);
-	} else if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
-		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
-						     Autoneg);
-}
-
-static int mvsw_modes_from_eth(struct mvsw_pr_port *port,
-			       const unsigned long *advertising,
-			       const unsigned long *supported,
-			       u64 *link_modes, u8 *fec)
-{
-	struct ethtool_link_ksettings curr = {};
-	u32 mode;
-
-	ethtool_link_ksettings_zero_link_mode(&curr, supported);
-	ethtool_link_ksettings_zero_link_mode(&curr, advertising);
-
-	mvsw_pr_port_autoneg_get(&curr, port);
-
-	if (linkmode_equal(advertising, curr.link_modes.advertising)) {
-		*link_modes = port->adver_link_modes;
-		*fec = port->adver_fec;
-		return 0;
-	}
-
-	if (!linkmode_subset(advertising, supported)) {
-		netdev_err(port->net_dev, "Unsupported link mode requested");
-		return -EINVAL;
-	}
-
-	*link_modes  = 0;
-	*fec = 0;
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if (!test_bit(mvsw_pr_link_modes[mode].eth_mode, advertising))
-			continue;
-		if (mvsw_pr_link_modes[mode].port_type != port->caps.type)
-			continue;
-		*link_modes |= mvsw_pr_link_modes[mode].pr_mask;
-	}
-
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if (!test_bit(mvsw_pr_fec_caps[mode].eth_mode, advertising))
-			continue;
-		*fec |= mvsw_pr_fec_caps[mode].pr_fec;
-	}
-
-	if (*link_modes == 0 && *fec == 0) {
-		netdev_err(port->net_dev, "No link modes requested");
-		return -EINVAL;
-	}
-	if (*link_modes == 0)
-		*link_modes = port->adver_link_modes;
-	if (*fec == 0)
-		*fec = port->adver_fec ? port->adver_fec :
-					 BIT(MVSW_PORT_FEC_OFF_BIT);
-
-	return 0;
-}
-
-static void mvsw_pr_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
-					struct mvsw_pr_port *port)
-{
-	u32 mode;
-	u8 ptype;
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((mvsw_pr_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes) == 0)
-			continue;
-		ptype = mvsw_pr_link_modes[mode].port_type;
-		__set_bit(mvsw_pr_port_types[ptype].eth_mode,
-			  ecmd->link_modes.supported);
-	}
-}
-
-static void mvsw_pr_port_speed_get(struct ethtool_link_ksettings *ecmd,
-				   struct mvsw_pr_port *port)
-{
-	u32 speed;
-	int err;
-
-	err = mvsw_pr_hw_port_speed_get(port, &speed);
-	ecmd->base.speed = !err ? speed : SPEED_UNKNOWN;
-}
-
-static int mvsw_pr_port_link_mode_set(struct mvsw_pr_port *port,
-				      u32 speed, u8 duplex, u8 type)
-{
-	u32 new_mode = MVSW_LINK_MODE_MAX;
-	u32 mode;
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if (speed != mvsw_pr_link_modes[mode].speed)
-			continue;
-		if (duplex != mvsw_pr_link_modes[mode].duplex)
-			continue;
-		if (!(mvsw_pr_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes))
-			continue;
-		if (type != mvsw_pr_link_modes[mode].port_type)
-			continue;
-
-		new_mode = mode;
-		break;
-	}
-
-	if (new_mode == MVSW_LINK_MODE_MAX) {
-		netdev_err(port->net_dev, "Unsupported speed/duplex requested");
-		return -EINVAL;
-	}
-
-	return mvsw_pr_hw_port_link_mode_set(port, new_mode);
-}
-
-static int mvsw_pr_port_speed_duplex_set(const struct ethtool_link_ksettings
-					 *ecmd, struct mvsw_pr_port *port)
-{
-	int err;
-	u8 duplex;
-	u32 speed;
-	u32 curr_mode;
-
-	err = mvsw_pr_hw_port_link_mode_get(port, &curr_mode);
-	if (err || curr_mode >= MVSW_LINK_MODE_MAX)
-		return -EINVAL;
-
-	if (ecmd->base.duplex != DUPLEX_UNKNOWN)
-		duplex = ecmd->base.duplex == DUPLEX_FULL ?
-			 MVSW_PORT_DUPLEX_FULL : MVSW_PORT_DUPLEX_HALF;
-	else
-		duplex = mvsw_pr_link_modes[curr_mode].duplex;
-
-	if (ecmd->base.speed != SPEED_UNKNOWN)
-		speed = ecmd->base.speed;
-	else
-		speed = mvsw_pr_link_modes[curr_mode].speed;
-
-	return mvsw_pr_port_link_mode_set(port, speed, duplex, port->caps.type);
-}
-
-static u8 mvsw_pr_port_type_get(struct mvsw_pr_port *port)
-{
-	if (port->caps.type < MVSW_PORT_TYPE_MAX)
-		return mvsw_pr_port_types[port->caps.type].eth_type;
-	return PORT_OTHER;
-}
-
-static int mvsw_pr_port_type_set(const struct ethtool_link_ksettings *ecmd,
-				 struct mvsw_pr_port *port)
-{
-	int err;
-	u32 type, mode;
-	u32 new_mode = MVSW_LINK_MODE_MAX;
-
-	for (type = 0; type < MVSW_PORT_TYPE_MAX; type++) {
-		if (mvsw_pr_port_types[type].eth_type == ecmd->base.port &&
-		    test_bit(mvsw_pr_port_types[type].eth_mode,
-			     ecmd->link_modes.supported)) {
-			break;
-		}
-	}
-
-	if (type == port->caps.type)
-		return 0;
-
-	if (type != port->caps.type && ecmd->base.autoneg == AUTONEG_ENABLE)
-		return -EINVAL;
-
-	if (type == MVSW_PORT_TYPE_MAX) {
-		pr_err("Unsupported port type requested\n");
-		return -EINVAL;
-	}
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((mvsw_pr_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes) &&
-		    type == mvsw_pr_link_modes[mode].port_type) {
-			new_mode = mode;
-		}
-	}
-
-	if (new_mode < MVSW_LINK_MODE_MAX)
-		err = mvsw_pr_hw_port_link_mode_set(port, new_mode);
-	else
-		err = -EINVAL;
-
-	if (!err) {
-		port->caps.type = type;
-		port->autoneg = false;
-	}
-
-	return err;
-}
-
-static void mvsw_pr_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
-					struct mvsw_pr_port *port)
-{
-	u64 bitmap;
-	bool pause;
-	bool asym_pause;
-
-	if (!mvsw_pr_hw_port_remote_cap_get(port, &bitmap)) {
-		mvsw_modes_to_eth(ecmd->link_modes.lp_advertising,
-				  bitmap, 0, MVSW_PORT_TYPE_NONE);
-
-		if (!bitmap_empty(ecmd->link_modes.lp_advertising,
-				  __ETHTOOL_LINK_MODE_MASK_NBITS)) {
-			ethtool_link_ksettings_add_link_mode(ecmd,
-							     lp_advertising,
-							     Autoneg);
-		}
-	}
-
-	if (mvsw_pr_hw_port_remote_fc_get(port, &pause, &asym_pause))
-		return;
-	if (pause)
-		ethtool_link_ksettings_add_link_mode(ecmd,
-						     lp_advertising,
-						     Pause);
-	if (asym_pause)
-		ethtool_link_ksettings_add_link_mode(ecmd,
-						     lp_advertising,
-						     Asym_Pause);
-}
-
-static void mvsw_pr_port_duplex_get(struct ethtool_link_ksettings *ecmd,
-				    struct mvsw_pr_port *port)
-{
-	u8 duplex;
-
-	if (!mvsw_pr_hw_port_duplex_get(port, &duplex)) {
-		ecmd->base.duplex = duplex == MVSW_PORT_DUPLEX_FULL ?
-				    DUPLEX_FULL : DUPLEX_HALF;
-	} else {
-		ecmd->base.duplex = DUPLEX_UNKNOWN;
-	}
-}
-
-static int mvsw_pr_port_autoneg_set(struct mvsw_pr_port *port, bool enable,
-				    u64 link_modes, u8 fec)
-{
-	if (port->caps.type != MVSW_PORT_TYPE_TP)
-		return enable ? -EINVAL : 0;
-
-	if (port->autoneg == enable && port->adver_link_modes == link_modes &&
-	    port->adver_fec == fec)
-		return 0;
-
-	if (mvsw_pr_hw_port_autoneg_set(port, enable, link_modes, fec))
-		return -EINVAL;
-
-	port->autoneg = enable;
-	port->adver_link_modes = link_modes;
-	port->adver_fec = fec;
-	return 0;
-}
-
-static int mvsw_pr_port_nway_reset(struct net_device *dev)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-
-	if (netif_running(dev) &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
-	    port->caps.type == MVSW_PORT_TYPE_TP)
-		return mvsw_pr_hw_port_autoneg_restart(port);
-
-	return -EINVAL;
-}
-
-static int mvsw_pr_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
-				 struct mvsw_pr_port *port)
-{
-	if (ecmd->base.eth_tp_mdix_ctrl != ETH_TP_MDI_INVALID &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
-	    port->caps.type == MVSW_PORT_TYPE_TP)
-		return mvsw_pr_hw_port_mdix_set(port,
-						ecmd->base.eth_tp_mdix_ctrl);
-	return 0;
-}
-
-static int mvsw_pr_port_get_link_ksettings(struct net_device *dev,
-					   struct ethtool_link_ksettings *ecmd)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-
-	/* Dirty hook: Deinit ecmd.
-	 * It caused by suspicious phylink_ethtool_ksettings_get()
-	 * implementation, which can left "kset" uninitialized, when there is no
-	 * SFP plugged
-	 */
-	ethtool_link_ksettings_zero_link_mode(ecmd, supported);
-	ethtool_link_ksettings_zero_link_mode(ecmd, advertising);
-	ethtool_link_ksettings_zero_link_mode(ecmd, lp_advertising);
-	ecmd->base.speed = SPEED_UNKNOWN;
-	ecmd->base.duplex = DUPLEX_UNKNOWN;
-	ecmd->base.autoneg = AUTONEG_DISABLE;
-#ifdef CONFIG_PHYLINK
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
-		return phylink_ethtool_ksettings_get(port->phy_link, ecmd);
-#endif /* CONFIG_PHYLINK */
-
-	mvsw_pr_port_supp_types_get(ecmd, port);
-
-	mvsw_pr_port_autoneg_get(ecmd, port);
-
-	if (port->autoneg && netif_carrier_ok(dev) &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
-		mvsw_pr_port_remote_cap_get(ecmd, port);
-
-	if (netif_carrier_ok(dev)) {
-		mvsw_pr_port_speed_get(ecmd, port);
-		mvsw_pr_port_duplex_get(ecmd, port);
-	} else {
-		ecmd->base.speed = SPEED_UNKNOWN;
-		ecmd->base.duplex = DUPLEX_UNKNOWN;
-	}
-
-	ecmd->base.port = mvsw_pr_port_type_get(port);
-
-	if (port->caps.type == MVSW_PORT_TYPE_TP &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
-		mvsw_pr_hw_port_mdix_get(port, &ecmd->base.eth_tp_mdix,
-					 &ecmd->base.eth_tp_mdix_ctrl);
-
-	return 0;
-}
-
-static int mvsw_pr_port_set_link_ksettings(struct net_device *dev,
-					   const struct ethtool_link_ksettings
-					   *ecmd)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	u64 adver_modes = 0;
-	u8 adver_fec = 0;
-	int err;
-
-#ifdef CONFIG_PHYLINK
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
-		return phylink_ethtool_ksettings_set(port->phy_link, ecmd);
-#endif /* CONFIG_PHYLINK */
-
-	err = mvsw_pr_port_type_set(ecmd, port);
-	if (err)
-		return err;
-
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER) {
-		err = mvsw_pr_port_mdix_set(ecmd, port);
-		if (err)
-			return err;
-	}
-
-	if (ecmd->base.autoneg == AUTONEG_ENABLE) {
-		if (mvsw_modes_from_eth(port, ecmd->link_modes.advertising,
-					ecmd->link_modes.supported,
-					&adver_modes, &adver_fec))
-			return -EINVAL;
-		if (!port->autoneg && !adver_modes)
-			adver_modes = port->caps.supp_link_modes;
-	} else {
-		adver_modes = port->adver_link_modes;
-		adver_fec = port->adver_fec;
-	}
-
-	err = mvsw_pr_port_autoneg_set(port,
-				       ecmd->base.autoneg == AUTONEG_ENABLE,
-				       adver_modes, adver_fec);
-	if (err)
-		return err;
-
-	if (ecmd->base.autoneg == AUTONEG_DISABLE) {
-		err = mvsw_pr_port_speed_duplex_set(ecmd, port);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int mvsw_pr_port_get_fecparam(struct net_device *dev,
-				     struct ethtool_fecparam *fecparam)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	u32 mode;
-	u8 active;
-	int err;
-
-	err = mvsw_pr_hw_port_fec_get(port, &active);
-	if (err)
-		return err;
-
-	fecparam->fec = 0;
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((mvsw_pr_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
-			continue;
-		fecparam->fec |= mvsw_pr_fec_caps[mode].eth_fec;
-	}
-
-	if (active < MVSW_PORT_FEC_MAX)
-		fecparam->active_fec = mvsw_pr_fec_caps[active].eth_fec;
-	else
-		fecparam->active_fec = ETHTOOL_FEC_AUTO;
-
-	return 0;
-}
-
-static int mvsw_pr_port_set_fecparam(struct net_device *dev,
-				     struct ethtool_fecparam *fecparam)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	u8 fec, active;
-	u32 mode;
-	int err;
-
-	if (port->autoneg) {
-		netdev_err(dev, "FEC set is not allowed while autoneg is on\n");
-		return -EINVAL;
-	}
-
-	err = mvsw_pr_hw_port_fec_get(port, &active);
-	if (err)
-		return err;
-
-	fec = MVSW_PORT_FEC_MAX;
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((mvsw_pr_fec_caps[mode].eth_fec & fecparam->fec) &&
-		    (mvsw_pr_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
-			fec = mode;
-			break;
-		}
-	}
-
-	if (fec == active)
-		return 0;
-
-	if (fec == MVSW_PORT_FEC_MAX) {
-		netdev_err(dev, "Unsupported FEC requested");
-		return -EINVAL;
-	}
-
-	return mvsw_pr_hw_port_fec_set(port, fec);
-}
-
-static void mvsw_pr_port_get_ethtool_stats(struct net_device *dev,
-					   struct ethtool_stats *stats,
-					   u64 *data)
+int prestera_port_cfg_mac_read(struct prestera_port *port,
+			       struct prestera_port_mac_config *cfg)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	struct mvsw_pr_port_stats *port_stats = &port->cached_hw_stats.stats;
-
-	memcpy((u8 *)data, port_stats, sizeof(*port_stats));
+	*cfg = port->cfg_mac;
+	return 0;
 }
 
-static void mvsw_pr_port_get_strings(struct net_device *dev,
-				     u32 stringset, u8 *data)
+int prestera_port_cfg_mac_write(struct prestera_port *port,
+				struct prestera_port_mac_config *cfg)
 {
-	if (stringset != ETH_SS_STATS)
-		return;
+	int err;
 
-	memcpy(data, *mvsw_pr_port_cnt_name, sizeof(mvsw_pr_port_cnt_name));
+	err = mvsw_pr_hw_port_mac_mode_set(port, cfg->admin,
+					   cfg->mode, cfg->inband, cfg->speed,
+					   cfg->duplex, cfg->fec);
+	if (err)
+		return err;
+
+	port->cfg_mac = *cfg;
+	return 0;
 }
 
-static int mvsw_pr_port_get_sset_count(struct net_device *dev, int sset)
+/* TODO:  Rename, that it only for integral */
+int prestera_port_autoneg_set(struct prestera_port *port, u64 link_modes)
 {
-	switch (sset) {
-	case ETH_SS_STATS:
-		return PORT_STATS_CNT;
-	default:
-		return -EOPNOTSUPP;
-	}
-}
+	/* TODO: Need separate config flow
+	 * for MAC-PHY link and PHY-PARTNER link
+	 */
+	if (port->autoneg == true && port->adver_link_modes == link_modes)
+		return 0;
 
-static const struct ethtool_ops mvsw_pr_ethtool_ops = {
-	.get_drvinfo = mvsw_pr_port_get_drvinfo,
-	.get_link_ksettings = mvsw_pr_port_get_link_ksettings,
-	.set_link_ksettings = mvsw_pr_port_set_link_ksettings,
-	.get_fecparam = mvsw_pr_port_get_fecparam,
-	.set_fecparam = mvsw_pr_port_set_fecparam,
-	.get_sset_count = mvsw_pr_port_get_sset_count,
-	.get_strings = mvsw_pr_port_get_strings,
-	.get_ethtool_stats = mvsw_pr_port_get_ethtool_stats,
-	.get_link = ethtool_op_get_link,
-	.nway_reset = mvsw_pr_port_nway_reset
-};
+	if (mvsw_pr_hw_port_phy_mode_set(port, port->cfg_phy.admin,
+					 true, 0, link_modes))
+		return -EINVAL;
 
-int mvsw_pr_port_learning_set(struct mvsw_pr_port *port, bool learn)
+	/* TODO: move all this parameters to cfg_phy */
+	port->autoneg = true;
+	port->cfg_phy.mode = 0;
+	port->adver_link_modes = link_modes;
+	port->adver_fec = BIT(MVSW_PORT_FEC_OFF_BIT);
+	return 0;
+}
+
+int prestera_port_learning_set(struct prestera_port *port, bool learn)
 {
 	return mvsw_pr_hw_port_learning_set(port, learn);
 }
 
-int mvsw_pr_port_uc_flood_set(struct mvsw_pr_port *port, bool flood)
+int prestera_port_uc_flood_set(struct prestera_port *port, bool flood)
 {
 	return mvsw_pr_hw_port_uc_flood_set(port, flood);
 }
 
-int mvsw_pr_port_mc_flood_set(struct mvsw_pr_port *port, bool flood)
+int prestera_port_mc_flood_set(struct prestera_port *port, bool flood)
 {
 	return mvsw_pr_hw_port_mc_flood_set(port, flood);
 }
 
-int mvsw_pr_port_pvid_set(struct mvsw_pr_port *port, u16 vid)
+/* Isolation group - is set of ports,
+ *  which can't comunicate with each other (symmetric).
+ * On other hand - we can configure asymmetric isolation
+ *  (when "default" and "filter" are equal).
+ * But this feature (asymmetric) left for future.
+ */
+int prestera_port_isolation_grp_set(struct prestera_port *port,
+				    u32 sourceid)
+{
+	int err;
+
+	err = prestera_hw_port_srcid_default_set(port, sourceid);
+	if (err)
+		goto err_out;
+
+	err = prestera_hw_port_srcid_filter_set(port, sourceid);
+	if (err)
+		goto err_out;
+
+	return 0;
+
+err_out:
+	prestera_hw_port_srcid_default_set(port, PRESTERA_PORT_SRCID_ZERO);
+	prestera_hw_port_srcid_filter_set(port, PRESTERA_PORT_SRCID_ZERO);
+	return err;
+}
+
+int prestera_port_pvid_set(struct prestera_port *port, u16 vid)
 {
 	int err;
 
@@ -1391,7 +532,7 @@ int mvsw_pr_port_pvid_set(struct mvsw_pr_port *port, u16 vid)
 	return err;
 }
 
-int mvsw_pr_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
+int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state)
 {
 	u8 hw_state = state;
 
@@ -1420,10 +561,10 @@ int mvsw_pr_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
 	return mvsw_pr_hw_port_vid_stp_set(port, vid, hw_state);
 }
 
-struct mvsw_pr_port_vlan*
-mvsw_pr_port_vlan_find_by_vid(const struct mvsw_pr_port *port, u16 vid)
+struct prestera_port_vlan*
+prestera_port_vlan_find_by_vid(const struct prestera_port *port, u16 vid)
 {
-	struct mvsw_pr_port_vlan *port_vlan;
+	struct prestera_port_vlan *port_vlan;
 
 	list_for_each_entry(port_vlan, &port->vlans_list, list) {
 		if (port_vlan->vid == vid)
@@ -1433,17 +574,17 @@ mvsw_pr_port_vlan_find_by_vid(const struct mvsw_pr_port *port, u16 vid)
 	return NULL;
 }
 
-struct mvsw_pr_port_vlan*
-mvsw_pr_port_vlan_create(struct mvsw_pr_port *port, u16 vid, bool untagged)
+struct prestera_port_vlan*
+prestera_port_vlan_create(struct prestera_port *port, u16 vid, bool untagged)
 {
-	struct mvsw_pr_port_vlan *port_vlan;
+	struct prestera_port_vlan *port_vlan;
 	int err;
 
-	port_vlan = mvsw_pr_port_vlan_find_by_vid(port, vid);
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (port_vlan)
 		return ERR_PTR(-EEXIST);
 
-	err = mvsw_pr_port_vlan_set(port, vid, true, untagged);
+	err = prestera_port_vlan_set(port, vid, true, untagged);
 	if (err)
 		return ERR_PTR(err);
 
@@ -1461,38 +602,38 @@ mvsw_pr_port_vlan_create(struct mvsw_pr_port *port, u16 vid, bool untagged)
 	return port_vlan;
 
 err_port_vlan_alloc:
-	mvsw_pr_port_vlan_set(port, vid, false, false);
+	prestera_port_vlan_set(port, vid, false, false);
 	return ERR_PTR(err);
 }
 
 static void
-mvsw_pr_port_vlan_cleanup(struct mvsw_pr_port_vlan *port_vlan)
+prestera_port_vlan_cleanup(struct prestera_port_vlan *port_vlan)
 {
 	if (port_vlan->bridge_port)
-		mvsw_pr_port_vlan_bridge_leave(port_vlan);
+		prestera_port_vlan_bridge_leave(port_vlan);
 }
 
-void mvsw_pr_port_vlan_destroy(struct mvsw_pr_port_vlan *port_vlan)
+void prestera_port_vlan_destroy(struct prestera_port_vlan *port_vlan)
 {
-	struct mvsw_pr_port *port = port_vlan->mvsw_pr_port;
+	struct prestera_port *port = port_vlan->mvsw_pr_port;
 	u16 vid = port_vlan->vid;
 
-	mvsw_pr_port_vlan_cleanup(port_vlan);
+	prestera_port_vlan_cleanup(port_vlan);
 	list_del(&port_vlan->list);
 	kfree(port_vlan);
 	mvsw_pr_hw_vlan_port_set(port, vid, false, false);
 }
 
-int mvsw_pr_port_vlan_set(struct mvsw_pr_port *port, u16 vid,
-			  bool is_member, bool untagged)
+int prestera_port_vlan_set(struct prestera_port *port, u16 vid,
+			   bool is_member, bool untagged)
 {
 	return mvsw_pr_hw_vlan_port_set(port, vid, is_member, untagged);
 }
 
 #ifdef CONFIG_PHYLINK
-static void mvsw_pr_link_validate(struct phylink_config *config,
-	unsigned long *supported,
-	struct phylink_link_state *state)
+static void prestera_link_validate(struct phylink_config *config,
+				   unsigned long *supported,
+				   struct phylink_link_state *state)
 {
 	__ETHTOOL_DECLARE_LINK_MODE_MASK(mask) = {0,};
 
@@ -1556,25 +697,23 @@ static void mvsw_pr_link_validate(struct phylink_config *config,
 
 empty_set:
 	bitmap_zero(supported, __ETHTOOL_LINK_MODE_MASK_NBITS);
-
 }
 
-static void mvsw_pr_mac_pcs_get_state(struct phylink_config *config,
-				      struct phylink_link_state *state)
+static void prestera_mac_pcs_get_state(struct phylink_config *config,
+				       struct phylink_link_state *state)
 {
 	struct net_device *ndev = to_net_dev(config->dev);
-	struct mvsw_pr_port *port = netdev_priv(ndev);
+	struct prestera_port *port = netdev_priv(ndev);
 
-	state->link = !!(port->hw_oper_state);
+	state->link = port->link_params.oper_state;
 	state->pause = 0;
 
-	if (port->hw_oper_state) {
+	if (port->link_params.oper_state) {
 		/* AN is completed, when port is up */
 		state->an_complete = port->autoneg;
 
-		state->speed = port->hw_speed;
-		state->duplex = (port->hw_duplex == MVSW_PORT_DUPLEX_FULL) ?
-					DUPLEX_FULL : DUPLEX_HALF;
+		state->speed = port->link_params.speed;
+		state->duplex = port->link_params.duplex;
 	} else {
 		state->an_complete = false;
 		state->speed = SPEED_UNKNOWN;
@@ -1582,53 +721,65 @@ static void mvsw_pr_mac_pcs_get_state(struct phylink_config *config,
 	}
 }
 
-static void mvsw_pr_mac_config(struct phylink_config *config,
-			       unsigned int an_mode,
-			       const struct phylink_link_state *state)
+static void prestera_mac_config(struct phylink_config *config,
+				unsigned int an_mode,
+				const struct phylink_link_state *state)
 {
 	struct net_device *ndev = to_net_dev(config->dev);
-	struct mvsw_pr_port *port = netdev_priv(ndev);
-	u32 mode;
+	struct prestera_port *port = netdev_priv(ndev);
+	struct prestera_port_mac_config cfg_mac;
+
+	prestera_port_cfg_mac_read(port, &cfg_mac);
+	cfg_mac.admin = true;
+	cfg_mac.mode = PRESTERA_MAC_MODE_MAX;
+	cfg_mac.inband = false;
+	cfg_mac.speed = 0;
+	cfg_mac.duplex = DUPLEX_UNKNOWN;
+	cfg_mac.fec = MVSW_PORT_FEC_OFF_BIT;
 
 	/* See sfp_select_interface... fIt */
 	switch (state->interface) {
 	case PHY_INTERFACE_MODE_10GBASER:
-		/* Or SR... doesn't matter */
-		mode = MVSW_LINK_MODE_10GbaseLR_Full_BIT;
+		cfg_mac.mode = PRESTERA_MAC_MODE_SR_LR;
+		cfg_mac.speed = SPEED_10000;
 		if (state->speed == SPEED_1000)
-			mode = MVSW_LINK_MODE_1000baseX_Full_BIT;
-		if (state->speed == SPEED_2500)
-			mode = MVSW_LINK_MODE_2500baseX_Full_BIT;
+			cfg_mac.mode = PRESTERA_MAC_MODE_1000BASE_X;
+		if (state->speed == SPEED_2500) {
+			cfg_mac.mode = PRESTERA_MAC_MODE_SGMII;
+			cfg_mac.inband = true;
+			cfg_mac.speed = SPEED_2500;
+			cfg_mac.duplex = DUPLEX_FULL;
+		}
 		break;
 	case PHY_INTERFACE_MODE_2500BASEX:
 		/* But it seems to be not supported in HW */
-		mode = MVSW_LINK_MODE_2500baseX_Full_BIT;
+		cfg_mac.mode = PRESTERA_MAC_MODE_SGMII;
+		cfg_mac.inband = true;
+		cfg_mac.speed = SPEED_2500;
+		cfg_mac.duplex = DUPLEX_FULL;
 		break;
 	case PHY_INTERFACE_MODE_SGMII:
-		/* Can be T or X. But for HW is no difference. */
-		mode = MVSW_LINK_MODE_1000baseT_Full_BIT;
+		cfg_mac.mode = PRESTERA_MAC_MODE_SGMII;
+		cfg_mac.inband = true;
 		break;
 	case PHY_INTERFACE_MODE_1000BASEX:
-		mode = MVSW_LINK_MODE_1000baseX_Full_BIT;
+		cfg_mac.mode = PRESTERA_MAC_MODE_1000BASE_X;
+		cfg_mac.inband = state->an_enabled;
 		break;
 	default:
-		mode = MVSW_LINK_MODE_1000baseX_Full_BIT;
+		cfg_mac.mode = PRESTERA_MAC_MODE_1000BASE_X;
 	}
 
-	mvsw_pr_hw_port_link_mode_set(port, mode);
-
-	/* NOTE: we suppose, that inband autoneg is primary used for
-	 * modes, which support only FC autonegotiation. But we don't support
-	 * FC. So inband autoneg always be disabled.
-	 */
+	prestera_port_cfg_mac_write(port, &cfg_mac);
+}
 
-	if (phylink_autoneg_inband(an_mode))
-		mvsw_pr_port_autoneg_set(port, false, 0, 0);
-	else
-		mvsw_pr_port_autoneg_set(port, false, 0, 0);
+int prestera_mac_finish(struct phylink_config *config, unsigned int mode,
+			phy_interface_t iface)
+{
+	return 0;
 }
 
-static void mvsw_pr_mac_an_restart(struct phylink_config *config)
+static void prestera_mac_an_restart(struct phylink_config *config)
 {
 	/* No need to restart autoneg as it is always with the same parameters,
 	 * because e.g. as for 1000baseX FC isn't supported. And for 1000baseT
@@ -1636,31 +787,32 @@ static void mvsw_pr_mac_an_restart(struct phylink_config *config)
 	 */
 }
 
-static void mvsw_pr_mac_link_down(struct phylink_config *config,
-				  unsigned int mode, phy_interface_t interface)
+static void prestera_mac_link_down(struct phylink_config *config,
+				   unsigned int mode, phy_interface_t interface)
 {
 }
 
-static void mvsw_pr_mac_link_up(struct phylink_config *config,
-				struct phy_device *phy,
-				unsigned int mode, phy_interface_t interface,
-				int speed, int duplex,
-				bool tx_pause, bool rx_pause)
+static void prestera_mac_link_up(struct phylink_config *config,
+				 struct phy_device *phy,
+				 unsigned int mode, phy_interface_t interface,
+				 int speed, int duplex,
+				 bool tx_pause, bool rx_pause)
 {
 }
 
-static const struct phylink_mac_ops mvsw_pr_mac_ops = {
-	.validate = mvsw_pr_link_validate,
-	.mac_pcs_get_state = mvsw_pr_mac_pcs_get_state,
-	.mac_config = mvsw_pr_mac_config,
-	.mac_an_restart = mvsw_pr_mac_an_restart,
-	.mac_link_down = mvsw_pr_mac_link_down,
-	.mac_link_up = mvsw_pr_mac_link_up,
+static const struct phylink_mac_ops prestera_mac_ops = {
+	.validate = prestera_link_validate,
+	.mac_pcs_get_state = prestera_mac_pcs_get_state,
+	.mac_config = prestera_mac_config,
+	.mac_finish = prestera_mac_finish,
+	.mac_an_restart = prestera_mac_an_restart,
+	.mac_link_down = prestera_mac_link_down,
+	.mac_link_up = prestera_mac_link_up,
 };
 
-static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
+static int prestera_port_sfp_bind(struct prestera_port *port)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct device_node *ports, *node;
 	struct fwnode_handle *fwnode;
 	struct phylink *phy_link;
@@ -1695,7 +847,7 @@ static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
 
 		phy_link = phylink_create(&port->phy_config, fwnode,
 					  PHY_INTERFACE_MODE_INTERNAL,
-					  &mvsw_pr_mac_ops);
+					  &prestera_mac_ops);
 		if (IS_ERR(phy_link)) {
 			netdev_err(port->net_dev, "failed to create phylink\n");
 			return PTR_ERR(phy_link);
@@ -1708,173 +860,315 @@ static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
 	return 0;
 }
 #else
-static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
+static int prestera_port_sfp_bind(struct prestera_port *port)
 {
 	return 0;
 }
 #endif
 
-static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
+static void __prestera_ports_free(struct prestera_switch *sw);
+static void __prestera_ports_unregister(struct prestera_switch *sw);
+
+/* alloc structures and configure HW */
+static int __prestera_ports_alloc(struct prestera_switch *sw)
 {
 	struct net_device *net_dev;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
+	struct prestera_port_mac_config cfg_mac;
 	char *mac;
 	int err;
+	u32 id;
 
-	net_dev = alloc_etherdev(sizeof(*port));
-	if (!net_dev)
-		return -ENOMEM;
+	for (id = 0; id < sw->port_count; id++) {
+		net_dev = alloc_etherdev(sizeof(*port));
+		if (!net_dev) {
+			err = -ENOMEM;
+			goto err_alloc_etherdev;
+		}
 
-	port = netdev_priv(net_dev);
+		port = netdev_priv(net_dev);
 
-	INIT_LIST_HEAD(&port->vlans_list);
-	port->pvid = MVSW_PR_DEFAULT_VID;
-	port->net_dev = net_dev;
-	port->id = id;
-	port->sw = sw;
-	port->lag_id = sw->lag_max;
+		port->rxtx_stats =
+			netdev_alloc_pcpu_stats(struct prestera_rxtx_stats);
+		if (!port->rxtx_stats) {
+			err = -ENOMEM;
+			goto err_alloc_stats;
+		}
 
-	err = mvsw_pr_hw_port_info_get(port, &port->fp_id,
-				       &port->hw_id, &port->dev_id);
-	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to get port(%u) info\n", id);
-		goto err_free_netdev;
-	}
+		INIT_LIST_HEAD(&port->vlans_list);
+		port->pvid = PRESTERA_DEFAULT_VID;
+		port->net_dev = net_dev;
+		port->id = id;
+		port->sw = sw;
+		port->lag_id = sw->lag_max;
 
-	err = prestera_devlink_port_register(port);
-	if (err)
-		goto err_devl_port_reg;
+		err = mvsw_pr_hw_port_info_get(port, &port->fp_id,
+					       &port->hw_id, &port->dev_id);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to get port(%u) info\n", id);
+			goto err_port_info_get;
+		}
 
-	net_dev->needed_headroom = MVSW_PR_DSA_HLEN + 4;
+		net_dev->needed_headroom = MVSW_PR_DSA_HLEN + 4;
 
-	net_dev->netdev_ops = &mvsw_pr_netdev_ops;
-	net_dev->ethtool_ops = &mvsw_pr_ethtool_ops;
-	net_dev->features |= NETIF_F_NETNS_LOCAL | NETIF_F_HW_TC;
-	net_dev->hw_features |= NETIF_F_HW_TC;
-	net_dev->ethtool_ops = &mvsw_pr_ethtool_ops;
-	net_dev->netdev_ops = &mvsw_pr_netdev_ops;
-	SET_NETDEV_DEV(net_dev, sw->dev->dev);
+		net_dev->features |= NETIF_F_NETNS_LOCAL | NETIF_F_HW_TC;
+		net_dev->hw_features |= NETIF_F_HW_TC;
+		net_dev->ethtool_ops = &prestera_ethtool_ops;
+		net_dev->netdev_ops = &prestera_netdev_ops;
+		SET_NETDEV_DEV(net_dev, sw->dev->dev);
 
-	net_dev->mtu = min_t(unsigned int, sw->mtu_max, MVSW_PR_MTU_DEFAULT);
-	net_dev->min_mtu = sw->mtu_min;
-	net_dev->max_mtu = sw->mtu_max;
+		net_dev->mtu = min_t(unsigned int, sw->mtu_max,
+				     PRESTERA_MTU_DEFAULT);
+		net_dev->min_mtu = sw->mtu_min;
+		net_dev->max_mtu = sw->mtu_max;
 
-	err = mvsw_pr_hw_port_mtu_set(port, net_dev->mtu);
-	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set port(%u) mtu\n", id);
-		goto err_port_init;
-	}
+		err = mvsw_pr_hw_port_mtu_set(port, net_dev->mtu);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to set port(%u) mtu\n", id);
+			goto err_mtu_set;
+		}
 
-	/* Only 0xFF mac addrs are supported */
-	if (port->fp_id >= 0xFF)
-		goto err_port_init;
+		/* Only 0xFF mac addrs are supported */
+		if (port->fp_id >= 0xFF) {
+			err = -ENOTSUPP;
+			goto err_fp_check;
+		}
 
-	mac = net_dev->dev_addr;
-	memcpy(mac, sw->base_mac, net_dev->addr_len);
-	mac[net_dev->addr_len - 1] += port->fp_id + MVSW_PR_MAC_ADDR_OFFSET;
+		mac = net_dev->dev_addr;
+		memcpy(mac, sw->base_mac, net_dev->addr_len);
+		mac[net_dev->addr_len - 1] += port->fp_id +
+					      PRESTERA_MAC_ADDR_OFFSET;
 
-	err = mvsw_pr_hw_port_mac_set(port, mac);
-	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set port(%u) mac addr\n", id);
-		goto err_port_init;
-	}
+		err = mvsw_pr_hw_port_mac_set(port, mac);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to set port(%u) mac addr\n", id);
+			goto err_mac_set;
+		}
 
-	err = mvsw_pr_hw_port_cap_get(port, &port->caps);
-	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to get port(%u) caps\n", id);
-		goto err_port_init;
-	}
+		err = mvsw_pr_hw_port_cap_get(port, &port->caps);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to get port(%u) caps\n", id);
+			goto err_cap_set;
+		}
 
 #ifdef CONFIG_PHYLINK
-	if (port->caps.transceiver != MVSW_PORT_TRANSCEIVER_SFP)
-		netif_carrier_off(net_dev);
+		if (port->caps.transceiver != MVSW_PORT_TRANSCEIVER_SFP)
+			netif_carrier_off(net_dev);
 #else
-	netif_carrier_off(net_dev);
+		netif_carrier_off(net_dev);
 #endif
 
-	port->adver_link_modes = 0;
-	port->adver_fec = 0;
-	port->autoneg = false;
-	mvsw_pr_port_autoneg_set(port, true, port->caps.supp_link_modes,
-				 BIT(MVSW_PORT_FEC_OFF_BIT));
+		/* TODO: this is related only for phy */
+		port->adver_link_modes = port->caps.supp_link_modes;
+		port->adver_fec = 0;
+		port->autoneg = true;
 
-	err = mvsw_pr_hw_port_state_set(port, false);
-	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set port(%u) down\n", id);
-		goto err_port_init;
+		/* initialize config mac */
+		if (port->caps.transceiver != MVSW_PORT_TRANSCEIVER_SFP) {
+			cfg_mac.admin = true;
+			cfg_mac.mode = PRESTERA_MAC_MODE_INTERNAL;
+		} else {
+			cfg_mac.admin = false;
+			cfg_mac.mode = PRESTERA_MAC_MODE_MAX;
+		}
+		cfg_mac.inband = false;
+		cfg_mac.speed = 0;
+		cfg_mac.duplex = DUPLEX_UNKNOWN;
+		cfg_mac.fec = MVSW_PORT_FEC_OFF_BIT;
+
+		err = prestera_port_cfg_mac_write(port, &cfg_mac);
+		if (err) {
+			dev_err(prestera_dev(sw),
+				"Failed to set port(%u) mac mode\n", id);
+			goto err_state_set;
+		}
+
+		/* initialize config phy (if this is inegral) */
+		if (port->caps.transceiver != MVSW_PORT_TRANSCEIVER_SFP) {
+			/* TODO: another parameters init */
+			port->cfg_phy.admin = false;
+			err = mvsw_pr_hw_port_phy_mode_set(port, false, false,
+							   0, 0);
+			if (err) {
+				dev_err(prestera_dev(sw),
+					"Failed to set port(%u) phy mode\n",
+					id);
+				goto err_state_set;
+			}
+		}
+
+		prestera_port_uc_flood_set(port, false);
+		prestera_port_mc_flood_set(port, false);
+
+		INIT_DELAYED_WORK(&port->cached_hw_stats.caching_dw,
+				  &update_stats_cache);
+
+		/* We can list_add before netdev_register,
+		 * as it done in deinit seq
+		 */
+		list_add_tail(&port->list, &sw->port_list);
+	}
+
+	return 0;
+
+	/* rollback */
+err_alloc_etherdev:
+	while (!list_empty(&sw->port_list)) {
+		port = list_last_entry(&sw->port_list, typeof(*port), list);
+		net_dev = port->net_dev;
+
+		list_del(&port->list);
+err_state_set:
+err_cap_set:
+err_mac_set:
+err_fp_check:
+err_mtu_set:
+err_port_info_get:
+		free_percpu(port->rxtx_stats);
+err_alloc_stats:
+		free_netdev(net_dev);
 	}
 
-	INIT_DELAYED_WORK(&port->cached_hw_stats.caching_dw,
-			  &update_stats_cache);
+	return err;
+}
 
-	err = register_netdev(net_dev);
-	if (err)
-		goto err_port_init;
+/* propagate port to kernel */
+static int __prestera_ports_register(struct prestera_switch *sw)
+{
+	struct prestera_port *port;
+	int err;
 
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP) {
-		err = mvsw_pr_port_sfp_bind(port);
+	list_for_each_entry(port, &sw->port_list, list) {
+		/* Believe, that traffic cannot be received on port before
+		 * this point
+		 */
+		err = prestera_devlink_port_register(port);
 		if (err)
-			goto err_sfp_bind;
+			goto err_devlink_register;
 	}
 
-	list_add(&port->list, &sw->port_list);
+	rtnl_lock();
+	list_for_each_entry(port, &sw->port_list, list) {
+		err = register_netdevice(port->net_dev);
+		if (err)
+			goto err_register_netdevice;
+	}
+	rtnl_unlock();
 
-	mvsw_pr_port_uc_flood_set(port, false);
-	mvsw_pr_port_mc_flood_set(port, false);
+	list_for_each_entry(port, &sw->port_list, list) {
+		if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP) {
+			err = prestera_port_sfp_bind(port);
+			if (err)
+				goto err_sfp_bind;
+		}
 
-	prestera_devlink_port_set(port);
+		prestera_devlink_port_set(port);
+	}
 
 	return 0;
 
 err_sfp_bind:
-	unregister_netdev(net_dev);
-	prestera_devlink_port_unregister(port);
-err_port_init:
-err_devl_port_reg:
-err_free_netdev:
-	free_netdev(net_dev);
+	/* rollback */
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list)
+		prestera_devlink_port_clear(port);
+
+	rtnl_lock();
+err_register_netdevice:
+	/* rollback */
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list)
+		unregister_netdevice(port->net_dev);
+	rtnl_unlock();
+
+err_devlink_register:
+	/* rollback */
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list) {
+#ifdef CONFIG_PHYLINK
+		if (port->phy_link)
+			phylink_destroy(port->phy_link);
+#endif
+		prestera_devlink_port_unregister(port);
+	}
+
+	return -ENOTSUPP;
+}
+
+static int prestera_ports_create(struct prestera_switch *sw)
+{
+	int err;
+
+	err = __prestera_ports_alloc(sw);
+	if (err)
+		goto err_alloc;
+
+	err = __prestera_ports_register(sw);
+	if (err)
+		goto err_register;
+
+	return 0;
+
+err_register:
+	__prestera_ports_free(sw);
+err_alloc:
 	return err;
 }
 
-static void mvsw_pr_port_vlan_flush(struct mvsw_pr_port *port,
-				    bool flush_default)
+static void prestera_port_vlan_flush(struct prestera_port *port,
+				     bool flush_default)
 {
-	struct mvsw_pr_port_vlan *port_vlan, *tmp;
+	struct prestera_port_vlan *port_vlan, *tmp;
 
 	list_for_each_entry_safe(port_vlan, tmp, &port->vlans_list, list) {
-		if (!flush_default && port_vlan->vid == MVSW_PR_DEFAULT_VID)
+		if (!flush_default && port_vlan->vid == PRESTERA_DEFAULT_VID)
 			continue;
 
-		mvsw_pr_port_vlan_destroy(port_vlan);
+		prestera_port_vlan_destroy(port_vlan);
 	}
 }
 
-int mvsw_pr_8021d_bridge_create(struct mvsw_pr_switch *sw, u16 *bridge_id)
+int prestera_8021d_bridge_create(struct prestera_switch *sw, u16 *bridge_id)
 {
 	return mvsw_pr_hw_bridge_create(sw, bridge_id);
 }
 
-int mvsw_pr_8021d_bridge_delete(struct mvsw_pr_switch *sw, u16 bridge_id)
+int prestera_8021d_bridge_delete(struct prestera_switch *sw, u16 bridge_id)
 {
 	return mvsw_pr_hw_bridge_delete(sw, bridge_id);
 }
 
-int mvsw_pr_8021d_bridge_port_add(struct mvsw_pr_port *port, u16 bridge_id)
+int prestera_8021d_bridge_port_add(struct prestera_port *port, u16 bridge_id)
 {
 	return mvsw_pr_hw_bridge_port_add(port, bridge_id);
 }
 
-int mvsw_pr_8021d_bridge_port_delete(struct mvsw_pr_port *port, u16 bridge_id)
+int prestera_8021d_bridge_port_delete(struct prestera_port *port, u16 bridge_id)
 {
 	return mvsw_pr_hw_bridge_port_delete(port, bridge_id);
 }
 
-int mvsw_pr_switch_ageing_set(struct mvsw_pr_switch *sw, u32 ageing_time)
+int prestera_switch_ageing_set(struct prestera_switch *sw, u32 ageing_time)
 {
 	return mvsw_pr_hw_switch_ageing_set(sw, ageing_time / 1000);
 }
 
-int mvsw_pr_dev_if_type(const struct net_device *dev)
+struct prestera_port *prestera_port_find_by_fp_id(u32 fp_id)
+{
+	struct prestera_port *port = NULL;
+	struct prestera_switch *sw;
+
+	list_for_each_entry(sw, &switches_registered, list) {
+		list_for_each_entry(port, &sw->port_list, list) {
+			if (port->fp_id == fp_id)
+				return port;
+		}
+	}
+	return NULL;
+}
+
+int prestera_dev_if_type(const struct net_device *dev)
 {
 	struct macvlan_dev *vlan;
 
@@ -1886,14 +1180,14 @@ int mvsw_pr_dev_if_type(const struct net_device *dev)
 		return MVSW_IF_LAG_E;
 	else if (netif_is_macvlan(dev)) {
 		vlan = netdev_priv(dev);
-		return mvsw_pr_dev_if_type(vlan->lowerdev);
+		return prestera_dev_if_type(vlan->lowerdev);
 	}
 	else
 		return MVSW_IF_PORT_E;
 }
 
-int mvsw_pr_lpm_add(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len, u32 grp_id)
+int prestera_lpm_add(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len, u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1906,8 +1200,8 @@ int mvsw_pr_lpm_add(struct mvsw_pr_switch *sw, u16 hw_vr_id,
 				  prefix_len, grp_id);
 }
 
-int mvsw_pr_lpm_del(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len)
+int prestera_lpm_del(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct prestera_ip_addr *addr, u32 prefix_len)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1920,8 +1214,8 @@ int mvsw_pr_lpm_del(struct mvsw_pr_switch *sw, u16 hw_vr_id,
 				  prefix_len);
 }
 
-int mvsw_pr_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id)
+int prestera_nh_entries_set(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1932,8 +1226,8 @@ int mvsw_pr_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
 	return mvsw_pr_hw_nh_entries_set(sw, count, nhs, grp_id);
 }
 
-int mvsw_pr_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id)
+int prestera_nh_entries_get(const struct prestera_switch *sw, int count,
+			    struct prestera_neigh_info *nhs, u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1944,8 +1238,20 @@ int mvsw_pr_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
 	return mvsw_pr_hw_nh_entries_get(sw, count, nhs, grp_id);
 }
 
-int mvsw_pr_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 *grp_id)
+int prestera_nhgrp_blk_get(const struct prestera_switch *sw, u8 *hw_state,
+			   u32 buf_size)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	return mvsw_pr_hw_nhgrp_blk_get(sw, hw_state, buf_size);
+}
+
+int prestera_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+			     u32 *grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1956,8 +1262,8 @@ int mvsw_pr_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return mvsw_pr_hw_nh_group_create(sw, nh_count, grp_id);
 }
 
-int mvsw_pr_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 grp_id)
+int prestera_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+			     u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1968,72 +1274,71 @@ int mvsw_pr_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return mvsw_pr_hw_nh_group_delete(sw, nh_count, grp_id);
 }
 
-int mvsw_pr_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy)
+int prestera_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy)
 {
 	return mvsw_pr_hw_mp4_hash_set(sw, hash_policy);
 }
 
-int mvsw_pr_fdb_flush_vlan(struct mvsw_pr_switch *sw, u16 vid,
-			   enum mvsw_pr_fdb_flush_mode mode)
+int prestera_fdb_flush_vlan(struct prestera_switch *sw, u16 vid,
+			    enum prestera_fdb_flush_mode mode)
 {
 	return mvsw_pr_hw_fdb_flush_vlan(sw, vid, mode);
 }
 
-int mvsw_pr_fdb_flush_port_vlan(struct mvsw_pr_port *port, u16 vid,
-				enum mvsw_pr_fdb_flush_mode mode)
+int prestera_fdb_flush_port_vlan(struct prestera_port *port, u16 vid,
+				 enum prestera_fdb_flush_mode mode)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_fdb_flush_lag_vlan(port->sw, port->lag_id,
 						     vid, mode);
 	else
 		return mvsw_pr_hw_fdb_flush_port_vlan(port, vid, mode);
 }
 
-int mvsw_pr_fdb_flush_port(struct mvsw_pr_port *port,
-			   enum mvsw_pr_fdb_flush_mode mode)
+int prestera_fdb_flush_port(struct prestera_port *port,
+			    enum prestera_fdb_flush_mode mode)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_fdb_flush_lag(port->sw, port->lag_id, mode);
 	else
 		return mvsw_pr_hw_fdb_flush_port(port, mode);
 }
 
-int mvsw_pr_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid)
+int prestera_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid)
 {
 	return mvsw_pr_hw_macvlan_add(sw, vr_id, mac,  vid);
 }
 
-int mvsw_pr_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid)
+int prestera_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid)
 {
 	return mvsw_pr_hw_macvlan_del(sw, vr_id, mac,  vid);
 }
 
-static struct prestera_lag *
-prestera_lag_get(struct mvsw_pr_switch *sw, u8 id)
+struct prestera_lag *prestera_lag_get(struct prestera_switch *sw, u8 id)
 {
 	return id < sw->lag_max ? &sw->lags[id] : NULL;
 }
 
-static void mvsw_pr_port_lag_create(struct mvsw_pr_switch *sw, u16 lag_id,
-				    struct net_device *lag_dev)
+static void prestera_port_lag_create(struct prestera_switch *sw, u16 lag_id,
+				     struct net_device *lag_dev)
 {
 	INIT_LIST_HEAD(&sw->lags[lag_id].members);
 	sw->lags[lag_id].dev = lag_dev;
 }
 
-static void mvsw_pr_port_lag_destroy(struct mvsw_pr_switch *sw, u16 lag_id)
+static void prestera_port_lag_destroy(struct prestera_switch *sw, u16 lag_id)
 {
 	WARN_ON(!list_empty(&sw->lags[lag_id].members));
 	sw->lags[lag_id].dev = NULL;
 	sw->lags[lag_id].member_count = 0;
 }
 
-int prestera_lag_member_add(struct mvsw_pr_port *port,
+int prestera_lag_member_add(struct prestera_port *port,
 			    struct net_device *lag_dev, u16 lag_id)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct prestera_lag_member *member;
 	struct prestera_lag *lag;
 
@@ -2042,7 +1347,7 @@ int prestera_lag_member_add(struct mvsw_pr_port *port,
 	if (lag->member_count >= sw->lag_member_max)
 		return -ENOSPC;
 	else if (!lag->member_count)
-		mvsw_pr_port_lag_create(sw, lag_id, lag_dev);
+		prestera_port_lag_create(sw, lag_id, lag_dev);
 
 	member = kzalloc(sizeof(*member), GFP_KERNEL);
 	if (!member)
@@ -2051,7 +1356,7 @@ int prestera_lag_member_add(struct mvsw_pr_port *port,
 	if (mvsw_pr_hw_lag_member_add(port, lag_id)) {
 		kfree(member);
 		if (!lag->member_count)
-			mvsw_pr_port_lag_destroy(sw, lag_id);
+			prestera_port_lag_destroy(sw, lag_id);
 		return -EBUSY;
 	}
 
@@ -2062,9 +1367,9 @@ int prestera_lag_member_add(struct mvsw_pr_port *port,
 	return 0;
 }
 
-int prestera_lag_member_del(struct mvsw_pr_port *port)
+int prestera_lag_member_del(struct prestera_port *port)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct prestera_lag_member *member;
 	struct list_head *pos, *n;
 	u16 lag_id = port->lag_id;
@@ -2093,23 +1398,23 @@ int prestera_lag_member_del(struct mvsw_pr_port *port)
 
 	if (!lag->member_count) {
 		prestera_lag_router_leave(sw, lag->dev);
-		mvsw_pr_port_lag_destroy(sw, lag_id);
+		prestera_port_lag_destroy(sw, lag_id);
 	}
 
 	return 0;
 }
 
-int prestera_lag_member_enable(struct mvsw_pr_port *port, bool enable)
+int prestera_lag_member_enable(struct prestera_port *port, bool enable)
 {
 	return mvsw_pr_hw_lag_member_enable(port, port->lag_id, enable);
 }
 
-bool mvsw_pr_port_is_lag_member(const struct mvsw_pr_port *port)
+bool prestera_port_is_lag_member(const struct prestera_port *port)
 {
 	return port->lag_id < port->sw->lag_max;
 }
 
-int prestera_lag_id_find(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
+int prestera_lag_id_find(struct prestera_switch *sw, struct net_device *lag_dev,
 			 u16 *lag_id)
 {
 	struct prestera_lag *lag;
@@ -2133,19 +1438,19 @@ int prestera_lag_id_find(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
 	return 0;
 }
 
-void prestera_lag_member_rif_leave(const struct mvsw_pr_port *port,
+void prestera_lag_member_rif_leave(const struct prestera_port *port,
 				   u16 lag_id, u16 vr_id)
 {
 	mvsw_pr_hw_lag_member_rif_leave(port, lag_id, vr_id);
 }
 
-static int prestera_lag_init(struct mvsw_pr_switch *sw)
+static int prestera_lag_init(struct prestera_switch *sw)
 {
 	sw->lags = kcalloc(sw->lag_max, sizeof(*sw->lags), GFP_KERNEL);
 	return sw->lags ? 0 : -ENOMEM;
 }
 
-static void prestera_lag_fini(struct mvsw_pr_switch *sw)
+static void prestera_lag_fini(struct prestera_switch *sw)
 {
 	u8 idx;
 
@@ -2155,37 +1460,187 @@ static void prestera_lag_fini(struct mvsw_pr_switch *sw)
 	kfree(sw->lags);
 }
 
-static int mvsw_pr_clear_ports(struct mvsw_pr_switch *sw)
+static int prestera_span_init(struct prestera_switch *sw)
+{
+	struct prestera_span *span;
+
+	span = kzalloc(sizeof(*span), GFP_KERNEL);
+	if (!span)
+		return -ENOMEM;
+
+	INIT_LIST_HEAD(&span->entries);
+
+	sw->span = span;
+	span->sw = sw;
+
+	return 0;
+}
+
+static void prestera_span_fini(struct prestera_switch *sw)
+{
+	struct prestera_span *span = sw->span;
+
+	WARN_ON(!list_empty(&span->entries));
+	kfree(span);
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_create(struct prestera_port *port, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+
+	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+	if (!entry)
+		return ERR_PTR(-ENOMEM);
+
+	refcount_set(&entry->ref_count, 1);
+	entry->port = port;
+	entry->id = span_id;
+	list_add_tail(&entry->list, &port->sw->span->entries);
+
+	return entry;
+}
+
+static void prestera_span_entry_del(struct prestera_span_entry *entry)
+{
+	list_del(&entry->list);
+	kfree(entry);
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_find_by_id(struct prestera_span *span, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+
+	list_for_each_entry(entry, &span->entries, list) {
+		if (entry->id == span_id)
+			return entry;
+	}
+
+	return NULL;
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_find_by_port(struct prestera_span *span,
+				 struct prestera_port *port)
+{
+	struct prestera_span_entry *entry;
+
+	list_for_each_entry(entry, &span->entries, list) {
+		if (entry->port == port)
+			return entry;
+	}
+
+	return NULL;
+}
+
+int prestera_span_get(struct prestera_port *port, u8 *span_id)
+{
+	u8 new_span_id;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_span_entry *entry;
+	int err;
+
+	entry = prestera_span_entry_find_by_port(sw->span, port);
+	if (entry) {
+		refcount_inc(&entry->ref_count);
+		*span_id = entry->id;
+		return 0;
+	}
+
+	err = prestera_hw_span_get(port, &new_span_id);
+	if (err)
+		return err;
+
+	entry = prestera_span_entry_create(port, new_span_id);
+	if (IS_ERR(entry)) {
+		prestera_hw_span_release(sw, new_span_id);
+		return PTR_ERR(entry);
+	}
+
+	*span_id = new_span_id;
+	return 0;
+}
+
+int prestera_span_put(const struct prestera_switch *sw, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+	int err;
+
+	entry = prestera_span_entry_find_by_id(sw->span, span_id);
+	if (!entry)
+		return false;
+
+	if (!refcount_dec_and_test(&entry->ref_count))
+		return 0;
+
+	err = prestera_hw_span_release(sw, span_id);
+	if (err)
+		return err;
+
+	prestera_span_entry_del(entry);
+	return 0;
+}
+
+/* "free" opposite to "alloc" */
+static void __prestera_ports_free(struct prestera_switch *sw)
 {
 	struct net_device *net_dev;
 	struct list_head *pos, *n;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
 	list_for_each_safe(pos, n, &sw->port_list) {
 		port = list_entry(pos, typeof(*port), list);
 		net_dev = port->net_dev;
 
+		/* This is assymetric to create */
+		prestera_port_vlan_flush(port, true);
+		WARN_ON_ONCE(!list_empty(&port->vlans_list));
+		prestera_port_router_leave(port);
+
+		list_del(pos);
+		free_percpu(port->rxtx_stats);
+		free_netdev(net_dev);
+	}
+	WARN_ON(!list_empty(&sw->port_list));
+}
+
+/* propagate port to kernel */
+static void __prestera_ports_unregister(struct prestera_switch *sw)
+{
+	struct prestera_port *port;
+
+	list_for_each_entry(port, &sw->port_list, list) {
+		/* assymetric to create */
 		cancel_delayed_work_sync(&port->cached_hw_stats.caching_dw);
+
 		prestera_devlink_port_clear(port);
-		unregister_netdev(net_dev);
+	}
+
+	rtnl_lock();
+	list_for_each_entry(port, &sw->port_list, list)
+		unregister_netdevice(port->net_dev);
+	rtnl_unlock();
+
+	list_for_each_entry(port, &sw->port_list, list) {
 #ifdef CONFIG_PHYLINK
 		if (port->phy_link)
 			phylink_destroy(port->phy_link);
 #endif
-		mvsw_pr_port_vlan_flush(port, true);
-		WARN_ON_ONCE(!list_empty(&port->vlans_list));
-		mvsw_pr_port_router_leave(port);
 		prestera_devlink_port_unregister(port);
-		free_netdev(net_dev);
-		list_del(pos);
 	}
-	return (!list_empty(&sw->port_list));
 }
 
-static void mvsw_pr_port_handle_event(struct mvsw_pr_switch *sw,
-				      struct mvsw_pr_event *evt, void *arg)
+static void prestera_clear_ports(struct prestera_switch *sw)
 {
-	struct mvsw_pr_port *port;
+	__prestera_ports_unregister(sw);
+	__prestera_ports_free(sw);
+}
+
+static void prestera_port_handle_event(struct prestera_switch *sw,
+				       struct prestera_event *evt, void *arg)
+{
+	struct prestera_port *port;
 	struct delayed_work *caching_dw;
 
 	port = __find_pr_port(sw, evt->port_evt.port_id);
@@ -2194,16 +1649,14 @@ static void mvsw_pr_port_handle_event(struct mvsw_pr_switch *sw,
 
 	caching_dw = &port->cached_hw_stats.caching_dw;
 
+	prestera_ethtool_port_state_changed(port, &evt->port_evt);
+
 	switch (evt->id) {
 	case MVSW_PORT_EVENT_STATE_CHANGED:
-		port->hw_oper_state = evt->port_evt.data.oper_state;
 
-		if (port->hw_oper_state) {
-			port->hw_duplex = evt->port_evt.data.duplex;
-			port->hw_speed = evt->port_evt.data.speed;
+		if (port->link_params.oper_state) {
 #ifdef CONFIG_PHYLINK
-			if (port->caps.transceiver ==
-			    MVSW_PORT_TRANSCEIVER_SFP)
+			if (port->phy_link)
 				phylink_mac_change(port->phy_link, true);
 			else
 				netif_carrier_on(port->net_dev);
@@ -2212,13 +1665,10 @@ static void mvsw_pr_port_handle_event(struct mvsw_pr_switch *sw,
 #endif
 
 			if (!delayed_work_pending(caching_dw))
-				queue_delayed_work(mvsw_pr_wq, caching_dw, 0);
+				queue_delayed_work(prestera_wq, caching_dw, 0);
 		} else {
-			port->hw_duplex = 0;
-			port->hw_speed = 0;
 #ifdef CONFIG_PHYLINK
-			if (port->caps.transceiver ==
-			    MVSW_PORT_TRANSCEIVER_SFP)
+			if (port->phy_link)
 				phylink_mac_change(port->phy_link, false);
 			else
 				netif_carrier_off(port->net_dev);
@@ -2233,18 +1683,18 @@ static void mvsw_pr_port_handle_event(struct mvsw_pr_switch *sw,
 	}
 }
 
-static bool prestera_lag_exists(const struct mvsw_pr_switch *sw, u16 lag_id)
+static bool prestera_lag_exists(const struct prestera_switch *sw, u16 lag_id)
 {
 	return lag_id < sw->lag_max &&
 	       sw->lags[lag_id].member_count != 0;
 }
 
-static void mvsw_pr_fdb_handle_event(struct mvsw_pr_switch *sw,
-				     struct mvsw_pr_event *evt, void *arg)
+static void prestera_fdb_handle_event(struct prestera_switch *sw,
+				      struct prestera_event *evt, void *arg)
 {
 	struct switchdev_notifier_fdb_info info;
 	struct net_device *dev = NULL;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 	u16 lag_id;
 
 	switch (evt->fdb_evt.type) {
@@ -2283,84 +1733,79 @@ static void mvsw_pr_fdb_handle_event(struct mvsw_pr_switch *sw,
 	rtnl_unlock();
 }
 
-int mvsw_pr_fdb_add(struct mvsw_pr_port *port, const unsigned char *mac,
-		    u16 vid, bool dynamic)
+int prestera_fdb_add(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid, bool dynamic)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_lag_fdb_add(port->sw, port->lag_id,
 					      mac, vid, dynamic);
 	else
 		return mvsw_pr_hw_fdb_add(port, mac, vid, dynamic);
 }
 
-int mvsw_pr_fdb_del(struct mvsw_pr_port *port, const unsigned char *mac,
-		    u16 vid)
+int prestera_fdb_del(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_lag_fdb_del(port->sw, port->lag_id,
 					      mac, vid);
 	else
 		return mvsw_pr_hw_fdb_del(port, mac, vid);
 }
 
-static void mvsw_pr_fdb_event_handler_unregister(struct mvsw_pr_switch *sw)
+static void prestera_fdb_event_handler_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_FDB);
 }
 
-static void mvsw_pr_port_event_handler_unregister(struct mvsw_pr_switch *sw)
+static void prestera_port_event_handler_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_PORT);
 }
 
-static void mvsw_pr_event_handlers_unregister(struct mvsw_pr_switch *sw)
+static void prestera_event_handlers_unregister(struct prestera_switch *sw)
 {
-	mvsw_pr_fdb_event_handler_unregister(sw);
-	mvsw_pr_port_event_handler_unregister(sw);
+	prestera_fdb_event_handler_unregister(sw);
+	prestera_port_event_handler_unregister(sw);
 }
 
-static int mvsw_pr_fdb_event_handler_register(struct mvsw_pr_switch *sw)
+static int prestera_fdb_event_handler_register(struct prestera_switch *sw)
 {
 	return mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_FDB,
-						 mvsw_pr_fdb_handle_event,
+						 prestera_fdb_handle_event,
 						 NULL);
 }
 
-static int mvsw_pr_port_event_handler_register(struct mvsw_pr_switch *sw)
+static int prestera_port_event_handler_register(struct prestera_switch *sw)
 {
 	return mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_PORT,
-						 mvsw_pr_port_handle_event,
+						 prestera_port_handle_event,
 						 NULL);
 }
 
-static int mvsw_pr_event_handlers_register(struct mvsw_pr_switch *sw)
+static int prestera_event_handlers_register(struct prestera_switch *sw)
 {
 	int err;
 
-	err = mvsw_pr_port_event_handler_register(sw);
+	err = prestera_port_event_handler_register(sw);
 	if (err)
 		return err;
 
-	err = mvsw_pr_fdb_event_handler_register(sw);
+	err = prestera_fdb_event_handler_register(sw);
 	if (err)
 		goto err_fdb_handler_register;
 
 	return 0;
 
 err_fdb_handler_register:
-	mvsw_pr_port_event_handler_unregister(sw);
+	prestera_port_event_handler_unregister(sw);
 	return err;
 }
 
-int mvsw_pr_schedule_dw(struct delayed_work *dwork, unsigned long delay)
+struct prestera_port *prestera_port_find(u32 dev_hw_id, u32 port_hw_id)
 {
-	return queue_delayed_work(mvsw_pr_wq, dwork, delay);
-}
-
-const struct mvsw_pr_port *mvsw_pr_port_find(u32 dev_hw_id, u32 port_hw_id)
-{
-	struct mvsw_pr_port *port = NULL;
-	struct mvsw_pr_switch *sw;
+	struct prestera_port *port = NULL;
+	struct prestera_switch *sw;
 
 	list_for_each_entry(sw, &switches_registered, list) {
 		list_for_each_entry(port, &sw->port_list, list) {
@@ -2372,7 +1817,7 @@ const struct mvsw_pr_port *mvsw_pr_port_find(u32 dev_hw_id, u32 port_hw_id)
 	return NULL;
 }
 
-static int mvsw_pr_sw_init_base_mac(struct mvsw_pr_switch *sw)
+static int prestera_sw_init_base_mac(struct prestera_switch *sw)
 {
 	struct device_node *mac_dev_np;
 	u32 lsb;
@@ -2393,7 +1838,7 @@ static int mvsw_pr_sw_init_base_mac(struct mvsw_pr_switch *sw)
 		eth_random_addr(sw->base_mac);
 
 	lsb = sw->base_mac[ETH_ALEN - 1];
-	if (lsb + sw->port_count + MVSW_PR_MAC_ADDR_OFFSET > 0xFF)
+	if (lsb + sw->port_count + PRESTERA_MAC_ADDR_OFFSET > 0xFF)
 		sw->base_mac[ETH_ALEN - 1] = 0;
 
 	err = mvsw_pr_hw_switch_mac_set(sw, sw->base_mac);
@@ -2403,30 +1848,30 @@ static int mvsw_pr_sw_init_base_mac(struct mvsw_pr_switch *sw)
 	return 0;
 }
 
-static int mvsw_pr_init(struct mvsw_pr_switch *sw)
+static int prestera_init(struct prestera_switch *sw)
 {
-	u32 port;
 	int err;
 
 	sw->np = of_find_compatible_node(NULL, NULL, "marvell,prestera");
 
 	err = mvsw_pr_hw_switch_init(sw);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to init Switch device\n");
+		dev_err(prestera_dev(sw), "Failed to init Switch device\n");
 		return err;
 	}
 
 	err = mvsw_pr_hw_switch_trap_policer_set(sw, trap_policer_profile);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set trap policer profile\n");
+		dev_err(prestera_dev(sw),
+			"Failed to set trap policer profile\n");
 		return err;
 	}
 
-	err = mvsw_pr_sw_init_base_mac(sw);
+	err = prestera_sw_init_base_mac(sw);
 	if (err)
 		return err;
 
-	dev_info(mvsw_dev(sw), "Initialized Switch device\n");
+	dev_info(prestera_dev(sw), "Initialized Switch device\n");
 
 	err = prestera_lag_init(sw);
 	if (err)
@@ -2440,63 +1885,79 @@ static int mvsw_pr_init(struct mvsw_pr_switch *sw)
 	if (err)
 		goto err_devl_reg;
 
+	err = prestera_counter_init(sw);
+	if (err)
+		goto err_counter_init;
+
+	err = prestera_acl_init(sw);
+	if (err)
+		goto err_acl_init;
+
+	err = prestera_span_init(sw);
+	if (err)
+		goto err_span_init;
+
 	INIT_LIST_HEAD(&sw->port_list);
 
-	for (port = 0; port < sw->port_count; port++) {
-		err = mvsw_pr_port_create(sw, port);
-		if (err)
-			goto err_ports_init;
-	}
+	err = prestera_ports_create(sw);
+	if (err)
+		goto err_ports_init;
 
-	err = mvsw_pr_rxtx_switch_init(sw);
+	err = prestera_rxtx_switch_init(sw);
 	if (err)
 		goto err_rxtx_init;
 
-	err = mvsw_pr_event_handlers_register(sw);
+	err = prestera_event_handlers_register(sw);
 	if (err)
 		goto err_event_handlers;
 
-	err = mvsw_pr_debugfs_init(sw);
+	err = prestera_debugfs_init(sw);
 	if (err)
 		goto err_debugfs_init;
 
-	err = prestera_acl_init(sw);
-	if (err)
-		goto err_acl_init;
-
 	return 0;
 
-err_acl_init:
 err_debugfs_init:
-	mvsw_pr_event_handlers_unregister(sw);
+	prestera_event_handlers_unregister(sw);
 err_event_handlers:
-	mvsw_pr_rxtx_switch_fini(sw);
+	prestera_rxtx_switch_fini(sw);
 err_rxtx_init:
+	prestera_clear_ports(sw);
 err_ports_init:
-	mvsw_pr_clear_ports(sw);
+	prestera_span_fini(sw);
+err_span_init:
+	prestera_acl_fini(sw);
+err_acl_init:
+	prestera_counter_fini(sw);
+err_counter_init:
+	prestera_devlink_unregister(sw);
 err_devl_reg:
 	prestera_switchdev_unregister(sw);
 	return err;
 }
 
-static void mvsw_pr_fini(struct mvsw_pr_switch *sw)
+static void prestera_fini(struct prestera_switch *sw)
 {
-	mvsw_pr_debugfs_fini(sw);
+	prestera_debugfs_fini(sw);
 
-	mvsw_pr_event_handlers_unregister(sw);
+	prestera_event_handlers_unregister(sw);
 
-	mvsw_pr_clear_ports(sw);
-	mvsw_pr_rxtx_switch_fini(sw);
+	prestera_clear_ports(sw);
+	prestera_rxtx_switch_fini(sw);
 	prestera_devlink_unregister(sw);
 	prestera_switchdev_unregister(sw);
+	prestera_span_fini(sw);
 	prestera_acl_fini(sw);
+	prestera_counter_fini(sw);
 	prestera_lag_fini(sw);
+	mvsw_pr_hw_keepalive_fini(sw);
+	prestera_hw_switch_reset(sw);
 	of_node_put(sw->np);
 }
 
 int prestera_device_register(struct prestera_device *dev)
 {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	int err;
 
 	sw = prestera_devlink_alloc();
@@ -2506,7 +1967,7 @@ int prestera_device_register(struct prestera_device *dev)
 	dev->priv = sw;
 	sw->dev = dev;
 
-	err = mvsw_pr_init(sw);
+	err = prestera_init(sw);
 	if (err) {
 		prestera_devlink_free(sw);
 		return err;
@@ -2520,45 +1981,35 @@ EXPORT_SYMBOL(prestera_device_register);
 
 void prestera_device_unregister(struct prestera_device *dev)
 {
-	struct mvsw_pr_switch *sw = dev->priv;
+	struct prestera_switch *sw = dev->priv;
 
 	list_del(&sw->list);
-	mvsw_pr_fini(sw);
+	prestera_fini(sw);
 	prestera_devlink_free(sw);
 }
 EXPORT_SYMBOL(prestera_device_unregister);
 
-static int __init mvsw_pr_module_init(void)
+static int __init prestera_module_init(void)
 {
-	int err;
-
 	INIT_LIST_HEAD(&switches_registered);
 
-	mvsw_pr_wq = alloc_workqueue(mvsw_driver_name, 0, 0);
-	if (!mvsw_pr_wq)
+	prestera_wq = alloc_workqueue(prestera_driver_name, 0, 0);
+	if (!prestera_wq)
 		return -ENOMEM;
 
-	err = mvsw_pr_rxtx_init();
-	if (err) {
-		pr_err("failed to initialize prestera rxtx\n");
-		destroy_workqueue(mvsw_pr_wq);
-		return err;
-	}
-
 	pr_info("Loading Marvell Prestera Switch Driver\n");
 	return 0;
 }
 
-static void __exit mvsw_pr_module_exit(void)
+static void __exit prestera_module_exit(void)
 {
-	destroy_workqueue(mvsw_pr_wq);
-	mvsw_pr_rxtx_fini();
+	destroy_workqueue(prestera_wq);
 
 	pr_info("Unloading Marvell Prestera Switch Driver\n");
 }
 
-module_init(mvsw_pr_module_init);
-module_exit(mvsw_pr_module_exit);
+module_init(prestera_module_init);
+module_exit(prestera_module_exit);
 
 MODULE_AUTHOR("Marvell Semi.");
 MODULE_LICENSE("GPL");
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_matchall.c b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
new file mode 100644
index 0000000..8272a9c
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
@@ -0,0 +1,146 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/kernel.h>
+#include <linux/list.h>
+
+#include "prestera.h"
+#include "prestera_hw.h"
+
+static int prestera_mall_rule_add(struct prestera_flow_block_binding *binding,
+				  struct prestera_port *to_port)
+{
+	int err;
+	u8 span_id;
+	struct prestera_switch *sw = binding->port->sw;
+
+	if (binding->span_id != PRESTERA_SPAN_INVALID_ID)
+		/* port already in mirroring */
+		return -EEXIST;
+
+	err = prestera_span_get(to_port, &span_id);
+	if (err)
+		return err;
+
+	err = prestera_hw_span_bind(binding->port, span_id);
+	if (err) {
+		prestera_span_put(sw, span_id);
+		return err;
+	}
+
+	binding->span_id = span_id;
+	return 0;
+}
+
+static int prestera_mall_rule_del(struct prestera_flow_block_binding *binding)
+{
+	int err;
+
+	err = prestera_hw_span_unbind(binding->port);
+	if (err)
+		return err;
+
+	err = prestera_span_put(binding->port->sw, binding->span_id);
+	if (err)
+		return err;
+
+	binding->span_id = PRESTERA_SPAN_INVALID_ID;
+	return 0;
+}
+
+static int prestera_mall_prio_check(struct prestera_flow_block *block,
+				    struct tc_cls_matchall_offload *f)
+{
+	u32 flower_prio;
+	int err;
+
+	err = prestera_flower_prio_get(block, &flower_prio);
+	if (err == -ENOENT)
+		return 0;
+	if (err)
+		return err;
+
+	if (f->common.prio >= flower_prio)
+		return -EOPNOTSUPP;
+
+	return 0;
+}
+
+int prestera_mall_prio_get(struct prestera_flow_block *block,
+			   u32 *prio)
+{
+	if (block->mall_prio == UINT_MAX)
+		return -ENOENT;
+
+	*prio = block->mall_prio;
+	return 0;
+}
+
+static void prestera_mall_prio_update(struct prestera_flow_block *block,
+				      struct tc_cls_matchall_offload *f)
+{
+	if (f->common.prio > block->mall_prio || block->mall_prio == UINT_MAX)
+		block->mall_prio = f->common.prio;
+}
+
+int prestera_mall_replace(struct prestera_flow_block *block,
+			  struct tc_cls_matchall_offload *f)
+{
+	struct prestera_flow_block_binding *binding;
+	__be16 protocol = f->common.protocol;
+	struct flow_action_entry *act;
+	struct prestera_port *port;
+	int err;
+
+	if (!flow_offload_has_one_action(&f->rule->action)) {
+		NL_SET_ERR_MSG(f->common.extack,
+			       "Only singular actions are supported");
+		return -EOPNOTSUPP;
+	}
+
+	act = &f->rule->action.entries[0];
+
+	if (act->id != FLOW_ACTION_MIRRED)
+		return -EOPNOTSUPP;
+
+	if (protocol != htons(ETH_P_ALL))
+		return -EOPNOTSUPP;
+
+	err = prestera_mall_prio_check(block, f);
+	if (err)
+		return err;
+
+	if (!prestera_netdev_check(act->dev)) {
+		NL_SET_ERR_MSG(f->common.extack,
+			       "Only switchdev port is supported");
+		return -EINVAL;
+	}
+
+	port = netdev_priv(act->dev);
+	list_for_each_entry(binding, &block->binding_list, list) {
+		err = prestera_mall_rule_add(binding, port);
+		if (err)
+			goto rollback;
+	}
+
+	prestera_mall_prio_update(block, f);
+
+	return 0;
+
+rollback:
+	list_for_each_entry_continue_reverse(binding,
+					     &block->binding_list, list)
+		prestera_mall_rule_del(binding);
+	return err;
+}
+
+void prestera_mall_destroy(struct prestera_flow_block *block)
+{
+	struct prestera_flow_block_binding *binding;
+
+	list_for_each_entry(binding, &block->binding_list, list)
+		prestera_mall_rule_del(binding);
+
+	block->mall_prio = UINT_MAX;
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_pci.c b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
index 28ef761..25adb8e 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_pci.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
@@ -1,8 +1,5 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <linux/module.h>
 #include <linux/kernel.h>
@@ -13,13 +10,14 @@
 
 #include "prestera.h"
 
-#define MVSW_FW_FILENAME	"marvell/mvsw_prestera_fw.img"
+#define PRESTERA_FW_DEFAULT_PATH	"marvell/mvsw_prestera_fw.img"
+#define PRESTERA_FW_ARM64_PATH		"marvell/mvsw_prestera_fw_arm64.img"
 
-#define MVSW_SUPP_FW_MAJ_VER 2
-#define MVSW_SUPP_FW_MIN_VER 8
-#define MVSW_SUPP_FW_PATCH_VER 0
+#define PRESTERA_SUPP_FW_MAJ_VER	3
+#define PRESTERA_SUPP_FW_MIN_VER	0
+#define PRESTERA_SUPP_FW_PATCH_VER	0
 
-#define mvsw_wait_timeout(cond, waitms) \
+#define prestera_wait(cond, waitms) \
 ({ \
 	unsigned long __wait_end = jiffies + msecs_to_jiffies(waitms); \
 	bool __wait_ret = false; \
@@ -33,9 +31,9 @@
 	__wait_ret; \
 })
 
-#define MVSW_FW_HDR_MAGIC 0x351D9D06
-#define MVSW_FW_DL_TIMEOUT 50000
-#define MVSW_FW_BLK_SZ 1024
+#define PRESTERA_FW_HDR_MAGIC	0x351D9D06
+#define PRESTERA_FW_DL_TIMEOUT	50000
+#define PRESTERA_FW_BLK_SZ	1024
 
 #define FW_VER_MAJ_MUL 1000000
 #define FW_VER_MIN_MUL 1000
@@ -48,13 +46,13 @@
 #define FW_VER_PATCH(v) \
 	(v - (FW_VER_MAJ(v) * FW_VER_MAJ_MUL) - (FW_VER_MIN(v) * FW_VER_MIN_MUL))
 
-struct mvsw_pr_fw_header {
+struct prestera_fw_header {
 	__be32 magic_number;
 	__be32 version_value;
 	u8 reserved[8];
 } __packed;
 
-struct mvsw_pr_ldr_regs {
+struct prestera_ldr_regs {
 	u32 ldr_ready;
 	u32 pad1;
 
@@ -71,55 +69,55 @@ struct mvsw_pr_ldr_regs {
 	u32 ldr_status;
 } __packed __aligned(4);
 
-#define MVSW_LDR_REG_OFFSET(f)	offsetof(struct mvsw_pr_ldr_regs, f)
+#define PRESTERA_LDR_REG_OFFSET(f)	offsetof(struct prestera_ldr_regs, f)
 
-#define MVSW_LDR_READY_MAGIC	0xf00dfeed
+#define PRESTERA_LDR_READY_MAGIC	0xf00dfeed
 
-#define MVSW_LDR_STATUS_IMG_DL		BIT(0)
-#define MVSW_LDR_STATUS_START_FW	BIT(1)
-#define MVSW_LDR_STATUS_INVALID_IMG	BIT(2)
-#define MVSW_LDR_STATUS_NOMEM		BIT(3)
+#define PRESTERA_LDR_STATUS_IMG_DL	BIT(0)
+#define PRESTERA_LDR_STATUS_START_FW	BIT(1)
+#define PRESTERA_LDR_STATUS_INVALID_IMG	BIT(2)
+#define PRESTERA_LDR_STATUS_NOMEM	BIT(3)
 
-#define mvsw_ldr_write(fw, reg, val) \
+#define prestera_ldr_write(fw, reg, val) \
 	writel(val, (fw)->ldr_regs + (reg))
-#define mvsw_ldr_read(fw, reg)	\
+#define prestera_ldr_read(fw, reg)	\
 	readl((fw)->ldr_regs + (reg))
 
 /* fw loader registers */
-#define MVSW_LDR_READY_REG	MVSW_LDR_REG_OFFSET(ldr_ready)
-#define MVSW_LDR_IMG_SIZE_REG	MVSW_LDR_REG_OFFSET(ldr_img_size)
-#define MVSW_LDR_CTL_REG	MVSW_LDR_REG_OFFSET(ldr_ctl_flags)
-#define MVSW_LDR_BUF_SIZE_REG	MVSW_LDR_REG_OFFSET(ldr_buf_size)
-#define MVSW_LDR_BUF_OFFS_REG	MVSW_LDR_REG_OFFSET(ldr_buf_offs)
-#define MVSW_LDR_BUF_RD_REG	MVSW_LDR_REG_OFFSET(ldr_buf_rd)
-#define MVSW_LDR_BUF_WR_REG	MVSW_LDR_REG_OFFSET(ldr_buf_wr)
-#define MVSW_LDR_STATUS_REG	MVSW_LDR_REG_OFFSET(ldr_status)
-
-#define MVSW_LDR_CTL_DL_START	BIT(0)
-
-#define MVSW_LDR_WR_IDX_MOVE(fw, n) \
+#define PRESTERA_LDR_READY_REG		PRESTERA_LDR_REG_OFFSET(ldr_ready)
+#define PRESTERA_LDR_IMG_SIZE_REG	PRESTERA_LDR_REG_OFFSET(ldr_img_size)
+#define PRESTERA_LDR_CTL_REG		PRESTERA_LDR_REG_OFFSET(ldr_ctl_flags)
+#define PRESTERA_LDR_BUF_SIZE_REG	PRESTERA_LDR_REG_OFFSET(ldr_buf_size)
+#define PRESTERA_LDR_BUF_OFFS_REG	PRESTERA_LDR_REG_OFFSET(ldr_buf_offs)
+#define PRESTERA_LDR_BUF_RD_REG		PRESTERA_LDR_REG_OFFSET(ldr_buf_rd)
+#define PRESTERA_LDR_BUF_WR_REG		PRESTERA_LDR_REG_OFFSET(ldr_buf_wr)
+#define PRESTERA_LDR_STATUS_REG		PRESTERA_LDR_REG_OFFSET(ldr_status)
+
+#define PRESTERA_LDR_CTL_DL_START	BIT(0)
+
+#define PRESTERA_LDR_WR_IDX_MOVE(fw, n) \
 do { \
 	typeof(fw) __fw = (fw); \
 	(__fw)->ldr_wr_idx = ((__fw)->ldr_wr_idx + (n)) & \
 				((__fw)->ldr_buf_len - 1); \
 } while (0)
 
-#define MVSW_LDR_WR_IDX_COMMIT(fw) \
+#define PRESTERA_LDR_WR_IDX_COMMIT(fw) \
 ({ \
 	typeof(fw) __fw = (fw); \
-	mvsw_ldr_write((__fw), MVSW_LDR_BUF_WR_REG, \
-		       (__fw)->ldr_wr_idx); \
+	prestera_ldr_write((__fw), PRESTERA_LDR_BUF_WR_REG, \
+			   (__fw)->ldr_wr_idx); \
 })
 
-#define MVSW_LDR_WR_PTR(fw) \
+#define PRESTERA_LDR_WR_PTR(fw) \
 ({ \
 	typeof(fw) __fw = (fw); \
 	((__fw)->ldr_ring_buf + (__fw)->ldr_wr_idx); \
 })
 
-#define MVSW_EVT_QNUM_MAX	4
+#define PRESTERA_EVT_QNUM_MAX	4
 
-struct mvsw_pr_fw_evtq_regs {
+struct prestera_fw_evtq_regs {
 	u32 rd_idx;
 	u32 pad1;
 	u32 wr_idx;
@@ -128,74 +126,96 @@ struct mvsw_pr_fw_evtq_regs {
 	u32 len;
 };
 
-struct mvsw_pr_fw_regs {
-	u32 fw_ready;
-	u32 pad;
-	u32 cmd_offs;
-	u32 cmd_len;
-	u32 evt_offs;
-	u32 evt_qnum;
+#define PRESTERA_CMD_QNUM_MAX	4
 
+struct prestera_fw_cmdq_regs {
 	u32 cmd_req_ctl;
 	u32 cmd_req_len;
 	u32 cmd_rcv_ctl;
 	u32 cmd_rcv_len;
+	u32 offs;
+	u32 len;
+};
+
+struct prestera_fw_regs {
+	u32 fw_ready;
+	u32 cmd_offs;
+	u32 cmd_len;
+	u32 cmd_qnum;
+	u32 evt_offs;
+	u32 evt_qnum;
 
 	u32 fw_status;
 	u32 rx_status;
 
-	struct mvsw_pr_fw_evtq_regs evtq_list[MVSW_EVT_QNUM_MAX];
+	struct prestera_fw_cmdq_regs cmdq_list[PRESTERA_CMD_QNUM_MAX];
+	struct prestera_fw_evtq_regs evtq_list[PRESTERA_EVT_QNUM_MAX];
 };
 
-#define MVSW_FW_REG_OFFSET(f)	offsetof(struct mvsw_pr_fw_regs, f)
+#define PRESTERA_FW_REG_OFFSET(f)	offsetof(struct prestera_fw_regs, f)
 
-#define MVSW_FW_READY_MAGIC	0xcafebabe
+#define PRESTERA_FW_READY_MAGIC	0xcafebabe
 
 /* fw registers */
-#define MVSW_FW_READY_REG		MVSW_FW_REG_OFFSET(fw_ready)
+#define PRESTERA_FW_READY_REG		PRESTERA_FW_REG_OFFSET(fw_ready)
+
+#define PRESTERA_CMDQ_REG_OFFSET(q, f)			\
+	(PRESTERA_FW_REG_OFFSET(cmdq_list) +		\
+	 (q) * sizeof(struct prestera_fw_cmdq_regs) +	\
+	 offsetof(struct prestera_fw_cmdq_regs, f))
+
+#define PRESTERA_CMD_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(cmd_offs)
+#define PRESTERA_CMD_BUF_LEN_REG	PRESTERA_FW_REG_OFFSET(cmd_len)
+#define PRESTERA_CMD_QNUM_REG		PRESTERA_FW_REG_OFFSET(cmd_qnum)
+#define PRESTERA_EVT_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(evt_offs)
+#define PRESTERA_EVT_QNUM_REG		PRESTERA_FW_REG_OFFSET(evt_qnum)
 
-#define MVSW_CMD_BUF_OFFS_REG		MVSW_FW_REG_OFFSET(cmd_offs)
-#define MVSW_CMD_BUF_LEN_REG		MVSW_FW_REG_OFFSET(cmd_len)
-#define MVSW_EVT_BUF_OFFS_REG		MVSW_FW_REG_OFFSET(evt_offs)
-#define MVSW_EVT_QNUM_REG		MVSW_FW_REG_OFFSET(evt_qnum)
+#define PRESTERA_CMDQ_REQ_CTL_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_req_ctl)
+#define PRESTERA_CMDQ_REQ_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_req_len)
+#define PRESTERA_CMDQ_RCV_CTL_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_rcv_ctl)
+#define PRESTERA_CMDQ_RCV_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_rcv_len)
+#define PRESTERA_CMDQ_OFFS_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, offs)
+#define PRESTERA_CMDQ_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, len)
 
-#define MVSW_CMD_REQ_CTL_REG		MVSW_FW_REG_OFFSET(cmd_req_ctl)
-#define MVSW_CMD_REQ_LEN_REG		MVSW_FW_REG_OFFSET(cmd_req_len)
+#define PRESTERA_FW_STATUS_REG		PRESTERA_FW_REG_OFFSET(fw_status)
+#define PRESTERA_RX_STATUS_REG		PRESTERA_FW_REG_OFFSET(rx_status)
 
-#define MVSW_CMD_RCV_CTL_REG		MVSW_FW_REG_OFFSET(cmd_rcv_ctl)
-#define MVSW_CMD_RCV_LEN_REG		MVSW_FW_REG_OFFSET(cmd_rcv_len)
-#define MVSW_FW_STATUS_REG		MVSW_FW_REG_OFFSET(fw_status)
-#define MVSW_RX_STATUS_REG		MVSW_FW_REG_OFFSET(rx_status)
+/* PRESTERA_CMDQ_REQ_CTL_REG flags */
+#define PRESTERA_CMD_F_REQ_SENT		BIT(0)
+#define PRESTERA_CMD_F_REPL_RCVD	BIT(1)
 
-/* MVSW_CMD_REQ_CTL_REG flags */
-#define MVSW_CMD_F_REQ_SENT		BIT(0)
-#define MVSW_CMD_F_REPL_RCVD		BIT(1)
+/* PRESTERA_CMDQ_RCV_CTL_REG flags */
+#define PRESTERA_CMD_F_REPL_SENT	BIT(0)
 
-/* MVSW_CMD_RCV_CTL_REG flags */
-#define MVSW_CMD_F_REPL_SENT		BIT(0)
+/* PRESTERA_FW_STATUS_REG flags */
+#define PRESTERA_STATUS_F_EVT_OFF	BIT(0)
 
-/* MVSW_FW_STATUS_REG flags */
-#define MVSW_STATUS_F_EVT_OFF		BIT(0)
+#define PRESTERA_EVTQ_REG_OFFSET(q, f)			\
+	(PRESTERA_FW_REG_OFFSET(evtq_list) +		\
+	 (q) * sizeof(struct prestera_fw_evtq_regs) +	\
+	 offsetof(struct prestera_fw_evtq_regs, f))
 
-#define MVSW_EVTQ_REG_OFFSET(q, f)			\
-	(MVSW_FW_REG_OFFSET(evtq_list) +		\
-	 (q) * sizeof(struct mvsw_pr_fw_evtq_regs) +	\
-	 offsetof(struct mvsw_pr_fw_evtq_regs, f))
+#define PRESTERA_EVTQ_RD_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, rd_idx)
+#define PRESTERA_EVTQ_WR_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, wr_idx)
+#define PRESTERA_EVTQ_OFFS_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, offs)
+#define PRESTERA_EVTQ_LEN_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, len)
 
-#define MVSW_EVTQ_RD_IDX_REG(q)		MVSW_EVTQ_REG_OFFSET(q, rd_idx)
-#define MVSW_EVTQ_WR_IDX_REG(q)		MVSW_EVTQ_REG_OFFSET(q, wr_idx)
-#define MVSW_EVTQ_OFFS_REG(q)		MVSW_EVTQ_REG_OFFSET(q, offs)
-#define MVSW_EVTQ_LEN_REG(q)		MVSW_EVTQ_REG_OFFSET(q, len)
+#define prestera_fw_write(fw, reg, val)	writel(val, (fw)->hw_regs + (reg))
+#define prestera_fw_read(fw, reg)	readl((fw)->hw_regs + (reg))
 
-#define mvsw_fw_write(fw, reg, val)	writel(val, (fw)->hw_regs + (reg))
-#define mvsw_fw_read(fw, reg)		readl((fw)->hw_regs + (reg))
+struct prestera_fw_evtq {
+	u8 __iomem *addr;
+	size_t len;
+};
 
-struct mvsw_pr_fw_evtq {
+struct prestera_fw_cmdq {
+	/* serialize access to dev->send_req */
+	struct mutex cmd_mtx;
 	u8 __iomem *addr;
 	size_t len;
 };
 
-struct mvsw_pr_fw {
+struct prestera_fw {
 	struct workqueue_struct *wq;
 	struct prestera_device dev;
 	struct pci_dev *pci_dev;
@@ -207,174 +227,206 @@ struct mvsw_pr_fw {
 	u8 __iomem *ldr_ring_buf;
 	u32 ldr_buf_len;
 	u32 ldr_wr_idx;
-	bool active;
 
-	/* serialize access to dev->send_req */
-	struct mutex cmd_mtx;
 	size_t cmd_mbox_len;
 	u8 __iomem *cmd_mbox;
-	struct mvsw_pr_fw_evtq evt_queue[MVSW_EVT_QNUM_MAX];
+	struct prestera_fw_cmdq cmd_queue[PRESTERA_CMD_QNUM_MAX];
+	u8 cmd_qnum;
+	struct prestera_fw_evtq evt_queue[PRESTERA_EVT_QNUM_MAX];
 	u8 evt_qnum;
 	struct work_struct evt_work;
 	u8 __iomem *evt_buf;
 	u8 *evt_msg;
 };
 
-#define mvsw_fw_dev(fw)	((fw)->dev.dev)
+#define prestera_fw_dev(fw)	((fw)->dev.dev)
 
 #define PRESTERA_DEVICE(id) PCI_VDEVICE(MARVELL, (id))
 
-static struct mvsw_pr_pci_match {
+#define PRESTERA_DEV_ID_AC3X_98DX_55	0xC804
+#define PRESTERA_DEV_ID_AC3X_98DX_65	0xC80C
+#define PRESTERA_DEV_ID_ALDRIN2		0xCC1E
+#define PRESTERA_DEV_ID_ALDRIN3S	0x981F
+#define PRESTERA_DEV_ID_98DX3500	0x9820
+
+static struct prestera_pci_match {
 	struct pci_driver driver;
 	const struct pci_device_id id;
 	bool registered;
-} mvsw_pci_devices[] = {
+} prestera_devices[] = {
 	{
 		.driver = { .name = "AC3x B2B 98DX3255", },
-		.id = { PRESTERA_DEVICE(0xC804), 0 },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_AC3X_98DX_55), 0 },
 	},
 	{
 		.driver = { .name = "AC3x B2B 98DX3265", },
-		.id = { PRESTERA_DEVICE(0xC80C), 0 },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_AC3X_98DX_65), 0 },
 	},
 	{
 		.driver = { .name = "Aldrin2", },
-		.id = { PRESTERA_DEVICE(0xCC1E), 0 },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_ALDRIN2), 0 },
+	},
+	{
+		.driver = { .name = "Aldrin3S", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_ALDRIN3S), 0 },
+	},
+	{
+		.driver = { .name = "AC5X 98DX3500", },
+		.id = { PRESTERA_DEVICE(PRESTERA_DEV_ID_98DX3500), 0 },
 	},
 	{{ }, }
 };
 
-static int mvsw_pr_fw_load(struct mvsw_pr_fw *fw);
+static int prestera_fw_load(struct prestera_fw *fw);
+
+static void prestera_fw_cmdq_lock(struct prestera_fw *fw, u8 qid)
+{
+	mutex_lock(&fw->cmd_queue[qid].cmd_mtx);
+}
+
+static void prestera_fw_cmdq_unlock(struct prestera_fw *fw, u8 qid)
+{
+	mutex_unlock(&fw->cmd_queue[qid].cmd_mtx);
+}
+
+static u32 prestera_fw_cmdq_len(struct prestera_fw *fw, u8 qid)
+{
+	return fw->cmd_queue[qid].len;
+}
+
+static u8 __iomem *prestera_fw_cmdq_buf(struct prestera_fw *fw, u8 qid)
+{
+	return fw->cmd_queue[qid].addr;
+}
 
-static u32 mvsw_pr_fw_evtq_len(struct mvsw_pr_fw *fw, u8 qid)
+static u32 prestera_fw_evtq_len(struct prestera_fw *fw, u8 qid)
 {
 	return fw->evt_queue[qid].len;
 }
 
-static u32 mvsw_pr_fw_evtq_avail(struct mvsw_pr_fw *fw, u8 qid)
+static u32 prestera_fw_evtq_avail(struct prestera_fw *fw, u8 qid)
 {
-	u32 wr_idx = mvsw_fw_read(fw, MVSW_EVTQ_WR_IDX_REG(qid));
-	u32 rd_idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
+	u32 wr_idx = prestera_fw_read(fw, PRESTERA_EVTQ_WR_IDX_REG(qid));
+	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
 
-	return CIRC_CNT(wr_idx, rd_idx, mvsw_pr_fw_evtq_len(fw, qid));
+	return CIRC_CNT(wr_idx, rd_idx, prestera_fw_evtq_len(fw, qid));
 }
 
-static void mvsw_pr_fw_evtq_rd_set(struct mvsw_pr_fw *fw,
-				   u8 qid, u32 idx)
+static void prestera_fw_evtq_rd_set(struct prestera_fw *fw, u8 qid, u32 idx)
 {
-	u32 rd_idx = idx & (mvsw_pr_fw_evtq_len(fw, qid) - 1);
+	u32 rd_idx = idx & (prestera_fw_evtq_len(fw, qid) - 1);
 
-	mvsw_fw_write(fw, MVSW_EVTQ_RD_IDX_REG(qid), rd_idx);
+	prestera_fw_write(fw, PRESTERA_EVTQ_RD_IDX_REG(qid), rd_idx);
 }
 
-static u8 __iomem *mvsw_pr_fw_evtq_buf(struct mvsw_pr_fw *fw,
-				       u8 qid)
+static u8 __iomem *prestera_fw_evtq_buf(struct prestera_fw *fw, u8 qid)
 {
 	return fw->evt_queue[qid].addr;
 }
 
-static u32 mvsw_pr_fw_evtq_read32(struct mvsw_pr_fw *fw, u8 qid)
+static u32 prestera_fw_evtq_read32(struct prestera_fw *fw, u8 qid)
 {
-	u32 rd_idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
+	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
 	u32 val;
 
-	val = readl(mvsw_pr_fw_evtq_buf(fw, qid) + rd_idx);
-	mvsw_pr_fw_evtq_rd_set(fw, qid, rd_idx + 4);
+	val = readl(prestera_fw_evtq_buf(fw, qid) + rd_idx);
+	prestera_fw_evtq_rd_set(fw, qid, rd_idx + 4);
 	return val;
 }
 
-static ssize_t mvsw_pr_fw_evtq_read_buf(struct mvsw_pr_fw *fw,
-					u8 qid, u8 *buf, size_t len)
+static ssize_t prestera_fw_evtq_read_buf(struct prestera_fw *fw, u8 qid,
+					 u8 *buf, size_t len)
 {
-	u32 idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
-	u8 __iomem *evtq_addr = mvsw_pr_fw_evtq_buf(fw, qid);
+	u32 idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
+	u8 __iomem *evtq_addr = prestera_fw_evtq_buf(fw, qid);
 	u32 *buf32 = (u32 *)buf;
 	int i;
 
 	for (i = 0; i < len / 4; buf32++, i++) {
 		*buf32 = readl_relaxed(evtq_addr + idx);
-		idx = (idx + 4) & (mvsw_pr_fw_evtq_len(fw, qid) - 1);
+		idx = (idx + 4) & (prestera_fw_evtq_len(fw, qid) - 1);
 	}
 
-	mvsw_pr_fw_evtq_rd_set(fw, qid, idx);
+	prestera_fw_evtq_rd_set(fw, qid, idx);
 
 	return i;
 }
 
-static u8 mvsw_pr_fw_evtq_pick(struct mvsw_pr_fw *fw)
+static u8 prestera_fw_evtq_pick(struct prestera_fw *fw)
 {
 	int qid;
 
 	for (qid = 0; qid < fw->evt_qnum; qid++) {
-		if (mvsw_pr_fw_evtq_avail(fw, qid) >= 4)
+		if (prestera_fw_evtq_avail(fw, qid) >= 4)
 			return qid;
 	}
 
-	return MVSW_EVT_QNUM_MAX;
+	return PRESTERA_EVT_QNUM_MAX;
 }
 
-static void mvsw_pr_fw_status_set(struct mvsw_pr_fw *fw, unsigned int val)
+static void prestera_fw_status_set(struct prestera_fw *fw, unsigned int val)
 {
-	u32 status = mvsw_fw_read(fw, MVSW_FW_STATUS_REG);
+	u32 status = prestera_fw_read(fw, PRESTERA_FW_STATUS_REG);
 
 	status |= val;
 
-	mvsw_fw_write(fw, MVSW_FW_STATUS_REG, status);
+	prestera_fw_write(fw, PRESTERA_FW_STATUS_REG, status);
 }
 
-static void mvsw_pr_fw_status_clear(struct mvsw_pr_fw *fw, u32 val)
+static void prestera_fw_status_clear(struct prestera_fw *fw, u32 val)
 {
-	u32 status = mvsw_fw_read(fw, MVSW_FW_STATUS_REG);
+	u32 status = prestera_fw_read(fw, PRESTERA_FW_STATUS_REG);
 
 	status &= ~val;
 
-	mvsw_fw_write(fw, MVSW_FW_STATUS_REG, status);
+	prestera_fw_write(fw, PRESTERA_FW_STATUS_REG, status);
 }
 
-static void mvsw_pr_fw_evt_work_fn(struct work_struct *work)
+static void prestera_fw_evt_work_fn(struct work_struct *work)
 {
-	struct mvsw_pr_fw *fw;
+	struct prestera_fw *fw;
 	u8 *msg;
 	u8 qid;
 
-	fw = container_of(work, struct mvsw_pr_fw, evt_work);
+	fw = container_of(work, struct prestera_fw, evt_work);
 	msg = fw->evt_msg;
 
-	mvsw_pr_fw_status_set(fw, MVSW_STATUS_F_EVT_OFF);
+	prestera_fw_status_set(fw, PRESTERA_STATUS_F_EVT_OFF);
 
-	while ((qid = mvsw_pr_fw_evtq_pick(fw)) < MVSW_EVT_QNUM_MAX) {
+	while ((qid = prestera_fw_evtq_pick(fw)) < PRESTERA_EVT_QNUM_MAX) {
 		u32 idx;
 		u32 len;
 
-		len = mvsw_pr_fw_evtq_read32(fw, qid);
-		idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
+		len = prestera_fw_evtq_read32(fw, qid);
+		idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
 
-		WARN_ON(mvsw_pr_fw_evtq_avail(fw, qid) < len);
+		WARN_ON(prestera_fw_evtq_avail(fw, qid) < len);
 
-		if (WARN_ON(len > MVSW_MSG_MAX_SIZE)) {
-			mvsw_pr_fw_evtq_rd_set(fw, qid, idx + len);
+		if (WARN_ON(len > PRESTERA_MSG_MAX_SIZE)) {
+			prestera_fw_evtq_rd_set(fw, qid, idx + len);
 			continue;
 		}
 
-		mvsw_pr_fw_evtq_read_buf(fw, qid, msg, len);
+		prestera_fw_evtq_read_buf(fw, qid, msg, len);
 
 		if (fw->dev.recv_msg)
 			fw->dev.recv_msg(&fw->dev, msg, len);
 	}
 
-	mvsw_pr_fw_status_clear(fw, MVSW_STATUS_F_EVT_OFF);
+	prestera_fw_status_clear(fw, PRESTERA_STATUS_F_EVT_OFF);
 }
 
-static int mvsw_pr_fw_wait_reg32(struct mvsw_pr_fw *fw,
-				 u32 reg, u32 val, unsigned int wait)
+static int prestera_fw_wait_reg32(struct prestera_fw *fw, u32 reg, u32 val,
+				  unsigned int wait)
 {
-	if (mvsw_wait_timeout(mvsw_fw_read(fw, reg) == val, wait))
-		return 0;
+	if (prestera_wait(prestera_fw_read(fw, reg) == val || !fw->dev.running,
+			  wait))
+		return fw->dev.running ? 0 : -ENODEV;
 
 	return -EBUSY;
 }
 
-static void mvsw_pci_copy_to(u8 __iomem *dst, u8 *src, size_t len)
+static void prestera_pci_copy_to(u8 __iomem *dst, u8 *src, size_t len)
 {
 	u32 __iomem *dst32 = (u32 __iomem *)dst;
 	u32 *src32 = (u32 *)src;
@@ -384,7 +436,7 @@ static void mvsw_pci_copy_to(u8 __iomem *dst, u8 *src, size_t len)
 		writel_relaxed(*src32, dst32);
 }
 
-static void mvsw_pci_copy_from(u8 *dst, u8 __iomem *src, size_t len)
+static void prestera_pci_copy_from(u8 *dst, u8 __iomem *src, size_t len)
 {
 	u32 *dst32 = (u32 *)dst;
 	u32 __iomem *src32 = (u32 __iomem *)src;
@@ -394,10 +446,10 @@ static void mvsw_pci_copy_from(u8 *dst, u8 __iomem *src, size_t len)
 		*dst32 = readl_relaxed(src32);
 }
 
-static int mvsw_pr_fw_cmd_send(struct mvsw_pr_fw *fw,
-			       u8 *in_msg, size_t in_size,
-			       u8 *out_msg, size_t out_size,
-			       unsigned int wait)
+static int prestera_fw_cmd_send(struct prestera_fw *fw, int qid,
+				u8 *in_msg, size_t in_size,
+				u8 *out_msg, size_t out_size,
+				unsigned int wait)
 {
 	u32 ret_size = 0;
 	int err = 0;
@@ -405,116 +457,131 @@ static int mvsw_pr_fw_cmd_send(struct mvsw_pr_fw *fw,
 	if (!wait)
 		wait = 30000;
 
-	if (ALIGN(in_size, 4) > fw->cmd_mbox_len)
+	if (ALIGN(in_size, 4) > prestera_fw_cmdq_len(fw, qid))
 		return -EMSGSIZE;
 
 	/* wait for finish previous reply from FW */
-	err = mvsw_pr_fw_wait_reg32(fw, MVSW_CMD_RCV_CTL_REG, 0, 1000);
+	err = prestera_fw_wait_reg32(fw, PRESTERA_CMDQ_RCV_CTL_REG(qid),
+				     0, 1000);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "finish reply from FW is timed out\n");
+		dev_err(prestera_fw_dev(fw),
+			"finish reply from FW is timed out\n");
 		return err;
 	}
 
-	mvsw_fw_write(fw, MVSW_CMD_REQ_LEN_REG, in_size);
-	mvsw_pci_copy_to(fw->cmd_mbox, in_msg, in_size);
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_LEN_REG(qid), in_size);
+	prestera_pci_copy_to(prestera_fw_cmdq_buf(fw, qid), in_msg, in_size);
 
-	mvsw_fw_write(fw, MVSW_CMD_REQ_CTL_REG, MVSW_CMD_F_REQ_SENT);
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_CTL_REG(qid),
+			  PRESTERA_CMD_F_REQ_SENT);
 
 	/* wait for reply from FW */
-	err = mvsw_pr_fw_wait_reg32(fw, MVSW_CMD_RCV_CTL_REG, MVSW_CMD_F_REPL_SENT,
-				    wait);
+	err = prestera_fw_wait_reg32(fw, PRESTERA_CMDQ_RCV_CTL_REG(qid),
+				     PRESTERA_CMD_F_REPL_SENT, wait);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "reply from FW is timed out\n");
-		fw->active = false;
+		dev_err(prestera_fw_dev(fw),
+			"reply from FW is timed out\n");
 		goto cmd_exit;
 	}
 
-	ret_size = mvsw_fw_read(fw, MVSW_CMD_RCV_LEN_REG);
+	ret_size = prestera_fw_read(fw, PRESTERA_CMDQ_RCV_LEN_REG(qid));
 	if (ret_size > out_size) {
-		dev_err(mvsw_fw_dev(fw), "ret_size (%u) > out_len(%zu)\n",
+		dev_err(prestera_fw_dev(fw), "ret_size (%u) > out_len(%zu)\n",
 			ret_size, out_size);
 		err = -EMSGSIZE;
 		goto cmd_exit;
 	}
 
-	mvsw_pci_copy_from(out_msg, fw->cmd_mbox + in_size, ret_size);
+	prestera_pci_copy_from(out_msg, prestera_fw_cmdq_buf(fw, qid) + in_size,
+			       ret_size);
 
 cmd_exit:
-	mvsw_fw_write(fw, MVSW_CMD_REQ_CTL_REG, MVSW_CMD_F_REPL_RCVD);
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_CTL_REG(qid),
+			  PRESTERA_CMD_F_REPL_RCVD);
 	return err;
 }
 
-static int mvsw_pr_fw_send_req(struct prestera_device *dev,
-			       u8 *in_msg, size_t in_size, u8 *out_msg,
-			       size_t out_size, unsigned int wait)
+static int prestera_fw_send_req(struct prestera_device *dev, int qid,
+				u8 *in_msg, size_t in_size, u8 *out_msg,
+				size_t out_size, unsigned int wait)
 {
-	struct mvsw_pr_fw *fw;
+	struct prestera_fw *fw;
 	ssize_t ret;
 
-	fw = container_of(dev, struct mvsw_pr_fw, dev);
+	fw = container_of(dev, struct prestera_fw, dev);
 
-	if (!fw->active)
-		return -1;
+	if (!fw->dev.running)
+		return -ENODEV;
 
-	mutex_lock(&fw->cmd_mtx);
-	ret = mvsw_pr_fw_cmd_send(fw, in_msg, in_size, out_msg, out_size, wait);
-	mutex_unlock(&fw->cmd_mtx);
+	prestera_fw_cmdq_lock(fw, qid);
+	ret = prestera_fw_cmd_send(fw, qid, in_msg, in_size, out_msg, out_size,
+				   wait);
+	prestera_fw_cmdq_unlock(fw, qid);
 
 	return ret;
 }
 
-static int mvsw_pr_fw_init(struct mvsw_pr_fw *fw)
+static int prestera_fw_init(struct prestera_fw *fw)
 {
 	u8 __iomem *base;
 	int err;
 	u8 qid;
 
-	err = mvsw_pr_fw_load(fw);
+	err = prestera_fw_load(fw);
 	if (err)
 		return err;
 
-	err = mvsw_pr_fw_wait_reg32(fw, MVSW_FW_READY_REG,
-				    MVSW_FW_READY_MAGIC, 20000);
+	err = prestera_fw_wait_reg32(fw, PRESTERA_FW_READY_REG,
+				     PRESTERA_FW_READY_MAGIC, 20000);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "FW is failed to start\n");
+		dev_err(prestera_fw_dev(fw), "FW is failed to start\n");
 		return err;
 	}
 
 	base = fw->mem_addr;
 
-	fw->cmd_mbox = base + mvsw_fw_read(fw, MVSW_CMD_BUF_OFFS_REG);
-	fw->cmd_mbox_len = mvsw_fw_read(fw, MVSW_CMD_BUF_LEN_REG);
-	mutex_init(&fw->cmd_mtx);
+	fw->cmd_mbox = base + prestera_fw_read(fw, PRESTERA_CMD_BUF_OFFS_REG);
+	fw->cmd_mbox_len = prestera_fw_read(fw, PRESTERA_CMD_BUF_LEN_REG);
+	fw->cmd_qnum = prestera_fw_read(fw, PRESTERA_CMD_QNUM_REG);
+
+	for (qid = 0; qid < fw->cmd_qnum; qid++) {
+		u32 offs = prestera_fw_read(fw, PRESTERA_CMDQ_OFFS_REG(qid));
+		struct prestera_fw_cmdq *cmdq = &fw->cmd_queue[qid];
+
+		cmdq->len = prestera_fw_read(fw, PRESTERA_CMDQ_LEN_REG(qid));
+		cmdq->addr = fw->cmd_mbox + offs;
+		mutex_init(&cmdq->cmd_mtx);
+	}
 
-	fw->evt_buf = base + mvsw_fw_read(fw, MVSW_EVT_BUF_OFFS_REG);
-	fw->evt_qnum = mvsw_fw_read(fw, MVSW_EVT_QNUM_REG);
-	fw->evt_msg = kmalloc(MVSW_MSG_MAX_SIZE, GFP_KERNEL);
+	fw->evt_buf = base + prestera_fw_read(fw, PRESTERA_EVT_BUF_OFFS_REG);
+	fw->evt_qnum = prestera_fw_read(fw, PRESTERA_EVT_QNUM_REG);
+	fw->evt_msg = kmalloc(PRESTERA_MSG_MAX_SIZE, GFP_KERNEL);
 	if (!fw->evt_msg)
 		return -ENOMEM;
 
 	for (qid = 0; qid < fw->evt_qnum; qid++) {
-		u32 offs = mvsw_fw_read(fw, MVSW_EVTQ_OFFS_REG(qid));
-		struct mvsw_pr_fw_evtq *evtq = &fw->evt_queue[qid];
+		u32 offs = prestera_fw_read(fw, PRESTERA_EVTQ_OFFS_REG(qid));
+		struct prestera_fw_evtq *evtq = &fw->evt_queue[qid];
 
-		evtq->len = mvsw_fw_read(fw, MVSW_EVTQ_LEN_REG(qid));
+		evtq->len = prestera_fw_read(fw, PRESTERA_EVTQ_LEN_REG(qid));
 		evtq->addr = fw->evt_buf + offs;
 	}
 
 	return 0;
 }
 
-static void mvsw_pr_fw_uninit(struct mvsw_pr_fw *fw)
+static void prestera_fw_uninit(struct prestera_fw *fw)
 {
 	kfree(fw->evt_msg);
 }
 
-static irqreturn_t mvsw_pci_irq_handler(int irq, void *dev_id)
+static irqreturn_t prestera_irq_handler(int irq, void *dev_id)
 {
-	struct mvsw_pr_fw *fw = dev_id;
+	struct prestera_fw *fw = dev_id;
 
-	if (mvsw_fw_read(fw, MVSW_RX_STATUS_REG)) {
+	if (prestera_fw_read(fw, PRESTERA_RX_STATUS_REG)) {
 		if (fw->dev.recv_pkt) {
-			mvsw_fw_write(fw, MVSW_RX_STATUS_REG, 0);
+			prestera_fw_write(fw, PRESTERA_RX_STATUS_REG, 0);
 			fw->dev.recv_pkt(&fw->dev);
 		}
 	}
@@ -524,64 +591,66 @@ static irqreturn_t mvsw_pci_irq_handler(int irq, void *dev_id)
 	return IRQ_HANDLED;
 }
 
-static int mvsw_pr_ldr_wait_reg32(struct mvsw_pr_fw *fw,
-				  u32 reg, u32 val, unsigned int wait)
+static int prestera_ldr_wait_reg32(struct prestera_fw *fw, u32 reg, u32 val,
+				   unsigned int wait)
 {
-	if (mvsw_wait_timeout(mvsw_ldr_read(fw, reg) == val, wait))
+	if (prestera_wait(prestera_ldr_read(fw, reg) == val, wait))
 		return 0;
 
 	return -EBUSY;
 }
 
-static u32 mvsw_pr_ldr_buf_avail(struct mvsw_pr_fw *fw)
+static u32 prestera_ldr_buf_avail(struct prestera_fw *fw)
 {
-	u32 rd_idx = mvsw_ldr_read(fw, MVSW_LDR_BUF_RD_REG);
+	u32 rd_idx = prestera_ldr_read(fw, PRESTERA_LDR_BUF_RD_REG);
 
 	return CIRC_SPACE(fw->ldr_wr_idx, rd_idx, fw->ldr_buf_len);
 }
 
-static int mvsw_pr_ldr_send_buf(struct mvsw_pr_fw *fw, const u8 *buf,
-				size_t len)
+static int prestera_ldr_send_buf(struct prestera_fw *fw, const u8 *buf,
+				 size_t len)
 {
 	int i;
 
-	if (!mvsw_wait_timeout(mvsw_pr_ldr_buf_avail(fw) >= len, 100)) {
-		dev_err(mvsw_fw_dev(fw), "failed wait for sending firmware\n");
+	if (!prestera_wait(prestera_ldr_buf_avail(fw) >= len, 100)) {
+		dev_err(prestera_fw_dev(fw),
+			"failed wait for sending firmware\n");
 		return -EBUSY;
 	}
 
 	for (i = 0; i < len; i += 4) {
-		writel_relaxed(*(u32 *)(buf + i), MVSW_LDR_WR_PTR(fw));
-		MVSW_LDR_WR_IDX_MOVE(fw, 4);
+		writel_relaxed(*(u32 *)(buf + i), PRESTERA_LDR_WR_PTR(fw));
+		PRESTERA_LDR_WR_IDX_MOVE(fw, 4);
 	}
 
-	MVSW_LDR_WR_IDX_COMMIT(fw);
+	PRESTERA_LDR_WR_IDX_COMMIT(fw);
 	return 0;
 }
 
-static int mvsw_pr_ldr_send(struct mvsw_pr_fw *fw,
-			    const char *img, u32 fw_size)
+static int prestera_ldr_send(struct prestera_fw *fw, const char *img,
+			     u32 fw_size)
 {
 	unsigned long mask;
 	u32 status;
 	u32 pos;
 	int err;
 
-	if (mvsw_pr_ldr_wait_reg32(fw, MVSW_LDR_STATUS_REG,
-				   MVSW_LDR_STATUS_IMG_DL, 1000)) {
-		dev_err(mvsw_fw_dev(fw), "Loader is not ready to load image\n");
+	if (prestera_ldr_wait_reg32(fw, PRESTERA_LDR_STATUS_REG,
+				    PRESTERA_LDR_STATUS_IMG_DL, 1000)) {
+		dev_err(prestera_fw_dev(fw),
+			"Loader is not ready to load image\n");
 		return -EBUSY;
 	}
 
-	for (pos = 0; pos < fw_size; pos += MVSW_FW_BLK_SZ) {
-		if (pos + MVSW_FW_BLK_SZ > fw_size)
+	for (pos = 0; pos < fw_size; pos += PRESTERA_FW_BLK_SZ) {
+		if (pos + PRESTERA_FW_BLK_SZ > fw_size)
 			break;
 
-		err = mvsw_pr_ldr_send_buf(fw, img + pos, MVSW_FW_BLK_SZ);
+		err = prestera_ldr_send_buf(fw, img + pos, PRESTERA_FW_BLK_SZ);
 		if (err) {
-			if (mvsw_fw_read(fw, MVSW_LDR_STATUS_REG) ==
-					 MVSW_LDR_STATUS_NOMEM) {
-				dev_err(mvsw_fw_dev(fw),
+			if (prestera_fw_read(fw, PRESTERA_LDR_STATUS_REG) ==
+					     PRESTERA_LDR_STATUS_NOMEM) {
+				dev_err(prestera_fw_dev(fw),
 					"Fw image is too big or invalid\n");
 				return -EINVAL;
 			}
@@ -590,29 +659,31 @@ static int mvsw_pr_ldr_send(struct mvsw_pr_fw *fw,
 	}
 
 	if (pos < fw_size) {
-		err = mvsw_pr_ldr_send_buf(fw, img + pos, fw_size - pos);
+		err = prestera_ldr_send_buf(fw, img + pos, fw_size - pos);
 		if (err)
 			return err;
 	}
 
 	/* Waiting for status IMG_DOWNLOADING to change to something else */
-	mask = ~(MVSW_LDR_STATUS_IMG_DL);
+	mask = ~(PRESTERA_LDR_STATUS_IMG_DL);
 
-	if (!mvsw_wait_timeout(mvsw_ldr_read(fw, MVSW_LDR_STATUS_REG) & mask,
-			       MVSW_FW_DL_TIMEOUT)) {
-		dev_err(mvsw_fw_dev(fw), "Timeout to load FW img [state=%d]",
-			mvsw_ldr_read(fw, MVSW_LDR_STATUS_REG));
+	if (!prestera_wait(prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG) &
+			   mask, PRESTERA_FW_DL_TIMEOUT)) {
+		dev_err(prestera_fw_dev(fw),
+			"Timeout to load FW img [state=%d]",
+			prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG));
 		return -ETIMEDOUT;
 	}
 
-	status = mvsw_ldr_read(fw, MVSW_LDR_STATUS_REG);
-	if (status != MVSW_LDR_STATUS_START_FW) {
+	status = prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG);
+	if (status != PRESTERA_LDR_STATUS_START_FW) {
 		switch (status) {
-		case MVSW_LDR_STATUS_INVALID_IMG:
-			dev_err(mvsw_fw_dev(fw), "FW img has bad crc\n");
+		case PRESTERA_LDR_STATUS_INVALID_IMG:
+			dev_err(prestera_fw_dev(fw), "FW img has bad crc\n");
 			return -EINVAL;
-		case MVSW_LDR_STATUS_NOMEM:
-			dev_err(mvsw_fw_dev(fw), "Loader has no enough mem\n");
+		case PRESTERA_LDR_STATUS_NOMEM:
+			dev_err(prestera_fw_dev(fw),
+				"Loader has no enough mem\n");
 			return -ENOMEM;
 		default:
 			break;
@@ -622,13 +693,14 @@ static int mvsw_pr_ldr_send(struct mvsw_pr_fw *fw,
 	return 0;
 }
 
-static bool mvsw_pr_ldr_is_ready(struct mvsw_pr_fw *fw)
+static bool prestera_ldr_is_ready(struct prestera_fw *fw)
 {
-	return mvsw_ldr_read(fw, MVSW_LDR_READY_REG) == MVSW_LDR_READY_MAGIC;
+	return prestera_ldr_read(fw, PRESTERA_LDR_READY_REG) ==
+				 PRESTERA_LDR_READY_MAGIC;
 }
 
-static void mvsw_pr_fw_rev_parse(const struct mvsw_pr_fw_header *hdr,
-				 struct prestera_fw_rev *rev)
+static void prestera_fw_rev_parse(const struct prestera_fw_header *hdr,
+				  struct prestera_fw_rev *rev)
 {
 	u32 version = be32_to_cpu(hdr->version_value);
 
@@ -637,41 +709,41 @@ static void mvsw_pr_fw_rev_parse(const struct mvsw_pr_fw_header *hdr,
 	rev->sub = FW_VER_PATCH(version);
 }
 
-static int mvsw_pr_fw_rev_check(struct mvsw_pr_fw *fw)
+static int prestera_fw_rev_check(struct prestera_fw *fw)
 {
 	struct prestera_fw_rev *rev = &fw->dev.fw_rev;
 
-	if (rev->maj == MVSW_SUPP_FW_MAJ_VER &&
-	    rev->min == MVSW_SUPP_FW_MIN_VER) {
+	if (rev->maj == PRESTERA_SUPP_FW_MAJ_VER &&
+	    rev->min == PRESTERA_SUPP_FW_MIN_VER) {
 		return 0;
 	}
 
 	return -EINVAL;
 }
 
-static int mvsw_pr_fw_hdr_parse(struct mvsw_pr_fw *fw,
-				const struct firmware *img)
+static int prestera_fw_hdr_parse(struct prestera_fw *fw,
+				 const struct firmware *img)
 {
-	struct mvsw_pr_fw_header *hdr = (struct mvsw_pr_fw_header *)img->data;
+	struct prestera_fw_header *hdr = (struct prestera_fw_header *)img->data;
 	struct prestera_fw_rev *rev = &fw->dev.fw_rev;
 	u32 magic;
 
 	magic = be32_to_cpu(hdr->magic_number);
-	if (magic != MVSW_FW_HDR_MAGIC) {
-		dev_err(mvsw_fw_dev(fw), "FW img type is invalid");
+	if (magic != PRESTERA_FW_HDR_MAGIC) {
+		dev_err(prestera_fw_dev(fw), "FW img type is invalid");
 		return -EINVAL;
 	}
 
-	mvsw_pr_fw_rev_parse(hdr, rev);
+	prestera_fw_rev_parse(hdr, rev);
 
-	dev_info(mvsw_fw_dev(fw), "FW version '%u.%u.%u'\n",
+	dev_info(prestera_fw_dev(fw), "FW version '%u.%u.%u'\n",
 		 rev->maj, rev->min, rev->sub);
-	dev_info(mvsw_fw_dev(fw), "Driver version '%u.%u.%u'\n",
-		 MVSW_SUPP_FW_MAJ_VER, MVSW_SUPP_FW_MIN_VER,
-		 MVSW_SUPP_FW_PATCH_VER);
+	dev_info(prestera_fw_dev(fw), "Driver version '%u.%u.%u'\n",
+		 PRESTERA_SUPP_FW_MAJ_VER, PRESTERA_SUPP_FW_MIN_VER,
+		 PRESTERA_SUPP_FW_PATCH_VER);
 
-	if (mvsw_pr_fw_rev_check(fw)) {
-		dev_err(mvsw_fw_dev(fw),
+	if (prestera_fw_rev_check(fw)) {
+		dev_err(prestera_fw_dev(fw),
 			"Driver is incomatible with FW: version mismatch");
 		return -EINVAL;
 	}
@@ -679,63 +751,89 @@ static int mvsw_pr_fw_hdr_parse(struct mvsw_pr_fw *fw,
 	return 0;
 }
 
-static int mvsw_pr_fw_load(struct mvsw_pr_fw *fw)
+static const char *prestera_fw_path_get(struct prestera_fw *fw)
+{
+	switch (fw->pci_dev->device) {
+	case PRESTERA_DEV_ID_98DX3500:
+		return PRESTERA_FW_ARM64_PATH;
+
+	default:
+		return PRESTERA_FW_DEFAULT_PATH;
+	}
+}
+
+static int prestera_fw_load(struct prestera_fw *fw)
 {
-	size_t hlen = sizeof(struct mvsw_pr_fw_header);
+	size_t hlen = sizeof(struct prestera_fw_header);
+	const char *fw_path = prestera_fw_path_get(fw);
 	const struct firmware *f;
 	bool has_ldr;
 	int err;
 
-	has_ldr = mvsw_wait_timeout(mvsw_pr_ldr_is_ready(fw), 1000);
+	/* 10s delay is required for soft reset feature */
+	has_ldr = prestera_wait(prestera_ldr_is_ready(fw), 15000);
 	if (!has_ldr) {
-		dev_err(mvsw_fw_dev(fw), "waiting for FW loader is timed out");
+		dev_err(prestera_fw_dev(fw),
+			"waiting for FW loader is timed out");
 		return -ETIMEDOUT;
 	}
 
 	fw->ldr_ring_buf = fw->ldr_regs +
-		mvsw_ldr_read(fw, MVSW_LDR_BUF_OFFS_REG);
+		prestera_ldr_read(fw, PRESTERA_LDR_BUF_OFFS_REG);
 
-	fw->ldr_buf_len =
-		mvsw_ldr_read(fw, MVSW_LDR_BUF_SIZE_REG);
+	fw->ldr_buf_len = prestera_ldr_read(fw, PRESTERA_LDR_BUF_SIZE_REG);
 
 	fw->ldr_wr_idx = 0;
 
-	err = request_firmware_direct(&f, MVSW_FW_FILENAME, &fw->pci_dev->dev);
+	err = request_firmware_direct(&f, fw_path, &fw->pci_dev->dev);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "failed to request firmware file\n");
+		dev_err(prestera_fw_dev(fw),
+			"failed to request firmware file: %s\n", fw_path);
 		return err;
 	}
 
 	if (!IS_ALIGNED(f->size, 4)) {
-		dev_err(mvsw_fw_dev(fw), "FW image file is not aligned");
+		dev_err(prestera_fw_dev(fw), "FW image file is not aligned");
 		release_firmware(f);
 		return -EINVAL;
 	}
 
-	err = mvsw_pr_fw_hdr_parse(fw, f);
+	err = prestera_fw_hdr_parse(fw, f);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "FW image is invalid\n");
+		dev_err(prestera_fw_dev(fw), "FW image is invalid\n");
 		release_firmware(f);
 		return err;
 	}
 
-	mvsw_ldr_write(fw, MVSW_LDR_IMG_SIZE_REG, f->size - hlen);
-	mvsw_ldr_write(fw, MVSW_LDR_CTL_REG, MVSW_LDR_CTL_DL_START);
+	prestera_ldr_write(fw, PRESTERA_LDR_IMG_SIZE_REG, f->size - hlen);
+	prestera_ldr_write(fw, PRESTERA_LDR_CTL_REG, PRESTERA_LDR_CTL_DL_START);
 
-	dev_info(mvsw_fw_dev(fw), "Loading prestera FW image ...");
+	dev_info(prestera_fw_dev(fw), "Loading prestera FW image ...");
 
-	err = mvsw_pr_ldr_send(fw, f->data + hlen, f->size - hlen);
+	err = prestera_ldr_send(fw, f->data + hlen, f->size - hlen);
 
 	release_firmware(f);
 	return err;
 }
 
-static int mvsw_pr_pci_probe(struct pci_dev *pdev,
-			     const struct pci_device_id *id)
+static bool prestera_pci_pp_use_bar2(struct pci_dev *pdev)
+{
+	switch (pdev->device) {
+	case PRESTERA_DEV_ID_ALDRIN3S:
+	case PRESTERA_DEV_ID_98DX3500:
+		return true;
+
+	default:
+		return false;
+	}
+}
+
+static int prestera_pci_probe(struct pci_dev *pdev,
+			      const struct pci_device_id *id)
 {
 	const char *driver_name = pdev->driver->name;
-	u8 __iomem *mem_addr, *pp_addr;
-	struct mvsw_pr_fw *fw;
+	u8 __iomem *mem_addr, *pp_addr = NULL;
+	struct prestera_fw *fw;
 	int err;
 
 	err = pci_enable_device(pdev);
@@ -755,19 +853,23 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 		goto err_dma_mask;
 	}
 
-	mem_addr = pci_ioremap_bar(pdev, 2);
+	mem_addr = pcim_iomap(pdev, 2, 0);
 	if (!mem_addr) {
 		dev_err(&pdev->dev, "pci mem ioremap failed\n");
 		err = -EIO;
 		goto err_mem_ioremap;
 	}
 
-	pp_addr = ioremap(pci_resource_start(pdev, 4),
-			  pci_resource_len(pdev, 4));
-	if (!pp_addr) {
-		dev_err(&pdev->dev, "pp regs ioremap failed\n");
-		err = -EIO;
-		goto err_pp_ioremap;
+	/* Aldrin3S uses second half of BAR2 */
+	if (prestera_pci_pp_use_bar2(pdev)) {
+		pp_addr = mem_addr + pci_resource_len(pdev, 2) / 2;
+	} else {
+		pp_addr = pcim_iomap(pdev, 4, 0);
+		if (!pp_addr) {
+			dev_err(&pdev->dev, "pp regs ioremap failed\n");
+			err = -EIO;
+			goto err_pp_ioremap;
+		}
 	}
 
 	pci_set_master(pdev);
@@ -780,18 +882,18 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 
 	fw->pci_dev = pdev;
 	fw->dev.dev = &pdev->dev;
-	fw->dev.send_req = mvsw_pr_fw_send_req;
+	fw->dev.send_req = prestera_fw_send_req;
 	fw->dev.pp_regs = pp_addr;
+	fw->dev.running = true;
 	fw->mem_addr = mem_addr;
 	fw->ldr_regs = mem_addr;
 	fw->hw_regs = mem_addr;
-	fw->active = true;
 
-	fw->wq = alloc_workqueue("mvsw_fw_wq", WQ_HIGHPRI, 1);
+	fw->wq = alloc_workqueue("prestera_fw_wq", WQ_HIGHPRI, 1);
 	if (!fw->wq)
 		goto err_wq_alloc;
 
-	INIT_WORK(&fw->evt_work, mvsw_pr_fw_evt_work_fn);
+	INIT_WORK(&fw->evt_work, prestera_fw_evt_work_fn);
 
 	err = pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_MSI);
 	if (err < 0) {
@@ -799,41 +901,39 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 		goto err_irq_alloc;
 	}
 
-	err = request_irq(pci_irq_vector(pdev, 0), mvsw_pci_irq_handler,
+	pci_set_drvdata(pdev, fw);
+
+	err = prestera_fw_init(fw);
+	if (err)
+		goto err_fw_init;
+
+	err = request_irq(pci_irq_vector(pdev, 0), prestera_irq_handler,
 			  0, driver_name, fw);
 	if (err) {
 		dev_err(&pdev->dev, "fail to request IRQ\n");
 		goto err_request_irq;
 	}
 
-	pci_set_drvdata(pdev, fw);
-
-	err = mvsw_pr_fw_init(fw);
-	if (err)
-		goto err_mvsw_fw_init;
-
-	dev_info(mvsw_fw_dev(fw), "Prestera Switch FW is ready\n");
+	dev_info(prestera_fw_dev(fw), "Prestera Switch FW is ready\n");
 
 	err = prestera_device_register(&fw->dev);
 	if (err)
-		goto err_mvsw_dev_register;
+		goto err_prestera_dev_register;
 
 	return 0;
 
-err_mvsw_dev_register:
-	mvsw_pr_fw_uninit(fw);
-err_mvsw_fw_init:
+err_prestera_dev_register:
 	free_irq(pci_irq_vector(pdev, 0), fw);
 err_request_irq:
+	prestera_fw_uninit(fw);
+err_fw_init:
 	pci_free_irq_vectors(pdev);
 err_irq_alloc:
 	destroy_workqueue(fw->wq);
 err_wq_alloc:
 	kfree(fw);
 err_pci_dev_alloc:
-	iounmap(pp_addr);
 err_pp_ioremap:
-	iounmap(mem_addr);
 err_mem_ioremap:
 err_dma_mask:
 	pci_release_regions(pdev);
@@ -843,31 +943,29 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 	return err;
 }
 
-static void mvsw_pr_pci_remove(struct pci_dev *pdev)
+static void prestera_pci_remove(struct pci_dev *pdev)
 {
-	struct mvsw_pr_fw *fw = pci_get_drvdata(pdev);
+	struct prestera_fw *fw = pci_get_drvdata(pdev);
 
 	free_irq(pci_irq_vector(pdev, 0), fw);
 	pci_free_irq_vectors(pdev);
 	prestera_device_unregister(&fw->dev);
 	flush_workqueue(fw->wq);
 	destroy_workqueue(fw->wq);
-	mvsw_pr_fw_uninit(fw);
-	iounmap(fw->dev.pp_regs);
-	iounmap(fw->mem_addr);
+	prestera_fw_uninit(fw);
 	pci_release_regions(pdev);
 	pci_disable_device(pdev);
 	kfree(fw);
 }
 
-static int __init mvsw_pr_pci_init(void)
+static int __init prestera_pci_init(void)
 {
-	struct mvsw_pr_pci_match *match;
+	struct prestera_pci_match *match;
 	int err = 0;
 
-	for (match = mvsw_pci_devices; match->driver.name; match++) {
-		match->driver.probe = mvsw_pr_pci_probe;
-		match->driver.remove = mvsw_pr_pci_remove;
+	for (match = prestera_devices; match->driver.name; match++) {
+		match->driver.probe = prestera_pci_probe;
+		match->driver.remove = prestera_pci_remove;
 		match->driver.id_table = &match->id;
 
 		err = pci_register_driver(&match->driver);
@@ -881,7 +979,7 @@ static int __init mvsw_pr_pci_init(void)
 	}
 
 	if (err) {
-		for (match = mvsw_pci_devices; match->driver.name; match++) {
+		for (match = prestera_devices; match->driver.name; match++) {
 			if (!match->registered)
 				break;
 
@@ -895,11 +993,11 @@ static int __init mvsw_pr_pci_init(void)
 	return 0;
 }
 
-static void __exit mvsw_pr_pci_exit(void)
+static void __exit prestera_pci_exit(void)
 {
-	struct mvsw_pr_pci_match *match;
+	struct prestera_pci_match *match;
 
-	for (match = mvsw_pci_devices; match->driver.name; match++) {
+	for (match = prestera_devices; match->driver.name; match++) {
 		if (!match->registered)
 			break;
 
@@ -909,8 +1007,8 @@ static void __exit mvsw_pr_pci_exit(void)
 	pr_info("prestera_pci: Unregistered Marvell Prestera PCI driver\n");
 }
 
-module_init(mvsw_pr_pci_init);
-module_exit(mvsw_pr_pci_exit);
+module_init(prestera_pci_init);
+module_exit(prestera_pci_exit);
 
 MODULE_AUTHOR("Marvell Semi.");
 MODULE_LICENSE("GPL");
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_router.c b/drivers/net/ethernet/marvell/prestera/prestera_router.c
index 141ac01..e4f6484 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_router.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_router.c
@@ -1,8 +1,5 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/*
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
 #include <linux/kernel.h>
 #include <linux/types.h>
@@ -11,7 +8,6 @@
 #include <linux/inetdevice.h>
 #include <linux/netdevice.h>
 #include <linux/if_bridge.h>
-#include <linux/rhashtable.h>
 #include <net/netevent.h>
 #include <net/neighbour.h>
 #include <net/addrconf.h>
@@ -19,21 +15,23 @@
 #include <net/switchdev.h>
 #include <net/arp.h>
 #include <net/nexthop.h>
+#include <linux/rhashtable.h>
 
 #include "prestera.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
 #include "prestera_hw.h"
 #include "prestera_log.h"
 
 #define MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH
 #define MVSW_PR_NH_PROBE_INTERVAL 5000 /* ms */
-#define MVSW_PR_NH_ACTIVE_JIFFER_FILTER 3000 /* ms */
 #define MVSW_PR_NHGR_UNUSED (0)
 #define MVSW_PR_NHGR_DROP (0xFFFFFFFF)
 
 static const char mvsw_driver_name[] = "mrvl_switchdev";
 
-struct mvsw_pr_rif {
-	struct mvsw_pr_iface iface;
+struct prestera_rif {
+	struct prestera_iface iface;
 	struct net_device *dev;
 	struct list_head router_node;
 	unsigned char addr[ETH_ALEN];
@@ -41,7 +39,7 @@ struct mvsw_pr_rif {
 	bool is_active;
 	u16 rif_id;
 	struct mvsw_pr_vr *vr;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	unsigned int ref_cnt;
 };
 
@@ -52,8 +50,8 @@ struct mvsw_pr_rif_params {
 
 struct mvsw_pr_fib_node {
 	struct rhash_head ht_node; /* node of mvsw_pr_vr */
-	struct mvsw_pr_fib_key key;
-	struct mvsw_pr_fib_info info; /* action related info */
+	struct prestera_fib_key key;
+	struct prestera_fib_info info; /* action related info */
 };
 
 struct mvsw_pr_vr {
@@ -63,12 +61,8 @@ struct mvsw_pr_vr {
 	unsigned int ref_cnt;
 };
 
-struct mvsw_pr_nexthop_group_key {
-	struct mvsw_pr_nh_neigh_key neigh[MVSW_PR_NHGR_SIZE_MAX];
-};
-
 struct mvsw_pr_nexthop_group {
-	struct mvsw_pr_nexthop_group_key key;
+	struct prestera_nexthop_group_key key;
 	/* Store intermediate object here.
 	 * This prevent overhead kzalloc call.
 	 */
@@ -79,10 +73,9 @@ struct mvsw_pr_nexthop_group {
 		/* ptr to neigh is not necessary.
 		 * It used to prevent lookup of nh_neigh by key (n) on destroy
 		 */
-		struct mvsw_pr_nh_neigh *neigh;
-	} nh_neigh_head[MVSW_PR_NHGR_SIZE_MAX];
+		struct prestera_nh_neigh *neigh;
+	} nh_neigh_head[PRESTERA_NHGR_SIZE_MAX];
 	u32 grp_id; /* hw */
-	unsigned long hw_last_connected; /* jiffies */
 	struct rhash_head ht_node; /* node of mvsw_pr_vr */
 	unsigned int ref_cnt;
 };
@@ -93,57 +86,74 @@ enum mvsw_pr_mp_hash_policy {
 	MVSW_MP_HASH_POLICY_MAX,
 };
 
-struct mvsw_pr_kern_neigh_cache {
-	struct mvsw_pr_nh_neigh_key key;
-	bool offloaded;
+struct prestera_kern_neigh_cache {
+	struct prestera_nh_neigh_key key;
 	struct rhash_head ht_node;
 	struct list_head kern_fib_cache_list;
-	bool lpm_added; /* Indicate if neigh is reachable by connected route */
-	bool in_kernel; /* Valid in kernel */
+	/* Lock cache if neigh is present in kernel */
+	bool in_kernel;
+	/* Hold prepared nh_neigh info if is in_kernel */
+	struct prestera_neigh_info nh_neigh_info;
+	/* Indicate if neighbour is reachable by direct route */
+	bool reachable;
+};
+
+struct mvsw_pr_kern_fib_cache_key {
+	struct prestera_ip_addr addr;
+	u32 prefix_len;
+	u32 kern_tb_id; /* tb_id from kernel (not fixed) */
 };
 
-/* Used to track offloaded fib entries */
+/* Subscribing on neighbours in kernel */
 struct mvsw_pr_kern_fib_cache {
-	struct mvsw_pr_fib_key key;
-	struct fib_info *fi;
+	struct mvsw_pr_kern_fib_cache_key key;
+	struct {
+		struct prestera_fib_key fib_key;
+		enum mvsw_pr_fib_type fib_type;
+		struct prestera_nexthop_group_key nh_grp_key;
+	} lpm_info; /* hold prepared lpm info */
+	/* Indicate if route is not overlapped by another table */
+	bool reachable;
+	bool allow_oflag;
 	struct rhash_head ht_node; /* node of mvsw_pr_router */
 	struct mvsw_pr_kern_neigh_cache_head {
 		struct mvsw_pr_kern_fib_cache *this;
 		struct list_head head;
-		struct mvsw_pr_kern_neigh_cache *n_cache;
-	} kern_neigh_cache_head[MVSW_PR_NHGR_SIZE_MAX];
+		struct prestera_kern_neigh_cache *n_cache;
+	} kern_neigh_cache_head[PRESTERA_NHGR_SIZE_MAX];
+	struct fib_info *fi;
 };
 
 static const struct rhashtable_params __mvsw_pr_kern_neigh_cache_ht_params = {
-	.key_offset  = offsetof(struct mvsw_pr_kern_neigh_cache, key),
-	.head_offset = offsetof(struct mvsw_pr_kern_neigh_cache, ht_node),
-	.key_len     = sizeof(struct mvsw_pr_nh_neigh_key),
+	.key_offset  = offsetof(struct prestera_kern_neigh_cache, key),
+	.head_offset = offsetof(struct prestera_kern_neigh_cache, ht_node),
+	.key_len     = sizeof(struct prestera_nh_neigh_key),
 	.automatic_shrinking = true,
 };
 
 static const struct rhashtable_params __mvsw_pr_kern_fib_cache_ht_params = {
 	.key_offset  = offsetof(struct mvsw_pr_kern_fib_cache, key),
 	.head_offset = offsetof(struct mvsw_pr_kern_fib_cache, ht_node),
-	.key_len     = sizeof(struct mvsw_pr_fib_key),
+	.key_len     = sizeof(struct mvsw_pr_kern_fib_cache_key),
 	.automatic_shrinking = true,
 };
 
 static const struct rhashtable_params __mvsw_pr_fib_ht_params = {
 	.key_offset  = offsetof(struct mvsw_pr_fib_node, key),
 	.head_offset = offsetof(struct mvsw_pr_fib_node, ht_node),
-	.key_len     = sizeof(struct mvsw_pr_fib_key),
+	.key_len     = sizeof(struct prestera_fib_key),
 	.automatic_shrinking = true,
 };
 
 static const struct rhashtable_params __mvsw_pr_nh_neigh_ht_params = {
-	.key_offset  = offsetof(struct mvsw_pr_nh_neigh, key),
-	.key_len     = sizeof(struct mvsw_pr_nh_neigh_key),
-	.head_offset = offsetof(struct mvsw_pr_nh_neigh, ht_node),
+	.key_offset  = offsetof(struct prestera_nh_neigh, key),
+	.key_len     = sizeof(struct prestera_nh_neigh_key),
+	.head_offset = offsetof(struct prestera_nh_neigh, ht_node),
 };
 
 static const struct rhashtable_params __mvsw_pr_nexthop_group_ht_params = {
 	.key_offset  = offsetof(struct mvsw_pr_nexthop_group, key),
-	.key_len     = sizeof(struct mvsw_pr_nexthop_group_key),
+	.key_len     = sizeof(struct prestera_nexthop_group_key),
 	.head_offset = offsetof(struct mvsw_pr_nexthop_group, ht_node),
 };
 
@@ -199,54 +209,56 @@ static const unsigned char mvsw_pr_mac_mask[ETH_ALEN] = {
 	0xff, 0xff, 0xff, 0xff, 0xfc, 0x00
 };
 
-static struct mvsw_pr_vr *mvsw_pr_vr_get(struct mvsw_pr_switch *sw, u32 tb_id,
+static struct mvsw_pr_vr *mvsw_pr_vr_get(struct prestera_switch *sw, u32 tb_id,
 					 struct netlink_ext_ack *extack);
 static u32 mvsw_pr_fix_tb_id(u32 tb_id);
-static void mvsw_pr_vr_put(struct mvsw_pr_switch *sw, struct mvsw_pr_vr *vr);
-static void mvsw_pr_vr_util_hw_abort(struct mvsw_pr_switch *sw);
-static struct mvsw_pr_rif *mvsw_pr_rif_create(struct mvsw_pr_switch *sw,
-					      const struct mvsw_pr_rif_params
-					      *params,
-					      struct netlink_ext_ack *extack);
-static int mvsw_pr_rif_vr_update(struct mvsw_pr_switch *sw,
-				 struct mvsw_pr_rif *rif,
+static void mvsw_pr_vr_put(struct prestera_switch *sw, struct mvsw_pr_vr *vr);
+static void mvsw_pr_vr_util_hw_abort(struct prestera_switch *sw);
+static struct prestera_rif *mvsw_pr_rif_create(struct prestera_switch *sw,
+					       const struct mvsw_pr_rif_params
+					       *params,
+					       struct netlink_ext_ack *extack);
+static int mvsw_pr_rif_vr_update(struct prestera_switch *sw,
+				 struct prestera_rif *rif,
 				 struct netlink_ext_ack *extack);
-static void mvsw_pr_rif_destroy(struct mvsw_pr_rif *rif);
-static void mvsw_pr_rif_put(struct mvsw_pr_rif *rif);
-static int mvsw_pr_rif_update(struct mvsw_pr_rif *rif, char *mac);
-static struct mvsw_pr_rif *mvsw_pr_rif_find(const struct mvsw_pr_switch *sw,
-					    const struct net_device *dev);
-static u16 mvsw_pr_rif_vr_id(struct mvsw_pr_rif *rif);
+static void mvsw_pr_rif_destroy(struct prestera_rif *rif);
+static void mvsw_pr_rif_put(struct prestera_rif *rif);
+static int mvsw_pr_rif_update(struct prestera_rif *rif, char *mac);
+static struct prestera_rif *mvsw_pr_rif_find(const struct prestera_switch *sw,
+					     const struct net_device *dev);
+static u16 mvsw_pr_rif_vr_id(struct prestera_rif *rif);
 static bool
-mvsw_pr_nh_neigh_util_hw_state(struct mvsw_pr_switch *sw,
-			       struct mvsw_pr_nh_neigh *nh_neigh);
+mvsw_pr_nh_neigh_util_hw_state(struct prestera_switch *sw,
+			       struct prestera_nh_neigh *nh_neigh);
 static bool
-mvsw_pr_nexthop_group_util_hw_state(struct mvsw_pr_switch *sw,
+mvsw_pr_nexthop_group_util_hw_state(struct prestera_switch *sw,
 				    struct mvsw_pr_nexthop_group *nh_grp);
-static struct mvsw_pr_nh_neigh *
-mvsw_pr_nh_neigh_find(struct mvsw_pr_switch *sw,
-		      struct mvsw_pr_nh_neigh_key *key);
-static int mvsw_pr_nh_neigh_set(struct mvsw_pr_switch *sw,
-				struct mvsw_pr_nh_neigh *neigh);
-static int mvsw_pr_nexthop_group_set(struct mvsw_pr_switch *sw,
+static int mvsw_pr_nh_neigh_set(struct prestera_switch *sw,
+				struct prestera_nh_neigh *neigh);
+static int mvsw_pr_nexthop_group_set(struct prestera_switch *sw,
 				     struct mvsw_pr_nexthop_group *nh_grp);
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_find(struct mvsw_pr_switch *sw, struct mvsw_pr_fib_key *key);
-static void mvsw_pr_fib_node_destroy(struct mvsw_pr_switch *sw,
+mvsw_pr_fib_node_find(struct prestera_switch *sw, struct prestera_fib_key *key);
+static void mvsw_pr_fib_node_destroy(struct prestera_switch *sw,
 				     struct mvsw_pr_fib_node *fib_node);
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
-			      struct mvsw_pr_fib_key *key,
-			      struct mvsw_pr_nexthop_group_key *nh_grp_key);
+mvsw_pr_fib_node_create(struct prestera_switch *sw,
+			struct prestera_fib_key *key,
+			enum mvsw_pr_fib_type fib_type,
+			struct prestera_nexthop_group_key *nh_grp_key);
 static bool mvsw_pr_fi_is_direct(struct fib_info *fi);
+static bool mvsw_pr_fi_is_hw_direct(struct prestera_switch *sw,
+				    struct fib_info *fi);
 static bool mvsw_pr_fi_is_nh(struct fib_info *fi);
+static bool mvsw_pr_nh_neigh_key_is_valid(struct prestera_nh_neigh_key *key);
 static bool
 mvsw_pr_fib_node_util_is_neighbour(struct mvsw_pr_fib_node *fib_node);
-static void
-mvsw_pr_kern_fib_cache_offload_set(struct mvsw_pr_switch *sw,
-				   struct mvsw_pr_kern_fib_cache *fib_cache);
+static int
+mvsw_pr_util_fi2nh_gr_key(struct prestera_switch *sw, struct fib_info *fi,
+			  size_t limit,
+			  struct prestera_nexthop_group_key *grp_key);
 
-static u16 mvsw_pr_nh_dev_to_vid(struct mvsw_pr_switch *sw,
+static u16 mvsw_pr_nh_dev_to_vid(struct prestera_switch *sw,
 				 struct net_device *dev)
 {
 	struct macvlan_dev *vlan;
@@ -258,7 +270,7 @@ static u16 mvsw_pr_nh_dev_to_vid(struct mvsw_pr_switch *sw,
 	} else if (netif_is_bridge_master(dev) && br_vlan_enabled(dev)) {
 		br_vlan_get_pvid(dev, &vid);
 	} else if (netif_is_bridge_master(dev)) {
-		vid = mvsw_pr_vlan_dev_vlan_id(sw->bridge, dev);
+		vid = prestera_vlan_dev_vlan_id(sw->bridge, dev);
 	} else if (netif_is_macvlan(dev)) {
 		vlan = netdev_priv(dev);
 		return mvsw_pr_nh_dev_to_vid(sw, vlan->lowerdev);
@@ -268,7 +280,7 @@ static u16 mvsw_pr_nh_dev_to_vid(struct mvsw_pr_switch *sw,
 }
 
 static struct net_device*
-mvsw_pr_nh_dev_egress(struct mvsw_pr_switch *sw, struct net_device *dev,
+mvsw_pr_nh_dev_egress(struct prestera_switch *sw, struct net_device *dev,
 		      u8 *ha)
 {
 	struct net_device *bridge_dev, *egress_dev = dev;
@@ -293,18 +305,18 @@ mvsw_pr_nh_dev_egress(struct mvsw_pr_switch *sw, struct net_device *dev,
 	return egress_dev;
 }
 
-static u16 mvsw_pr_rif_vr_id(struct mvsw_pr_rif *rif)
+static u16 mvsw_pr_rif_vr_id(struct prestera_rif *rif)
 {
 	return rif->vr->hw_vr_id;
 }
 
 static int
-mvsw_pr_rif_iface_init(struct mvsw_pr_rif *rif)
+mvsw_pr_rif_iface_init(struct prestera_rif *rif)
 {
 	struct net_device *dev = rif->dev;
-	struct mvsw_pr_switch *sw = rif->sw;
-	struct mvsw_pr_port *port;
-	int if_type = mvsw_pr_dev_if_type(dev);
+	struct prestera_switch *sw = rif->sw;
+	struct prestera_port *port;
+	int if_type = prestera_dev_if_type(dev);
 
 	switch (if_type) {
 	case MVSW_IF_PORT_E:
@@ -330,16 +342,16 @@ mvsw_pr_rif_iface_init(struct mvsw_pr_rif *rif)
 }
 
 static int
-__mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
-			   struct mvsw_pr_iface *iface,
+__mvsw_pr_neigh_iface_init(struct prestera_switch *sw,
+			   struct prestera_iface *iface,
 			   struct neighbour *n,
 			   struct net_device *dev)
 {
 	bool is_nud_perm = n->nud_state & NUD_PERMANENT;
 	struct net_device *egress_dev;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
-	iface->type = mvsw_pr_dev_if_type(dev);
+	iface->type = prestera_dev_if_type(dev);
 
 	switch (iface->type) {
 	case MVSW_IF_PORT_E:
@@ -350,13 +362,13 @@ __mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
 		 * of the ports which is needed by the hardware, therefore
 		 * use any valid lower
 		 */
-			port = mvsw_pr_port_dev_lower_find(dev);
+			port = prestera_port_dev_lower_find(dev);
 			egress_dev = port->net_dev;
 		}
 		if (!egress_dev)
 			return -ENOENT;
 
-		if (!mvsw_pr_netdev_check(egress_dev))
+		if (!prestera_netdev_check(egress_dev))
 			return __mvsw_pr_neigh_iface_init(sw, iface, n,
 							  egress_dev);
 
@@ -376,9 +388,9 @@ __mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
 }
 
 static int
-mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
-			struct mvsw_pr_iface *iface,
-			struct neighbour *n)
+mvsw_pr_neigh_iface_init(struct prestera_switch *sw,
+			 struct prestera_iface *iface,
+			 struct neighbour *n)
 {
 	/* TODO vr_id is obsolete in iface ? */
 	iface->vlan_id = mvsw_pr_nh_dev_to_vid(sw, n->dev);
@@ -395,21 +407,6 @@ static void mvsw_pr_util_kern_set_neigh_offload(struct neighbour *n,
 }
 
 static void
-__mvsw_pr_util_kern_unset_allneigh_offload_cb(struct neighbour *n,
-					      void *cookie)
-{
-	mvsw_pr_util_kern_set_neigh_offload(n, false);
-}
-
-static void mvsw_pr_util_kern_unset_allneigh_offload(void)
-{
-	/* Walk through every neighbour in kernel */
-	neigh_for_each(&arp_tbl,
-		       __mvsw_pr_util_kern_unset_allneigh_offload_cb,
-		       NULL);
-}
-
-static void
 mvsw_pr_util_kern_set_nh_offload(struct fib_nh *fib_nh, bool offloaded)
 {
 		if (offloaded)
@@ -421,7 +418,7 @@ mvsw_pr_util_kern_set_nh_offload(struct fib_nh *fib_nh, bool offloaded)
 /* must be called with rcu_read_lock() */
 static int mvsw_pr_util_kern_get_route(struct fib_result *res,
 				       u32 tb_id,
-				       struct mvsw_pr_ip_addr *addr)
+				       struct prestera_ip_addr *addr)
 {
 	struct fib_table *tb;
 	struct flowi4 fl4;
@@ -443,25 +440,171 @@ static int mvsw_pr_util_kern_get_route(struct fib_result *res,
 	return 0;
 }
 
+int prestera_util_kern_dip2nh_grp_key(struct prestera_switch *sw,
+				      u32 tb_id, struct prestera_ip_addr *addr,
+				      struct prestera_nexthop_group_key *res)
+{
+	int err;
+	struct fib_result fib_res;
+	struct fib_nh *fib_nh;
+
+	err = mvsw_pr_util_kern_get_route(&fib_res, tb_id, addr);
+	if (err)
+		return 0;
+
+	if (mvsw_pr_fi_is_direct(fib_res.fi)) {
+		fib_nh = fib_info_nh(fib_res.fi, 0);
+		memset(res, 0, sizeof(*res));
+		res->neigh[0].addr = *addr;
+		res->neigh[0].rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+		if (!res->neigh[0].rif || !res->neigh[0].rif->is_active)
+			return 0;
+
+		return 1;
+	}
+
+	return mvsw_pr_util_fi2nh_gr_key(sw, fib_res.fi,
+					 PRESTERA_NHGR_SIZE_MAX, res);
+}
+
+/* Check if neigh route is reachable */
+static bool
+mvsw_pr_util_kern_n_is_reachable(u32 tb_id,
+				 struct prestera_ip_addr *addr,
+				 struct net_device *dev)
+{
+	bool reachable;
+	struct fib_nh *fib_nh;
+	struct fib_result res;
+
+	reachable = false;
+
+	if (!mvsw_pr_util_kern_get_route(&res, tb_id, addr))
+		if (res.type == RTN_UNICAST &&
+		    mvsw_pr_fi_is_direct(res.fi)) {
+			fib_nh = fib_info_nh(res.fi, 0);
+			if (dev == fib_nh->fib_nh_dev)
+				reachable = true;
+		}
+
+	return reachable;
+}
+
+static bool
+mvsw_pr_util_fi_is_point2dev(struct fib_info *fi,
+			     const struct net_device *dev)
+{
+	int nhs, i;
+	struct fib_nh *fib_nh;
+
+	nhs = fib_info_num_path(fi);
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fi, i);
+		if (fib_nh->fib_nh_dev == dev)
+			return true;
+	}
+
+	return false;
+}
+
 static int
-mvsw_pr_util_fib_nh2nh_neigh_key(struct mvsw_pr_switch *sw,
+mvsw_pr_util_fib_nh2nh_neigh_key(struct prestera_switch *sw,
 				 struct fib_nh *fib_nh,
-				 struct mvsw_pr_nh_neigh_key *nh_key)
+				 struct prestera_nh_neigh_key *nh_key)
 {
 	memset(nh_key, 0, sizeof(*nh_key));
 	nh_key->addr.u.ipv4 = fib_nh->fib_nh_gw4;
 	nh_key->rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
-	if (!nh_key->rif)
+	if (!nh_key->rif || !nh_key->rif->is_active)
+		return -ENOENT;
+
+	return 0;
+}
+
+static int
+mvsw_pr_util_fi2nh_gr_key(struct prestera_switch *sw, struct fib_info *fi,
+			  size_t limit,
+			  struct prestera_nexthop_group_key *grp_key)
+{
+	int i, nhs, err;
+	struct fib_nh *fib_nh;
+
+	if (!mvsw_pr_fi_is_nh(fi))
+		return 0;
+
+	nhs = fib_info_num_path(fi);
+	if (nhs > limit)
+		return 0;
+
+	memset(grp_key, 0, sizeof(*grp_key));
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fi, i);
+		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw,
+						       fib_nh,
+						       &grp_key->neigh[i]);
+		if (err)
+			return 0;
+	}
+
+	return nhs;
+}
+
+static void
+mvsw_pr_util_fen_info2fib_cache_key(struct fib_entry_notifier_info *fen_info,
+				    struct mvsw_pr_kern_fib_cache_key *key)
+{
+	memset(key, 0, sizeof(*key));
+	key->addr.u.ipv4 = cpu_to_be32(fen_info->dst);
+	key->prefix_len = fen_info->dst_len;
+	key->kern_tb_id = fen_info->tb_id;
+}
+
+static void
+mvsw_pr_util_fib_cache_key2fib_key(struct mvsw_pr_kern_fib_cache_key *ckey,
+				   struct prestera_fib_key *fkey)
+{
+	memset(fkey, 0, sizeof(*fkey));
+	fkey->addr = ckey->addr;
+	fkey->prefix_len = ckey->prefix_len;
+	fkey->tb_id = mvsw_pr_fix_tb_id(ckey->kern_tb_id);
+}
+
+static bool
+mvsw_pr_util_is_fib_nh_equal2nh_neigh_key(struct prestera_switch *sw,
+					  struct fib_nh *fib_nh,
+					  struct prestera_nh_neigh_key *nk)
+{
+	int err;
+	struct prestera_nh_neigh_key tk;
+
+	err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_nh, &tk);
+	if (err)
+		return false;
+
+	if (memcmp(&tk, nk, sizeof(tk)))
+		return false;
+
+	return true;
+}
+
+static int mvsw_pr_util_neigh2nh_neigh_key(struct prestera_switch *sw,
+					   struct neighbour *n,
+					   struct prestera_nh_neigh_key *key)
+{
+	memset(key, 0, sizeof(*key));
+	key->addr.u.ipv4 = *(__be32 *)n->primary_key;
+	key->rif = mvsw_pr_rif_find(sw, n->dev);
+	if (!key->rif)
 		return -ENOENT;
 
 	return 0;
 }
 
-static struct mvsw_pr_kern_neigh_cache *
-mvsw_pr_kern_neigh_cache_find(struct mvsw_pr_switch *sw,
-			      struct mvsw_pr_nh_neigh_key *key)
+static struct prestera_kern_neigh_cache *
+mvsw_pr_kern_neigh_cache_find(struct prestera_switch *sw,
+			      struct prestera_nh_neigh_key *key)
 {
-	struct mvsw_pr_kern_neigh_cache *n_cache;
+	struct prestera_kern_neigh_cache *n_cache;
 
 	n_cache =
 	 rhashtable_lookup_fast(&sw->router->kern_neigh_cache_ht, key,
@@ -470,8 +613,8 @@ mvsw_pr_kern_neigh_cache_find(struct mvsw_pr_switch *sw,
 }
 
 static void
-__mvsw_pr_kern_neigh_cache_destroy(struct mvsw_pr_switch *sw,
-				   struct mvsw_pr_kern_neigh_cache *n_cache)
+__mvsw_pr_kern_neigh_cache_destroy(struct prestera_switch *sw,
+				   struct prestera_kern_neigh_cache *n_cache)
 {
 	n_cache->key.rif->ref_cnt--;
 	mvsw_pr_rif_put(n_cache->key.rif);
@@ -481,11 +624,11 @@ __mvsw_pr_kern_neigh_cache_destroy(struct mvsw_pr_switch *sw,
 	kfree(n_cache);
 }
 
-static struct mvsw_pr_kern_neigh_cache *
-__mvsw_pr_kern_neigh_cache_create(struct mvsw_pr_switch *sw,
-				  struct mvsw_pr_nh_neigh_key *key)
+static struct prestera_kern_neigh_cache *
+__mvsw_pr_kern_neigh_cache_create(struct prestera_switch *sw,
+				  struct prestera_nh_neigh_key *key)
 {
-	struct mvsw_pr_kern_neigh_cache *n_cache;
+	struct prestera_kern_neigh_cache *n_cache;
 	int err;
 
 	n_cache = kzalloc(sizeof(*n_cache), GFP_KERNEL);
@@ -512,11 +655,11 @@ __mvsw_pr_kern_neigh_cache_create(struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static struct mvsw_pr_kern_neigh_cache *
-mvsw_pr_kern_neigh_cache_get(struct mvsw_pr_switch *sw,
-			     struct mvsw_pr_nh_neigh_key *key)
+static struct prestera_kern_neigh_cache *
+mvsw_pr_kern_neigh_cache_get(struct prestera_switch *sw,
+			     struct prestera_nh_neigh_key *key)
 {
-	struct mvsw_pr_kern_neigh_cache *n_cache;
+	struct prestera_kern_neigh_cache *n_cache;
 
 	n_cache = mvsw_pr_kern_neigh_cache_find(sw, key);
 	if (!n_cache)
@@ -525,61 +668,22 @@ mvsw_pr_kern_neigh_cache_get(struct mvsw_pr_switch *sw,
 	return n_cache;
 }
 
-static void
-mvsw_pr_kern_neigh_cache_put(struct mvsw_pr_switch *sw,
-			     struct mvsw_pr_kern_neigh_cache *n_cache)
+static struct prestera_kern_neigh_cache *
+mvsw_pr_kern_neigh_cache_put(struct prestera_switch *sw,
+			     struct prestera_kern_neigh_cache *n_cache)
 {
-	if (!n_cache->in_kernel && !n_cache->lpm_added &&
-	    list_empty(&n_cache->kern_fib_cache_list))
+	if (!n_cache->in_kernel &&
+	    list_empty(&n_cache->kern_fib_cache_list)) {
 		__mvsw_pr_kern_neigh_cache_destroy(sw, n_cache);
-}
-
-static void
-mvsw_pr_kern_neigh_cache_offload_set(struct mvsw_pr_switch *sw,
-				     struct mvsw_pr_kern_neigh_cache *n_cache)
-{
-	struct mvsw_pr_kern_neigh_cache_head *n_head;
-
-	list_for_each_entry(n_head, &n_cache->kern_fib_cache_list, head) {
-		mvsw_pr_kern_fib_cache_offload_set(sw, n_head->this);
-	}
-}
-
-static void
-mvsw_pr_kern_neigh_cache_lpm_set(struct mvsw_pr_switch *sw,
-				 struct mvsw_pr_kern_neigh_cache *n_cache)
-{
-	struct mvsw_pr_fib_key fib_key;
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_nexthop_group_key nh_grp_key;
-
-	memset(&fib_key, 0, sizeof(fib_key));
-	fib_key.addr = n_cache->key.addr;
-	fib_key.prefix_len = 32;
-	fib_key.tb_id = n_cache->key.rif->vr->tb_id;
-	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
-	if (!n_cache->lpm_added && fib_node) {
-		if (mvsw_pr_fib_node_util_is_neighbour(fib_node))
-			mvsw_pr_fib_node_destroy(sw, fib_node);
-		return;
+		return NULL;
 	}
 
-	if (n_cache->lpm_added && !fib_node) {
-		memset(&nh_grp_key, 0, sizeof(nh_grp_key));
-		nh_grp_key.neigh[0] = n_cache->key;
-		fib_node = mvsw_pr_fib_node_uc_nh_create(sw, &fib_key,
-							 &nh_grp_key);
-		if (!fib_node)
-			MVSW_LOG_ERROR("%s failed ip=%pI4n",
-				       "mvsw_pr_fib_node_uc_nh_create",
-				       &fib_key.addr.u.ipv4);
-		return;
-	}
+	return n_cache;
 }
 
 static struct mvsw_pr_kern_fib_cache *
-mvsw_pr_kern_fib_cache_find(struct mvsw_pr_switch *sw,
-			    struct mvsw_pr_fib_key *key)
+mvsw_pr_kern_fib_cache_find(struct prestera_switch *sw,
+			    struct mvsw_pr_kern_fib_cache_key *key)
 {
 	struct mvsw_pr_kern_fib_cache *fib_cache;
 
@@ -590,116 +694,40 @@ mvsw_pr_kern_fib_cache_find(struct mvsw_pr_switch *sw,
 }
 
 static void
-__mvsw_pr_kern_fib_cache_destruct(struct mvsw_pr_switch *sw,
-				  struct mvsw_pr_kern_fib_cache *fib_cache)
+mvsw_pr_kern_fib_cache_destroy(struct prestera_switch *sw,
+			       struct mvsw_pr_kern_fib_cache *fib_cache)
 {
 	int i;
-	struct mvsw_pr_kern_neigh_cache *n_cache;
-	struct fib_nh *fib_nh;
-
-	if (mvsw_pr_fi_is_direct(fib_cache->fi)) {
-		fib_nh = fib_info_nh(fib_cache->fi, 0);
-		mvsw_pr_util_kern_set_nh_offload(fib_nh, true);
-		goto out;
-	}
+	struct prestera_kern_neigh_cache *n_cache;
 
-	for (i = 0; i < MVSW_PR_NHGR_SIZE_MAX; i++) {
+	for (i = 0; i < PRESTERA_NHGR_SIZE_MAX; i++) {
 		n_cache = fib_cache->kern_neigh_cache_head[i].n_cache;
 		if (n_cache) {
 			list_del(&fib_cache->kern_neigh_cache_head[i].head);
 			mvsw_pr_kern_neigh_cache_put(sw, n_cache);
-			fib_nh = fib_info_nh(fib_cache->fi, i);
-			mvsw_pr_util_kern_set_nh_offload(fib_nh, false);
 		}
 	}
 
-out:
 	fib_info_put(fib_cache->fi);
-}
-
-static void
-mvsw_pr_kern_fib_cache_offload_set(struct mvsw_pr_switch *sw,
-				   struct mvsw_pr_kern_fib_cache *fib_cache)
-{
-	int i;
-	struct mvsw_pr_kern_neigh_cache *n_cache;
-	struct fib_nh *fib_nh;
-	bool offloaded;
-
-	if (mvsw_pr_fi_is_direct(fib_cache->fi)) {
-		fib_nh = fib_info_nh(fib_cache->fi, 0);
-		if (mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev))
-			mvsw_pr_util_kern_set_nh_offload(fib_nh, true);
-		goto out;
-	}
-
-	for (i = 0; i < MVSW_PR_NHGR_SIZE_MAX; i++) {
-		n_cache = fib_cache->kern_neigh_cache_head[i].n_cache;
-		if (!n_cache)
-			continue;
-
-		offloaded = n_cache->offloaded;
-		fib_nh = fib_info_nh(fib_cache->fi, i);
-		mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
-	}
-
-out:
-	return;
-}
-
-static void
-mvsw_pr_kern_fib_cache_destroy(struct mvsw_pr_switch *sw,
-			       struct mvsw_pr_kern_fib_cache *fib_cache)
-{
-	__mvsw_pr_kern_fib_cache_destruct(sw, fib_cache);
 	rhashtable_remove_fast(&sw->router->kern_fib_cache_ht,
 			       &fib_cache->ht_node,
 			       __mvsw_pr_kern_fib_cache_ht_params);
 	kfree(fib_cache);
 }
 
-static void
-mvsw_pr_kern_fib_cache_destroy_ht(struct mvsw_pr_switch *sw)
-{
-	struct mvsw_pr_kern_fib_cache *fib_cache, *tfib_cache;
-	struct rhashtable_iter iter;
-
-	tfib_cache = NULL;
-	rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
-	rhashtable_walk_start(&iter);
-	while (1) {
-		fib_cache = rhashtable_walk_next(&iter);
-		if (tfib_cache) {
-			rhashtable_remove_fast(&sw->router->kern_fib_cache_ht,
-					       &tfib_cache->ht_node,
-					    __mvsw_pr_kern_fib_cache_ht_params);
-			kfree(tfib_cache);
-			tfib_cache = NULL;
-		}
-
-		if (!fib_cache)
-			break;
-
-		if (IS_ERR(fib_cache))
-			continue;
-
-		__mvsw_pr_kern_fib_cache_destruct(sw, fib_cache);
-		tfib_cache = fib_cache;
-	}
-	rhashtable_walk_stop(&iter);
-	rhashtable_walk_exit(&iter);
-}
-
+/* Pass also grp_key, because we may implement logic to     *
+ * differ fib_nh's and created nh_neighs.                   *
+ * Operations on fi (offload, etc) must be wrapped in utils *
+ */
 static struct mvsw_pr_kern_fib_cache *
-mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
-			      struct mvsw_pr_fib_key *key,
-			      struct fib_info *fi)
+__mvsw_pr_kern_fib_cache_create(struct prestera_switch *sw,
+				struct mvsw_pr_kern_fib_cache_key *key,
+				struct prestera_nexthop_group_key *grp_key,
+				struct fib_info *fi)
 {
 	struct mvsw_pr_kern_fib_cache *fib_cache;
-	struct mvsw_pr_kern_neigh_cache *n_cache;
-	struct mvsw_pr_nh_neigh_key nh_key;
-	struct fib_nh *fib_nh;
-	int err, i, nhs;
+	struct prestera_kern_neigh_cache *n_cache;
+	int err, i;
 
 	fib_cache = kzalloc(sizeof(*fib_cache), GFP_KERNEL);
 	if (!fib_cache)
@@ -715,17 +743,14 @@ mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
 	if (err)
 		goto err_ht_insert;
 
-	if (!mvsw_pr_fi_is_nh(fi))
+	if (!grp_key)
 		goto out;
 
-	nhs = fib_info_num_path(fi);
-	for (i = 0; i < nhs; i++) {
-		fib_nh = fib_info_nh(fi, i);
-		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_nh, &nh_key);
-		if (err)
-			continue;
+	for (i = 0; i < PRESTERA_NHGR_SIZE_MAX; i++) {
+		if (!mvsw_pr_nh_neigh_key_is_valid(&grp_key->neigh[i]))
+			break;
 
-		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &nh_key);
+		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &grp_key->neigh[i]);
 		if (!n_cache)
 			continue;
 
@@ -736,8 +761,6 @@ mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
 	}
 
 out:
-	mvsw_pr_kern_fib_cache_offload_set(sw, fib_cache);
-
 	return fib_cache;
 
 err_ht_insert:
@@ -747,220 +770,518 @@ mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static int mvsw_pr_util_neigh2nh_neigh_key(struct mvsw_pr_switch *sw,
-					   struct neighbour *n,
-					   struct mvsw_pr_nh_neigh_key *key)
+static struct mvsw_pr_kern_fib_cache *
+mvsw_pr_kern_fib_cache_create(struct prestera_switch *sw,
+			      struct mvsw_pr_kern_fib_cache_key *fc_key,
+			      struct fib_info *fi)
 {
-	memset(key, 0, sizeof(*key));
-	key->addr.u.ipv4 = *(__be32 *)n->primary_key;
-	key->rif = mvsw_pr_rif_find(sw, n->dev);
-	if (!key->rif)
-		return -ENOENT;
+	struct mvsw_pr_kern_fib_cache *fc;
+	struct prestera_nexthop_group_key grp_key;
+	int nh_cnt;
 
-	return 0;
+	switch (fi->fib_type) {
+	case RTN_UNICAST:
+		nh_cnt = mvsw_pr_util_fi2nh_gr_key(sw, fi,
+						   PRESTERA_NHGR_SIZE_MAX,
+						   &grp_key);
+		fc = __mvsw_pr_kern_fib_cache_create(sw, fc_key,
+						     nh_cnt ? &grp_key : NULL,
+						     fi);
+		if (!fc)
+			return NULL;
+
+		fc->lpm_info.fib_type = nh_cnt ?
+					MVSW_PR_FIB_TYPE_UC_NH :
+					MVSW_PR_FIB_TYPE_TRAP;
+		fc->lpm_info.nh_grp_key = grp_key;
+		fc->allow_oflag = !!(nh_cnt || mvsw_pr_fi_is_hw_direct(sw, fi));
+		break;
+	/* Unsupported. Leave it for kernel: */
+	case RTN_BROADCAST:
+	case RTN_MULTICAST:
+	/* Routes we must trap by design: */
+	case RTN_LOCAL:
+	case RTN_UNREACHABLE:
+	case RTN_PROHIBIT:
+		fc = __mvsw_pr_kern_fib_cache_create(sw, fc_key, NULL, fi);
+		if (!fc)
+			return NULL;
+
+		fc->lpm_info.fib_type = MVSW_PR_FIB_TYPE_TRAP;
+		break;
+	case RTN_BLACKHOLE:
+		fc = __mvsw_pr_kern_fib_cache_create(sw, fc_key, NULL, fi);
+		if (!fc)
+			return NULL;
+
+		fc->lpm_info.fib_type = MVSW_PR_FIB_TYPE_DROP;
+		break;
+	default:
+		MVSW_LOG_ERROR("Unsupported fib_type");
+		return NULL;
+	}
+
+	mvsw_pr_util_fib_cache_key2fib_key(fc_key,
+					   &fc->lpm_info.fib_key);
+
+	return fc;
 }
 
-static void __mvsw_pr_neigh2nh_neigh_update(struct mvsw_pr_switch *sw,
-					    struct neighbour *n)
+static void
+__mvsw_pr_k_arb_fib_offload_set(struct prestera_switch *sw,
+				struct mvsw_pr_kern_fib_cache *fibc,
+				struct prestera_kern_neigh_cache *nc,
+				bool offloaded)
 {
-	struct mvsw_pr_nh_neigh_key nh_neigh_key;
-	struct mvsw_pr_nh_neigh *nh_neigh;
-	struct mvsw_pr_neigh_info new_info;
-	struct mvsw_pr_kern_neigh_cache *n_cache;
-	bool offloaded;
-	int err;
+	int i, nhs;
+	struct fib_nh *fib_nh;
 
-	err = mvsw_pr_util_neigh2nh_neigh_key(sw, n, &nh_neigh_key);
-	if (err)
+	nhs = fib_info_num_path(fibc->fi);
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fibc->fi, i);
+		if (!nc) {
+			mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
+			continue;
+		}
+
+		if (mvsw_pr_util_is_fib_nh_equal2nh_neigh_key(sw,
+							      fib_nh,
+							      &nc->key)) {
+			mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
+			break;
+		}
+	}
+}
+
+static void
+__mvsw_pr_k_arb_n_offload_set(struct prestera_switch *sw,
+			      struct prestera_kern_neigh_cache *nc,
+			      bool offloaded)
+{
+	struct neighbour *n;
+
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+
+	if (!n)
 		return;
 
-	nh_neigh = mvsw_pr_nh_neigh_find(sw, &nh_neigh_key);
-	if (!nh_neigh)
+	mvsw_pr_util_kern_set_neigh_offload(n, offloaded);
+	neigh_release(n);
+}
+
+static void
+__mvsw_pr_k_arb_n_lpm_set(struct prestera_switch *sw,
+			  struct prestera_kern_neigh_cache *n_cache,
+			  bool enabled)
+{
+	struct prestera_fib_key fib_key;
+	struct mvsw_pr_fib_node *fib_node;
+	struct prestera_nexthop_group_key nh_grp_key;
+
+	memset(&fib_key, 0, sizeof(fib_key));
+	fib_key.addr = n_cache->key.addr;
+	fib_key.prefix_len = 32;
+	fib_key.tb_id = n_cache->key.rif->vr->tb_id;
+	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
+	if (!enabled && fib_node) {
+		if (mvsw_pr_fib_node_util_is_neighbour(fib_node))
+			mvsw_pr_fib_node_destroy(sw, fib_node);
+		return;
+	}
+
+	if (enabled && !fib_node) {
+		memset(&nh_grp_key, 0, sizeof(nh_grp_key));
+		nh_grp_key.neigh[0] = n_cache->key;
+		fib_node = mvsw_pr_fib_node_create(sw, &fib_key,
+						   MVSW_PR_FIB_TYPE_UC_NH,
+						   &nh_grp_key);
+		if (!fib_node)
+			MVSW_LOG_ERROR("%s failed ip=%pI4n",
+				       "mvsw_pr_fib_node_create",
+				       &fib_key.addr.u.ipv4);
 		return;
+	}
+}
+
+static void
+__mvsw_pr_k_arb_nc_kern_fib_fetch(struct prestera_switch *sw,
+				  struct prestera_kern_neigh_cache *nc)
+{
+	if (mvsw_pr_util_kern_n_is_reachable(nc->key.rif->vr->tb_id,
+					     &nc->key.addr,
+					     nc->key.rif->dev))
+		nc->reachable = true;
+	else
+		nc->reachable = false;
+}
+
+/* Kernel neighbour -> neigh_cache info */
+static void
+__mvsw_pr_k_arb_nc_kern_n_fetch(struct prestera_switch *sw,
+				struct prestera_kern_neigh_cache *nc)
+{
+	struct neighbour *n;
+	int err;
+
+	memset(&nc->nh_neigh_info, 0, sizeof(nc->nh_neigh_info));
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+	if (!n)
+		goto out;
 
-	memset(&new_info, 0, sizeof(new_info));
 	read_lock_bh(&n->lock);
 	if (n->nud_state & NUD_VALID && !n->dead) {
-		memcpy(&new_info.ha[0], &n->ha[0], ETH_ALEN);
-		err = mvsw_pr_neigh_iface_init(sw, &new_info.iface, n);
+		err = mvsw_pr_neigh_iface_init(sw, &nc->nh_neigh_info.iface, n);
 		if (err) {
 			MVSW_LOG_ERROR("Cannot initialize iface for %pI4n %pM",
 				       n->primary_key, &n->ha[0]);
-			new_info.connected = false;
-		} else {
-			new_info.connected = true;
+			goto n_read_out;
 		}
-	} else {
-		new_info.connected = false;
+
+		memcpy(&nc->nh_neigh_info.ha[0], &n->ha[0], ETH_ALEN);
+		nc->nh_neigh_info.connected = true;
 	}
+n_read_out:
 	read_unlock_bh(&n->lock);
+out:
+	nc->in_kernel = nc->nh_neigh_info.connected;
+	if (n)
+		neigh_release(n);
+}
+
+/* neigh_cache info -> lpm update */
+static void
+__mvsw_pr_k_arb_nc_apply(struct prestera_switch *sw,
+			 struct prestera_kern_neigh_cache *nc)
+{
+	struct prestera_nh_neigh *nh_neigh;
+	struct mvsw_pr_kern_neigh_cache_head *nhead;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_port *port;
+	u32 port_hw_id, port_dev_id;
+	int err;
+
+	__mvsw_pr_k_arb_n_lpm_set(sw, nc,
+				  nc->reachable && nc->in_kernel);
+	__mvsw_pr_k_arb_n_offload_set(sw, nc,
+				      nc->reachable && nc->in_kernel);
+
+	/* update NAT port on neighbour change */
+	port_hw_id = nc->key.rif->iface.dev_port.port_num;
+	port_dev_id = nc->key.rif->iface.dev_port.hw_dev_num;
+	nat_port = prestera_acl_nat_port_get(sw->acl, port_hw_id,
+					     port_dev_id);
+	if (!nat_port)
+		goto skip_nat_port_update;
+
+	port = prestera_acl_nat_port_to_port(nat_port);
+	prestera_acl_nat_port_put(nat_port);
+
+	err = prestera_hw_nat_port_neigh_update(port,
+						nc->nh_neigh_info.ha);
+	if (err)
+		/* do not fail others, just print an error */
+		MVSW_LOG_ERROR("Update NAT neigh fail [%pI4n, %pM]",
+			       &nc->key.addr.u.ipv4,
+			       nc->nh_neigh_info.ha);
+
+skip_nat_port_update:
+	nh_neigh = prestera_nh_neigh_find(sw, &nc->key);
+	if (!nh_neigh)
+		goto out;
 
-	offloaded = new_info.connected;
 	/* Do hw update only if something changed to prevent nh flap */
-	if (memcmp(&new_info, &nh_neigh->info, sizeof(new_info))) {
-		memcpy(&nh_neigh->info, &new_info, sizeof(new_info));
+	if (memcmp(&nc->nh_neigh_info, &nh_neigh->info,
+		   sizeof(nh_neigh->info))) {
+		memcpy(&nh_neigh->info, &nc->nh_neigh_info,
+		       sizeof(nh_neigh->info));
 		err = mvsw_pr_nh_neigh_set(sw, nh_neigh);
 		if (err) {
-			offloaded = false;
 			MVSW_LOG_ERROR("%s failed with err=%d ip=%pI4n mac=%pM",
 				       "mvsw_pr_nh_neigh_set", err,
 				       &nh_neigh->key.addr.u.ipv4,
 				       &nh_neigh->info.ha[0]);
+			goto out;
 		}
 	}
 
-	mvsw_pr_util_kern_set_neigh_offload(n, offloaded);
-	n_cache = mvsw_pr_kern_neigh_cache_find(sw, &nh_neigh_key);
-	if (!n_cache) {
-		MVSW_LOG_ERROR("Cannot get neigh cache for %pI4n %pM",
-			       n->primary_key, &n->ha[0]);
-	} else {
-		n_cache->offloaded = offloaded;
-		mvsw_pr_kern_neigh_cache_offload_set(sw, n_cache);
+out:
+	list_for_each_entry(nhead, &nc->kern_fib_cache_list, head) {
+		__mvsw_pr_k_arb_fib_offload_set(sw, nhead->this, nc,
+						nc->in_kernel &&
+						nhead->this->reachable &&
+						nhead->this->allow_oflag);
 	}
 }
 
-static void __mvsw_pr_neigh2nh_neigh_update_all(struct mvsw_pr_switch *sw)
+static void __mvsw_pr_k_arb_hw_state_upd(struct prestera_switch *sw,
+					 struct prestera_kern_neigh_cache *nc)
 {
-	struct mvsw_pr_nh_neigh *nh_neigh;
-	struct rhashtable_iter iter;
+	bool hw_active;
+	struct prestera_nh_neigh *nh_neigh;
 	struct neighbour *n;
-	struct mvsw_pr_nh_neigh_key *nkey;
 
-	rhashtable_walk_enter(&sw->router->nh_neigh_ht, &iter);
-	rhashtable_walk_start(&iter);
-	while ((nh_neigh = rhashtable_walk_next(&iter))) {
-		if (IS_ERR(nh_neigh))
-			continue;
+	nh_neigh = prestera_nh_neigh_find(sw, &nc->key);
+	if (!nh_neigh) {
+		MVSW_LOG_ERROR("Cannot find nh_neigh for cached %pI4n",
+			       &nc->key.addr.u.ipv4);
+		return;
+	}
+
+	hw_active = mvsw_pr_nh_neigh_util_hw_state(sw, nh_neigh);
+
+#ifdef MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH
+	if (!hw_active && nc->in_kernel)
+		goto out;
+#else /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
+	if (!hw_active)
+		goto out;
+#endif /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
 
-		nkey = &nh_neigh->key;
-		n = neigh_lookup(&arp_tbl, &nkey->addr.u.ipv4, nkey->rif->dev);
-		if (n) {
-			__mvsw_pr_neigh2nh_neigh_update(sw, n);
-			neigh_release(n);
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+	if (!n) {
+		n = neigh_create(&arp_tbl, &nc->key.addr.u.ipv4,
+				 nc->key.rif->dev);
+		if (IS_ERR(n)) {
+			n = NULL;
+			MVSW_LOG_ERROR("Cannot create neighbour %pI4n",
+				       &nc->key.addr.u.ipv4);
 		}
 	}
-	rhashtable_walk_stop(&iter);
-	rhashtable_walk_exit(&iter);
+
+	if (n) {
+		neigh_event_send(n, NULL);
+		neigh_release(n);
+	}
+
+out:
+	return;
 }
 
-/* I dont think that optimiztaion of this
- * function withone neighbour will make sense...
- * Just select direction nh_neigh -> kernel or vice versa
- */
-static void
-__mvsw_pr_neigh_hwstate_update_all(struct mvsw_pr_switch *sw)
+static int __mvsw_pr_k_arb_f_lpm_set(struct prestera_switch *sw,
+				     struct mvsw_pr_kern_fib_cache *fc,
+				     bool enabled)
+{
+	struct mvsw_pr_fib_node *fib_node;
+
+	fib_node = mvsw_pr_fib_node_find(sw, &fc->lpm_info.fib_key);
+	if (fib_node)
+		mvsw_pr_fib_node_destroy(sw, fib_node);
+
+	if (!enabled)
+		return 0;
+
+	fib_node = mvsw_pr_fib_node_create(sw, &fc->lpm_info.fib_key,
+					   fc->lpm_info.fib_type,
+					   &fc->lpm_info.nh_grp_key);
+
+	if (!fib_node) {
+		MVSW_LOG_ERROR("fib_node=NULL %pI4n/%d kern_tb_id = %d",
+			       &fc->key.addr.u.ipv4, fc->key.prefix_len,
+			       fc->key.kern_tb_id);
+		return -ENOENT;
+	}
+
+	return 0;
+}
+
+static int __mvsw_pr_k_arb_fc_apply(struct prestera_switch *sw,
+				    struct mvsw_pr_kern_fib_cache *fc)
+{
+	int err;
+
+	/* 1. Update lpm */
+	err = __mvsw_pr_k_arb_f_lpm_set(sw, fc, fc->reachable);
+	if (err)
+		return err;
+
+	/* UC_NH offload flag is managed by neighbours cache */
+	if (fc->lpm_info.fib_type != MVSW_PR_FIB_TYPE_UC_NH || !fc->reachable)
+		__mvsw_pr_k_arb_fib_offload_set(sw, fc, NULL, fc->reachable &&
+						fc->allow_oflag);
+
+	return 0;
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_util_fib_overlaps(struct prestera_switch *sw,
+				  struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct mvsw_pr_kern_fib_cache *rfc;
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+
+	/* TODO: parse kernel rules */
+	rfc = NULL;
+	if (fc->key.kern_tb_id == RT_TABLE_LOCAL) {
+		memcpy(&fc_key, &fc->key, sizeof(fc_key));
+		fc_key.kern_tb_id = RT_TABLE_MAIN;
+		rfc = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	}
+
+	return rfc;
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_util_fib_overlapped(struct prestera_switch *sw,
+				    struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct mvsw_pr_kern_fib_cache *rfc;
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+
+	/* TODO: parse kernel rules */
+	rfc = NULL;
+	if (fc->key.kern_tb_id == RT_TABLE_MAIN) {
+		memcpy(&fc_key, &fc->key, sizeof(fc_key));
+		fc_key.kern_tb_id = RT_TABLE_LOCAL;
+		rfc = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	}
+
+	return rfc;
+}
+
+static void __mvsw_pr_k_arb_abort_neigh(struct prestera_switch *sw)
 {
-	struct mvsw_pr_nh_neigh *nh_neigh;
+	struct prestera_kern_neigh_cache *n_cache;
 	struct rhashtable_iter iter;
-	struct neighbour *n;
-	struct mvsw_pr_nh_neigh_key *nkey;
-	bool n_resolved, hw_active;
 
-	rhashtable_walk_enter(&sw->router->nh_neigh_ht, &iter);
-	rhashtable_walk_start(&iter);
-	while ((nh_neigh = rhashtable_walk_next(&iter))) {
-		if (IS_ERR(nh_neigh))
-			continue;
+	while (1) {
+		rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+		rhashtable_walk_start(&iter);
+
+		n_cache = rhashtable_walk_next(&iter);
+
+		rhashtable_walk_stop(&iter);
+		rhashtable_walk_exit(&iter);
 
-		hw_active = mvsw_pr_nh_neigh_util_hw_state(sw, nh_neigh);
-		nkey = &nh_neigh->key;
-		n = neigh_lookup(&arp_tbl, &nkey->addr.u.ipv4, nkey->rif->dev);
-		if (n) {
-			read_lock_bh(&n->lock);
-			if (n->dead || !(n->nud_state & NUD_VALID))
-				n_resolved = false;
-			else
-				n_resolved = true;
-			read_unlock_bh(&n->lock);
-		} else {
-			n_resolved = false;
+		if (!n_cache) {
+			break;
+		} else if (IS_ERR(n_cache)) {
+			continue;
+		} else if (n_cache) {
+			__mvsw_pr_k_arb_n_offload_set(sw, n_cache, false);
+			n_cache->in_kernel = false;
+			/* No need to destroy lpm.
+			 * It will be aborted by destroy_ht
+			 */
+			__mvsw_pr_kern_neigh_cache_destroy(sw, n_cache);
 		}
+	}
+}
 
-#ifdef MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH
-		if (!hw_active && n_resolved)
-			goto next_nh_neigh;
-#else /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
-		if (!hw_active)
-			goto next_nh_neigh;
-#endif /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
+static void __mvsw_pr_k_arb_abort_fib(struct prestera_switch *sw)
+{
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+	struct rhashtable_iter iter;
 
-		if (!n) {
-			MVSW_LOG_INFO("Push active neighbour %pI4n to kernel",
-				      &nkey->addr.u.ipv4);
-			n = neigh_create(&arp_tbl, &nkey->addr.u.ipv4,
-					 nkey->rif->dev);
-			if (IS_ERR(n)) {
-				n = NULL;
-				MVSW_LOG_ERROR("Cannot create neighbour %pI4n",
-					       &nkey->addr.u.ipv4);
-
-				goto next_nh_neigh;
-			}
+	while (1) {
+		rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
+		rhashtable_walk_start(&iter);
+
+		fib_cache = rhashtable_walk_next(&iter);
+
+		rhashtable_walk_stop(&iter);
+		rhashtable_walk_exit(&iter);
+
+		if (!fib_cache) {
+			break;
+		} else if (IS_ERR(fib_cache)) {
+			continue;
+		} else if (fib_cache) {
+			__mvsw_pr_k_arb_fib_offload_set(sw, fib_cache, NULL,
+							false);
+			/* No need to destroy lpm.
+			 * It will be aborted by destroy_ht
+			 */
+			mvsw_pr_kern_fib_cache_destroy(sw, fib_cache);
 		}
+	}
+}
 
-		neigh_event_send(n, NULL);
+static void mvsw_pr_k_arb_abort(struct prestera_switch *sw)
+{
+	__mvsw_pr_k_arb_abort_fib(sw);
+	__mvsw_pr_k_arb_abort_neigh(sw);
+}
+
+/* Make necesssary things  with neighbour, if FDB upupdated
+ * Known useacase for this function:
+ *  if FDB entry (which tied on neigh) updated - we need to reaply it in HW
+ */
+void prestera_k_arb_fdb_evt(struct prestera_switch *sw, struct net_device *dev)
+{
+	struct net_device *upper_dev;
+	struct list_head *list_iter;
+	struct prestera_rif *rif;
+	struct prestera_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	rif = mvsw_pr_rif_find(sw, dev);
+	if (rif) {
+		/* TODO: seems to be a lot of places, where such iteration used.
+		 * Maybe, make sense to write macros.
+		 */
+		rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+		rhashtable_walk_start(&iter);
+		while (1) {
+			n_cache = rhashtable_walk_next(&iter);
+
+			if (!n_cache)
+				break;
+
+			if (IS_ERR(n_cache))
+				continue;
 
-next_nh_neigh:
-		if (n)
-			neigh_release(n);
+			if (n_cache->key.rif != rif)
+				continue;
+
+			rhashtable_walk_stop(&iter);
+			__mvsw_pr_k_arb_nc_kern_fib_fetch(sw, n_cache);
+			__mvsw_pr_k_arb_nc_apply(sw, n_cache);
+			rhashtable_walk_start(&iter);
+		}
+		rhashtable_walk_stop(&iter);
+		rhashtable_walk_exit(&iter);
 	}
-	rhashtable_walk_stop(&iter);
-	rhashtable_walk_exit(&iter);
+
+	netdev_for_each_upper_dev_rcu(dev, upper_dev, list_iter)
+		prestera_k_arb_fdb_evt(sw, upper_dev);
 }
 
-static void
-__mvsw_pr_sync_neigh_cache_kernel(struct mvsw_pr_switch *sw,
-				  struct mvsw_pr_kern_neigh_cache *n_cache)
+/* Propagate kernel event to hw */
+static void mvsw_pr_k_arb_n_evt(struct prestera_switch *sw,
+				struct neighbour *n)
 {
-	struct neighbour *n;
-	struct fib_result res;
-	struct fib_nh *fib_nh;
-	struct mvsw_pr_nh_neigh_key *key;
+	struct prestera_kern_neigh_cache *n_cache;
+	struct prestera_nh_neigh_key n_key;
+	int err;
 
-	key = &n_cache->key;
+	err = mvsw_pr_util_neigh2nh_neigh_key(sw, n, &n_key);
+	if (err)
+		return;
 
-	n_cache->in_kernel = false;
-	n_cache->lpm_added = false;
-	n = neigh_lookup(&arp_tbl, &key->addr.u.ipv4, key->rif->dev);
-	if (n) {
-		read_lock_bh(&n->lock);
-		if (!n->dead && (n->nud_state & NUD_VALID))
-			n_cache->in_kernel = true;
-		read_unlock_bh(&n->lock);
-	}
-
-	if (n_cache->in_kernel) {
-		if (!mvsw_pr_util_kern_get_route(&res, key->rif->vr->tb_id,
-						 &key->addr))
-			if (res.type == RTN_UNICAST &&
-			    mvsw_pr_fi_is_direct(res.fi)) {
-				fib_nh = fib_info_nh(res.fi, 0);
-				if (n->dev == fib_nh->fib_nh_dev)
-					n_cache->lpm_added = true;
-			}
+	n_cache = mvsw_pr_kern_neigh_cache_find(sw, &n_key);
+	if (!n_cache) {
+		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &n_key);
+		if (!n_cache)
+			return;
+		__mvsw_pr_k_arb_nc_kern_fib_fetch(sw, n_cache);
 	}
 
-	if (n)
-		neigh_release(n);
+	__mvsw_pr_k_arb_nc_kern_n_fetch(sw, n_cache);
+	__mvsw_pr_k_arb_nc_apply(sw, n_cache);
 
-	mvsw_pr_kern_neigh_cache_lpm_set(sw, n_cache);
+	mvsw_pr_kern_neigh_cache_put(sw, n_cache);
 }
 
-static void __mvsw_pr_sync_neigh_cache_kernel_all(struct mvsw_pr_switch *sw)
+/* Propagate hw state to kernel */
+static void mvsw_pr_k_arb_hw_evt(struct prestera_switch *sw)
 {
-	struct mvsw_pr_kern_neigh_cache *n_cache, *tn_cache;
+	struct prestera_kern_neigh_cache *n_cache;
 	struct rhashtable_iter iter;
 
-	tn_cache = NULL;
 	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
 	rhashtable_walk_start(&iter);
 	while (1) {
 		n_cache = rhashtable_walk_next(&iter);
-		if (tn_cache) {
-			mvsw_pr_kern_neigh_cache_put(sw, tn_cache);
-			tn_cache = NULL;
-		}
 
 		if (!n_cache)
 			break;
@@ -968,70 +1289,224 @@ static void __mvsw_pr_sync_neigh_cache_kernel_all(struct mvsw_pr_switch *sw)
 		if (IS_ERR(n_cache))
 			continue;
 
-		__mvsw_pr_sync_neigh_cache_kernel(sw, n_cache);
-		tn_cache = n_cache;
+		rhashtable_walk_stop(&iter);
+		__mvsw_pr_k_arb_hw_state_upd(sw, n_cache);
+		rhashtable_walk_start(&iter);
 	}
 	rhashtable_walk_stop(&iter);
 	rhashtable_walk_exit(&iter);
 }
 
-/* Propagate kernel event to hw */
-static void mvsw_pr_neigh_arbiter_n_evt(struct mvsw_pr_switch *sw,
-					struct neighbour *n)
+static void __mvsw_pr_k_arb_fib_evt2nc(struct prestera_switch *sw)
 {
-	struct mvsw_pr_kern_neigh_cache *n_cache;
-	struct mvsw_pr_nh_neigh_key n_key;
+	struct prestera_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		n_cache = rhashtable_walk_next(&iter);
+
+		if (!n_cache)
+			break;
+
+		if (IS_ERR(n_cache))
+			continue;
+
+		rhashtable_walk_stop(&iter);
+		__mvsw_pr_k_arb_nc_kern_fib_fetch(sw, n_cache);
+		__mvsw_pr_k_arb_nc_apply(sw, n_cache);
+		rhashtable_walk_start(&iter);
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+}
+
+/* Propagate fib changes to hw neighs */
+static int
+mvsw_pr_k_arb_fib_evt(struct prestera_switch *sw,
+		      bool replace, /* replace or del */
+		      struct fib_entry_notifier_info *fen_info)
+{
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+	struct mvsw_pr_kern_fib_cache *tfib_cache, *bfib_cache;
 	int err;
 
-	err = mvsw_pr_util_neigh2nh_neigh_key(sw, n, &n_key);
+	mvsw_pr_util_fen_info2fib_cache_key(fen_info, &fc_key);
+	fib_cache = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	if (fib_cache) {
+		fib_cache->reachable = false;
+		err = __mvsw_pr_k_arb_fc_apply(sw, fib_cache);
+		if (err)
+			MVSW_LOG_ERROR("Applying destroyed fib_cache failed");
+
+		bfib_cache = __mvsw_pr_k_arb_util_fib_overlaps(sw, fib_cache);
+		tfib_cache = __mvsw_pr_k_arb_util_fib_overlapped(sw, fib_cache);
+		if (!tfib_cache && bfib_cache) {
+			bfib_cache->reachable = true;
+			err = __mvsw_pr_k_arb_fc_apply(sw, bfib_cache);
+			if (err) {
+				MVSW_LOG_ERROR("Applying fib_cache btm failed");
+				return -ENOENT;
+			}
+		}
+
+		mvsw_pr_kern_fib_cache_destroy(sw, fib_cache);
+	}
+
+	if (replace) {
+		fib_cache = mvsw_pr_kern_fib_cache_create(sw, &fc_key,
+							  fen_info->fi);
+		if (!fib_cache) {
+			MVSW_LOG_ERROR("fib_cache == NULL");
+			return -ENOENT;
+		}
+
+		bfib_cache = __mvsw_pr_k_arb_util_fib_overlaps(sw, fib_cache);
+		tfib_cache = __mvsw_pr_k_arb_util_fib_overlapped(sw, fib_cache);
+		if (!tfib_cache)
+			fib_cache->reachable = true;
+
+		if (bfib_cache) {
+			bfib_cache->reachable = false;
+			err = __mvsw_pr_k_arb_fc_apply(sw, bfib_cache);
+			if (err)
+				MVSW_LOG_ERROR("Applying fib_cache btm failed");
+		}
+
+		err = __mvsw_pr_k_arb_fc_apply(sw, fib_cache);
+		if (err) {
+			MVSW_LOG_ERROR("Applying fib_cache failed");
+			return -ENOENT;
+		}
+	}
+
+	/* Update all neighs to resolve overlapped and apply related */
+	__mvsw_pr_k_arb_fib_evt2nc(sw);
+
+	return 0;
+}
+
+static void mvsw_pr_k_arb_nh_evt(struct prestera_switch *sw,
+				 bool replace,
+				 struct fib_nh *fib_nh)
+{
+	struct prestera_kern_neigh_cache *nc;
+	struct prestera_nh_neigh_key nkey;
+	int err;
+
+	err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_nh, &nkey);
 	if (err)
 		return;
 
-	n_cache = mvsw_pr_kern_neigh_cache_get(sw, &n_key);
-	if (!n_cache)
+	nc = mvsw_pr_kern_neigh_cache_find(sw, &nkey);
+	if (!nc)
 		return;
 
-	__mvsw_pr_sync_neigh_cache_kernel(sw, n_cache);
-	mvsw_pr_kern_neigh_cache_put(sw, n_cache);
-
-	__mvsw_pr_neigh2nh_neigh_update(sw, n);
+	/* NOTE: we also get from kernel n_evt after this one
+	 * mvsw_pr_k_arb_nh_evt is used only to speedup nh update after
+	 * linkdown on ECMP routes
+	 */
+	nc->nh_neigh_info.connected = false;
+	__mvsw_pr_k_arb_nc_apply(sw, nc);
 }
 
-/* Propagate hw state to kernel */
-static void mvsw_pr_neigh_arbiter_hw_evt(struct mvsw_pr_switch *sw)
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_fc_rebuild(struct prestera_switch *sw,
+			   struct mvsw_pr_kern_fib_cache *fc)
 {
-	__mvsw_pr_neigh_hwstate_update_all(sw);
+	struct fib_info *fi;
+	struct mvsw_pr_kern_fib_cache_key key;
+	struct mvsw_pr_kern_fib_cache *new_fc;
+	bool reachable;
+
+	memcpy(&key, &fc->key, sizeof(key));
+	fi = fc->fi;
+	fib_info_hold(fi);
+	reachable = fc->reachable;
+
+	fc->reachable = false;
+	__mvsw_pr_k_arb_fc_apply(sw, fc);
+	mvsw_pr_kern_fib_cache_destroy(sw, fc);
+
+	new_fc = mvsw_pr_kern_fib_cache_create(sw, &key, fi);
+	fib_info_put(fi);
+	if (!new_fc)
+		return NULL;
+
+	new_fc->reachable = reachable;
+	__mvsw_pr_k_arb_fc_apply(sw, new_fc);
+
+	return new_fc;
 }
 
-/* Propagate fib changes to hw neighs */
-static void
-mvsw_pr_neigh_arbiter_fib_evt(struct mvsw_pr_switch *sw,
-			      bool replace, /* replace or del */
-			      struct mvsw_pr_fib_key *fib_key,
-			      struct fib_info *fi)
-{
-	struct mvsw_pr_kern_fib_cache *fib_cache;
+static void mvsw_pr_k_arb_rif_evt(struct prestera_switch *sw,
+				  struct prestera_rif *rif)
+{
+	struct mvsw_pr_kern_fib_cache *fc, *tfc, *nfc;
+	struct prestera_kern_neigh_cache *nc, *tnc;
+	struct rhashtable_iter iter;
+
+	/* Walk every fc, which related to rif and set to trap */
+	tfc = NULL;
+	rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		fc = rhashtable_walk_next(&iter);
+		if (tfc && mvsw_pr_util_fi_is_point2dev(tfc->fi, rif->dev)) {
+			rhashtable_walk_stop(&iter);
+			nfc = __mvsw_pr_k_arb_fc_rebuild(sw, tfc);
+			rhashtable_walk_start(&iter);
+			/* TODO: way to crash ? */
+			if (WARN_ON(!nfc))
+				MVSW_LOG_ERROR("Rebuild failed %pI4n/%d",
+					       &tfc->key.addr.u.ipv4,
+					       tfc->key.prefix_len);
+		}
+
+		if (!fc)
+			break;
+
+		tfc = NULL;
+		if (IS_ERR(fc))
+			continue;
+
+		tfc = fc;
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+
+	/* Destroy every nc, which related to rif */
+	tnc = NULL;
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		nc = rhashtable_walk_next(&iter);
+		if (tnc && tnc->key.rif == rif) {
+			tnc->in_kernel = false;
+			rhashtable_walk_stop(&iter);
+			__mvsw_pr_k_arb_nc_apply(sw, tnc);
+			WARN_ON(mvsw_pr_kern_neigh_cache_put(sw, tnc));
+			rhashtable_walk_start(&iter);
+		}
+
+		if (!nc)
+			break;
 
-	fib_cache = mvsw_pr_kern_fib_cache_find(sw, fib_key);
-		if (fib_cache)
-			mvsw_pr_kern_fib_cache_destroy(sw, fib_cache);
+		tnc = NULL;
+		if (IS_ERR(nc))
+			continue;
 
-	/* TODO: add util function IS_NH / IS_DIR */
-	if (replace) {
-		fib_cache = mvsw_pr_kern_fib_cache_create(sw, fib_key, fi);
-		if (!fib_cache)
-			MVSW_LOG_ERROR("%s failed for %pI4n",
-				       "mvsw_pr_kern_fib_cache_create",
-				       &fib_key->addr.u.ipv4);
+		tnc = nc;
 	}
-
-	__mvsw_pr_sync_neigh_cache_kernel_all(sw);
-	__mvsw_pr_neigh2nh_neigh_update_all(sw);
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
 }
 
 struct mvsw_pr_netevent_work {
 	struct work_struct work;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct neighbour *n;
 };
 
@@ -1039,7 +1514,7 @@ static void mvsw_pr_router_neigh_event_work(struct work_struct *work)
 {
 	struct mvsw_pr_netevent_work *net_work =
 		container_of(work, struct mvsw_pr_netevent_work, work);
-	struct mvsw_pr_switch *sw = net_work->sw;
+	struct prestera_switch *sw = net_work->sw;
 	struct neighbour *n = net_work->n;
 
 	/* neigh - its not hw related object. It stored only in kernel. So... */
@@ -1048,7 +1523,7 @@ static void mvsw_pr_router_neigh_event_work(struct work_struct *work)
 	if (sw->router->aborted)
 		goto out;
 
-	mvsw_pr_neigh_arbiter_n_evt(sw, n);
+	mvsw_pr_k_arb_n_evt(sw, n);
 
 out:
 	neigh_release(n);
@@ -1060,11 +1535,11 @@ static int mvsw_pr_router_netevent_event(struct notifier_block *nb,
 					 unsigned long event, void *ptr)
 {
 	struct mvsw_pr_netevent_work *net_work;
-	struct mvsw_pr_router *router;
-	struct mvsw_pr_rif *rif;
+	struct prestera_router *router;
+	struct prestera_rif *rif;
 	struct neighbour *n = ptr;
 
-	router = container_of(nb, struct mvsw_pr_router, netevent_nb);
+	router = container_of(nb, struct prestera_router, netevent_nb);
 
 	switch (event) {
 	case NETEVENT_NEIGH_UPDATE:
@@ -1090,23 +1565,23 @@ static int mvsw_pr_router_netevent_event(struct notifier_block *nb,
 }
 
 static void
-mvsw_pr_router_neighs_update_interval_init(struct mvsw_pr_router *router)
+mvsw_pr_router_neighs_update_interval_init(struct prestera_router *router)
 {
 	router->neighs_update.interval = MVSW_PR_NH_PROBE_INTERVAL;
 }
 
 static void mvsw_pr_router_update_neighs_work(struct work_struct *work)
 {
-	struct mvsw_pr_router *router;
+	struct prestera_router *router;
 
-	router = container_of(work, struct mvsw_pr_router,
+	router = container_of(work, struct prestera_router,
 			      neighs_update.dw.work);
 	rtnl_lock();
 
 	if (router->aborted)
 		goto out;
 
-	mvsw_pr_neigh_arbiter_hw_evt(router->sw);
+	mvsw_pr_k_arb_hw_evt(router->sw);
 
 out:
 	rtnl_unlock();
@@ -1115,7 +1590,7 @@ static void mvsw_pr_router_update_neighs_work(struct work_struct *work)
 			   msecs_to_jiffies(router->neighs_update.interval));
 }
 
-static int mvsw_pr_neigh_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_neigh_init(struct prestera_switch *sw)
 {
 	int err;
 
@@ -1132,17 +1607,17 @@ static int mvsw_pr_neigh_init(struct mvsw_pr_switch *sw)
 	return 0;
 }
 
-static void mvsw_pr_neigh_fini(struct mvsw_pr_switch *sw)
+static void mvsw_pr_neigh_fini(struct prestera_switch *sw)
 {
 	cancel_delayed_work_sync(&sw->router->neighs_update.dw);
 	rhashtable_destroy(&sw->router->nh_neigh_ht);
 }
 
-static struct mvsw_pr_rif*
-mvsw_pr_rif_find(const struct mvsw_pr_switch *sw,
+static struct prestera_rif*
+mvsw_pr_rif_find(const struct prestera_switch *sw,
 		 const struct net_device *dev)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	list_for_each_entry(rif, &sw->router->rif_list, router_node) {
 		if (rif->dev == dev)
@@ -1152,24 +1627,24 @@ mvsw_pr_rif_find(const struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-bool mvsw_pr_rif_exists(const struct mvsw_pr_switch *sw,
-			const struct net_device *dev)
+bool prestera_rif_exists(const struct prestera_switch *sw,
+			 const struct net_device *dev)
 {
 	return !!mvsw_pr_rif_find(sw, dev);
 }
 
 static int
-mvsw_pr_port_vlan_router_join(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan,
+mvsw_pr_port_vlan_router_join(struct prestera_port_vlan *mvsw_pr_port_vlan,
 			      struct net_device *dev,
 			      struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *mvsw_pr_port = mvsw_pr_port_vlan->mvsw_pr_port;
-	struct mvsw_pr_switch *sw = mvsw_pr_port->sw;
+	struct prestera_port *port = mvsw_pr_port_vlan->mvsw_pr_port;
+	struct prestera_switch *sw = port->sw;
 
 	struct mvsw_pr_rif_params params = {
 		.dev = dev,
 	};
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	MVSW_LOG_ERROR("NOT IMPLEMENTED!!!");
 
@@ -1191,13 +1666,13 @@ mvsw_pr_port_vlan_router_join(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan,
 }
 
 static void
-mvsw_pr_port_vlan_router_leave(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan,
+mvsw_pr_port_vlan_router_leave(struct prestera_port_vlan *mvsw_pr_port_vlan,
 			       struct net_device *dev)
 
 {
-	struct mvsw_pr_port *mvsw_pr_port = mvsw_pr_port_vlan->mvsw_pr_port;
-	struct mvsw_pr_switch *sw = mvsw_pr_port->sw;
-	struct mvsw_pr_rif *rif;
+	struct prestera_port *port = mvsw_pr_port_vlan->mvsw_pr_port;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_rif *rif;
 
 	rif = mvsw_pr_rif_find(sw, dev);
 
@@ -1210,16 +1685,16 @@ mvsw_pr_port_vlan_router_leave(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan,
 }
 
 static int
-mvsw_pr_port_router_join(struct mvsw_pr_port *mvsw_pr_port,
+mvsw_pr_port_router_join(struct prestera_port *port,
 			 struct net_device *dev,
 			 struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_port->sw;
+	struct prestera_switch *sw = port->sw;
 
 	struct mvsw_pr_rif_params params = {
 		.dev = dev,
 	};
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	rif = mvsw_pr_rif_find(sw, dev);
 	if (!rif)
@@ -1238,41 +1713,41 @@ mvsw_pr_port_router_join(struct mvsw_pr_port *mvsw_pr_port,
 	return 0;
 }
 
-void mvsw_pr_port_router_leave(struct mvsw_pr_port *mvsw_pr_port)
+void prestera_port_router_leave(struct prestera_port *port)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	/* TODO:
 	 * - stp state set (BLOCKING)
 	 * - vid learning set (true)
 	 */
 
-	rif = mvsw_pr_rif_find(mvsw_pr_port->sw, mvsw_pr_port->net_dev);
+	rif = mvsw_pr_rif_find(port->sw, port->net_dev);
 	if (rif) {
 		rif->is_active = false;
 		mvsw_pr_rif_put(rif);
 	}
 }
 
-static int mvsw_pr_rif_fdb_op(struct mvsw_pr_rif *rif, const char *mac,
+static int mvsw_pr_rif_fdb_op(struct prestera_rif *rif, const char *mac,
 			      bool adding)
 {
 	if (adding)
-		mvsw_pr_macvlan_add(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
-				    rif->iface.vlan_id);
+		prestera_macvlan_add(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
+				     rif->iface.vlan_id);
 	else
-		mvsw_pr_macvlan_del(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
-				    rif->iface.vlan_id);
+		prestera_macvlan_del(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
+				     rif->iface.vlan_id);
 
 	return 0;
 }
 
-static int mvsw_pr_rif_macvlan_add(struct mvsw_pr_switch *sw,
+static int mvsw_pr_rif_macvlan_add(struct prestera_switch *sw,
 				   const struct net_device *macvlan_dev,
 				   struct netlink_ext_ack *extack)
 {
 	struct macvlan_dev *vlan = netdev_priv(macvlan_dev);
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 	int err;
 
 	rif = mvsw_pr_rif_find(sw, vlan->lowerdev);
@@ -1289,11 +1764,11 @@ static int mvsw_pr_rif_macvlan_add(struct mvsw_pr_switch *sw,
 	return err;
 }
 
-static void __mvsw_pr_rif_macvlan_del(struct mvsw_pr_switch *sw,
+static void __mvsw_pr_rif_macvlan_del(struct prestera_switch *sw,
 				      const struct net_device *macvlan_dev)
 {
 	struct macvlan_dev *vlan = netdev_priv(macvlan_dev);
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	rif = mvsw_pr_rif_find(sw, vlan->lowerdev);
 	if (!rif)
@@ -1302,13 +1777,13 @@ static void __mvsw_pr_rif_macvlan_del(struct mvsw_pr_switch *sw,
 	mvsw_pr_rif_fdb_op(rif, macvlan_dev->dev_addr,  false);
 }
 
-static void mvsw_pr_rif_macvlan_del(struct mvsw_pr_switch *sw,
+static void mvsw_pr_rif_macvlan_del(struct prestera_switch *sw,
 				    const struct net_device *macvlan_dev)
 {
 	__mvsw_pr_rif_macvlan_del(sw, macvlan_dev);
 }
 
-static int mvsw_pr_inetaddr_macvlan_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_macvlan_event(struct prestera_switch *sw,
 					  struct net_device *macvlan_dev,
 					  unsigned long event,
 					  struct netlink_ext_ack *extack)
@@ -1324,7 +1799,7 @@ static int mvsw_pr_inetaddr_macvlan_event(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-static int mvsw_pr_router_port_check_rif_addr(struct mvsw_pr_switch *sw,
+static int mvsw_pr_router_port_check_rif_addr(struct prestera_switch *sw,
 					      struct net_device *dev,
 					      const unsigned char *dev_addr,
 					      struct netlink_ext_ack *extack)
@@ -1346,7 +1821,7 @@ static int mvsw_pr_inetaddr_port_event(struct net_device *port_dev,
 				       unsigned long event,
 				       struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *mvsw_pr_port = netdev_priv(port_dev);
+	struct prestera_port *port = netdev_priv(port_dev);
 
 	MVSW_LOG_ERROR("dev=%s", port_dev->name);
 
@@ -1355,16 +1830,16 @@ static int mvsw_pr_inetaddr_port_event(struct net_device *port_dev,
 		if (netif_is_bridge_port(port_dev) ||
 		    netif_is_lag_port(port_dev) || netif_is_ovs_port(port_dev))
 			return 0;
-		return mvsw_pr_port_router_join(mvsw_pr_port, port_dev, extack);
+		return mvsw_pr_port_router_join(port, port_dev, extack);
 	case NETDEV_DOWN:
-		mvsw_pr_port_router_leave(mvsw_pr_port);
+		prestera_port_router_leave(port);
 		break;
 	}
 
 	return 0;
 }
 
-static int mvsw_pr_inetaddr_bridge_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_bridge_event(struct prestera_switch *sw,
 					 struct net_device *dev,
 					 unsigned long event,
 					 struct netlink_ext_ack *extack)
@@ -1372,7 +1847,7 @@ static int mvsw_pr_inetaddr_bridge_event(struct mvsw_pr_switch *sw,
 	struct mvsw_pr_rif_params params = {
 		.dev = dev,
 	};
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	switch (event) {
 	case NETDEV_UP:
@@ -1399,10 +1874,10 @@ static int mvsw_pr_inetaddr_port_vlan_event(struct net_device *l3_dev,
 					    unsigned long event, u16 vid,
 					    struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *mvsw_pr_port = netdev_priv(port_dev);
-	struct mvsw_pr_port_vlan *mvsw_pr_port_vlan;
+	struct prestera_port *port = netdev_priv(port_dev);
+	struct prestera_port_vlan *mvsw_pr_port_vlan;
 
-	mvsw_pr_port_vlan = mvsw_pr_port_vlan_find_by_vid(mvsw_pr_port, vid);
+	mvsw_pr_port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (WARN_ON(!mvsw_pr_port_vlan))
 		return -EINVAL;
 
@@ -1418,7 +1893,7 @@ static int mvsw_pr_inetaddr_port_vlan_event(struct net_device *l3_dev,
 	return 0;
 }
 
-static int mvsw_pr_inetaddr_vlan_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_vlan_event(struct prestera_switch *sw,
 				       struct net_device *vlan_dev,
 				       unsigned long event,
 				       struct netlink_ext_ack *extack)
@@ -1431,7 +1906,7 @@ static int mvsw_pr_inetaddr_vlan_event(struct mvsw_pr_switch *sw,
 	if (netif_is_bridge_port(vlan_dev))
 		return 0;
 
-	if (mvsw_pr_netdev_check(real_dev))
+	if (prestera_netdev_check(real_dev))
 		return mvsw_pr_inetaddr_port_vlan_event(vlan_dev, real_dev,
 							event, vid, extack);
 	else if (netif_is_bridge_master(real_dev) && br_vlan_enabled(real_dev))
@@ -1441,7 +1916,7 @@ static int mvsw_pr_inetaddr_vlan_event(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-static int mvsw_pr_inetaddr_lag_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_lag_event(struct prestera_switch *sw,
 				      struct net_device *lag_dev,
 				      unsigned long event,
 				      struct netlink_ext_ack *extack)
@@ -1449,7 +1924,7 @@ static int mvsw_pr_inetaddr_lag_event(struct mvsw_pr_switch *sw,
 	struct mvsw_pr_rif_params params = {
 		.dev = lag_dev,
 	};
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	MVSW_LOG_ERROR("lag_dev=%s", lag_dev->name);
 
@@ -1473,12 +1948,12 @@ static int mvsw_pr_inetaddr_lag_event(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-static int __mvsw_pr_inetaddr_event(struct mvsw_pr_switch *sw,
+static int __mvsw_pr_inetaddr_event(struct prestera_switch *sw,
 				    struct net_device *dev,
 				    unsigned long event,
 				    struct netlink_ext_ack *extack)
 {
-	if (mvsw_pr_netdev_check(dev))
+	if (prestera_netdev_check(dev))
 		return mvsw_pr_inetaddr_port_event(dev, event, extack);
 	else if (is_vlan_dev(dev))
 		return mvsw_pr_inetaddr_vlan_event(sw, dev, event, extack);
@@ -1493,7 +1968,7 @@ static int __mvsw_pr_inetaddr_event(struct mvsw_pr_switch *sw,
 }
 
 static bool
-mvsw_pr_rif_should_config(struct mvsw_pr_rif *rif, struct net_device *dev,
+mvsw_pr_rif_should_config(struct prestera_rif *rif, struct net_device *dev,
 			  unsigned long event)
 {
 	bool addr_list_empty = true;
@@ -1524,9 +1999,9 @@ static int mvsw_pr_inetaddr_event(struct notifier_block *nb,
 {
 	struct in_ifaddr *ifa = (struct in_ifaddr *)ptr;
 	struct net_device *dev = ifa->ifa_dev->dev;
-	struct mvsw_pr_router *router;
-	struct mvsw_pr_switch *sw;
-	struct mvsw_pr_rif *rif;
+	struct prestera_router *router;
+	struct prestera_switch *sw;
+	struct prestera_rif *rif;
 	int err = 0;
 
 	/* Wait until previously created works finished (e.g. neigh events) */
@@ -1536,7 +2011,7 @@ static int mvsw_pr_inetaddr_event(struct notifier_block *nb,
 		goto out;
 
 	MVSW_LOG_ERROR("dev=%s", dev->name);
-	router = container_of(nb, struct mvsw_pr_router, inetaddr_nb);
+	router = container_of(nb, struct prestera_router, inetaddr_nb);
 	sw = router->sw;
 
 	if (netif_is_macvlan(dev))
@@ -1554,16 +2029,16 @@ static int mvsw_pr_inetaddr_event(struct notifier_block *nb,
 	return notifier_from_errno(err);
 }
 
-int mvsw_pr_inetaddr_valid_event(struct notifier_block *unused,
-				 unsigned long event, void *ptr)
+int prestera_inetaddr_valid_event(struct notifier_block *unused,
+				  unsigned long event, void *ptr)
 {
 	struct in_validator_info *ivi = (struct in_validator_info *)ptr;
 	struct net_device *dev = ivi->ivi_dev->dev;
-	struct mvsw_pr_switch *sw;
-	struct mvsw_pr_rif *rif;
+	struct prestera_switch *sw;
+	struct prestera_rif *rif;
 	int err = 0;
 
-	sw = mvsw_pr_switch_get(dev);
+	sw = prestera_switch_get(dev);
 	if (!sw)
 		goto out;
 
@@ -1608,6 +2083,23 @@ static bool mvsw_pr_fi_is_direct(struct fib_info *fi)
 	return __mvsw_pr_fi_is_direct(fi);
 }
 
+static bool mvsw_pr_fi_is_hw_direct(struct prestera_switch *sw,
+				    struct fib_info *fi)
+{
+	struct fib_nh *fib_nh;
+	struct prestera_rif *rif;
+
+	if (!mvsw_pr_fi_is_direct(fi))
+		return false;
+
+	fib_nh = fib_info_nh(fi, 0);
+	rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+	if (!rif || !rif->is_active)
+		return false;
+
+	return true;
+}
+
 static bool mvsw_pr_fi_is_nh(struct fib_info *fi)
 {
 	if (fi->fib_type != RTN_UNICAST)
@@ -1616,8 +2108,8 @@ static bool mvsw_pr_fi_is_nh(struct fib_info *fi)
 	return !__mvsw_pr_fi_is_direct(fi);
 }
 
-static void __mvsw_pr_nh_neigh_destroy(struct mvsw_pr_switch *sw,
-				       struct mvsw_pr_nh_neigh *neigh)
+static void __mvsw_pr_nh_neigh_destroy(struct prestera_switch *sw,
+				       struct prestera_nh_neigh *neigh)
 {
 	neigh->key.rif->ref_cnt--;
 	mvsw_pr_rif_put(neigh->key.rif);
@@ -1627,11 +2119,11 @@ static void __mvsw_pr_nh_neigh_destroy(struct mvsw_pr_switch *sw,
 	kfree(neigh);
 }
 
-static struct mvsw_pr_nh_neigh *
-__mvsw_pr_nh_neigh_create(struct mvsw_pr_switch *sw,
-			  struct mvsw_pr_nh_neigh_key *key)
+static struct prestera_nh_neigh *
+__mvsw_pr_nh_neigh_create(struct prestera_switch *sw,
+			  struct prestera_nh_neigh_key *key)
 {
-	struct mvsw_pr_nh_neigh *neigh;
+	struct prestera_nh_neigh *neigh;
 	int err;
 
 	neigh = kzalloc(sizeof(*neigh), GFP_KERNEL);
@@ -1642,6 +2134,7 @@ __mvsw_pr_nh_neigh_create(struct mvsw_pr_switch *sw,
 	neigh->key.rif->ref_cnt++;
 	neigh->info.connected = false;
 	INIT_LIST_HEAD(&neigh->nexthop_group_list);
+	INIT_LIST_HEAD(&neigh->nh_mangle_entry_list);
 	err = rhashtable_insert_fast(&sw->router->nh_neigh_ht,
 				     &neigh->ht_node,
 				     __mvsw_pr_nh_neigh_ht_params);
@@ -1651,48 +2144,52 @@ __mvsw_pr_nh_neigh_create(struct mvsw_pr_switch *sw,
 	return neigh;
 
 err_rhashtable_insert:
+	neigh->key.rif->ref_cnt--;
+	mvsw_pr_rif_put(neigh->key.rif);
 	kfree(neigh);
 err_kzalloc:
 	return NULL;
 }
 
-static struct mvsw_pr_nh_neigh *
-mvsw_pr_nh_neigh_find(struct mvsw_pr_switch *sw,
-		      struct mvsw_pr_nh_neigh_key *key)
+struct prestera_nh_neigh *
+prestera_nh_neigh_find(struct prestera_switch *sw,
+		       struct prestera_nh_neigh_key *key)
 {
-	struct mvsw_pr_nh_neigh *nh_neigh;
+	struct prestera_nh_neigh *nh_neigh;
 
 	nh_neigh = rhashtable_lookup_fast(&sw->router->nh_neigh_ht,
 					  key, __mvsw_pr_nh_neigh_ht_params);
 	return IS_ERR(nh_neigh) ? NULL : nh_neigh;
 }
 
-static struct mvsw_pr_nh_neigh *
-mvsw_pr_nh_neigh_get(struct mvsw_pr_switch *sw,
-		     struct mvsw_pr_nh_neigh_key *key)
+struct prestera_nh_neigh *
+prestera_nh_neigh_get(struct prestera_switch *sw,
+		      struct prestera_nh_neigh_key *key)
 {
-	struct mvsw_pr_nh_neigh *neigh;
+	struct prestera_nh_neigh *neigh;
 
-	neigh = mvsw_pr_nh_neigh_find(sw, key);
+	neigh = prestera_nh_neigh_find(sw, key);
 	if (!neigh)
 		return __mvsw_pr_nh_neigh_create(sw, key);
 
 	return neigh;
 }
 
-static void mvsw_pr_nh_neigh_put(struct mvsw_pr_switch *sw,
-				 struct mvsw_pr_nh_neigh *neigh)
+void prestera_nh_neigh_put(struct prestera_switch *sw,
+			   struct prestera_nh_neigh *neigh)
 {
-	if (list_empty(&neigh->nexthop_group_list))
+	if (list_empty(&neigh->nexthop_group_list) &&
+	    list_empty(&neigh->nh_mangle_entry_list))
 		__mvsw_pr_nh_neigh_destroy(sw, neigh);
 }
 
 /* Updates new mvsw_pr_neigh_info */
-static int mvsw_pr_nh_neigh_set(struct mvsw_pr_switch *sw,
-				struct mvsw_pr_nh_neigh *neigh)
+static int mvsw_pr_nh_neigh_set(struct prestera_switch *sw,
+				struct prestera_nh_neigh *neigh)
 {
 	struct mvsw_pr_nh_neigh_head *nh_head;
 	struct mvsw_pr_nexthop_group *nh_grp;
+	struct prestera_nh_mangle_entry *nm;
 	int err;
 
 	list_for_each_entry(nh_head, &neigh->nexthop_group_list, head) {
@@ -1702,64 +2199,66 @@ static int mvsw_pr_nh_neigh_set(struct mvsw_pr_switch *sw,
 			return err;
 	}
 
+	list_for_each_entry(nm, &neigh->nh_mangle_entry_list, nh_neigh_head) {
+		err = prestera_nh_mangle_entry_set(sw, nm);
+		if (err)
+			return err;
+	}
+
 	return 0;
 }
 
-static bool __mvsw_pr_nh_neigh_key_is_valid(struct mvsw_pr_nh_neigh_key *key)
+static bool mvsw_pr_nh_neigh_key_is_valid(struct prestera_nh_neigh_key *key)
 {
 	return memchr_inv(key, 0, sizeof(*key)) ? true : false;
 }
 
 static bool
-mvsw_pr_nh_neigh_util_hw_state(struct mvsw_pr_switch *sw,
-			       struct mvsw_pr_nh_neigh *nh_neigh)
+mvsw_pr_nh_neigh_util_hw_state(struct prestera_switch *sw,
+			       struct prestera_nh_neigh *nh_neigh)
 {
 	bool state;
 	struct mvsw_pr_nh_neigh_head *nh_head, *tmp;
+	struct prestera_nh_mangle_entry  *nm, *nm_tmp;
 
 	state = false;
 	list_for_each_entry_safe(nh_head, tmp,
 				 &nh_neigh->nexthop_group_list, head) {
 		state = mvsw_pr_nexthop_group_util_hw_state(sw, nh_head->this);
 		if (state)
-			break;
+			goto out;
 	}
-
-	return state;
-}
-
-static size_t
-__mvsw_pr_nexthop_group_key_size(struct mvsw_pr_nexthop_group_key *key)
-{
-	size_t nh_cnt;
-
-	for (nh_cnt = 0; nh_cnt < MVSW_PR_NHGR_SIZE_MAX; nh_cnt++) {
-		if (!__mvsw_pr_nh_neigh_key_is_valid(&key->neigh[nh_cnt]))
-			break;
+	list_for_each_entry_safe(nm, nm_tmp, &nh_neigh->nh_mangle_entry_list,
+				 nh_neigh_head) {
+		state = prestera_nh_mangle_entry_util_hw_state(sw, nm);
+		if (state)
+			goto out;
 	}
 
-	return nh_cnt;
+out:
+	return state;
 }
 
 static struct mvsw_pr_nexthop_group *
-__mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
-			       struct mvsw_pr_nexthop_group_key *key)
+__mvsw_pr_nexthop_group_create(struct prestera_switch *sw,
+			       struct prestera_nexthop_group_key *key)
 {
 	struct mvsw_pr_nexthop_group *nh_grp;
-	struct mvsw_pr_nh_neigh *nh_neigh;
-	int nh_cnt, err;
+	struct prestera_nh_neigh *nh_neigh;
+	int nh_cnt, err, gid;
 
 	nh_grp = kzalloc(sizeof(*nh_grp), GFP_KERNEL);
 	if (!nh_grp)
 		goto err_kzalloc;
 
 	memcpy(&nh_grp->key, key, sizeof(*key));
-	for (nh_cnt = 0; nh_cnt < MVSW_PR_NHGR_SIZE_MAX; nh_cnt++) {
-		if (!__mvsw_pr_nh_neigh_key_is_valid(&nh_grp->key.neigh[nh_cnt])
+	for (nh_cnt = 0; nh_cnt < PRESTERA_NHGR_SIZE_MAX; nh_cnt++) {
+		if (!mvsw_pr_nh_neigh_key_is_valid(&nh_grp->key.neigh[nh_cnt])
 		   )
 			break;
 
-		nh_neigh = mvsw_pr_nh_neigh_get(sw, &nh_grp->key.neigh[nh_cnt]);
+		nh_neigh = prestera_nh_neigh_get(sw,
+						 &nh_grp->key.neigh[nh_cnt]);
 		if (!nh_neigh)
 			goto err_nh_neigh_get;
 
@@ -1769,7 +2268,7 @@ __mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
 			 &nh_neigh->nexthop_group_list);
 	}
 
-	err = mvsw_pr_nh_group_create(sw, nh_cnt, &nh_grp->grp_id);
+	err = prestera_nh_group_create(sw, nh_cnt, &nh_grp->grp_id);
 	if (err)
 		goto err_nh_group_create;
 
@@ -1783,16 +2282,20 @@ __mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
 	if (err)
 		goto err_ht_insert;
 
+	/* reset cache for created group */
+	gid = nh_grp->grp_id;
+	sw->router->nhgrp_hw_state_cache[gid / 8] &= ~BIT(gid % 8);
+
 	return nh_grp;
 
 err_ht_insert:
 err_nexthop_group_set:
-	mvsw_pr_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
+	prestera_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
 err_nh_group_create:
 err_nh_neigh_get:
 	for (nh_cnt--; nh_cnt >= 0; nh_cnt--) {
 		list_del(&nh_grp->nh_neigh_head[nh_cnt].head);
-		mvsw_pr_nh_neigh_put(sw, nh_grp->nh_neigh_head[nh_cnt].neigh);
+		prestera_nh_neigh_put(sw, nh_grp->nh_neigh_head[nh_cnt].neigh);
 	}
 
 	kfree(nh_grp);
@@ -1801,32 +2304,32 @@ __mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
 }
 
 static void
-__mvsw_pr_nexthop_group_destroy(struct mvsw_pr_switch *sw,
+__mvsw_pr_nexthop_group_destroy(struct prestera_switch *sw,
 				struct mvsw_pr_nexthop_group *nh_grp)
 {
-	struct mvsw_pr_nh_neigh *nh_neigh;
+	struct prestera_nh_neigh *nh_neigh;
 	int nh_cnt;
 
 	rhashtable_remove_fast(&sw->router->nexthop_group_ht,
 			       &nh_grp->ht_node,
 			       __mvsw_pr_nexthop_group_ht_params);
 
-	for (nh_cnt = 0; nh_cnt < MVSW_PR_NHGR_SIZE_MAX; nh_cnt++) {
+	for (nh_cnt = 0; nh_cnt < PRESTERA_NHGR_SIZE_MAX; nh_cnt++) {
 		nh_neigh = nh_grp->nh_neigh_head[nh_cnt].neigh;
 		if (!nh_neigh)
 			break;
 
 		list_del(&nh_grp->nh_neigh_head[nh_cnt].head);
-		mvsw_pr_nh_neigh_put(sw, nh_neigh);
+		prestera_nh_neigh_put(sw, nh_neigh);
 	}
 
-	mvsw_pr_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
+	prestera_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
 	kfree(nh_grp);
 }
 
 static struct mvsw_pr_nexthop_group *
-mvsw_pr_nexthop_group_find(struct mvsw_pr_switch *sw,
-			   struct mvsw_pr_nexthop_group_key *key)
+mvsw_pr_nexthop_group_find(struct prestera_switch *sw,
+			   struct prestera_nexthop_group_key *key)
 {
 	struct mvsw_pr_nexthop_group *nh_grp;
 
@@ -1836,8 +2339,8 @@ mvsw_pr_nexthop_group_find(struct mvsw_pr_switch *sw,
 }
 
 static struct mvsw_pr_nexthop_group *
-mvsw_pr_nexthop_group_get(struct mvsw_pr_switch *sw,
-			  struct mvsw_pr_nexthop_group_key *key)
+mvsw_pr_nexthop_group_get(struct prestera_switch *sw,
+			  struct prestera_nexthop_group_key *key)
 {
 	struct mvsw_pr_nexthop_group *nh_grp;
 
@@ -1848,7 +2351,7 @@ mvsw_pr_nexthop_group_get(struct mvsw_pr_switch *sw,
 	return nh_grp;
 }
 
-static void mvsw_pr_nexthop_group_put(struct mvsw_pr_switch *sw,
+static void mvsw_pr_nexthop_group_put(struct prestera_switch *sw,
 				      struct mvsw_pr_nexthop_group *nh_grp)
 {
 	if (!nh_grp->ref_cnt)
@@ -1856,15 +2359,15 @@ static void mvsw_pr_nexthop_group_put(struct mvsw_pr_switch *sw,
 }
 
 /* Updates with new nh_neigh's info */
-static int mvsw_pr_nexthop_group_set(struct mvsw_pr_switch *sw,
+static int mvsw_pr_nexthop_group_set(struct prestera_switch *sw,
 				     struct mvsw_pr_nexthop_group *nh_grp)
 {
-	struct mvsw_pr_neigh_info info[MVSW_PR_NHGR_SIZE_MAX];
-	struct mvsw_pr_nh_neigh *neigh;
+	struct prestera_neigh_info info[PRESTERA_NHGR_SIZE_MAX];
+	struct prestera_nh_neigh *neigh;
 	int nh_cnt;
 
 	memset(&info[0], 0, sizeof(info));
-	for (nh_cnt = 0; nh_cnt < MVSW_PR_NHGR_SIZE_MAX; nh_cnt++) {
+	for (nh_cnt = 0; nh_cnt < PRESTERA_NHGR_SIZE_MAX; nh_cnt++) {
 		neigh = nh_grp->nh_neigh_head[nh_cnt].neigh;
 		if (!neigh)
 			break;
@@ -1872,45 +2375,42 @@ static int mvsw_pr_nexthop_group_set(struct mvsw_pr_switch *sw,
 		memcpy(&info[nh_cnt], &neigh->info, sizeof(neigh->info));
 	}
 
-	return mvsw_pr_nh_entries_set(sw, nh_cnt, &info[0], nh_grp->grp_id);
+	return prestera_nh_entries_set(sw, nh_cnt, &info[0], nh_grp->grp_id);
 }
 
 static bool
-mvsw_pr_nexthop_group_util_hw_state(struct mvsw_pr_switch *sw,
+mvsw_pr_nexthop_group_util_hw_state(struct prestera_switch *sw,
 				    struct mvsw_pr_nexthop_group *nh_grp)
 {
-	int err, nh_cnt;
-	struct mvsw_pr_neigh_info info[MVSW_PR_NHGR_SIZE_MAX];
-	size_t grp_size;
+	int err;
+	u32 buf_size = sw->size_tbl_router_nexthop / 8 + 1;
+	u32 gid = nh_grp->grp_id;
+	u8 *cache = sw->router->nhgrp_hw_state_cache;
 
 	/* Antijitter
 	 * Prevent situation, when we read state of nh_grp twice in short time,
 	 * and state bit is still cleared on second call. So just stuck active
 	 * state for MVSW_PR_NH_ACTIVE_JIFFER_FILTER, after last occurred.
 	 */
-	if (time_before(jiffies, nh_grp->hw_last_connected +
-			msecs_to_jiffies(MVSW_PR_NH_ACTIVE_JIFFER_FILTER)))
-		return true;
+	if (!time_before(jiffies, sw->router->nhgrp_hw_cache_kick +
+			msecs_to_jiffies(MVSW_PR_NH_ACTIVE_JIFFER_FILTER))) {
+		err = prestera_nhgrp_blk_get(sw, cache, buf_size);
+		if (err) {
+			MVSW_LOG_ERROR("Failed to get hw state nh_grp's");
+			return false;
+		}
 
-	grp_size =  __mvsw_pr_nexthop_group_key_size(&nh_grp->key);
-	err = mvsw_pr_nh_entries_get(sw, grp_size, &info[0], nh_grp->grp_id);
-	if (err) {
-		MVSW_LOG_ERROR("Failed to get hw state of nh_grp %d",
-			       nh_grp->grp_id);
-		return false;
+		sw->router->nhgrp_hw_cache_kick = jiffies;
 	}
 
-	for (nh_cnt = 0; nh_cnt < grp_size; nh_cnt++)
-		if (info[nh_cnt].connected) {
-			nh_grp->hw_last_connected = jiffies;
-			return true;
-		}
+	if (cache[gid / 8] & BIT(gid % 8))
+		return true;
 
 	return false;
 }
 
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_find(struct mvsw_pr_switch *sw, struct mvsw_pr_fib_key *key)
+mvsw_pr_fib_node_find(struct prestera_switch *sw, struct prestera_fib_key *key)
 {
 	struct mvsw_pr_fib_node *fib_node;
 
@@ -1919,14 +2419,14 @@ mvsw_pr_fib_node_find(struct mvsw_pr_switch *sw, struct mvsw_pr_fib_key *key)
 	return IS_ERR(fib_node) ? NULL : fib_node;
 }
 
-static void __mvsw_pr_fib_node_destruct(struct mvsw_pr_switch *sw,
+static void __mvsw_pr_fib_node_destruct(struct prestera_switch *sw,
 					struct mvsw_pr_fib_node *fib_node)
 {
 	struct mvsw_pr_vr *vr;
 
 	vr = fib_node->info.vr;
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id, &fib_node->key.addr,
-			fib_node->key.prefix_len);
+	prestera_lpm_del(sw, vr->hw_vr_id, &fib_node->key.addr,
+			 fib_node->key.prefix_len);
 	switch (fib_node->info.type) {
 	case MVSW_PR_FIB_TYPE_UC_NH:
 		fib_node->info.nh_grp->ref_cnt--;
@@ -1945,7 +2445,7 @@ static void __mvsw_pr_fib_node_destruct(struct mvsw_pr_switch *sw,
 	mvsw_pr_vr_put(sw, vr);
 }
 
-static void mvsw_pr_fib_node_destroy(struct mvsw_pr_switch *sw,
+static void mvsw_pr_fib_node_destroy(struct prestera_switch *sw,
 				     struct mvsw_pr_fib_node *fib_node)
 {
 	__mvsw_pr_fib_node_destruct(sw, fib_node);
@@ -1954,7 +2454,7 @@ static void mvsw_pr_fib_node_destroy(struct mvsw_pr_switch *sw,
 	kfree(fib_node);
 }
 
-static void mvsw_pr_fib_node_destroy_ht(struct mvsw_pr_switch *sw)
+static void mvsw_pr_fib_node_destroy_ht(struct prestera_switch *sw)
 {
 	struct mvsw_pr_fib_node *node, *tnode;
 	struct rhashtable_iter iter;
@@ -1978,20 +2478,24 @@ static void mvsw_pr_fib_node_destroy_ht(struct mvsw_pr_switch *sw)
 		if (IS_ERR(node))
 			continue;
 
+		rhashtable_walk_stop(&iter);
 		__mvsw_pr_fib_node_destruct(sw, node);
+		rhashtable_walk_start(&iter);
 		tnode = node;
 	}
 	rhashtable_walk_stop(&iter);
 	rhashtable_walk_exit(&iter);
 }
 
+/* nh_grp_key valid only if fib_type == MVSW_PR_FIB_TYPE_UC_NH */
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
-			      struct mvsw_pr_fib_key *key,
-			      struct mvsw_pr_nexthop_group_key *nh_grp_key)
+mvsw_pr_fib_node_create(struct prestera_switch *sw,
+			struct prestera_fib_key *key,
+			enum mvsw_pr_fib_type fib_type,
+			struct prestera_nexthop_group_key *nh_grp_key)
 {
 	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_nexthop_group *nh_grp;
+	u32 grp_id;
 	struct mvsw_pr_vr *vr;
 	int err;
 
@@ -2000,24 +2504,39 @@ mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
 		goto err_kzalloc;
 
 	memcpy(&fib_node->key, key, sizeof(*key));
-	fib_node->info.type = MVSW_PR_FIB_TYPE_UC_NH;
+	fib_node->info.type = fib_type;
 
 	vr = mvsw_pr_vr_get(sw, key->tb_id, NULL);
-	if (!vr)
+	if (IS_ERR(vr))
 		goto err_vr_get;
 
 	fib_node->info.vr = vr;
 	vr->ref_cnt++;
 
-	nh_grp = mvsw_pr_nexthop_group_get(sw, nh_grp_key);
-	if (!nh_grp)
+	switch (fib_type) {
+	case MVSW_PR_FIB_TYPE_TRAP:
+		grp_id = MVSW_PR_NHGR_UNUSED;
+		break;
+	case MVSW_PR_FIB_TYPE_DROP:
+		grp_id = MVSW_PR_NHGR_DROP;
+		break;
+	case MVSW_PR_FIB_TYPE_UC_NH:
+		fib_node->info.nh_grp = mvsw_pr_nexthop_group_get(sw,
+								  nh_grp_key);
+		if (!fib_node->info.nh_grp)
+			goto err_nh_grp_get;
+
+		fib_node->info.nh_grp->ref_cnt++;
+		grp_id = fib_node->info.nh_grp->grp_id;
+		break;
+	default:
+		MVSW_LOG_ERROR("Unsupported fib_type %d", fib_type);
 		goto err_nh_grp_get;
+	}
 
-	fib_node->info.nh_grp = nh_grp;
-	nh_grp->ref_cnt++;
 
-	err = mvsw_pr_lpm_add(sw, vr->hw_vr_id, &key->addr,
-			      key->prefix_len, nh_grp->grp_id);
+	err = prestera_lpm_add(sw, vr->hw_vr_id, &key->addr,
+			       key->prefix_len, grp_id);
 	if (err)
 		goto err_lpm_add;
 
@@ -2029,10 +2548,12 @@ mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
 	return fib_node;
 
 err_ht_insert:
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id, &key->addr, key->prefix_len);
+	prestera_lpm_del(sw, vr->hw_vr_id, &key->addr, key->prefix_len);
 err_lpm_add:
-	nh_grp->ref_cnt--;
-	mvsw_pr_nexthop_group_put(sw, nh_grp);
+	if (fib_type == MVSW_PR_FIB_TYPE_UC_NH) {
+		fib_node->info.nh_grp->ref_cnt--;
+		mvsw_pr_nexthop_group_put(sw, fib_node->info.nh_grp);
+	}
 err_nh_grp_get:
 	vr->ref_cnt--;
 	mvsw_pr_vr_put(sw, vr);
@@ -2040,6 +2561,7 @@ mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
 	kfree(fib_node);
 err_kzalloc:
 	return NULL;
+
 }
 
 /* Decided, that uc_nh route with key==nh is obviously neighbour route */
@@ -2056,271 +2578,22 @@ mvsw_pr_fib_node_util_is_neighbour(struct mvsw_pr_fib_node *fib_node)
 		return false;
 
 	if (memcmp(&fib_node->info.nh_grp->nh_neigh_head[0].neigh->key.addr,
-		   &fib_node->key.addr, sizeof(struct mvsw_pr_ip_addr)))
+		   &fib_node->key.addr, sizeof(struct prestera_ip_addr)))
 		return false;
 
 	return true;
 }
 
-static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_trap_create(struct mvsw_pr_switch *sw,
-			     struct mvsw_pr_fib_key *key)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_vr *vr;
-	int err;
-
-	fib_node = kzalloc(sizeof(*fib_node), GFP_KERNEL);
-	if (!fib_node)
-		goto err_kzalloc;
-
-	vr = mvsw_pr_vr_get(sw, key->tb_id, NULL);
-	if (!vr)
-		goto err_vr_get;
-
-	fib_node->info.vr = vr;
-	vr->ref_cnt++;
-
-	memcpy(&fib_node->key, key, sizeof(*key));
-	fib_node->info.type = MVSW_PR_FIB_TYPE_TRAP;
-	err = mvsw_pr_lpm_add(sw, vr->hw_vr_id, &key->addr,
-			      key->prefix_len, MVSW_PR_NHGR_UNUSED);
-	if (err)
-		goto err_lpm_add;
-
-	err = rhashtable_insert_fast(&sw->router->fib_ht, &fib_node->ht_node,
-				     __mvsw_pr_fib_ht_params);
-	if (err)
-		goto err_ht_insert;
-
-	return fib_node;
-
-err_ht_insert:
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id, &key->addr, key->prefix_len);
-err_lpm_add:
-	vr->ref_cnt--;
-	mvsw_pr_vr_put(sw, vr);
-err_vr_get:
-	kfree(fib_node);
-err_kzalloc:
-	return NULL;
-}
-
-static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_drop_create(struct mvsw_pr_switch *sw,
-			     struct mvsw_pr_fib_key *key)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_vr *vr;
-	int err;
-
-	fib_node = kzalloc(sizeof(*fib_node), GFP_KERNEL);
-	if (!fib_node)
-		goto err_kzalloc;
-
-	vr = mvsw_pr_vr_get(sw, key->tb_id, NULL);
-	if (!vr)
-		goto err_vr_get;
-
-	fib_node->info.vr = vr;
-	vr->ref_cnt++;
-
-	memcpy(&fib_node->key, key, sizeof(*key));
-	fib_node->info.type = MVSW_PR_FIB_TYPE_DROP;
-	err = mvsw_pr_lpm_add(sw, vr->hw_vr_id,
-			      &key->addr, key->prefix_len, MVSW_PR_NHGR_DROP);
-	if (err)
-		goto err_lpm_add;
-
-	err = rhashtable_insert_fast(&sw->router->fib_ht, &fib_node->ht_node,
-				     __mvsw_pr_fib_ht_params);
-	if (err)
-		goto err_ht_insert;
-
-	return fib_node;
-
-err_ht_insert:
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id,
-			&key->addr, key->prefix_len);
-err_lpm_add:
-	vr->ref_cnt--;
-	mvsw_pr_vr_put(sw, vr);
-err_vr_get:
-	kfree(fib_node);
-err_kzalloc:
-	return NULL;
-}
-
-static void mvsw_pr_fib_nh_del2nh_neigh_set(struct mvsw_pr_switch *sw,
-					    struct fib_nh *fib_nh)
-{
-	struct mvsw_pr_nh_neigh_key nh_neigh_key;
-	struct mvsw_pr_nh_neigh *nh_neigh;
-
-	memset(&nh_neigh_key, 0, sizeof(nh_neigh_key));
-	nh_neigh_key.addr.u.ipv4 = fib_nh->fib_nh_gw4;
-	nh_neigh_key.rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
-	if (!nh_neigh_key.rif)
-		return;
-
-	nh_neigh = mvsw_pr_nh_neigh_find(sw, &nh_neigh_key);
-	if (!nh_neigh)
-		return;
-
-	nh_neigh->info.connected = false;
-	mvsw_pr_nh_neigh_set(sw, nh_neigh);
-}
-
-static void __mvsw_pr_fen_info2fib_key(struct fib_entry_notifier_info *fen_info,
-				       struct mvsw_pr_fib_key *key)
-{
-	memset(key, 0, sizeof(*key));
-	key->addr.u.ipv4 = cpu_to_be32(fen_info->dst);
-	key->prefix_len = fen_info->dst_len;
-	key->tb_id = mvsw_pr_fix_tb_id(fen_info->tb_id);
-}
-
-static int
-mvsw_pr_fi2nh_gr_key(struct mvsw_pr_switch *sw, struct fib_info *fi,
-		     size_t limit, struct mvsw_pr_nexthop_group_key *grp_key)
-{
-	int i, nhs, err;
-	struct fib_nh *fib_nh;
-
-	nhs = fib_info_num_path(fi);
-	if (nhs > limit)
-		return 0;
-
-	memset(grp_key, 0, sizeof(*grp_key));
-	for (i = 0; i < nhs; i++) {
-		fib_nh = fib_info_nh(fi, i);
-		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw,
-						       fib_nh,
-						       &grp_key->neigh[i]);
-		if (err)
-			return 0;
-	}
-
-	return nhs;
-}
-
-static int
-mvsw_pr_router_fib_replace(struct mvsw_pr_switch *sw,
-			   struct fib_entry_notifier_info *fen_info)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_fib_key fib_key;
-	struct mvsw_pr_nexthop_group_key nh_grp_key;
-	int nh_cnt;
-
-	__mvsw_pr_fen_info2fib_key(fen_info, &fib_key);
-
-	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
-	if (fib_node) {
-		MVSW_LOG_INFO("fib_node found. destroy.");
-		mvsw_pr_fib_node_destroy(sw, fib_node);
-	}
-
-	/* TODO: fib lookup here to check if another route with the same key
-	 * is occurred in another kernel's table
-	 */
-	switch (fen_info->fi->fib_type) {
-	case RTN_UNICAST:
-		if (mvsw_pr_fi_is_nh(fen_info->fi))
-			nh_cnt = mvsw_pr_fi2nh_gr_key(sw, fen_info->fi,
-						      MVSW_PR_NHGR_SIZE_MAX,
-						      &nh_grp_key);
-		else
-			nh_cnt = 0;
-
-		if (nh_cnt) {
-			fib_node = mvsw_pr_fib_node_uc_nh_create(sw, &fib_key,
-								 &nh_grp_key);
-		} else {
-			fib_node = mvsw_pr_fib_node_trap_create(sw, &fib_key);
-		}
-
-		if (!fib_node)
-			goto err_fib_create;
-
-		break;
-	/* Unsupported. Leave it for kernel: */
-	case RTN_BROADCAST:
-	case RTN_MULTICAST:
-	/* Routes we must trap by design: */
-	case RTN_LOCAL:
-	case RTN_UNREACHABLE:
-	case RTN_PROHIBIT:
-		fib_node = mvsw_pr_fib_node_trap_create(sw, &fib_key);
-		if (!fib_node)
-			goto err_fib_create;
-		break;
-	case RTN_BLACKHOLE:
-		fib_node = mvsw_pr_fib_node_drop_create(sw, &fib_key);
-		if (!fib_node)
-			goto err_fib_create;
-
-		break;
-	default:
-		goto err_type;
-	}
-
-	mvsw_pr_neigh_arbiter_fib_evt(sw, true, &fib_key, fen_info->fi);
-
-	return 0;
-
-err_fib_create:
-	MVSW_LOG_ERROR("fib_create failed");
-	goto err_out;
-err_type:
-	MVSW_LOG_ERROR("Invalid fen_info->fi->fib_type %d",
-		       fen_info->fi->fib_type);
-	goto err_out;
-err_out:
-	MVSW_LOG_ERROR("Error when processing %pI4h/%d", &fen_info->dst,
-		       fen_info->dst_len);
-	return -EINVAL;
-}
-
-static void mvsw_pr_router_fib_del(struct mvsw_pr_switch *sw,
-				   struct fib_entry_notifier_info *fen_info)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_fib_key fib_key;
-
-	/* TODO: fib lookup here to check if another route with the same key
-	 * is occurred in another kernel's table
-	 */
-	__mvsw_pr_fen_info2fib_key(fen_info, &fib_key);
-
-	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
-	if (fib_node) {
-		mvsw_pr_fib_node_destroy(sw, fib_node);
-	} else {
-		MVSW_LOG_ERROR("Cant find fib_node");
-		goto err_out;
-	}
-
-	mvsw_pr_neigh_arbiter_fib_evt(sw, false, &fib_key, fen_info->fi);
-
-	return;
-
-err_out:
-	MVSW_LOG_ERROR("Error when processing %pI4h/%d", &fen_info->dst,
-		       fen_info->dst_len);
-}
-
-static void mvsw_pr_router_fib_abort(struct mvsw_pr_switch *sw)
+static void mvsw_pr_router_fib_abort(struct prestera_switch *sw)
 {
 	mvsw_pr_vr_util_hw_abort(sw);
 	mvsw_pr_fib_node_destroy_ht(sw);
-	mvsw_pr_kern_fib_cache_destroy_ht(sw);
-	mvsw_pr_util_kern_unset_allneigh_offload();
+	mvsw_pr_k_arb_abort(sw);
 }
 
 struct mvsw_pr_fib_event_work {
 	struct work_struct work;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	union {
 		struct fib_entry_notifier_info fen_info;
 		struct fib_nh_notifier_info fnh_info;
@@ -2332,7 +2605,7 @@ static void mvsw_pr_router_fib4_event_work(struct work_struct *work)
 {
 	struct mvsw_pr_fib_event_work *fib_work =
 			container_of(work, struct mvsw_pr_fib_event_work, work);
-	struct mvsw_pr_switch *sw = fib_work->sw;
+	struct prestera_switch *sw = fib_work->sw;
 	int err;
 
 	mvsw_owq_lock();
@@ -2342,19 +2615,27 @@ static void mvsw_pr_router_fib4_event_work(struct work_struct *work)
 
 	switch (fib_work->event) {
 	case FIB_EVENT_ENTRY_REPLACE:
-		err = mvsw_pr_router_fib_replace(sw,
-						 &fib_work->fen_info);
+		err = mvsw_pr_k_arb_fib_evt(sw, true, &fib_work->fen_info);
 		if (err)
 			goto abort_out;
+
 		break;
 	case FIB_EVENT_ENTRY_DEL:
-		mvsw_pr_router_fib_del(sw, &fib_work->fen_info);
+		err = mvsw_pr_k_arb_fib_evt(sw, false, &fib_work->fen_info);
+		if (err)
+			MVSW_LOG_ERROR("Cant delete %pI4n/%d",
+				       &fib_work->fen_info.dst,
+				       fib_work->fen_info.dst_len);
+
 		break;
 	}
 
 	goto out;
 
 abort_out:
+	dev_err(sw->dev->dev, "Error when processing %pI4h/%d",
+		&fib_work->fen_info.dst,
+		fib_work->fen_info.dst_len);
 	sw->router->aborted = true;
 	mvsw_pr_router_fib_abort(sw);
 	dev_err(sw->dev->dev, "Abort. HW routing offloading disabled");
@@ -2368,7 +2649,7 @@ static void mvsw_pr_router_nh_update_event_work(struct work_struct *work)
 {
 	struct mvsw_pr_fib_event_work *fib_work =
 			container_of(work, struct mvsw_pr_fib_event_work, work);
-	struct mvsw_pr_switch *sw = fib_work->sw;
+	struct prestera_switch *sw = fib_work->sw;
 	struct fib_nh *fib_nh = fib_work->fnh_info.fib_nh;
 
 	mvsw_owq_lock();
@@ -2378,7 +2659,7 @@ static void mvsw_pr_router_nh_update_event_work(struct work_struct *work)
 
 	/* For now provided only deletion */
 	if (fib_work->event == FIB_EVENT_NH_DEL)
-		mvsw_pr_fib_nh_del2nh_neigh_set(sw, fib_nh);
+		mvsw_pr_k_arb_nh_evt(sw, false, fib_nh);
 
 out:
 	fib_info_put(fib_nh->nh_parent);
@@ -2395,13 +2676,13 @@ static int mvsw_pr_router_fib_event(struct notifier_block *nb,
 	struct fib_nh_notifier_info *fnh_info;
 	struct fib_notifier_info *info = ptr;
 	struct mvsw_pr_fib_event_work *fib_work;
-	struct mvsw_pr_router *router;
+	struct prestera_router *router;
 	struct fib_info *fi;
 
 	if (info->family != AF_INET)
 		return NOTIFY_DONE;
 
-	router = container_of(nb, struct mvsw_pr_router, fib_nb);
+	router = container_of(nb, struct prestera_router, fib_nb);
 
 	switch (event) {
 	case FIB_EVENT_ENTRY_REPLACE:
@@ -2421,7 +2702,7 @@ static int mvsw_pr_router_fib_event(struct notifier_block *nb,
 			if (fi->fib_nh_is_v6)
 				return notifier_from_errno(-EINVAL);
 
-			if (fib_info_num_path(fi) > MVSW_PR_NHGR_SIZE_MAX) {
+			if (fib_info_num_path(fi) > PRESTERA_NHGR_SIZE_MAX) {
 				NL_SET_ERR_MSG_MOD(info->extack,
 						   "Exceeded number of nexthops per route"
 						   );
@@ -2469,7 +2750,7 @@ static int mvsw_pr_router_fib_event(struct notifier_block *nb,
 
 static void mvsw_pr_router_fib_dump_flush(struct notifier_block *nb)
 {
-	struct mvsw_pr_router *router;
+	struct prestera_router *router;
 
 	/* Flush pending FIB notifications and then flush the device's
 	 * table before requesting another dump. The FIB notification
@@ -2477,14 +2758,14 @@ static void mvsw_pr_router_fib_dump_flush(struct notifier_block *nb)
 	 * No neighbours are expected to be present since FIBs  are not
 	 * registered yet
 	 */
-	router = container_of(nb, struct mvsw_pr_router, fib_nb);
+	router = container_of(nb, struct prestera_router, fib_nb);
 	flush_workqueue(mvsw_r_owq);
 	flush_workqueue(mvsw_r_wq);
 	mvsw_pr_fib_node_destroy_ht(router->sw);
 }
 
 static int
-mvsw_pr_router_port_change(struct mvsw_pr_rif *rif)
+mvsw_pr_router_port_change(struct prestera_rif *rif)
 {
 	struct net_device *dev = rif->dev;
 	int err;
@@ -2502,7 +2783,7 @@ mvsw_pr_router_port_change(struct mvsw_pr_rif *rif)
 }
 
 static int
-mvsw_pr_router_port_pre_change(struct mvsw_pr_rif *rif,
+mvsw_pr_router_port_pre_change(struct prestera_rif *rif,
 			       struct netdev_notifier_pre_changeaddr_info *info)
 {
 	struct netlink_ext_ack *extack;
@@ -2512,13 +2793,13 @@ mvsw_pr_router_port_pre_change(struct mvsw_pr_rif *rif,
 						  info->dev_addr, extack);
 }
 
-int mvsw_pr_netdevice_router_port_event(struct net_device *dev,
-					unsigned long event, void *ptr)
+int prestera_netdevice_router_port_event(struct net_device *dev,
+					 unsigned long event, void *ptr)
 {
-	struct mvsw_pr_switch *sw;
-	struct mvsw_pr_rif *rif;
+	struct prestera_switch *sw;
+	struct prestera_rif *rif;
 
-	sw = mvsw_pr_switch_get(dev);
+	sw = prestera_switch_get(dev);
 	if (!sw)
 		return 0;
 
@@ -2536,11 +2817,11 @@ int mvsw_pr_netdevice_router_port_event(struct net_device *dev,
 	return 0;
 }
 
-static int mvsw_pr_port_vrf_join(struct mvsw_pr_switch *sw,
+static int mvsw_pr_port_vrf_join(struct prestera_switch *sw,
 				 struct net_device *dev,
 				 struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	/* If netdev is already associated with a RIF, then we need to
 	 * destroy it and create a new one with the new virtual router ID.
@@ -2554,11 +2835,11 @@ static int mvsw_pr_port_vrf_join(struct mvsw_pr_switch *sw,
 	return mvsw_pr_rif_vr_update(sw, rif, extack);
 }
 
-static void mvsw_pr_port_vrf_leave(struct mvsw_pr_switch *sw,
+static void mvsw_pr_port_vrf_leave(struct prestera_switch *sw,
 				   struct net_device *dev,
 				   struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 	struct in_device *idev;
 
 	rif = mvsw_pr_rif_find(sw, dev);
@@ -2577,16 +2858,18 @@ static void mvsw_pr_port_vrf_leave(struct mvsw_pr_switch *sw,
 		__mvsw_pr_inetaddr_event(sw, dev, NETDEV_UP, NULL);
 }
 
-int mvsw_pr_netdevice_vrf_event(struct net_device *dev, unsigned long event,
-				struct netdev_notifier_changeupper_info *info)
+int prestera_netdevice_vrf_event(struct net_device *dev, unsigned long event,
+				 struct netdev_notifier_changeupper_info *info)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(dev);
+	struct prestera_switch *sw = prestera_switch_get(dev);
 	struct netlink_ext_ack *extack = NULL;
 	int err = 0;
 
 	if (!sw || netif_is_macvlan(dev))
 		return 0;
 
+	mvsw_owq_flush();
+
 	switch (event) {
 	case NETDEV_PRECHANGEUPPER:
 		return 0;
@@ -2605,7 +2888,7 @@ int mvsw_pr_netdevice_vrf_event(struct net_device *dev, unsigned long event,
 static int __mvsw_pr_rif_macvlan_flush(struct net_device *dev,
 				       struct netdev_nested_priv *priv)
 {
-	struct mvsw_pr_rif *rif = priv->data;
+	struct prestera_rif *rif = priv->data;
 
 	if (!netif_is_macvlan(dev))
 		return 0;
@@ -2613,7 +2896,7 @@ static int __mvsw_pr_rif_macvlan_flush(struct net_device *dev,
 	return mvsw_pr_rif_fdb_op(rif, dev->dev_addr, false);
 }
 
-static int mvsw_pr_rif_macvlan_flush(struct mvsw_pr_rif *rif)
+static int mvsw_pr_rif_macvlan_flush(struct prestera_rif *rif)
 {
 	struct netdev_nested_priv priv = {
 		.data = (void *)rif,
@@ -2625,32 +2908,33 @@ static int mvsw_pr_rif_macvlan_flush(struct mvsw_pr_rif *rif)
 	netdev_warn(rif->dev,
 		    "Router interface is deleted. Upper macvlans will not work\n");
 	return netdev_walk_all_upper_dev_rcu(rif->dev,
-					     __mvsw_pr_rif_macvlan_flush, &priv);
+					     __mvsw_pr_rif_macvlan_flush,
+					     &priv);
 }
 
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
-static int mvsw_pr_mp_hash_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_mp_hash_init(struct prestera_switch *sw)
 {
 	u8 hash_policy;
 
 	hash_policy = init_net.ipv4.sysctl_fib_multipath_hash_policy;
-	return  mvsw_pr_mp4_hash_set(sw, hash_policy);
+	return  prestera_mp4_hash_set(sw, hash_policy);
 }
 #else
-static int mvsw_pr_mp_hash_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_mp_hash_init(struct prestera_switch *sw)
 {
 	return 0;
 }
 #endif
 
 static struct notifier_block mvsw_pr_inetaddr_valid_nb __read_mostly = {
-	.notifier_call = mvsw_pr_inetaddr_valid_event,
+	.notifier_call = prestera_inetaddr_valid_event,
 };
 
-int mvsw_pr_router_init(struct mvsw_pr_switch *sw)
+int prestera_router_init(struct prestera_switch *sw)
 {
-	struct mvsw_pr_router *router;
-	int err;
+	struct prestera_router *router;
+	int err, nhgrp_cache_bytes;
 
 	router = kzalloc(sizeof(*sw->router), GFP_KERNEL);
 	if (!router)
@@ -2682,6 +2966,11 @@ int mvsw_pr_router_init(struct mvsw_pr_switch *sw)
 	if (err)
 		goto err_kern_neigh_cache_ht_init;
 
+	nhgrp_cache_bytes = sw->size_tbl_router_nexthop / 8 + 1;
+	router->nhgrp_hw_state_cache = kzalloc(nhgrp_cache_bytes, GFP_KERNEL);
+	if (!router->nhgrp_hw_state_cache)
+		return -ENOMEM;
+
 	INIT_LIST_HEAD(&sw->router->rif_list);
 	INIT_LIST_HEAD(&sw->router->vr_list);
 
@@ -2749,9 +3038,9 @@ int mvsw_pr_router_init(struct mvsw_pr_switch *sw)
 	return err;
 }
 
-static void mvsw_pr_rifs_fini(struct mvsw_pr_switch *sw)
+static void mvsw_pr_rifs_fini(struct prestera_switch *sw)
 {
-	struct mvsw_pr_rif *rif, *tmp;
+	struct prestera_rif *rif, *tmp;
 
 	list_for_each_entry_safe(rif, tmp, &sw->router->rif_list, router_node) {
 		rif->is_active = false;
@@ -2759,16 +3048,19 @@ static void mvsw_pr_rifs_fini(struct mvsw_pr_switch *sw)
 	}
 }
 
-void mvsw_pr_router_fini(struct mvsw_pr_switch *sw)
+void prestera_router_fini(struct prestera_switch *sw)
 {
 	unregister_fib_notifier(&init_net, &sw->router->fib_nb);
 	unregister_netevent_notifier(&sw->router->netevent_nb);
+	unregister_inetaddr_notifier(&sw->router->inetaddr_nb);
+	unregister_inetaddr_validator_notifier(&mvsw_pr_inetaddr_valid_nb);
 	mvsw_pr_neigh_fini(sw);
 	/* TODO: check if vrs necessary ? */
 	mvsw_pr_rifs_fini(sw);
-	unregister_inetaddr_notifier(&sw->router->inetaddr_nb);
-	unregister_inetaddr_validator_notifier(&mvsw_pr_inetaddr_valid_nb);
+	mvsw_pr_k_arb_abort(sw);
 
+	rhashtable_destroy(&sw->router->kern_neigh_cache_ht);
+	rhashtable_destroy(&sw->router->kern_fib_cache_ht);
 	rhashtable_destroy(&sw->router->fib_ht);
 	rhashtable_destroy(&sw->router->nexthop_group_ht);
 
@@ -2793,7 +3085,7 @@ static u32 mvsw_pr_fix_tb_id(u32 tb_id)
 	return tb_id;
 }
 
-static struct mvsw_pr_vr *__mvsw_pr_vr_find(struct mvsw_pr_switch *sw,
+static struct mvsw_pr_vr *__mvsw_pr_vr_find(struct prestera_switch *sw,
 					    u32 tb_id)
 {
 	struct mvsw_pr_vr *vr;
@@ -2806,7 +3098,7 @@ static struct mvsw_pr_vr *__mvsw_pr_vr_find(struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static struct mvsw_pr_vr *__mvsw_pr_vr_create(struct mvsw_pr_switch *sw,
+static struct mvsw_pr_vr *__mvsw_pr_vr_create(struct prestera_switch *sw,
 					      u32 tb_id,
 					      struct netlink_ext_ack *extack)
 {
@@ -2837,7 +3129,7 @@ static struct mvsw_pr_vr *__mvsw_pr_vr_create(struct mvsw_pr_switch *sw,
 	return ERR_PTR(err);
 }
 
-static void __mvsw_pr_vr_destroy(struct mvsw_pr_switch *sw,
+static void __mvsw_pr_vr_destroy(struct prestera_switch *sw,
 				 struct mvsw_pr_vr *vr)
 {
 	mvsw_pr_hw_vr_delete(sw, vr->hw_vr_id);
@@ -2845,7 +3137,7 @@ static void __mvsw_pr_vr_destroy(struct mvsw_pr_switch *sw,
 	kfree(vr);
 }
 
-static struct mvsw_pr_vr *mvsw_pr_vr_get(struct mvsw_pr_switch *sw, u32 tb_id,
+static struct mvsw_pr_vr *mvsw_pr_vr_get(struct prestera_switch *sw, u32 tb_id,
 					 struct netlink_ext_ack *extack)
 {
 	struct mvsw_pr_vr *vr;
@@ -2859,13 +3151,13 @@ static struct mvsw_pr_vr *mvsw_pr_vr_get(struct mvsw_pr_switch *sw, u32 tb_id,
 	return vr;
 }
 
-static void mvsw_pr_vr_put(struct mvsw_pr_switch *sw, struct mvsw_pr_vr *vr)
+static void mvsw_pr_vr_put(struct prestera_switch *sw, struct mvsw_pr_vr *vr)
 {
 	if (!vr->ref_cnt)
 		__mvsw_pr_vr_destroy(sw, vr);
 }
 
-static void mvsw_pr_vr_util_hw_abort(struct mvsw_pr_switch *sw)
+static void mvsw_pr_vr_util_hw_abort(struct prestera_switch *sw)
 {
 	struct mvsw_pr_vr *vr, *vr_tmp;
 
@@ -2874,12 +3166,12 @@ static void mvsw_pr_vr_util_hw_abort(struct mvsw_pr_switch *sw)
 		mvsw_pr_hw_vr_abort(sw, vr->hw_vr_id);
 }
 
-static struct mvsw_pr_rif*
-mvsw_pr_rif_alloc(struct mvsw_pr_switch *sw,
+static struct prestera_rif*
+mvsw_pr_rif_alloc(struct prestera_switch *sw,
 		  struct mvsw_pr_vr *vr,
 		  const struct mvsw_pr_rif_params *params)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 	int err;
 
 	rif = kzalloc(sizeof(*rif), GFP_KERNEL);
@@ -2906,19 +3198,19 @@ mvsw_pr_rif_alloc(struct mvsw_pr_switch *sw,
 	return ERR_PTR(err);
 }
 
-static int mvsw_pr_rif_offload(struct mvsw_pr_rif *rif)
+static int mvsw_pr_rif_offload(struct prestera_rif *rif)
 {
 	return mvsw_pr_hw_rif_create(rif->sw, &rif->iface, rif->addr,
 				     &rif->rif_id);
 }
 
-static struct mvsw_pr_rif *mvsw_pr_rif_create(struct mvsw_pr_switch *sw,
-					      const struct mvsw_pr_rif_params
-					      *params,
-					      struct netlink_ext_ack *extack)
+static struct prestera_rif *mvsw_pr_rif_create(struct prestera_switch *sw,
+					       const struct mvsw_pr_rif_params
+					       *params,
+					       struct netlink_ext_ack *extack)
 {
 	u32 tb_id = mvsw_pr_fix_tb_id(l3mdev_fib_table(params->dev));
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 	struct mvsw_pr_vr *vr;
 	int err;
 
@@ -2950,12 +3242,12 @@ static struct mvsw_pr_rif *mvsw_pr_rif_create(struct mvsw_pr_switch *sw,
 	return ERR_PTR(err);
 }
 
-static int mvsw_pr_rif_delete(struct mvsw_pr_rif *rif)
+static int mvsw_pr_rif_delete(struct prestera_rif *rif)
 {
 	return mvsw_pr_hw_rif_delete(rif->sw, rif->rif_id, &rif->iface);
 }
 
-static void mvsw_pr_rif_destroy(struct mvsw_pr_rif *rif)
+static void mvsw_pr_rif_destroy(struct prestera_rif *rif)
 {
 	mvsw_pr_rif_macvlan_flush(rif);
 	if (!rif->is_active) {
@@ -2968,16 +3260,16 @@ static void mvsw_pr_rif_destroy(struct mvsw_pr_rif *rif)
 	}
 }
 
-static void mvsw_pr_rif_put(struct mvsw_pr_rif *rif)
+static void mvsw_pr_rif_put(struct prestera_rif *rif)
 {
-	if (!rif->ref_cnt)
+	if (!rif->ref_cnt && !rif->is_active)
 		mvsw_pr_rif_destroy(rif);
 }
 
-void mvsw_pr_rif_enable(struct mvsw_pr_switch *sw,
-			struct net_device *dev, bool enable)
+void prestera_rif_enable(struct prestera_switch *sw,
+			 struct net_device *dev, bool enable)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	rif = mvsw_pr_rif_find(sw, dev);
 	if (!rif)
@@ -2989,13 +3281,13 @@ void mvsw_pr_rif_enable(struct mvsw_pr_switch *sw,
 		mvsw_pr_rif_delete(rif);
 }
 
-static int mvsw_pr_rif_update(struct mvsw_pr_rif *rif, char *mac)
+static int mvsw_pr_rif_update(struct prestera_rif *rif, char *mac)
 {
 	return mvsw_pr_hw_rif_set(rif->sw, &rif->rif_id, &rif->iface, mac);
 }
 
-static int mvsw_pr_rif_vr_update(struct mvsw_pr_switch *sw,
-				 struct mvsw_pr_rif *rif,
+static int mvsw_pr_rif_vr_update(struct prestera_switch *sw,
+				 struct prestera_rif *rif,
 				 struct netlink_ext_ack *extack)
 {
 	u32 tb_id = mvsw_pr_fix_tb_id(l3mdev_fib_table(rif->dev));
@@ -3015,10 +3307,10 @@ static int mvsw_pr_rif_vr_update(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-void mvsw_pr_router_lag_member_leave(const struct mvsw_pr_port *port,
-				     const struct net_device *dev)
+void prestera_router_lag_member_leave(const struct prestera_port *port,
+				      const struct net_device *dev)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 	u16 vr_id;
 
 	rif = mvsw_pr_rif_find(port->sw, dev);
@@ -3029,10 +3321,10 @@ void mvsw_pr_router_lag_member_leave(const struct mvsw_pr_port *port,
 	prestera_lag_member_rif_leave(port, port->lag_id, vr_id);
 }
 
-void prestera_lag_router_leave(struct mvsw_pr_switch *sw,
+void prestera_lag_router_leave(struct prestera_switch *sw,
 			       struct net_device *lag_dev)
 {
-	struct mvsw_pr_rif *rif;
+	struct prestera_rif *rif;
 
 	rif = mvsw_pr_rif_find(sw, lag_dev);
 	if (rif) {
@@ -3041,29 +3333,40 @@ void prestera_lag_router_leave(struct mvsw_pr_switch *sw,
 	}
 }
 
-static int mvsw_pr_bridge_device_rif_put(struct net_device *bridge_dev,
-					struct netdev_nested_priv *priv)
+static int mvsw_pr_bridge_device_rif_put(struct net_device *dev,
+					 struct netdev_nested_priv *priv)
 {
-	struct mvsw_pr_rif *rif;
-	struct mvsw_pr_switch *sw = priv->data;
+	struct prestera_switch *sw = priv->data;
+	struct prestera_rif *rif;
 
-	rif = mvsw_pr_rif_find(sw, bridge_dev);
+	rif = mvsw_pr_rif_find(sw, dev);
 	if (rif) {
+		/* Hold refcnt, because "is_active = false" may cause freeing */
+		rif->ref_cnt++;
 		rif->is_active = false;
+		mvsw_pr_k_arb_rif_evt(sw, rif);
+		rif->ref_cnt--;
 		mvsw_pr_rif_put(rif);
 	}
 
 	return 0;
 }
 
-void mvsw_pr_bridge_device_rifs_destroy(struct mvsw_pr_switch *sw,
-					struct net_device *bridge_dev)
+void prestera_bridge_device_rifs_destroy(struct prestera_switch *sw,
+					 struct net_device *bridge_dev)
 {
 	struct netdev_nested_priv priv = {
 		.data = (void *)sw,
 	};
+
 	mvsw_pr_bridge_device_rif_put(bridge_dev, &priv);
 	netdev_walk_all_upper_dev_rcu(bridge_dev,
 				      mvsw_pr_bridge_device_rif_put,
 				      &priv);
 }
+
+struct prestera_neigh_info *
+prestera_kern_neigh_cache_to_neigh_info(struct prestera_kern_neigh_cache *nc)
+{
+	return &nc->nh_neigh_info;
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
index 50b811e..8c877aa 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
@@ -1,93 +1,259 @@
 // SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/*
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
-#include "prestera.h"
-#include "prestera_rxtx_priv.h"
-#include "prestera_dsa.h"
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
 
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/dmapool.h>
 #include <linux/if_vlan.h>
 #include <net/ip.h>
 
+#include "prestera.h"
+#include "prestera_hw.h"
+#include "prestera_dsa.h"
+#include "prestera_rxtx.h"
+#include "prestera_devlink.h"
+
 #define MVSW_DSA_TAG_ARP_BROADCAST 5
 #define MVSW_DSA_TAG_IPV4_BROADCAST 19
+#define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC 16
 #define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_1 29
 #define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_2 30
 #define MVSW_DSA_TAG_UDP_BROADCAST 33
 #define MVSW_DSA_TAG_ARP_BROADCAST_TO_ME 179
 
-struct mvsw_pr_rxtx;
+struct mvsw_sdma_desc {
+	__le32 word1;
+	__le32 word2;
+	__le32 buff;
+	__le32 next;
+} __packed __aligned(16);
+
+#define SDMA_BUFF_SIZE_MAX	1544
+
+#define SDMA_RX_DESC_PKT_LEN(desc) \
+	((le32_to_cpu((desc)->word2) >> 16) & 0x3FFF)
+
+#define SDMA_RX_DESC_OWNER(desc) \
+	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
+
+#define SDMA_RX_DESC_CPU_OWN	0
+#define SDMA_RX_DESC_DMA_OWN	1
+
+#define SDMA_RX_QUEUE_NUM	8
+
+#define SDMA_RX_DESC_PER_Q	1000
+
+#define SDMA_TX_DESC_PER_Q	1000
+#define SDMA_TX_MAX_BURST	32
+
+#define SDMA_TX_DESC_OWNER(desc) \
+	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
+
+#define SDMA_TX_DESC_CPU_OWN	0
+#define SDMA_TX_DESC_DMA_OWN	1
+
+#define SDMA_TX_DESC_IS_SENT(desc) \
+	(SDMA_TX_DESC_OWNER(desc) == SDMA_TX_DESC_CPU_OWN)
+
+#define SDMA_TX_DESC_LAST	BIT(20)
+#define SDMA_TX_DESC_FIRST	BIT(21)
+#define SDMA_TX_DESC_SINGLE	(SDMA_TX_DESC_FIRST | SDMA_TX_DESC_LAST)
+#define SDMA_TX_DESC_CALC_CRC	BIT(12)
+
+#define mvsw_reg_write(sw, reg, val) \
+	writel(val, (sw)->dev->pp_regs + (reg))
+#define mvsw_reg_read(sw, reg) \
+	readl((sw)->dev->pp_regs + (reg))
+
+#define SDMA_RX_INTR_MASK_REG		0x2814
+#define SDMA_RX_QUEUE_STATUS_REG	0x2680
+#define SDMA_RX_QUEUE_DESC_REG(n)	(0x260C + (n) * 16)
+
+#define SDMA_TX_QUEUE_DESC_REG		0x26C0
+#define SDMA_TX_QUEUE_START_REG		0x2868
+
+struct mvsw_sdma_buf {
+	struct mvsw_sdma_desc *desc;
+	dma_addr_t desc_dma;
+	struct sk_buff *skb;
+	dma_addr_t buf_dma;
+	bool is_used;
+};
+
+struct mvsw_sdma_rx_ring {
+	struct mvsw_sdma_buf *bufs;
+	int next_rx;
+	int weight;
+	int recvd;
+};
+
+struct mvsw_sdma_tx_ring {
+	struct mvsw_sdma_buf *bufs;
+	int next_tx;
+	int max_burst;
+	int burst;
+};
 
-enum mvsw_pr_rxtx_type {
-	MVSW_PR_RXTX_MVPP,
-	MVSW_PR_RXTX_ETH,
-	MVSW_PR_RXTX_SDMA,
+struct mvsw_pr_rxtx_sdma {
+	struct mvsw_sdma_rx_ring rx_ring[SDMA_RX_QUEUE_NUM];
+	struct mvsw_sdma_tx_ring tx_ring;
+	const struct prestera_switch *sw;
+	struct dma_pool *desc_pool;
+	struct work_struct tx_work;
+	struct napi_struct rx_napi;
+	int next_rxq;
+	struct net_device napi_dev;
+	/* protect SDMA with concurrrent access from multiple CPUs */
+	spinlock_t tx_lock;
+	u32 map_addr;
+	u64 dma_mask;
 };
 
-static struct mvsw_pr_rxtx *rxtx_registered;
+struct prestera_rxtx {
+	struct mvsw_pr_rxtx_sdma sdma;
+};
+
+static int prestera_rx_weight_map[SDMA_RX_QUEUE_NUM] = {
+	1, 2, 2, 2, 2, 4, 4, 8
+};
 
 static u64 *cpu_code_stats;
 
-netdev_tx_t mvsw_pr_rxtx_xmit(struct sk_buff *skb,
-			      struct mvsw_pr_rxtx_info *info)
+static int mvsw_sdma_buf_desc_alloc(struct mvsw_pr_rxtx_sdma *sdma,
+				    struct mvsw_sdma_buf *buf)
 {
-	struct mvsw_pr_dsa dsa;
-	struct mvsw_pr_dsa_from_cpu *from_cpu;
-	struct net_device *dev = skb->dev;
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	size_t dsa_resize_len = MVSW_PR_DSA_HLEN;
+	struct device *dma_dev = sdma->sw->dev->dev;
+	struct mvsw_sdma_desc *desc;
+	dma_addr_t dma;
 
-	if (!rxtx_registered)
-		return NET_XMIT_DROP;
+	desc = dma_pool_alloc(sdma->desc_pool, GFP_DMA | GFP_KERNEL, &dma);
+	if (!desc)
+		return -ENOMEM;
 
-	/* common DSA tag fill-up */
-	memset(&dsa, 0, sizeof(dsa));
-	dsa.dsa_cmd = MVSW_NET_DSA_CMD_FROM_CPU_E;
+	if (dma + sizeof(struct mvsw_sdma_desc) > sdma->dma_mask) {
+		dev_err(dma_dev, "failed to alloc desc\n");
+		dma_pool_free(sdma->desc_pool, desc, dma);
+		return -ENOMEM;
+	}
 
-	from_cpu = &dsa.dsa_info.from_cpu;
-	from_cpu->egr_filter_en = false;
-	from_cpu->egr_filter_registered = false;
-	from_cpu->dst_eport = port->hw_id;
+	buf->desc_dma = dma;
+	buf->desc = desc;
 
-	from_cpu->dst_iface.dev_port.port_num = port->hw_id;
-	from_cpu->dst_iface.dev_port.hw_dev_num = port->dev_id;
-	from_cpu->dst_iface.type = MVSW_IF_PORT_E;
+	return 0;
+}
 
-	/* epmorary removing due to issue with vlan sub interface
-	 * on 1.Q bridge
-	 */
-	/* If (skb->protocol == htons(ETH_P_8021Q)) { */
-		/* 802.1q packet tag size is 4 bytes, so DSA len would
-		 * need only allocation of MVSW_PR_DSA_HLEN - size of
-		 * 802.1q tag
-		 */
-		/*dsa.common_params.vpt = skb_vlan_tag_get_prio(skb);
-		 * dsa.common_params.cfi_bit = skb_vlan_tag_get_cfi(skb);
-		 * dsa.common_params.vid = skb_vlan_tag_get_id(skb);
-		 * dsa_resize_len -= VLAN_HLEN;
-		 */
-	/* } */
+static u32 mvsw_sdma_addr_phy(struct mvsw_pr_rxtx_sdma *sdma, dma_addr_t pa)
+{
+	return sdma->map_addr + pa;
+}
 
+static void mvsw_sdma_rx_desc_set_len(struct mvsw_sdma_desc *desc, size_t val)
+{
+	u32 word = le32_to_cpu(desc->word2);
 
-	if (skb_cow_head(skb, dsa_resize_len) < 0)
-		return NET_XMIT_DROP;
+	word = (word & ~GENMASK(15, 0)) | val;
+	desc->word2 = cpu_to_le32(word);
+}
 
-	/* expects skb->data at mac header */
-	skb_push(skb, dsa_resize_len);
-	memmove(skb->data, skb->data + dsa_resize_len, 2 * ETH_ALEN);
+static void mvsw_sdma_rx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_desc *desc,
+				   dma_addr_t buf)
+{
+	mvsw_sdma_rx_desc_set_len(desc, SDMA_BUFF_SIZE_MAX);
+	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
+	/* make sure buffer is set before reset the descriptor */
+	wmb();
+	desc->word1 = cpu_to_le32(0xA0000000);
+}
 
-	if (mvsw_pr_dsa_build(&dsa, skb->data + 2 * ETH_ALEN) != 0)
-		return NET_XMIT_DROP;
+static void mvsw_sdma_rx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
+				       struct mvsw_sdma_desc *desc,
+				       dma_addr_t next)
+{
+	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
+}
+
+static int mvsw_sdma_rx_dma_alloc(struct mvsw_pr_rxtx_sdma *sdma,
+				  struct mvsw_sdma_buf *buf)
+{
+	struct device *dev = sdma->sw->dev->dev;
+
+	buf->skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_DMA | GFP_ATOMIC);
+	if (!buf->skb)
+		return -ENOMEM;
+
+	buf->buf_dma = dma_map_single(dev, buf->skb->data, buf->skb->len,
+				      DMA_FROM_DEVICE);
 
-	return rxtx_registered->ops->rxtx_xmit(rxtx_registered, skb);
+	if (dma_mapping_error(dev, buf->buf_dma))
+		goto err_dma_map;
+	if (buf->buf_dma + buf->skb->len > sdma->dma_mask)
+		goto err_dma_range;
+
+	return 0;
+
+err_dma_range:
+	dma_unmap_single(dev, buf->buf_dma, buf->skb->len, DMA_FROM_DEVICE);
+	buf->buf_dma = DMA_MAPPING_ERROR;
+err_dma_map:
+	kfree_skb(buf->skb);
+	buf->skb = NULL;
+
+	return -ENOMEM;
+}
+
+static struct sk_buff *mvsw_sdma_rx_buf_get(struct mvsw_pr_rxtx_sdma *sdma,
+					    struct mvsw_sdma_buf *buf)
+{
+	struct sk_buff *skb_orig = buf->skb;
+	dma_addr_t buf_dma = buf->buf_dma;
+	u32 len = skb_orig->len;
+	int err;
+
+	err = mvsw_sdma_rx_dma_alloc(sdma, buf);
+	if (err) {
+		struct sk_buff *skb;
+
+		buf->buf_dma = buf_dma;
+		buf->skb = skb_orig;
+
+		skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_ATOMIC);
+		if (!skb)
+			return NULL;
+
+		skb_copy_from_linear_data(buf->skb, skb_put(skb, len), len);
+		return skb;
+	}
+
+	return skb_orig;
+}
+
+static void mvsw_sdma_rx_set_next_queue(struct mvsw_pr_rxtx_sdma *sdma, int rxq)
+{
+	sdma->next_rxq = rxq % SDMA_RX_QUEUE_NUM;
+}
+
+static int mvsw_sdma_rx_pick_next_queue(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[sdma->next_rxq];
+
+	if (ring->recvd >= ring->weight) {
+		mvsw_sdma_rx_set_next_queue(sdma, sdma->next_rxq + 1);
+		ring->recvd = 0;
+	}
+
+	return sdma->next_rxq;
 }
 
-int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb)
+static int mvsw_pr_sdma_recv_skb(struct sk_buff *skb)
 {
-	const struct mvsw_pr_port *port;
+	struct prestera_rxtx_stats *rxtx_stats;
+	struct prestera_port *port;
 	struct mvsw_pr_dsa dsa;
 	u32 hw_port, hw_id;
+	u8 cpu_code;
 	int err;
 
 	skb_pull(skb, ETH_HLEN);
@@ -102,7 +268,7 @@ int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb)
 	/* get switch port */
 	hw_port = dsa.dsa_info.to_cpu.iface.port_num;
 	hw_id = dsa.dsa_info.to_cpu.hw_dev_num;
-	port = mvsw_pr_port_find(hw_id, hw_port);
+	port = prestera_port_find(hw_id, hw_port);
 	if (unlikely(!port)) {
 		pr_warn_ratelimited("prestera: received pkt for non-existent port(%u, %u)\n",
 				    hw_id, hw_port);
@@ -132,88 +298,628 @@ int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb)
 		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), tci);
 	}
 
-	switch (dsa.dsa_info.to_cpu.cpu_code) {
+	cpu_code = dsa.dsa_info.to_cpu.cpu_code;
+
+	prestera_devlink_trap_report(port, skb, cpu_code);
+
+	switch (cpu_code) {
 	case MVSW_DSA_TAG_ARP_BROADCAST:
 	case MVSW_DSA_TAG_IPV4_BROADCAST:
+	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC:
 	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_1:
 	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_2:
 	case MVSW_DSA_TAG_UDP_BROADCAST:
 	case MVSW_DSA_TAG_ARP_BROADCAST_TO_ME:
 		skb->offload_fwd_mark = 1;
 	}
-	++cpu_code_stats[dsa.dsa_info.to_cpu.cpu_code];
+	++cpu_code_stats[cpu_code];
+
+	rxtx_stats = this_cpu_ptr(port->rxtx_stats);
+	u64_stats_update_begin(&rxtx_stats->syncp);
+	rxtx_stats->rx_packets++;
+	rxtx_stats->rx_bytes += skb->len;
+	u64_stats_update_end(&rxtx_stats->syncp);
 
 	return 0;
 }
 
-static struct mvsw_pr_rxtx_ops rxtx_driver_ops[] = {
-	[MVSW_PR_RXTX_SDMA] = {
-		.rxtx_init = mvsw_pr_rxtx_sdma_init,
-		.rxtx_fini = mvsw_pr_rxtx_sdma_fini,
-		.rxtx_switch_init = mvsw_pr_rxtx_sdma_switch_init,
-		.rxtx_switch_fini = mvsw_pr_rxtx_sdma_switch_fini,
-		.rxtx_xmit = mvsw_pr_rxtx_sdma_xmit,
-	},
-};
+static int mvsw_sdma_rx_poll(struct napi_struct *napi, int budget)
+{
+	unsigned int qmask = GENMASK(SDMA_RX_QUEUE_NUM - 1, 0);
+	struct mvsw_pr_rxtx_sdma *sdma;
+	unsigned int rxq_done_map = 0;
+	struct list_head rx_list;
+	int pkts_done = 0;
+
+	INIT_LIST_HEAD(&rx_list);
+
+	sdma = container_of(napi, struct mvsw_pr_rxtx_sdma, rx_napi);
+
+	while (pkts_done < budget && rxq_done_map != qmask) {
+		struct mvsw_sdma_rx_ring *ring;
+		struct mvsw_sdma_desc *desc;
+		struct mvsw_sdma_buf *buf;
+		struct sk_buff *skb;
+		int buf_idx;
+		int rxq;
+
+		rxq = mvsw_sdma_rx_pick_next_queue(sdma);
+		ring = &sdma->rx_ring[rxq];
+
+		buf_idx = ring->next_rx;
+		buf = &ring->bufs[buf_idx];
+		desc = buf->desc;
+
+		if (SDMA_RX_DESC_OWNER(desc) != SDMA_RX_DESC_CPU_OWN) {
+			mvsw_sdma_rx_set_next_queue(sdma, rxq + 1);
+			rxq_done_map |= BIT(rxq);
+			continue;
+		} else {
+			rxq_done_map &= ~BIT(rxq);
+		}
+
+		ring->recvd++;
+		pkts_done++;
+
+		__skb_trim(buf->skb, SDMA_RX_DESC_PKT_LEN(desc));
+
+		skb = mvsw_sdma_rx_buf_get(sdma, buf);
+		if (!skb)
+			goto rx_reset_buf;
+
+		if (unlikely(mvsw_pr_sdma_recv_skb(skb)))
+			goto rx_reset_buf;
+
+		list_add_tail(&skb->list, &rx_list);
+rx_reset_buf:
+		mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
+		ring->next_rx = (buf_idx + 1) % SDMA_RX_DESC_PER_Q;
+	}
+
+	if (pkts_done < budget && napi_complete_done(napi, pkts_done))
+		mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0xff << 2);
 
-int mvsw_pr_rxtx_init(void)
+	netif_receive_skb_list(&rx_list);
+
+	return pkts_done;
+}
+
+static void mvsw_sdma_rx_fini(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	cpu_code_stats = kzalloc(sizeof(u64) * MVSW_PR_RXTX_CPU_CODE_MAX_NUM,
-				 GFP_KERNEL);
-	if (!cpu_code_stats)
+	int q, b;
+
+	/* disable all rx queues */
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
+
+	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
+		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
+
+		if (!ring->bufs)
+			break;
+
+		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
+			struct mvsw_sdma_buf *buf = &ring->bufs[b];
+
+			if (buf->desc_dma)
+				dma_pool_free(sdma->desc_pool, buf->desc,
+					      buf->desc_dma);
+
+			if (!buf->skb)
+				continue;
+
+			if (buf->buf_dma != DMA_MAPPING_ERROR)
+				dma_unmap_single(sdma->sw->dev->dev,
+						 buf->buf_dma, buf->skb->len,
+						 DMA_FROM_DEVICE);
+			kfree_skb(buf->skb);
+		}
+	}
+}
+
+static int mvsw_sdma_rx_init(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	int q, b;
+	int err;
+
+	/* disable all rx queues */
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
+
+	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
+		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
+		struct mvsw_sdma_buf *head;
+
+		ring->bufs = kmalloc_array(SDMA_RX_DESC_PER_Q, sizeof(*head),
+					   GFP_KERNEL);
+		if (!ring->bufs)
+			return -ENOMEM;
+
+		ring->weight = prestera_rx_weight_map[q];
+		ring->recvd = 0;
+		ring->next_rx = 0;
+
+		head = &ring->bufs[0];
+
+		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
+			struct mvsw_sdma_buf *buf = &ring->bufs[b];
+
+			err = mvsw_sdma_buf_desc_alloc(sdma, buf);
+			if (err)
+				return err;
+
+			err = mvsw_sdma_rx_dma_alloc(sdma, buf);
+			if (err)
+				return err;
+
+			mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
+
+			if (b == 0)
+				continue;
+
+			mvsw_sdma_rx_desc_set_next(sdma, ring->bufs[b - 1].desc,
+						   buf->desc_dma);
+
+			if (b == SDMA_RX_DESC_PER_Q - 1)
+				mvsw_sdma_rx_desc_set_next(sdma, buf->desc,
+							   head->desc_dma);
+		}
+
+		mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_DESC_REG(q),
+			       mvsw_sdma_addr_phy(sdma, head->desc_dma));
+	}
+
+	/* make sure all rx descs are filled before enabling all rx queues */
+	wmb();
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff);
+
+	return 0;
+}
+
+static void mvsw_sdma_tx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_desc *desc)
+{
+	desc->word1 = cpu_to_le32(SDMA_TX_DESC_SINGLE | SDMA_TX_DESC_CALC_CRC);
+	desc->word2 = 0;
+}
+
+static void mvsw_sdma_tx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
+				       struct mvsw_sdma_desc *desc,
+				       dma_addr_t next)
+{
+	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
+}
+
+static void mvsw_sdma_tx_desc_set_buf(struct mvsw_pr_rxtx_sdma *sdma,
+				      struct mvsw_sdma_desc *desc,
+				      dma_addr_t buf, size_t len)
+{
+	u32 word = le32_to_cpu(desc->word2);
+
+	word = (word & ~GENMASK(30, 16)) | ((len + 4) << 16);
+
+	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
+	desc->word2 = cpu_to_le32(word);
+}
+
+static void mvsw_sdma_tx_desc_xmit(struct mvsw_sdma_desc *desc)
+{
+	u32 word = le32_to_cpu(desc->word1);
+
+	word |= (SDMA_TX_DESC_DMA_OWN << 31);
+
+	/* make sure everything is written before enable xmit */
+	wmb();
+	desc->word1 = cpu_to_le32(word);
+}
+
+static int mvsw_sdma_tx_buf_map(struct mvsw_pr_rxtx_sdma *sdma,
+				struct mvsw_sdma_buf *buf,
+				struct sk_buff *skb)
+{
+	struct device *dma_dev = sdma->sw->dev->dev;
+	struct sk_buff *new_skb;
+	size_t len = skb->len;
+	dma_addr_t dma;
+
+	dma = dma_map_single(dma_dev, skb->data, len, DMA_TO_DEVICE);
+	if (!dma_mapping_error(dma_dev, dma) && dma + len <= sdma->dma_mask) {
+		buf->buf_dma = dma;
+		buf->skb = skb;
+		return 0;
+	}
+
+	if (!dma_mapping_error(dma_dev, dma))
+		dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
+
+	new_skb = alloc_skb(len, GFP_ATOMIC | GFP_DMA);
+	if (!new_skb)
+		goto err_alloc_skb;
+
+	dma = dma_map_single(dma_dev, new_skb->data, len, DMA_TO_DEVICE);
+	if (dma_mapping_error(dma_dev, dma))
+		goto err_dma_map;
+	if (dma + len > sdma->dma_mask)
+		goto err_dma_range;
+
+	skb_copy_from_linear_data(skb, skb_put(new_skb, len), len);
+
+	dev_consume_skb_any(skb);
+
+	buf->skb = new_skb;
+	buf->buf_dma = dma;
+
+	return 0;
+
+err_dma_range:
+	dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
+err_dma_map:
+	dev_kfree_skb(new_skb);
+err_alloc_skb:
+	dev_kfree_skb(skb);
+
+	return -ENOMEM;
+}
+
+static void mvsw_sdma_tx_buf_unmap(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_buf *buf)
+{
+	struct device *dma_dev = sdma->sw->dev->dev;
+
+	dma_unmap_single(dma_dev, buf->buf_dma, buf->skb->len, DMA_TO_DEVICE);
+}
+
+static void mvsw_sdma_tx_recycle_work_fn(struct work_struct *work)
+{
+	struct mvsw_sdma_tx_ring *tx_ring;
+	struct mvsw_pr_rxtx_sdma *sdma;
+	struct device *dma_dev;
+	int b;
+
+	sdma = container_of(work, struct mvsw_pr_rxtx_sdma, tx_work);
+
+	dma_dev = sdma->sw->dev->dev;
+	tx_ring = &sdma->tx_ring;
+
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
+
+		if (!buf->is_used)
+			continue;
+
+		if (!SDMA_TX_DESC_IS_SENT(buf->desc))
+			continue;
+
+		mvsw_sdma_tx_buf_unmap(sdma, buf);
+		dev_consume_skb_any(buf->skb);
+		buf->skb = NULL;
+
+		/* make sure everything is cleaned up */
+		wmb();
+
+		buf->is_used = false;
+	}
+}
+
+static int mvsw_sdma_tx_init(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	struct mvsw_sdma_tx_ring *tx_ring = &sdma->tx_ring;
+	struct mvsw_sdma_buf *head;
+	int err;
+	int b;
+
+	spin_lock_init(&sdma->tx_lock);
+
+	INIT_WORK(&sdma->tx_work, mvsw_sdma_tx_recycle_work_fn);
+
+	tx_ring->bufs = kmalloc_array(SDMA_TX_DESC_PER_Q, sizeof(*head),
+				      GFP_KERNEL);
+	if (!tx_ring->bufs)
 		return -ENOMEM;
 
-	rxtx_registered = kzalloc(sizeof(*rxtx_registered), GFP_KERNEL);
-	if (!rxtx_registered) {
-		kfree(cpu_code_stats);
+	head = &tx_ring->bufs[0];
+
+	tx_ring->max_burst = SDMA_TX_MAX_BURST;
+	tx_ring->burst = tx_ring->max_burst;
+	tx_ring->next_tx = 0;
+
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
+
+		err = mvsw_sdma_buf_desc_alloc(sdma, buf);
+		if (err)
+			return err;
+
+		mvsw_sdma_tx_desc_init(sdma, buf->desc);
+
+		buf->is_used = false;
+		buf->skb = NULL;
+
+		if (b == 0)
+			continue;
+
+		mvsw_sdma_tx_desc_set_next(sdma, tx_ring->bufs[b - 1].desc,
+					   buf->desc_dma);
+
+		if (b == SDMA_TX_DESC_PER_Q - 1)
+			mvsw_sdma_tx_desc_set_next(sdma, buf->desc,
+						   head->desc_dma);
+	}
+
+	/* make sure descriptors are written */
+	wmb();
+	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_DESC_REG,
+		       mvsw_sdma_addr_phy(sdma, head->desc_dma));
+
+	return 0;
+}
+
+static void mvsw_sdma_tx_fini(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	struct mvsw_sdma_tx_ring *ring = &sdma->tx_ring;
+	int b;
+
+	cancel_work_sync(&sdma->tx_work);
+
+	if (!ring->bufs)
+		return;
+
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &ring->bufs[b];
+
+		if (buf->desc)
+			dma_pool_free(sdma->desc_pool, buf->desc,
+				      buf->desc_dma);
+
+		if (!buf->skb)
+			continue;
+
+		dma_unmap_single(sdma->sw->dev->dev, buf->buf_dma,
+				 buf->skb->len, DMA_TO_DEVICE);
+
+		dev_consume_skb_any(buf->skb);
+	}
+}
+
+static void mvsw_rxtx_handle_event(struct prestera_switch *sw,
+				   struct prestera_event *evt, void *arg)
+{
+	struct mvsw_pr_rxtx_sdma *sdma = arg;
+
+	if (evt->id != MVSW_RXTX_EVENT_RCV_PKT)
+		return;
+
+	mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0);
+	napi_schedule(&sdma->rx_napi);
+}
+
+int prestera_rxtx_switch_init(struct prestera_switch *sw)
+{
+	struct mvsw_pr_rxtx_sdma *sdma;
+	int err;
+
+	cpu_code_stats = kzalloc(sizeof(u64) *
+				 MVSW_PR_RXTX_CPU_CODE_MAX_NUM, GFP_KERNEL);
+	if (!cpu_code_stats)
 		return -ENOMEM;
+
+	sw->rxtx = kzalloc(sizeof(*sw->rxtx), GFP_KERNEL);
+	if (!sw->rxtx) {
+		err = -ENOMEM;
+		goto err_rxtx_alloc;
+	}
+
+	sdma = &sw->rxtx->sdma;
+
+	err = mvsw_pr_hw_rxtx_init(sw, true, &sdma->map_addr);
+	if (err) {
+		dev_err(sw->dev->dev, "failed to init rxtx by hw\n");
+		goto err_hw_rxtx_init;
+	}
+
+	sdma->dma_mask = dma_get_mask(sw->dev->dev);
+	sdma->sw = sw;
+
+	sdma->desc_pool = dma_pool_create("desc_pool", sdma->sw->dev->dev,
+					  sizeof(struct mvsw_sdma_desc), 16, 0);
+	if (!sdma->desc_pool) {
+		err = -ENOMEM;
+		goto err_dma_pool;
+	}
+
+	err = mvsw_sdma_rx_init(sdma);
+	if (err) {
+		dev_err(sw->dev->dev, "failed to init rx ring\n");
+		goto err_rx_init;
+	}
+
+	err = mvsw_sdma_tx_init(sdma);
+	if (err) {
+		dev_err(sw->dev->dev, "failed to init tx ring\n");
+		goto err_tx_init;
 	}
 
-	rxtx_registered->ops = &rxtx_driver_ops[MVSW_PR_RXTX_SDMA];
+	err = mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_RXTX,
+						mvsw_rxtx_handle_event, sdma);
+	if (err)
+		goto err_evt_register;
+
+	init_dummy_netdev(&sdma->napi_dev);
 
-	if (rxtx_registered->ops->rxtx_init)
-		return rxtx_registered->ops->rxtx_init(rxtx_registered);
+	netif_napi_add(&sdma->napi_dev, &sdma->rx_napi, mvsw_sdma_rx_poll, 64);
+	napi_enable(&sdma->rx_napi);
 
 	return 0;
+
+err_evt_register:
+err_tx_init:
+	mvsw_sdma_tx_fini(sdma);
+err_rx_init:
+	mvsw_sdma_rx_fini(sdma);
+
+	dma_pool_destroy(sdma->desc_pool);
+err_dma_pool:
+err_hw_rxtx_init:
+	kfree(sw->rxtx);
+err_rxtx_alloc:
+	kfree(cpu_code_stats);
+	return err;
 }
 
-void mvsw_pr_rxtx_fini(void)
+void prestera_rxtx_switch_fini(struct prestera_switch *sw)
 {
-	struct mvsw_pr_rxtx *rxtx = rxtx_registered;
+	struct mvsw_pr_rxtx_sdma *sdma = &sw->rxtx->sdma;
+
+	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_RXTX);
+	napi_disable(&sdma->rx_napi);
+	netif_napi_del(&sdma->rx_napi);
+	mvsw_sdma_rx_fini(sdma);
+	mvsw_sdma_tx_fini(sdma);
+	dma_pool_destroy(sdma->desc_pool);
+	kfree(sw->rxtx);
+	kfree(cpu_code_stats);
+}
 
-	if (rxtx->ops->rxtx_fini)
-		rxtx->ops->rxtx_fini(rxtx);
+static int mvsw_sdma_wait_tx(struct mvsw_pr_rxtx_sdma *sdma,
+			     struct mvsw_sdma_tx_ring *tx_ring)
+{
+	int tx_retry_num = 10 * tx_ring->max_burst;
 
-	kfree(rxtx_registered);
-	rxtx_registered = NULL;
-	kfree(cpu_code_stats);
+	while (--tx_retry_num) {
+		if (!(mvsw_reg_read(sdma->sw, SDMA_TX_QUEUE_START_REG) & 1))
+			return 0;
+
+		udelay(5);
+	}
+
+	return -EBUSY;
+}
+
+static void mvsw_sdma_start_tx(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_START_REG, 1);
+	schedule_work(&sdma->tx_work);
 }
 
-int mvsw_pr_rxtx_switch_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_rxtx_sdma_xmit(struct prestera_rxtx *rxtx,
+				  struct sk_buff *skb)
 {
+	struct mvsw_pr_rxtx_sdma *sdma = &rxtx->sdma;
+	struct device *dma_dev = sdma->sw->dev->dev;
+	struct mvsw_sdma_tx_ring *tx_ring;
+	struct net_device *dev = skb->dev;
+	struct mvsw_sdma_buf *buf;
 	int err;
 
-	if (!rxtx_registered) {
-		pr_info("No RxTx driver registered");
-		return 0;
+	spin_lock(&sdma->tx_lock);
+
+	tx_ring = &sdma->tx_ring;
+
+	buf = &tx_ring->bufs[tx_ring->next_tx];
+	if (buf->is_used) {
+		schedule_work(&sdma->tx_work);
+		err = -EBUSY;
+		goto drop_skb;
 	}
 
-	if (!rxtx_registered->ops->rxtx_switch_init)
-		return 0;
+	if (unlikely(skb_put_padto(skb, ETH_ZLEN))) {
+		err = -ENOMEM;
+		goto drop_skb;
+	}
 
-	err = rxtx_registered->ops->rxtx_switch_init(rxtx_registered, sw);
+	err = mvsw_sdma_tx_buf_map(sdma, buf, skb);
 	if (err)
-		return err;
+		goto drop_skb;
 
-	return 0;
+	mvsw_sdma_tx_desc_set_buf(sdma, buf->desc, buf->buf_dma, skb->len);
+
+	dma_sync_single_for_device(dma_dev, buf->buf_dma, skb->len,
+				   DMA_TO_DEVICE);
+
+	if (!tx_ring->burst--) {
+		tx_ring->burst = tx_ring->max_burst;
+
+		err = mvsw_sdma_wait_tx(sdma, tx_ring);
+		if (err)
+			goto drop_skb_unmap;
+	}
+
+	tx_ring->next_tx = (tx_ring->next_tx + 1) % SDMA_TX_DESC_PER_Q;
+	mvsw_sdma_tx_desc_xmit(buf->desc);
+	buf->is_used = true;
+
+	mvsw_sdma_start_tx(sdma);
+
+	goto tx_done;
+
+drop_skb_unmap:
+	mvsw_sdma_tx_buf_unmap(sdma, buf);
+drop_skb:
+	dev->stats.tx_dropped++;
+tx_done:
+	spin_unlock(&sdma->tx_lock);
+	return err;
 }
 
-void mvsw_pr_rxtx_switch_fini(struct mvsw_pr_switch *sw)
+netdev_tx_t prestera_rxtx_xmit(struct sk_buff *skb, struct prestera_port *port)
 {
-	if (!rxtx_registered || !rxtx_registered->ops->rxtx_switch_init)
-		return;
+	size_t dsa_resize_len = MVSW_PR_DSA_HLEN;
+	struct prestera_rxtx_stats *rxtx_stats;
+	struct mvsw_pr_dsa_from_cpu *from_cpu;
+	struct mvsw_pr_dsa dsa;
+	u64 skb_len = skb->len;
+
+	/* common DSA tag fill-up */
+	memset(&dsa, 0, sizeof(dsa));
+	dsa.dsa_cmd = MVSW_NET_DSA_CMD_FROM_CPU_E;
+
+	from_cpu = &dsa.dsa_info.from_cpu;
+	from_cpu->egr_filter_en = false;
+	from_cpu->egr_filter_registered = false;
+	from_cpu->dst_eport = port->hw_id;
+
+	from_cpu->dst_iface.dev_port.port_num = port->hw_id;
+	from_cpu->dst_iface.dev_port.hw_dev_num = port->dev_id;
+	from_cpu->dst_iface.type = MVSW_IF_PORT_E;
+
+	/* epmorary removing due to issue with vlan sub interface
+	 * on 1.Q bridge
+	 */
+	/* If (skb->protocol == htons(ETH_P_8021Q)) { */
+		/* 802.1q packet tag size is 4 bytes, so DSA len would
+		 * need only allocation of MVSW_PR_DSA_HLEN - size of
+		 * 802.1q tag
+		 */
+		/*dsa.common_params.vpt = skb_vlan_tag_get_prio(skb);
+		 * dsa.common_params.cfi_bit = skb_vlan_tag_get_cfi(skb);
+		 * dsa.common_params.vid = skb_vlan_tag_get_id(skb);
+		 * dsa_resize_len -= VLAN_HLEN;
+		 */
+	/* } */
+
+	if (skb_cow_head(skb, dsa_resize_len) < 0)
+		goto tx_drop;
+
+	/* expects skb->data at mac header */
+	skb_push(skb, dsa_resize_len);
+	memmove(skb->data, skb->data + dsa_resize_len, 2 * ETH_ALEN);
+
+	if (mvsw_pr_dsa_build(&dsa, skb->data + 2 * ETH_ALEN) != 0)
+		goto tx_drop;
+
+	if (mvsw_pr_rxtx_sdma_xmit(port->sw->rxtx, skb))
+		goto tx_drop;
+
+	rxtx_stats = this_cpu_ptr(port->rxtx_stats);
+	u64_stats_update_begin(&rxtx_stats->syncp);
+	rxtx_stats->tx_packets++;
+	rxtx_stats->tx_bytes += skb_len;
+	u64_stats_update_end(&rxtx_stats->syncp);
+
+	return NETDEV_TX_OK;
 
-	return rxtx_registered->ops->rxtx_switch_fini(rxtx_registered, sw);
+tx_drop:
+	dev_kfree_skb_any(skb);
+	this_cpu_inc(port->rxtx_stats->tx_dropped);
+	return NET_XMIT_DROP;
 }
 
 u64 mvsw_pr_rxtx_get_cpu_code_stats(u8 cpu_code)
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
index a105225..3bf1516 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
@@ -1,8 +1,5 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
 
 #ifndef _MVSW_PRESTERA_RXTX_H_
 #define _MVSW_PRESTERA_RXTX_H_
@@ -11,21 +8,12 @@
 
 #define MVSW_PR_RXTX_CPU_CODE_MAX_NUM	256
 
-struct mvsw_pr_switch;
+struct prestera_switch;
 
-struct mvsw_pr_rxtx_info {
-	u32 port_id;
-	u32 dev_id;
-};
+int prestera_rxtx_switch_init(struct prestera_switch *sw);
+void prestera_rxtx_switch_fini(struct prestera_switch *sw);
 
-int mvsw_pr_rxtx_init(void);
-void mvsw_pr_rxtx_fini(void);
-
-int mvsw_pr_rxtx_switch_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_rxtx_switch_fini(struct mvsw_pr_switch *sw);
-
-netdev_tx_t mvsw_pr_rxtx_xmit(struct sk_buff *skb,
-			      struct mvsw_pr_rxtx_info *info);
+netdev_tx_t prestera_rxtx_xmit(struct sk_buff *skb, struct prestera_port *port);
 
 u64 mvsw_pr_rxtx_get_cpu_code_stats(u8 cpu_code);
 
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_priv.h b/drivers/net/ethernet/marvell/prestera/prestera_rxtx_priv.h
deleted file mode 100644
index 13527b9..0000000
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_priv.h
+++ /dev/null
@@ -1,61 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
-#include <linux/kernel.h>
-#include <linux/netdevice.h>
-#include <linux/rtnetlink.h>
-#include <linux/platform_device.h>
-#include <linux/of.h>
-#include <linux/of_device.h>
-
-#include "prestera_rxtx.h"
-
-struct mvsw_pr_rxtx;
-
-struct mvsw_pr_rxtx_ops {
-	int (*rxtx_init)(struct mvsw_pr_rxtx *rxtx);
-	int (*rxtx_fini)(struct mvsw_pr_rxtx *rxtx);
-
-	int (*rxtx_switch_init)(struct mvsw_pr_rxtx *rxtx,
-				struct mvsw_pr_switch *sw);
-	void (*rxtx_switch_fini)(struct mvsw_pr_rxtx *rxtx,
-				 struct mvsw_pr_switch *sw);
-
-	netdev_tx_t (*rxtx_xmit)(struct mvsw_pr_rxtx *rxtx,
-				 struct sk_buff *skb);
-};
-
-struct mvsw_pr_rxtx {
-	struct platform_device *pdev;
-	struct device *dev;
-
-	const struct mvsw_pr_rxtx_ops *ops;
-	void *priv;
-};
-
-int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb);
-
-int mvsw_pr_rxtx_eth_init(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_eth_fini(struct mvsw_pr_rxtx *rxtx);
-netdev_tx_t mvsw_pr_rxtx_eth_xmit(struct mvsw_pr_rxtx *rxtx,
-				  struct sk_buff *skb);
-
-int mvsw_pr_rxtx_mvpp_init(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_mvpp_fini(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_eth_switch_init(struct mvsw_pr_rxtx *rxtx,
-				 struct mvsw_pr_switch *sw);
-void mvsw_pr_rxtx_eth_switch_fini(struct mvsw_pr_rxtx *rxtx,
-				  struct mvsw_pr_switch *sw);
-netdev_tx_t mvsw_pr_rxtx_mvpp_xmit(struct mvsw_pr_rxtx *rxtx,
-				   struct sk_buff *skb);
-
-int mvsw_pr_rxtx_sdma_init(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_sdma_fini(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_sdma_switch_init(struct mvsw_pr_rxtx *rxtx,
-				  struct mvsw_pr_switch *sw);
-void mvsw_pr_rxtx_sdma_switch_fini(struct mvsw_pr_rxtx *rxtx,
-				   struct mvsw_pr_switch *sw);
-netdev_tx_t mvsw_pr_rxtx_sdma_xmit(struct mvsw_pr_rxtx *rxtx,
-				   struct sk_buff *skb);
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_sdma.c b/drivers/net/ethernet/marvell/prestera/prestera_rxtx_sdma.c
deleted file mode 100644
index 9a65f3c..0000000
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_sdma.c
+++ /dev/null
@@ -1,769 +0,0 @@
-// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/*
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
-
-#include <linux/platform_device.h>
-#include <linux/of.h>
-#include <linux/of_address.h>
-#include <linux/of_device.h>
-#include <linux/dmapool.h>
-
-#include "prestera.h"
-#include "prestera_hw.h"
-#include "prestera_rxtx_priv.h"
-
-struct mvsw_sdma_desc {
-	__le32 word1;
-	__le32 word2;
-	__le32 buff;
-	__le32 next;
-} __packed __aligned(16);
-
-#define SDMA_BUFF_SIZE_MAX	1544
-
-#define SDMA_RX_DESC_PKT_LEN(desc) \
-	((le32_to_cpu((desc)->word2) >> 16) & 0x3FFF)
-
-#define SDMA_RX_DESC_OWNER(desc) \
-	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
-
-#define SDMA_RX_DESC_CPU_OWN	0
-#define SDMA_RX_DESC_DMA_OWN	1
-
-#define SDMA_RX_QUEUE_NUM	8
-
-#define SDMA_RX_DESC_PER_Q	1000
-
-#define SDMA_TX_DESC_PER_Q	1000
-#define SDMA_TX_MAX_BURST	32
-
-#define SDMA_TX_DESC_OWNER(desc) \
-	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
-
-#define SDMA_TX_DESC_CPU_OWN	0
-#define SDMA_TX_DESC_DMA_OWN	1
-
-#define SDMA_TX_DESC_IS_SENT(desc) \
-	(SDMA_TX_DESC_OWNER(desc) == SDMA_TX_DESC_CPU_OWN)
-
-#define SDMA_TX_DESC_LAST	BIT(20)
-#define SDMA_TX_DESC_FIRST	BIT(21)
-#define SDMA_TX_DESC_SINGLE	(SDMA_TX_DESC_FIRST | SDMA_TX_DESC_LAST)
-#define SDMA_TX_DESC_CALC_CRC	BIT(12)
-
-#define mvsw_reg_write(sw, reg, val) \
-	writel(val, (sw)->dev->pp_regs + (reg))
-#define mvsw_reg_read(sw, reg) \
-	readl((sw)->dev->pp_regs + (reg))
-
-#define SDMA_RX_INTR_MASK_REG		0x2814
-#define SDMA_RX_QUEUE_STATUS_REG	0x2680
-#define SDMA_RX_QUEUE_DESC_REG(n)	(0x260C + (n) * 16)
-
-#define SDMA_TX_QUEUE_DESC_REG		0x26C0
-#define SDMA_TX_QUEUE_START_REG		0x2868
-
-struct mvsw_sdma_buf {
-	struct mvsw_sdma_desc *desc;
-	dma_addr_t desc_dma;
-	struct sk_buff *skb;
-	dma_addr_t buf_dma;
-	bool is_used;
-};
-
-struct mvsw_sdma_rx_ring {
-	struct mvsw_sdma_buf *bufs;
-	int next_rx;
-	int weight;
-	int recvd;
-};
-
-struct mvsw_sdma_tx_ring {
-	struct mvsw_sdma_buf *bufs;
-	int next_tx;
-	int max_burst;
-	int burst;
-};
-
-struct mvsw_pr_rxtx_sdma {
-	struct mvsw_sdma_rx_ring rx_ring[SDMA_RX_QUEUE_NUM];
-	struct mvsw_sdma_tx_ring tx_ring;
-	const struct mvsw_pr_switch *sw;
-	struct dma_pool *desc_pool;
-	struct mvsw_pr_rxtx *rxtx;
-	struct work_struct tx_work;
-	struct napi_struct rx_napi;
-	int next_rxq;
-	struct net_device napi_dev;
-	/* protect SDMA with concurrrent access from multiple CPUs */
-	spinlock_t tx_lock;
-	u32 map_addr;
-	u64 dma_mask;
-};
-
-static int prestera_rx_weight_map[SDMA_RX_QUEUE_NUM] = {
-	1, 2, 2, 2, 2, 4, 4, 8
-};
-
-static int mvsw_sdma_buf_desc_alloc(struct mvsw_pr_rxtx_sdma *sdma,
-				    struct mvsw_sdma_buf *buf)
-{
-	struct device *dma_dev = sdma->sw->dev->dev;
-	struct mvsw_sdma_desc *desc;
-	dma_addr_t dma;
-
-	desc = dma_pool_alloc(sdma->desc_pool, GFP_DMA | GFP_KERNEL, &dma);
-	if (!desc)
-		return -ENOMEM;
-
-	if (dma + sizeof(struct mvsw_sdma_desc) > sdma->dma_mask) {
-		dev_err(dma_dev, "failed to alloc desc\n");
-		dma_pool_free(sdma->desc_pool, desc, dma);
-		return -ENOMEM;
-	}
-
-	buf->desc_dma = dma;
-	buf->desc = desc;
-
-	return 0;
-}
-
-static u32 mvsw_sdma_addr_phy(struct mvsw_pr_rxtx_sdma *sdma, dma_addr_t pa)
-{
-	return sdma->map_addr + pa;
-}
-
-static void mvsw_sdma_rx_desc_set_len(struct mvsw_sdma_desc *desc, size_t val)
-{
-	u32 word = le32_to_cpu(desc->word2);
-
-	word = (word & ~GENMASK(15, 0)) | val;
-	desc->word2 = cpu_to_le32(word);
-}
-
-static void mvsw_sdma_rx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
-				   struct mvsw_sdma_desc *desc,
-				   dma_addr_t buf)
-{
-	mvsw_sdma_rx_desc_set_len(desc, SDMA_BUFF_SIZE_MAX);
-	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
-	/* make sure buffer is set before reset the descriptor */
-	wmb();
-	desc->word1 = cpu_to_le32(0xA0000000);
-}
-
-static void mvsw_sdma_rx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
-				       struct mvsw_sdma_desc *desc,
-				       dma_addr_t next)
-{
-	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
-}
-
-static int mvsw_sdma_rx_dma_alloc(struct mvsw_pr_rxtx_sdma *sdma,
-				  struct mvsw_sdma_buf *buf)
-{
-	struct device *dev = sdma->sw->dev->dev;
-
-	buf->skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_DMA | GFP_ATOMIC);
-	if (!buf->skb)
-		return -ENOMEM;
-
-	buf->buf_dma = dma_map_single(dev, buf->skb->data, buf->skb->len,
-				      DMA_FROM_DEVICE);
-
-	if (dma_mapping_error(dev, buf->buf_dma))
-		goto err_dma_map;
-	if (buf->buf_dma + buf->skb->len > sdma->dma_mask)
-		goto err_dma_range;
-
-	return 0;
-
-err_dma_range:
-	dma_unmap_single(dev, buf->buf_dma, buf->skb->len, DMA_FROM_DEVICE);
-	buf->buf_dma = DMA_MAPPING_ERROR;
-err_dma_map:
-	kfree_skb(buf->skb);
-	buf->skb = NULL;
-
-	return -ENOMEM;
-}
-
-static struct sk_buff *mvsw_sdma_rx_buf_get(struct mvsw_pr_rxtx_sdma *sdma,
-					    struct mvsw_sdma_buf *buf)
-{
-	struct sk_buff *skb_orig = buf->skb;
-	dma_addr_t buf_dma = buf->buf_dma;
-	u32 len = skb_orig->len;
-	int err;
-
-	err = mvsw_sdma_rx_dma_alloc(sdma, buf);
-	if (err) {
-		struct sk_buff *skb;
-
-		buf->buf_dma = buf_dma;
-		buf->skb = skb_orig;
-
-		skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_ATOMIC);
-		if (!skb)
-			return NULL;
-
-		skb_copy_from_linear_data(buf->skb, skb_put(skb, len), len);
-		return skb;
-	}
-
-	return skb_orig;
-}
-
-static void mvsw_sdma_rx_set_next_queue(struct mvsw_pr_rxtx_sdma *sdma, int rxq)
-{
-	sdma->next_rxq = rxq % SDMA_RX_QUEUE_NUM;
-}
-
-static int mvsw_sdma_rx_pick_next_queue(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[sdma->next_rxq];
-
-	if (ring->recvd >= ring->weight) {
-		mvsw_sdma_rx_set_next_queue(sdma, sdma->next_rxq + 1);
-		ring->recvd = 0;
-	}
-
-	return sdma->next_rxq;
-}
-
-static int mvsw_sdma_rx_poll(struct napi_struct *napi, int budget)
-{
-	unsigned int qmask = GENMASK(SDMA_RX_QUEUE_NUM - 1, 0);
-	struct mvsw_pr_rxtx_sdma *sdma;
-	unsigned int rxq_done_map = 0;
-	struct list_head rx_list;
-	int pkts_done = 0;
-
-	INIT_LIST_HEAD(&rx_list);
-
-	sdma = container_of(napi, struct mvsw_pr_rxtx_sdma, rx_napi);
-
-	while (pkts_done < budget && rxq_done_map != qmask) {
-		struct mvsw_sdma_rx_ring *ring;
-		struct mvsw_sdma_desc *desc;
-		struct mvsw_sdma_buf *buf;
-		struct sk_buff *skb;
-		int buf_idx;
-		int rxq;
-
-		rxq = mvsw_sdma_rx_pick_next_queue(sdma);
-		ring = &sdma->rx_ring[rxq];
-
-		buf_idx = ring->next_rx;
-		buf = &ring->bufs[buf_idx];
-		desc = buf->desc;
-
-		if (SDMA_RX_DESC_OWNER(desc) != SDMA_RX_DESC_CPU_OWN) {
-			mvsw_sdma_rx_set_next_queue(sdma, rxq + 1);
-			rxq_done_map |= BIT(rxq);
-			continue;
-		} else {
-			rxq_done_map &= ~BIT(rxq);
-		}
-
-		ring->recvd++;
-		pkts_done++;
-
-		__skb_trim(buf->skb, SDMA_RX_DESC_PKT_LEN(desc));
-
-		skb = mvsw_sdma_rx_buf_get(sdma, buf);
-		if (!skb)
-			goto rx_reset_buf;
-
-		if (unlikely(mvsw_pr_rxtx_recv_skb(sdma->rxtx, skb)))
-			goto rx_reset_buf;
-
-		list_add_tail(&skb->list, &rx_list);
-rx_reset_buf:
-		mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
-		ring->next_rx = (buf_idx + 1) % SDMA_RX_DESC_PER_Q;
-	}
-
-	if (pkts_done < budget && napi_complete_done(napi, pkts_done))
-		mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0xff << 2);
-
-	netif_receive_skb_list(&rx_list);
-
-	return pkts_done;
-}
-
-static void mvsw_sdma_rx_fini(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	int q, b;
-
-	/* disable all rx queues */
-	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
-
-	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
-		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
-
-		if (!ring->bufs)
-			break;
-
-		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
-			struct mvsw_sdma_buf *buf = &ring->bufs[b];
-
-			if (buf->desc_dma)
-				dma_pool_free(sdma->desc_pool, buf->desc,
-					      buf->desc_dma);
-
-			if (!buf->skb)
-				continue;
-
-			if (buf->buf_dma != DMA_MAPPING_ERROR)
-				dma_unmap_single(sdma->sw->dev->dev,
-						 buf->buf_dma, buf->skb->len,
-						 DMA_FROM_DEVICE);
-			kfree_skb(buf->skb);
-		}
-	}
-}
-
-static int mvsw_sdma_rx_init(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	int q, b;
-	int err;
-
-	/* disable all rx queues */
-	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
-
-	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
-		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
-		struct mvsw_sdma_buf *head;
-
-		ring->bufs = kmalloc_array(SDMA_RX_DESC_PER_Q, sizeof(*head),
-					   GFP_KERNEL);
-		if (!ring->bufs)
-			return -ENOMEM;
-
-		ring->weight = prestera_rx_weight_map[q];
-		ring->recvd = 0;
-		ring->next_rx = 0;
-
-		head = &ring->bufs[0];
-
-		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
-			struct mvsw_sdma_buf *buf = &ring->bufs[b];
-
-			err = mvsw_sdma_buf_desc_alloc(sdma, buf);
-			if (err)
-				return err;
-
-			err = mvsw_sdma_rx_dma_alloc(sdma, buf);
-			if (err)
-				return err;
-
-			mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
-
-			if (b == 0)
-				continue;
-
-			mvsw_sdma_rx_desc_set_next(sdma, ring->bufs[b - 1].desc,
-						   buf->desc_dma);
-
-			if (b == SDMA_RX_DESC_PER_Q - 1)
-				mvsw_sdma_rx_desc_set_next(sdma, buf->desc,
-							   head->desc_dma);
-		}
-
-		mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_DESC_REG(q),
-			       mvsw_sdma_addr_phy(sdma, head->desc_dma));
-	}
-
-	/* make sure all rx descs are filled before enabling all rx queues */
-	wmb();
-	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff);
-
-	return 0;
-}
-
-static void mvsw_sdma_tx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
-				   struct mvsw_sdma_desc *desc)
-{
-	desc->word1 = cpu_to_le32(SDMA_TX_DESC_SINGLE | SDMA_TX_DESC_CALC_CRC);
-	desc->word2 = 0;
-}
-
-static void mvsw_sdma_tx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
-				       struct mvsw_sdma_desc *desc,
-				       dma_addr_t next)
-{
-	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
-}
-
-static void mvsw_sdma_tx_desc_set_buf(struct mvsw_pr_rxtx_sdma *sdma,
-				      struct mvsw_sdma_desc *desc,
-				      dma_addr_t buf, size_t len)
-{
-	u32 word = le32_to_cpu(desc->word2);
-
-	word = (word & ~GENMASK(30, 16)) | ((len + 4) << 16);
-
-	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
-	desc->word2 = cpu_to_le32(word);
-}
-
-static void mvsw_sdma_tx_desc_xmit(struct mvsw_sdma_desc *desc)
-{
-	u32 word = le32_to_cpu(desc->word1);
-
-	word |= (SDMA_TX_DESC_DMA_OWN << 31);
-
-	/* make sure everything is written before enable xmit */
-	wmb();
-	desc->word1 = cpu_to_le32(word);
-}
-
-static int mvsw_sdma_tx_buf_map(struct mvsw_pr_rxtx_sdma *sdma,
-				struct mvsw_sdma_buf *buf,
-				struct sk_buff *skb)
-{
-	struct device *dma_dev = sdma->sw->dev->dev;
-	struct sk_buff *new_skb;
-	size_t len = skb->len;
-	dma_addr_t dma;
-
-	dma = dma_map_single(dma_dev, skb->data, len, DMA_TO_DEVICE);
-	if (!dma_mapping_error(dma_dev, dma) && dma + len <= sdma->dma_mask) {
-		buf->buf_dma = dma;
-		buf->skb = skb;
-		return 0;
-	}
-
-	if (!dma_mapping_error(dma_dev, dma))
-		dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
-
-	new_skb = alloc_skb(len, GFP_ATOMIC | GFP_DMA);
-	if (!new_skb)
-		goto err_alloc_skb;
-
-	dma = dma_map_single(dma_dev, new_skb->data, len, DMA_TO_DEVICE);
-	if (dma_mapping_error(dma_dev, dma))
-		goto err_dma_map;
-	if (dma + len > sdma->dma_mask)
-		goto err_dma_range;
-
-	skb_copy_from_linear_data(skb, skb_put(new_skb, len), len);
-
-	dev_consume_skb_any(skb);
-
-	buf->skb = new_skb;
-	buf->buf_dma = dma;
-
-	return 0;
-
-err_dma_range:
-	dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
-err_dma_map:
-	dev_kfree_skb(new_skb);
-err_alloc_skb:
-	dev_kfree_skb(skb);
-
-	return -ENOMEM;
-}
-
-static void mvsw_sdma_tx_buf_unmap(struct mvsw_pr_rxtx_sdma *sdma,
-				   struct mvsw_sdma_buf *buf)
-{
-	struct device *dma_dev = sdma->sw->dev->dev;
-
-	dma_unmap_single(dma_dev, buf->buf_dma, buf->skb->len, DMA_TO_DEVICE);
-}
-
-static void mvsw_sdma_tx_recycle_work_fn(struct work_struct *work)
-{
-	struct mvsw_sdma_tx_ring *tx_ring;
-	struct mvsw_pr_rxtx_sdma *sdma;
-	struct device *dma_dev;
-	int b;
-
-	sdma = container_of(work, struct mvsw_pr_rxtx_sdma, tx_work);
-
-	dma_dev = sdma->sw->dev->dev;
-	tx_ring = &sdma->tx_ring;
-
-	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
-		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
-
-		if (!buf->is_used)
-			continue;
-
-		if (!SDMA_TX_DESC_IS_SENT(buf->desc))
-			continue;
-
-		mvsw_sdma_tx_buf_unmap(sdma, buf);
-		dev_consume_skb_any(buf->skb);
-		buf->skb = NULL;
-
-		/* make sure everything is cleaned up */
-		wmb();
-
-		buf->is_used = false;
-	}
-}
-
-static int mvsw_sdma_tx_init(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	struct mvsw_sdma_tx_ring *tx_ring = &sdma->tx_ring;
-	struct mvsw_sdma_buf *head;
-	int err;
-	int b;
-
-	spin_lock_init(&sdma->tx_lock);
-
-	INIT_WORK(&sdma->tx_work, mvsw_sdma_tx_recycle_work_fn);
-
-	tx_ring->bufs = kmalloc_array(SDMA_TX_DESC_PER_Q, sizeof(*head),
-				      GFP_KERNEL);
-	if (!tx_ring->bufs)
-		return -ENOMEM;
-
-	head = &tx_ring->bufs[0];
-
-	tx_ring->max_burst = SDMA_TX_MAX_BURST;
-	tx_ring->burst = tx_ring->max_burst;
-	tx_ring->next_tx = 0;
-
-	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
-		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
-
-		err = mvsw_sdma_buf_desc_alloc(sdma, buf);
-		if (err)
-			return err;
-
-		mvsw_sdma_tx_desc_init(sdma, buf->desc);
-
-		buf->is_used = false;
-		buf->skb = NULL;
-
-		if (b == 0)
-			continue;
-
-		mvsw_sdma_tx_desc_set_next(sdma, tx_ring->bufs[b - 1].desc,
-					   buf->desc_dma);
-
-		if (b == SDMA_TX_DESC_PER_Q - 1)
-			mvsw_sdma_tx_desc_set_next(sdma, buf->desc,
-						   head->desc_dma);
-	}
-
-	/* make sure descriptors are written */
-	wmb();
-	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_DESC_REG,
-		       mvsw_sdma_addr_phy(sdma, head->desc_dma));
-
-	return 0;
-}
-
-static void mvsw_sdma_tx_fini(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	struct mvsw_sdma_tx_ring *ring = &sdma->tx_ring;
-	int b;
-
-	cancel_work_sync(&sdma->tx_work);
-
-	if (!ring->bufs)
-		return;
-
-	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
-		struct mvsw_sdma_buf *buf = &ring->bufs[b];
-
-		if (buf->desc)
-			dma_pool_free(sdma->desc_pool, buf->desc,
-				      buf->desc_dma);
-
-		if (!buf->skb)
-			continue;
-
-		dma_unmap_single(sdma->sw->dev->dev, buf->buf_dma,
-				 buf->skb->len, DMA_TO_DEVICE);
-
-		dev_consume_skb_any(buf->skb);
-	}
-}
-
-int mvsw_pr_rxtx_sdma_init(struct mvsw_pr_rxtx *rxtx)
-{
-	struct mvsw_pr_rxtx_sdma *sdma;
-
-	sdma = kzalloc(sizeof(*sdma), GFP_KERNEL);
-	if (!sdma)
-		return -ENOMEM;
-
-	rxtx->priv = sdma;
-	sdma->rxtx = rxtx;
-
-	return 0;
-}
-
-int mvsw_pr_rxtx_sdma_fini(struct mvsw_pr_rxtx *rxtx)
-{
-	kfree(rxtx->priv);
-	return 0;
-}
-
-static void mvsw_rxtx_handle_event(struct mvsw_pr_switch *sw,
-				   struct mvsw_pr_event *evt, void *arg)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = arg;
-
-	if (evt->id != MVSW_RXTX_EVENT_RCV_PKT)
-		return;
-
-	mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0);
-	napi_schedule(&sdma->rx_napi);
-}
-
-int mvsw_pr_rxtx_sdma_switch_init(struct mvsw_pr_rxtx *rxtx,
-				  struct mvsw_pr_switch *sw)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = rxtx->priv;
-	int err;
-
-	err = mvsw_pr_hw_rxtx_init(sw, true, &sdma->map_addr);
-	if (err) {
-		dev_err(sw->dev->dev, "failed to init rxtx by hw\n");
-		return err;
-	}
-
-	sdma->dma_mask = dma_get_mask(sw->dev->dev);
-	sdma->sw = sw;
-
-	sdma->desc_pool = dma_pool_create("desc_pool", sdma->sw->dev->dev,
-					  sizeof(struct mvsw_sdma_desc), 16, 0);
-	if (!sdma->desc_pool)
-		return -ENOMEM;
-
-	err = mvsw_sdma_rx_init(sdma);
-	if (err) {
-		dev_err(sw->dev->dev, "failed to init rx ring\n");
-		goto err_rx_init;
-	}
-
-	err = mvsw_sdma_tx_init(sdma);
-	if (err) {
-		dev_err(sw->dev->dev, "failed to init tx ring\n");
-		goto err_tx_init;
-	}
-
-	err = mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_RXTX,
-						mvsw_rxtx_handle_event, sdma);
-	if (err)
-		goto err_evt_register;
-
-	init_dummy_netdev(&sdma->napi_dev);
-
-	netif_napi_add(&sdma->napi_dev, &sdma->rx_napi, mvsw_sdma_rx_poll, 64);
-	napi_enable(&sdma->rx_napi);
-
-	return 0;
-
-err_evt_register:
-err_tx_init:
-	mvsw_sdma_tx_fini(sdma);
-err_rx_init:
-	mvsw_sdma_rx_fini(sdma);
-
-	dma_pool_destroy(sdma->desc_pool);
-	return err;
-}
-
-void mvsw_pr_rxtx_sdma_switch_fini(struct mvsw_pr_rxtx *rxtx,
-				   struct mvsw_pr_switch *sw)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = rxtx->priv;
-
-	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_RXTX);
-	napi_disable(&sdma->rx_napi);
-	netif_napi_del(&sdma->rx_napi);
-	mvsw_sdma_rx_fini(sdma);
-	mvsw_sdma_tx_fini(sdma);
-	dma_pool_destroy(sdma->desc_pool);
-}
-
-static int mvsw_sdma_wait_tx(struct mvsw_pr_rxtx_sdma *sdma,
-			     struct mvsw_sdma_tx_ring *tx_ring)
-{
-	int tx_retry_num = 10 * tx_ring->max_burst;
-
-	while (--tx_retry_num) {
-		if (!(mvsw_reg_read(sdma->sw, SDMA_TX_QUEUE_START_REG) & 1))
-			return 0;
-
-		udelay(5);
-	}
-
-	return -EBUSY;
-}
-
-static void mvsw_sdma_start_tx(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_START_REG, 1);
-	schedule_work(&sdma->tx_work);
-}
-
-netdev_tx_t mvsw_pr_rxtx_sdma_xmit(struct mvsw_pr_rxtx *rxtx,
-				   struct sk_buff *skb)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = rxtx->priv;
-	struct device *dma_dev = sdma->sw->dev->dev;
-	struct mvsw_sdma_tx_ring *tx_ring;
-	struct net_device *dev = skb->dev;
-	struct mvsw_sdma_buf *buf;
-	int err;
-
-	spin_lock(&sdma->tx_lock);
-
-	tx_ring = &sdma->tx_ring;
-
-	buf = &tx_ring->bufs[tx_ring->next_tx];
-	if (buf->is_used) {
-		schedule_work(&sdma->tx_work);
-		goto drop_skb;
-	}
-
-	if (unlikely(skb_put_padto(skb, ETH_ZLEN)))
-		goto drop_skb_nofree;
-
-	err = mvsw_sdma_tx_buf_map(sdma, buf, skb);
-	if (err)
-		goto drop_skb;
-
-	mvsw_sdma_tx_desc_set_buf(sdma, buf->desc, buf->buf_dma, skb->len);
-
-	dma_sync_single_for_device(dma_dev, buf->buf_dma, skb->len,
-				   DMA_TO_DEVICE);
-
-	if (!tx_ring->burst--) {
-		tx_ring->burst = tx_ring->max_burst;
-
-		err = mvsw_sdma_wait_tx(sdma, tx_ring);
-		if (err)
-			goto drop_skb_unmap;
-	}
-
-	tx_ring->next_tx = (tx_ring->next_tx + 1) % SDMA_TX_DESC_PER_Q;
-	mvsw_sdma_tx_desc_xmit(buf->desc);
-	buf->is_used = true;
-
-	mvsw_sdma_start_tx(sdma);
-
-	goto tx_done;
-
-drop_skb_unmap:
-	mvsw_sdma_tx_buf_unmap(sdma, buf);
-drop_skb:
-	dev_consume_skb_any(skb);
-drop_skb_nofree:
-	dev->stats.tx_dropped++;
-tx_done:
-	spin_unlock(&sdma->tx_lock);
-	return NETDEV_TX_OK;
-}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c
new file mode 100644
index 0000000..173339b
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c
@@ -0,0 +1,189 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include "prestera_storm_control.h"
+#include "prestera_hw.h"
+
+#define SYSFS_ATTR_MODE		0644
+
+static ssize_t storm_control_attr_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size);
+static ssize_t storm_control_attr_show(struct device *dev,
+				       struct device_attribute *attr,
+				       char *buf);
+
+struct strom_control_attributes {
+	u32 bc_kbyte_per_sec_rate;
+	u32 unknown_uc_kbyte_per_sec_rate;
+	u32 unreg_mc_kbyte_per_sec_rate;
+};
+
+struct prestera_storm_control {
+	struct prestera_switch *sw;
+	struct strom_control_attributes *attribute_values;
+};
+
+static DEVICE_ATTR(broadcast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static DEVICE_ATTR(unknown_unicast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static DEVICE_ATTR(unregistered_multicast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static struct attribute *prestera_sw_dev_attrs[] = {
+	&dev_attr_broadcast_kbyte_per_sec_rate.attr,
+	&dev_attr_unknown_unicast_kbyte_per_sec_rate.attr,
+	&dev_attr_unregistered_multicast_kbyte_per_sec_rate.attr,
+	NULL
+};
+
+static struct attribute_group prestera_sw_dev_attr_group = {
+	.name = "storm_control", /* we want them in subdirectory */
+	.attrs = prestera_sw_dev_attrs,
+};
+
+static ssize_t storm_control_attr_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size)
+{
+	struct prestera_port *port = dev_to_prestera_port(dev);
+	struct strom_control_attributes *sc_attr;
+	struct prestera_storm_control *sc;
+	u32 *attr_to_change = NULL;
+	u32 kbyte_per_sec_rate;
+	ssize_t ret = -EINVAL;
+	u32 storm_type;
+
+	if (!port)
+		return -EINVAL;
+
+	sc = port->sw->storm_control;
+	sc_attr = &sc->attribute_values[port->fp_id];
+
+	ret = kstrtou32(buf, 10, &kbyte_per_sec_rate);
+	if (ret)
+		return ret;
+
+	if (!strcmp(attr->attr.name, "broadcast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->bc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_BC;
+	}
+
+	if (!strcmp(attr->attr.name, "unknown_unicast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->unknown_uc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_UC_UNK;
+	}
+
+	if (!strcmp(attr->attr.name,
+		    "unregistered_multicast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->unreg_mc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_MC;
+	}
+
+	if (!attr_to_change)
+		return -EINVAL;
+
+	if (kbyte_per_sec_rate != *attr_to_change)
+		ret = mvsw_pr_hw_port_storm_control_cfg_set(port, storm_type,
+							    kbyte_per_sec_rate);
+	else
+		return size;
+
+	if (ret)
+		return ret;
+
+	*attr_to_change = kbyte_per_sec_rate;
+
+	return size;
+}
+
+static ssize_t storm_control_attr_show(struct device *dev,
+				       struct device_attribute *attr,
+				       char *buf)
+{
+	struct prestera_port *port = dev_to_prestera_port(dev);
+	struct strom_control_attributes *sc_attr;
+	struct prestera_storm_control *sc;
+
+	if (!port)
+		return -EINVAL;
+
+	sc = port->sw->storm_control;
+
+	sc_attr = &sc->attribute_values[port->fp_id];
+
+	if (!strcmp(attr->attr.name, "broadcast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n", sc_attr->bc_kbyte_per_sec_rate);
+
+	if (!strcmp(attr->attr.name, "unknown_unicast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n",
+			       sc_attr->unknown_uc_kbyte_per_sec_rate);
+
+	if (!strcmp(attr->attr.name,
+		    "unregistered_multicast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n",
+			       sc_attr->unreg_mc_kbyte_per_sec_rate);
+
+	return -EINVAL;
+}
+
+int prestera_storm_control_init(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc;
+	struct prestera_port *port;
+	int err;
+
+	sc = kzalloc(sizeof(*sc), GFP_KERNEL);
+	if (!sc)
+		return -ENOMEM;
+
+	sc->attribute_values = kcalloc(sw->port_count,
+				       sizeof(*sc->attribute_values),
+				       GFP_KERNEL);
+	if (!sc->attribute_values) {
+		err = -ENOMEM;
+		goto err_values_alloca;
+	}
+
+	list_for_each_entry(port, &sw->port_list, list) {
+		err = sysfs_create_group(&port->net_dev->dev.kobj,
+					 &prestera_sw_dev_attr_group);
+		if (err) {
+			pr_err("Failed to create sysfs group for %s\n",
+			       dev_name(&port->net_dev->dev));
+			goto err_group_create;
+		}
+	}
+
+	sc->sw = sw;
+	sw->storm_control = sc;
+
+	return 0;
+
+err_group_create:
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list) {
+		sysfs_remove_group(&port->net_dev->dev.kobj,
+				   &prestera_sw_dev_attr_group);
+	}
+	kfree(sc->attribute_values);
+err_values_alloca:
+	kfree(sc);
+	return err;
+}
+
+void prestera_storm_control_fini(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc = sw->storm_control;
+	struct prestera_port *port;
+
+	list_for_each_entry(port, &sw->port_list, list)
+		sysfs_remove_group(&port->net_dev->dev.kobj,
+				   &prestera_sw_dev_attr_group);
+
+	kfree(sc->attribute_values);
+	kfree(sc);
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h
new file mode 100644
index 0000000..c1e7c53
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h
@@ -0,0 +1,12 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved. */
+
+#ifndef _MVSW_PRESTERA_STORM_CONTROL_H_
+#define _MVSW_PRESTERA_STORM_CONTROL_H_
+
+#include "prestera.h"
+
+int prestera_storm_control_init(struct prestera_switch *sw);
+void prestera_storm_control_fini(struct prestera_switch *sw);
+
+#endif /* _MVSW_PRESTERA_STORM_CONTROL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
index 969daeb..7605203 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
@@ -15,25 +15,28 @@
 #include "prestera.h"
 
 #define MVSW_PR_VID_ALL (0xffff)
+#define PRESTERA_DEFAULT_ISOLATION_SRCID 1 /* source_id */
 
-struct mvsw_pr_bridge {
-	struct mvsw_pr_switch *sw;
+struct prestera_bridge {
+	struct prestera_switch *sw;
 	u32 ageing_time;
 	struct list_head bridge_list;
 	bool bridge_8021q_exists;
 };
 
-struct mvsw_pr_bridge_device {
+struct prestera_bridge_device {
 	struct net_device *dev;
 	struct list_head bridge_node;
 	struct list_head port_list;
 	u16 bridge_id;
+	/* This can be extended to list of isolation groups */
+	u32 isolation_srcid; /* source_id */
 	u8 vlan_enabled:1, multicast_enabled:1, mrouter:1;
 };
 
-struct mvsw_pr_bridge_port {
+struct prestera_bridge_port {
 	struct net_device *dev;
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_bridge_device *bridge_device;
 	struct list_head bridge_device_node;
 	struct list_head vlan_list;
 	unsigned int ref_count;
@@ -56,18 +59,18 @@ struct mvsw_pr_event_work {
 
 static struct workqueue_struct *mvsw_owq;
 
-static struct mvsw_pr_bridge_port *
-mvsw_pr_bridge_port_get(struct mvsw_pr_bridge *bridge,
+static struct prestera_bridge_port *
+mvsw_pr_bridge_port_get(struct prestera_bridge *bridge,
 			struct net_device *brport_dev);
 
-static void mvsw_pr_bridge_port_put(struct mvsw_pr_bridge *bridge,
-				    struct mvsw_pr_bridge_port *br_port);
+static void mvsw_pr_bridge_port_put(struct prestera_bridge *bridge,
+				    struct prestera_bridge_port *br_port);
 
-struct mvsw_pr_bridge_device *
-mvsw_pr_bridge_device_find(const struct mvsw_pr_bridge *bridge,
-			   const struct net_device *br_dev)
+struct prestera_bridge_device *
+prestera_bridge_device_find(const struct prestera_bridge *bridge,
+			    const struct net_device *br_dev)
 {
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_bridge_device *bridge_device;
 
 	list_for_each_entry(bridge_device, &bridge->bridge_list,
 			    bridge_node)
@@ -78,17 +81,17 @@ mvsw_pr_bridge_device_find(const struct mvsw_pr_bridge *bridge,
 }
 
 static bool
-mvsw_pr_bridge_device_is_offloaded(const struct mvsw_pr_switch *sw,
+mvsw_pr_bridge_device_is_offloaded(const struct prestera_switch *sw,
 				   const struct net_device *br_dev)
 {
-	return !!mvsw_pr_bridge_device_find(sw->bridge, br_dev);
+	return !!prestera_bridge_device_find(sw->bridge, br_dev);
 }
 
-static struct mvsw_pr_bridge_port *
-__mvsw_pr_bridge_port_find(const struct mvsw_pr_bridge_device *bridge_device,
+static struct prestera_bridge_port *
+__mvsw_pr_bridge_port_find(const struct prestera_bridge_device *bridge_device,
 			   const struct net_device *brport_dev)
 {
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_bridge_port *br_port;
 
 	list_for_each_entry(br_port, &bridge_device->port_list,
 			    bridge_device_node) {
@@ -99,25 +102,69 @@ __mvsw_pr_bridge_port_find(const struct mvsw_pr_bridge_device *bridge_device,
 	return NULL;
 }
 
-static struct mvsw_pr_bridge_port *
-mvsw_pr_bridge_port_find(struct mvsw_pr_bridge *bridge,
+static struct prestera_bridge_port *
+mvsw_pr_bridge_port_find(struct prestera_bridge *bridge,
 			 struct net_device *brport_dev)
 {
 	struct net_device *br_dev = netdev_master_upper_dev_get(brport_dev);
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_bridge_device *bridge_device;
 
 	if (!br_dev)
 		return NULL;
 
-	bridge_device = mvsw_pr_bridge_device_find(bridge, br_dev);
+	bridge_device = prestera_bridge_device_find(bridge, br_dev);
 	if (!bridge_device)
 		return NULL;
 
 	return __mvsw_pr_bridge_port_find(bridge_device, brport_dev);
 }
 
+static void
+prestera_br_port_flags_reset(struct prestera_bridge_port *br_port,
+			     struct prestera_port *port)
+{
+	prestera_port_uc_flood_set(port, false);
+	prestera_port_mc_flood_set(port, false);
+	prestera_port_learning_set(port, false);
+	prestera_port_isolation_grp_set(port, PRESTERA_PORT_SRCID_ZERO);
+}
+
+static int prestera_br_port_flags_set(struct prestera_bridge_port *br_port,
+				      struct prestera_port *port)
+{
+	struct prestera_bridge_device *br_dev;
+	u32 iso_srcid;
+	int err;
+
+	br_dev = br_port->bridge_device;
+
+	err = prestera_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
+	if (err)
+		goto err_out;
+
+	err = prestera_port_mc_flood_set(port, br_port->flags & BR_MCAST_FLOOD);
+	if (err)
+		goto err_out;
+
+	err = prestera_port_learning_set(port, br_port->flags & BR_LEARNING);
+	if (err)
+		goto err_out;
+
+	iso_srcid = br_port->flags & BR_ISOLATED ?
+			br_dev->isolation_srcid : PRESTERA_PORT_SRCID_ZERO;
+	err = prestera_port_isolation_grp_set(port, iso_srcid);
+	if (err)
+		goto err_out;
+
+	return 0;
+
+err_out:
+	prestera_br_port_flags_reset(br_port, port);
+	return err;
+}
+
 static struct mvsw_pr_bridge_vlan *
-mvsw_pr_bridge_vlan_find(const struct mvsw_pr_bridge_port *br_port, u16 vid)
+mvsw_pr_bridge_vlan_find(const struct prestera_bridge_port *br_port, u16 vid)
 {
 	struct mvsw_pr_bridge_vlan *br_vlan;
 
@@ -129,18 +176,18 @@ mvsw_pr_bridge_vlan_find(const struct mvsw_pr_bridge_port *br_port, u16 vid)
 	return NULL;
 }
 
-u16 mvsw_pr_vlan_dev_vlan_id(struct mvsw_pr_bridge *bridge,
-			     struct net_device *dev)
+u16 prestera_vlan_dev_vlan_id(struct prestera_bridge *bridge,
+			      struct net_device *dev)
 {
-	struct mvsw_pr_bridge_device *bridge_dev;
+	struct prestera_bridge_device *bridge_dev;
 
-	bridge_dev = mvsw_pr_bridge_device_find(bridge, dev);
+	bridge_dev = prestera_bridge_device_find(bridge, dev);
 
 	return bridge_dev ? bridge_dev->bridge_id : 0;
 }
 
 static struct mvsw_pr_bridge_vlan *
-mvsw_pr_bridge_vlan_create(struct mvsw_pr_bridge_port *br_port, u16 vid)
+mvsw_pr_bridge_vlan_create(struct prestera_bridge_port *br_port, u16 vid)
 {
 	struct mvsw_pr_bridge_vlan *br_vlan;
 
@@ -164,7 +211,7 @@ mvsw_pr_bridge_vlan_destroy(struct mvsw_pr_bridge_vlan *br_vlan)
 }
 
 static struct mvsw_pr_bridge_vlan *
-mvsw_pr_bridge_vlan_get(struct mvsw_pr_bridge_port *br_port, u16 vid)
+mvsw_pr_bridge_vlan_get(struct prestera_bridge_port *br_port, u16 vid)
 {
 	struct mvsw_pr_bridge_vlan *br_vlan;
 
@@ -182,11 +229,11 @@ static void mvsw_pr_bridge_vlan_put(struct mvsw_pr_bridge_vlan *br_vlan)
 }
 
 static int
-mvsw_pr_port_vlan_bridge_join(struct mvsw_pr_port_vlan *port_vlan,
-			      struct mvsw_pr_bridge_port *br_port,
+mvsw_pr_port_vlan_bridge_join(struct prestera_port_vlan *port_vlan,
+			      struct prestera_bridge_port *br_port,
 			      struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *port = port_vlan->mvsw_pr_port;
+	struct prestera_port *port = port_vlan->mvsw_pr_port;
 	struct mvsw_pr_bridge_vlan *br_vlan;
 	u16 vid = port_vlan->vid;
 	int err;
@@ -194,19 +241,11 @@ mvsw_pr_port_vlan_bridge_join(struct mvsw_pr_port_vlan *port_vlan,
 	if (port_vlan->bridge_port)
 		return 0;
 
-	err = mvsw_pr_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
+	err = prestera_br_port_flags_set(br_port, port);
 	if (err)
-		return err;
+		goto err_flags2port_set;
 
-	err = mvsw_pr_port_mc_flood_set(port, br_port->flags & BR_MCAST_FLOOD);
-	if (err)
-		return err;
-
-	err = mvsw_pr_port_learning_set(port, br_port->flags & BR_LEARNING);
-	if (err)
-		goto err_port_learning_set;
-
-	err = mvsw_pr_port_vid_stp_set(port, vid, br_port->stp_state);
+	err = prestera_port_vid_stp_set(port, vid, br_port->stp_state);
 	if (err)
 		goto err_port_vid_stp_set;
 
@@ -224,19 +263,19 @@ mvsw_pr_port_vlan_bridge_join(struct mvsw_pr_port_vlan *port_vlan,
 	return 0;
 
 err_bridge_vlan_get:
-	mvsw_pr_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
+	prestera_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
 err_port_vid_stp_set:
-	mvsw_pr_port_learning_set(port, false);
-err_port_learning_set:
+	prestera_br_port_flags_reset(br_port, port);
+err_flags2port_set:
 	return err;
 }
 
 static int
-mvsw_pr_bridge_vlan_port_count_get(struct mvsw_pr_bridge_device *bridge_device,
+mvsw_pr_bridge_vlan_port_count_get(struct prestera_bridge_device *bridge_device,
 				   u16 vid)
 {
 	int count = 0;
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_bridge_port *br_port;
 	struct mvsw_pr_bridge_vlan *br_vlan;
 
 	list_for_each_entry(br_port, &bridge_device->port_list,
@@ -254,12 +293,12 @@ mvsw_pr_bridge_vlan_port_count_get(struct mvsw_pr_bridge_device *bridge_device,
 }
 
 void
-mvsw_pr_port_vlan_bridge_leave(struct mvsw_pr_port_vlan *port_vlan)
+prestera_port_vlan_bridge_leave(struct prestera_port_vlan *port_vlan)
 {
-	struct mvsw_pr_port *port = port_vlan->mvsw_pr_port;
+	struct prestera_port *port = port_vlan->mvsw_pr_port;
 	u32 mode = MVSW_PR_FDB_FLUSH_MODE_DYNAMIC;
 	struct mvsw_pr_bridge_vlan *br_vlan;
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_bridge_port *br_port;
 	u16 vid = port_vlan->vid;
 	bool last_port, last_vlan;
 	int port_count;
@@ -271,27 +310,27 @@ mvsw_pr_port_vlan_bridge_leave(struct mvsw_pr_port_vlan *port_vlan)
 	br_vlan = mvsw_pr_bridge_vlan_find(br_port, vid);
 	last_port = port_count == 1;
 	if (last_vlan)
-		mvsw_pr_fdb_flush_port(port, mode);
+		prestera_fdb_flush_port(port, mode);
 	else if (last_port)
-		mvsw_pr_fdb_flush_vlan(port->sw, vid, mode);
+		prestera_fdb_flush_vlan(port->sw, vid, mode);
 	else
-		mvsw_pr_fdb_flush_port_vlan(port, vid, mode);
+		prestera_fdb_flush_port_vlan(port, vid, mode);
 
 	list_del(&port_vlan->bridge_vlan_node);
 	mvsw_pr_bridge_vlan_put(br_vlan);
-	mvsw_pr_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
+	prestera_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
 	mvsw_pr_bridge_port_put(port->sw->bridge, br_port);
 	port_vlan->bridge_port = NULL;
 }
 
 static int
-mvsw_pr_bridge_port_vlan_add(struct mvsw_pr_port *port,
-			     struct mvsw_pr_bridge_port *br_port,
+mvsw_pr_bridge_port_vlan_add(struct prestera_port *port,
+			     struct prestera_bridge_port *br_port,
 			     u16 vid, bool is_untagged, bool is_pvid,
 			     struct netlink_ext_ack *extack)
 {
 	u16 pvid;
-	struct mvsw_pr_port_vlan *port_vlan;
+	struct prestera_port_vlan *port_vlan;
 	u16 old_pvid = port->pvid;
 	int err;
 
@@ -300,21 +339,21 @@ mvsw_pr_bridge_port_vlan_add(struct mvsw_pr_port *port,
 	else
 		pvid = port->pvid == vid ? 0 : port->pvid;
 
-	port_vlan = mvsw_pr_port_vlan_find_by_vid(port, vid);
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (port_vlan && port_vlan->bridge_port != br_port)
 		return -EEXIST;
 
 	if (!port_vlan) {
-		port_vlan = mvsw_pr_port_vlan_create(port, vid, is_untagged);
+		port_vlan = prestera_port_vlan_create(port, vid, is_untagged);
 		if (IS_ERR(port_vlan))
 			return PTR_ERR(port_vlan);
 	} else {
-		err = mvsw_pr_port_vlan_set(port, vid, true, is_untagged);
+		err = prestera_port_vlan_set(port, vid, true, is_untagged);
 		if (err)
 			goto err_port_vlan_set;
 	}
 
-	err = mvsw_pr_port_pvid_set(port, pvid);
+	err = prestera_port_pvid_set(port, pvid);
 	if (err)
 		goto err_port_pvid_set;
 
@@ -325,16 +364,16 @@ mvsw_pr_bridge_port_vlan_add(struct mvsw_pr_port *port,
 	return 0;
 
 err_port_vlan_bridge_join:
-	mvsw_pr_port_pvid_set(port, old_pvid);
+	prestera_port_pvid_set(port, old_pvid);
 err_port_pvid_set:
-	mvsw_pr_port_vlan_set(port, vid, false, false);
+	prestera_port_vlan_set(port, vid, false, false);
 err_port_vlan_set:
-	mvsw_pr_port_vlan_destroy(port_vlan);
+	prestera_port_vlan_destroy(port_vlan);
 
 	return err;
 }
 
-static int mvsw_pr_port_vlans_add(struct mvsw_pr_port *port,
+static int mvsw_pr_port_vlans_add(struct prestera_port *port,
 				  const struct switchdev_obj_port_vlan *vlan,
 				  struct switchdev_trans *trans,
 				  struct netlink_ext_ack *extack)
@@ -342,9 +381,9 @@ static int mvsw_pr_port_vlans_add(struct mvsw_pr_port *port,
 	bool flag_untagged = vlan->flags & BRIDGE_VLAN_INFO_UNTAGGED;
 	bool flag_pvid = vlan->flags & BRIDGE_VLAN_INFO_PVID;
 	struct net_device *orig_dev = vlan->obj.orig_dev;
-	struct mvsw_pr_bridge_port *br_port;
-	struct mvsw_pr_bridge_device *bridge_device;
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_bridge_port *br_port;
+	struct prestera_bridge_device *bridge_device;
+	struct prestera_switch *sw = port->sw;
 	u16 vid;
 
 	if (netif_is_bridge_master(orig_dev))
@@ -372,7 +411,7 @@ static int mvsw_pr_port_vlans_add(struct mvsw_pr_port *port,
 	}
 
 	if (list_is_singular(&bridge_device->port_list))
-		mvsw_pr_rif_enable(port->sw, bridge_device->dev, true);
+		prestera_rif_enable(port->sw, bridge_device->dev, true);
 
 	return 0;
 }
@@ -383,7 +422,7 @@ static int mvsw_pr_port_obj_add(struct net_device *dev,
 				struct netlink_ext_ack *extack)
 {
 	int err = 0;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	const struct switchdev_obj_port_vlan *vlan;
 
 	switch (obj->id) {
@@ -399,27 +438,27 @@ static int mvsw_pr_port_obj_add(struct net_device *dev,
 }
 
 static void
-mvsw_pr_bridge_port_vlan_del(struct mvsw_pr_port *port,
-			     struct mvsw_pr_bridge_port *br_port, u16 vid)
+mvsw_pr_bridge_port_vlan_del(struct prestera_port *port,
+			     struct prestera_bridge_port *br_port, u16 vid)
 {
 	u16 pvid = port->pvid == vid ? 0 : port->pvid;
-	struct mvsw_pr_port_vlan *port_vlan;
+	struct prestera_port_vlan *port_vlan;
 
-	port_vlan = mvsw_pr_port_vlan_find_by_vid(port, vid);
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (WARN_ON(!port_vlan))
 		return;
 
-	mvsw_pr_port_vlan_bridge_leave(port_vlan);
-	mvsw_pr_port_pvid_set(port, pvid);
-	mvsw_pr_port_vlan_destroy(port_vlan);
+	prestera_port_vlan_bridge_leave(port_vlan);
+	prestera_port_pvid_set(port, pvid);
+	prestera_port_vlan_destroy(port_vlan);
 }
 
-static int mvsw_pr_port_vlans_del(struct mvsw_pr_port *port,
+static int mvsw_pr_port_vlans_del(struct prestera_port *port,
 				  const struct switchdev_obj_port_vlan *vlan)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct net_device *orig_dev = vlan->obj.orig_dev;
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_bridge_port *br_port;
 	u16 vid;
 
 	if (netif_is_bridge_master(orig_dev))
@@ -442,7 +481,7 @@ static int mvsw_pr_port_obj_del(struct net_device *dev,
 				const struct switchdev_obj *obj)
 {
 	int err = 0;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	switch (obj->id) {
 	case SWITCHDEV_OBJ_ID_PORT_VLAN:
@@ -457,18 +496,18 @@ static int mvsw_pr_port_obj_del(struct net_device *dev,
 	return err;
 }
 
-static int mvsw_pr_port_attr_br_vlan_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_vlan_set(struct prestera_port *port,
 					 struct switchdev_trans *trans,
 					 struct net_device *orig_dev,
 					 bool vlan_enabled)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_bridge_device *bridge_device;
 
 	if (!switchdev_trans_ph_prepare(trans))
 		return 0;
 
-	bridge_device = mvsw_pr_bridge_device_find(sw->bridge, orig_dev);
+	bridge_device = prestera_bridge_device_find(sw->bridge, orig_dev);
 	if (WARN_ON(!bridge_device))
 		return -EINVAL;
 
@@ -480,13 +519,12 @@ static int mvsw_pr_port_attr_br_vlan_set(struct mvsw_pr_port *port,
 	return -EINVAL;
 }
 
-static int mvsw_pr_port_attr_br_flags_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_flags_set(struct prestera_port *port,
 					  struct switchdev_trans *trans,
 					  struct net_device *orig_dev,
 					  unsigned long flags)
 {
-	struct mvsw_pr_bridge_port *br_port;
-	int err;
+	struct prestera_bridge_port *br_port;
 
 	if (switchdev_trans_ph_prepare(trans))
 		return 0;
@@ -495,40 +533,28 @@ static int mvsw_pr_port_attr_br_flags_set(struct mvsw_pr_port *port,
 	if (!br_port)
 		return 0;
 
-	err = mvsw_pr_port_uc_flood_set(port, flags & BR_FLOOD);
-	if (err)
-		return err;
-
-	err = mvsw_pr_port_mc_flood_set(port, flags & BR_MCAST_FLOOD);
-	if (err)
-		return err;
-
-	err = mvsw_pr_port_learning_set(port, flags & BR_LEARNING);
-	if (err)
-		return err;
-
 	memcpy(&br_port->flags, &flags, sizeof(flags));
-	return 0;
+	return prestera_br_port_flags_set(br_port, port);
 }
 
-static int mvsw_pr_port_attr_br_ageing_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_ageing_set(struct prestera_port *port,
 					   struct switchdev_trans *trans,
 					   unsigned long ageing_clock_t)
 {
 	int err;
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	unsigned long ageing_jiffies = clock_t_to_jiffies(ageing_clock_t);
 	u32 ageing_time = jiffies_to_msecs(ageing_jiffies);
 
 	if (switchdev_trans_ph_prepare(trans)) {
-		if (ageing_time < MVSW_PR_MIN_AGEING_TIME ||
-		    ageing_time > MVSW_PR_MAX_AGEING_TIME)
+		if (ageing_time < PRESTERA_MIN_AGEING_TIME ||
+		    ageing_time > PRESTERA_MAX_AGEING_TIME)
 			return -ERANGE;
 		else
 			return 0;
 	}
 
-	err = mvsw_pr_switch_ageing_set(sw, ageing_time);
+	err = prestera_switch_ageing_set(sw, ageing_time);
 	if (!err)
 		sw->bridge->ageing_time = ageing_time;
 
@@ -536,28 +562,28 @@ static int mvsw_pr_port_attr_br_ageing_set(struct mvsw_pr_port *port,
 }
 
 static int
-mvsw_pr_port_bridge_vlan_stp_set(struct mvsw_pr_port *port,
+mvsw_pr_port_bridge_vlan_stp_set(struct prestera_port *port,
 				 struct mvsw_pr_bridge_vlan *br_vlan,
 				 u8 state)
 {
-	struct mvsw_pr_port_vlan *port_vlan;
+	struct prestera_port_vlan *port_vlan;
 
 	list_for_each_entry(port_vlan, &br_vlan->port_vlan_list,
 			    bridge_vlan_node) {
 		if (port_vlan->mvsw_pr_port != port)
 			continue;
-		return mvsw_pr_port_vid_stp_set(port, br_vlan->vid, state);
+		return prestera_port_vid_stp_set(port, br_vlan->vid, state);
 	}
 
 	return 0;
 }
 
-static int mvsw_pr_port_attr_stp_state_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_stp_state_set(struct prestera_port *port,
 					   struct switchdev_trans *trans,
 					   struct net_device *orig_dev,
 					   u8 state)
 {
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_bridge_port *br_port;
 	struct mvsw_pr_bridge_vlan *br_vlan;
 	int err;
 	u16 vid;
@@ -571,7 +597,7 @@ static int mvsw_pr_port_attr_stp_state_set(struct mvsw_pr_port *port,
 
 	if (!br_port->bridge_device->vlan_enabled) {
 		vid = br_port->bridge_device->bridge_id;
-		err = mvsw_pr_port_vid_stp_set(port, vid, state);
+		err = prestera_port_vid_stp_set(port, vid, state);
 		if (err)
 			goto err_port_bridge_stp_set;
 	} else {
@@ -596,26 +622,26 @@ static int mvsw_pr_port_attr_stp_state_set(struct mvsw_pr_port *port,
 	return err;
 
 err_port_bridge_stp_set:
-	mvsw_pr_port_vid_stp_set(port, vid, br_port->stp_state);
+	prestera_port_vid_stp_set(port, vid, br_port->stp_state);
 
 	return err;
 }
 
-static int mvsw_pr_port_attr_br_mc_disabled_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_mc_disabled_set(struct prestera_port *port,
 						struct switchdev_trans *trans,
 						struct net_device *orig_dev,
 						bool mc_disabled)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct mvsw_pr_bridge_device *br_dev;
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_bridge_device *br_dev;
+	struct prestera_bridge_port *br_port;
 	bool enabled = !mc_disabled;
 	int err;
 
 	if (!switchdev_trans_ph_prepare(trans))
 		return 0;
 
-	br_dev = mvsw_pr_bridge_device_find(sw->bridge, orig_dev);
+	br_dev = prestera_bridge_device_find(sw->bridge, orig_dev);
 	if (!br_dev)
 		return 0;
 
@@ -623,8 +649,8 @@ static int mvsw_pr_port_attr_br_mc_disabled_set(struct mvsw_pr_port *port,
 		return 0;
 
 	list_for_each_entry(br_port, &br_dev->port_list, bridge_device_node) {
-		err = mvsw_pr_port_mc_flood_set(netdev_priv(br_port->dev),
-						enabled);
+		err = prestera_port_mc_flood_set(netdev_priv(br_port->dev),
+						 enabled);
 		if (err)
 			return err;
 	}
@@ -639,7 +665,7 @@ static int mvsw_pr_port_obj_attr_set(struct net_device *dev,
 				     struct switchdev_trans *trans)
 {
 	int err = 0;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	switch (attr->id) {
 	case SWITCHDEV_ATTR_ID_PORT_STP_STATE:
@@ -649,7 +675,7 @@ static int mvsw_pr_port_obj_attr_set(struct net_device *dev,
 		break;
 	case SWITCHDEV_ATTR_ID_PORT_PRE_BRIDGE_FLAGS:
 		if (attr->u.brport_flags &
-		    ~(BR_LEARNING | BR_FLOOD | BR_MCAST_FLOOD))
+		    ~(BR_LEARNING | BR_FLOOD | BR_MCAST_FLOOD | BR_ISOLATED))
 			err = -EINVAL;
 		break;
 	case SWITCHDEV_ATTR_ID_PORT_BRIDGE_FLAGS:
@@ -678,25 +704,32 @@ static int mvsw_pr_port_obj_attr_set(struct net_device *dev,
 	return err;
 }
 
-static void mvsw_fdb_offload_notify(struct mvsw_pr_port *port,
+static void mvsw_fdb_offload_notify(struct prestera_port *port,
 				    struct switchdev_notifier_fdb_info *info)
 {
 	struct switchdev_notifier_fdb_info send_info;
+	struct net_device *net_dev = port->net_dev;
+	struct prestera_lag *lag;
 
 	send_info.addr = info->addr;
 	send_info.vid = info->vid;
 	send_info.offloaded = true;
+	if (prestera_port_is_lag_member(port)) {
+		lag = prestera_lag_get(port->sw, port->lag_id);
+		if (lag)
+			net_dev = lag->dev;
+	}
 	call_switchdev_notifiers(SWITCHDEV_FDB_OFFLOADED,
-				 port->net_dev, &send_info.info, NULL);
+				 net_dev, &send_info.info, NULL);
 }
 
 static int
-mvsw_pr_port_fdb_set(struct mvsw_pr_port *port,
+mvsw_pr_port_fdb_set(struct prestera_port *port,
 		     struct switchdev_notifier_fdb_info *fdb_info, bool adding)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct mvsw_pr_bridge_port *br_port;
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_bridge_port *br_port;
+	struct prestera_bridge_device *bridge_device;
 	struct net_device *orig_dev = fdb_info->info.dev;
 	int err;
 	u16 vid;
@@ -713,9 +746,9 @@ mvsw_pr_port_fdb_set(struct mvsw_pr_port *port,
 		vid = bridge_device->bridge_id;
 
 	if (adding)
-		err = mvsw_pr_fdb_add(port, fdb_info->addr, vid, false);
+		err = prestera_fdb_add(port, fdb_info->addr, vid, false);
 	else
-		err = mvsw_pr_fdb_del(port, fdb_info->addr, vid);
+		err = prestera_fdb_del(port, fdb_info->addr, vid);
 
 	return err;
 }
@@ -727,13 +760,13 @@ static void mvsw_pr_bridge_fdb_event_work(struct work_struct *work)
 	    container_of(work, struct mvsw_pr_event_work, work);
 	struct net_device *dev = switchdev_work->dev;
 	struct switchdev_notifier_fdb_info *fdb_info;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
 	rtnl_lock();
 	if (netif_is_vxlan(dev))
 		goto out;
 
-	port = mvsw_pr_port_dev_lower_find(dev);
+	port = prestera_port_dev_lower_find(dev);
 	if (!port)
 		goto out;
 
@@ -753,6 +786,7 @@ static void mvsw_pr_bridge_fdb_event_work(struct work_struct *work)
 		break;
 	case SWITCHDEV_FDB_ADD_TO_BRIDGE:
 	case SWITCHDEV_FDB_DEL_TO_BRIDGE:
+		prestera_k_arb_fdb_evt(port->sw, port->net_dev);
 		break;
 	}
 
@@ -775,7 +809,7 @@ static int prestera_switchdev_event(struct notifier_block *unused,
 
 	if (event == SWITCHDEV_PORT_ATTR_SET) {
 		err = switchdev_handle_port_attr_set(net_dev, ptr,
-						     mvsw_pr_netdev_check,
+						     prestera_netdev_check,
 						     mvsw_pr_port_obj_attr_set);
 		return notifier_from_errno(err);
 	}
@@ -797,6 +831,8 @@ static int prestera_switchdev_event(struct notifier_block *unused,
 	switch (event) {
 	case SWITCHDEV_FDB_ADD_TO_DEVICE:
 	case SWITCHDEV_FDB_DEL_TO_DEVICE:
+	case SWITCHDEV_FDB_ADD_TO_BRIDGE:
+	case SWITCHDEV_FDB_DEL_TO_BRIDGE:
 		fdb_info = container_of(info,
 					struct switchdev_notifier_fdb_info,
 					info);
@@ -812,8 +848,6 @@ static int prestera_switchdev_event(struct notifier_block *unused,
 		dev_hold(net_dev);
 
 		break;
-	case SWITCHDEV_FDB_ADD_TO_BRIDGE:
-	case SWITCHDEV_FDB_DEL_TO_BRIDGE:
 	case SWITCHDEV_VXLAN_FDB_ADD_TO_DEVICE:
 	case SWITCHDEV_VXLAN_FDB_DEL_TO_DEVICE:
 	default:
@@ -840,7 +874,7 @@ static int prestera_switchdev_blocking_event(struct notifier_block *unused,
 			err = -EOPNOTSUPP;
 		} else {
 			err = switchdev_handle_port_obj_add
-			    (net_dev, ptr, mvsw_pr_netdev_check,
+			    (net_dev, ptr, prestera_netdev_check,
 			     mvsw_pr_port_obj_add);
 		}
 		break;
@@ -849,13 +883,13 @@ static int prestera_switchdev_blocking_event(struct notifier_block *unused,
 			err = -EOPNOTSUPP;
 		} else {
 			err = switchdev_handle_port_obj_del
-			    (net_dev, ptr, mvsw_pr_netdev_check,
+			    (net_dev, ptr, prestera_netdev_check,
 			     mvsw_pr_port_obj_del);
 		}
 		break;
 	case SWITCHDEV_PORT_ATTR_SET:
 		err = switchdev_handle_port_attr_set
-		    (net_dev, ptr, mvsw_pr_netdev_check,
+		    (net_dev, ptr, prestera_netdev_check,
 		    mvsw_pr_port_obj_attr_set);
 		break;
 	default:
@@ -865,11 +899,11 @@ static int prestera_switchdev_blocking_event(struct notifier_block *unused,
 	return notifier_from_errno(err);
 }
 
-static struct mvsw_pr_bridge_device *
-mvsw_pr_bridge_device_create(struct mvsw_pr_bridge *bridge,
+static struct prestera_bridge_device *
+mvsw_pr_bridge_device_create(struct prestera_bridge *bridge,
 			     struct net_device *br_dev)
 {
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_bridge_device *bridge_device;
 	bool vlan_enabled = br_vlan_enabled(br_dev);
 	u16 bridge_id;
 	int err;
@@ -886,7 +920,7 @@ mvsw_pr_bridge_device_create(struct mvsw_pr_bridge *bridge,
 	if (vlan_enabled) {
 		bridge->bridge_8021q_exists = true;
 	} else {
-		err = mvsw_pr_8021d_bridge_create(bridge->sw, &bridge_id);
+		err = prestera_8021d_bridge_create(bridge->sw, &bridge_id);
 		if (err) {
 			kfree(bridge_device);
 			return ERR_PTR(err);
@@ -897,6 +931,7 @@ mvsw_pr_bridge_device_create(struct mvsw_pr_bridge *bridge,
 
 	bridge_device->dev = br_dev;
 	bridge_device->vlan_enabled = vlan_enabled;
+	bridge_device->isolation_srcid = PRESTERA_DEFAULT_ISOLATION_SRCID;
 	bridge_device->multicast_enabled = br_multicast_enabled(br_dev);
 	bridge_device->mrouter = br_multicast_router(br_dev);
 	INIT_LIST_HEAD(&bridge_device->port_list);
@@ -907,27 +942,27 @@ mvsw_pr_bridge_device_create(struct mvsw_pr_bridge *bridge,
 }
 
 static void
-mvsw_pr_bridge_device_destroy(struct mvsw_pr_bridge *bridge,
-			      struct mvsw_pr_bridge_device *bridge_device)
+mvsw_pr_bridge_device_destroy(struct prestera_bridge *bridge,
+			      struct prestera_bridge_device *bridge_device)
 {
 	list_del(&bridge_device->bridge_node);
 	if (bridge_device->vlan_enabled)
 		bridge->bridge_8021q_exists = false;
 	else
-		mvsw_pr_8021d_bridge_delete(bridge->sw,
-					    bridge_device->bridge_id);
+		prestera_8021d_bridge_delete(bridge->sw,
+					     bridge_device->bridge_id);
 
 	WARN_ON(!list_empty(&bridge_device->port_list));
 	kfree(bridge_device);
 }
 
-static struct mvsw_pr_bridge_device *
-mvsw_pr_bridge_device_get(struct mvsw_pr_bridge *bridge,
+static struct prestera_bridge_device *
+mvsw_pr_bridge_device_get(struct prestera_bridge *bridge,
 			  struct net_device *br_dev)
 {
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_bridge_device *bridge_device;
 
-	bridge_device = mvsw_pr_bridge_device_find(bridge, br_dev);
+	bridge_device = prestera_bridge_device_find(bridge, br_dev);
 	if (bridge_device)
 		return bridge_device;
 
@@ -935,25 +970,25 @@ mvsw_pr_bridge_device_get(struct mvsw_pr_bridge *bridge,
 }
 
 static void
-mvsw_pr_bridge_device_put(struct mvsw_pr_bridge *bridge,
-			  struct mvsw_pr_bridge_device *bridge_device)
+mvsw_pr_bridge_device_put(struct prestera_bridge *bridge,
+			  struct prestera_bridge_device *bridge_device)
 {
 	if (list_empty(&bridge_device->port_list))
 		mvsw_pr_bridge_device_destroy(bridge, bridge_device);
 }
 
-static struct mvsw_pr_bridge_port *
-mvsw_pr_bridge_port_create(struct mvsw_pr_bridge_device *bridge_device,
+static struct prestera_bridge_port *
+mvsw_pr_bridge_port_create(struct prestera_bridge_device *bridge_device,
 			   struct net_device *brport_dev)
 {
-	struct mvsw_pr_bridge_port *br_port;
-	struct mvsw_pr_port *port;
+	struct prestera_bridge_port *br_port;
+	struct prestera_port *port;
 
 	br_port = kzalloc(sizeof(*br_port), GFP_KERNEL);
 	if (!br_port)
 		return NULL;
 
-	port = mvsw_pr_port_dev_lower_find(brport_dev);
+	port = prestera_port_dev_lower_find(brport_dev);
 
 	br_port->dev = brport_dev;
 	br_port->bridge_device = bridge_device;
@@ -968,20 +1003,20 @@ mvsw_pr_bridge_port_create(struct mvsw_pr_bridge_device *bridge_device,
 }
 
 static void
-mvsw_pr_bridge_port_destroy(struct mvsw_pr_bridge_port *br_port)
+mvsw_pr_bridge_port_destroy(struct prestera_bridge_port *br_port)
 {
 	list_del(&br_port->bridge_device_node);
 	WARN_ON(!list_empty(&br_port->vlan_list));
 	kfree(br_port);
 }
 
-static struct mvsw_pr_bridge_port *
-mvsw_pr_bridge_port_get(struct mvsw_pr_bridge *bridge,
+static struct prestera_bridge_port *
+mvsw_pr_bridge_port_get(struct prestera_bridge *bridge,
 			struct net_device *brport_dev)
 {
 	struct net_device *br_dev = netdev_master_upper_dev_get(brport_dev);
-	struct mvsw_pr_bridge_device *bridge_device;
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_bridge_device *bridge_device;
+	struct prestera_bridge_port *br_port;
 	int err;
 
 	br_port = mvsw_pr_bridge_port_find(bridge, brport_dev);
@@ -1007,27 +1042,27 @@ mvsw_pr_bridge_port_get(struct mvsw_pr_bridge *bridge,
 	return ERR_PTR(err);
 }
 
-static void mvsw_pr_bridge_port_put(struct mvsw_pr_bridge *bridge,
-				    struct mvsw_pr_bridge_port *br_port)
+static void mvsw_pr_bridge_port_put(struct prestera_bridge *bridge,
+				    struct prestera_bridge_port *br_port)
 {
-	struct mvsw_pr_bridge_device *bridge_device;
+	struct prestera_bridge_device *bridge_device;
 
 	if (--br_port->ref_count != 0)
 		return;
 	bridge_device = br_port->bridge_device;
 	mvsw_pr_bridge_port_destroy(br_port);
 	if (list_empty(&bridge_device->port_list)) {
-		mvsw_pr_rif_enable(bridge->sw, bridge_device->dev, false);
-		mvsw_pr_bridge_device_rifs_destroy(bridge->sw,
-						   bridge_device->dev);
+		prestera_rif_enable(bridge->sw, bridge_device->dev, false);
+		prestera_bridge_device_rifs_destroy(bridge->sw,
+						    bridge_device->dev);
 	}
 	mvsw_pr_bridge_device_put(bridge, bridge_device);
 }
 
 static int
-mvsw_pr_bridge_8021q_port_join(struct mvsw_pr_bridge_device *bridge_device,
-			       struct mvsw_pr_bridge_port *br_port,
-			       struct mvsw_pr_port *port,
+mvsw_pr_bridge_8021q_port_join(struct prestera_bridge_device *bridge_device,
+			       struct prestera_bridge_port *br_port,
+			       struct prestera_port *port,
 			       struct netlink_ext_ack *extack)
 {
 	if (is_vlan_dev(br_port->dev)) {
@@ -1040,9 +1075,9 @@ mvsw_pr_bridge_8021q_port_join(struct mvsw_pr_bridge_device *bridge_device,
 }
 
 static int
-mvsw_pr_bridge_8021d_port_join(struct mvsw_pr_bridge_device *bridge_device,
-			       struct mvsw_pr_bridge_port *br_port,
-			       struct mvsw_pr_port *port,
+mvsw_pr_bridge_8021d_port_join(struct prestera_bridge_device *bridge_device,
+			       struct prestera_bridge_port *br_port,
+			       struct prestera_port *port,
 			       struct netlink_ext_ack *extack)
 {
 	int err;
@@ -1052,44 +1087,32 @@ mvsw_pr_bridge_8021d_port_join(struct mvsw_pr_bridge_device *bridge_device,
 				   "Enslaving of a VLAN device is not supported");
 		return -ENOTSUPP;
 	}
-	err = mvsw_pr_8021d_bridge_port_add(port, bridge_device->bridge_id);
+	err = prestera_8021d_bridge_port_add(port, bridge_device->bridge_id);
 	if (err)
 		return err;
 
-	err = mvsw_pr_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
-	if (err)
-		goto err_port_uc_flood_set;
-
-	err = mvsw_pr_port_mc_flood_set(port, br_port->flags & BR_MCAST_FLOOD);
-	if (err)
-		goto err_port_mc_flood_set;
-
-	err = mvsw_pr_port_learning_set(port, br_port->flags & BR_LEARNING);
+	err = prestera_br_port_flags_set(br_port, port);
 	if (err)
-		goto err_port_learning_set;
+		goto err_flags2port_set;
 
 	if (list_is_singular(&bridge_device->port_list))
-		mvsw_pr_rif_enable(port->sw, bridge_device->dev, true);
+		prestera_rif_enable(port->sw, bridge_device->dev, true);
 
 	return err;
 
-err_port_learning_set:
-	mvsw_pr_port_mc_flood_set(port, false);
-err_port_mc_flood_set:
-	mvsw_pr_port_uc_flood_set(port, false);
-err_port_uc_flood_set:
-	mvsw_pr_8021d_bridge_port_delete(port, bridge_device->bridge_id);
+err_flags2port_set:
+	prestera_8021d_bridge_port_delete(port, bridge_device->bridge_id);
 	return err;
 }
 
-static int mvsw_pr_port_bridge_join(struct mvsw_pr_port *port,
+static int mvsw_pr_port_bridge_join(struct prestera_port *port,
 				    struct net_device *brport_dev,
 				    struct net_device *br_dev,
 				    struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_bridge_device *bridge_device;
-	struct mvsw_pr_switch *sw = port->sw;
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_bridge_device *bridge_device;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_bridge_port *br_port;
 	int err;
 
 	br_port = mvsw_pr_bridge_port_get(sw->bridge, brport_dev);
@@ -1099,8 +1122,8 @@ static int mvsw_pr_port_bridge_join(struct mvsw_pr_port *port,
 	bridge_device = br_port->bridge_device;
 
 	/* Enslaved port is not usable as a router interface */
-	if (mvsw_pr_rif_exists(sw, port->net_dev))
-		mvsw_pr_rif_enable(sw, port->net_dev, false);
+	if (prestera_rif_exists(sw, port->net_dev))
+		prestera_rif_enable(sw, port->net_dev, false);
 
 	if (bridge_device->vlan_enabled) {
 		err = mvsw_pr_bridge_8021q_port_join(bridge_device, br_port,
@@ -1121,32 +1144,32 @@ static int mvsw_pr_port_bridge_join(struct mvsw_pr_port *port,
 }
 
 static void
-mvsw_pr_bridge_8021d_port_leave(struct mvsw_pr_bridge_device *bridge_device,
-				struct mvsw_pr_bridge_port *br_port,
-				struct mvsw_pr_port *port)
+mvsw_pr_bridge_8021d_port_leave(struct prestera_bridge_device *bridge_device,
+				struct prestera_bridge_port *br_port,
+				struct prestera_port *port)
 {
-	mvsw_pr_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
-	mvsw_pr_8021d_bridge_port_delete(port, bridge_device->bridge_id);
+	prestera_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
+	prestera_8021d_bridge_port_delete(port, bridge_device->bridge_id);
 }
 
 static void
-mvsw_pr_bridge_8021q_port_leave(struct mvsw_pr_bridge_device *bridge_device,
-				struct mvsw_pr_bridge_port *br_port,
-				struct mvsw_pr_port *port)
+mvsw_pr_bridge_8021q_port_leave(struct prestera_bridge_device *bridge_device,
+				struct prestera_bridge_port *br_port,
+				struct prestera_port *port)
 {
-	mvsw_pr_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
-	mvsw_pr_port_pvid_set(port, MVSW_PR_DEFAULT_VID);
+	prestera_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
+	prestera_port_pvid_set(port, PRESTERA_DEFAULT_VID);
 }
 
-static void mvsw_pr_port_bridge_leave(struct mvsw_pr_port *port,
+static void mvsw_pr_port_bridge_leave(struct prestera_port *port,
 				      struct net_device *brport_dev,
 				      struct net_device *br_dev)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct mvsw_pr_bridge_device *bridge_device;
-	struct mvsw_pr_bridge_port *br_port;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_bridge_device *bridge_device;
+	struct prestera_bridge_port *br_port;
 
-	bridge_device = mvsw_pr_bridge_device_find(sw->bridge, br_dev);
+	bridge_device = prestera_bridge_device_find(sw->bridge, br_dev);
 	if (!bridge_device)
 		return;
 	br_port = __mvsw_pr_bridge_port_find(bridge_device, brport_dev);
@@ -1158,20 +1181,19 @@ static void mvsw_pr_port_bridge_leave(struct mvsw_pr_port *port,
 	else
 		mvsw_pr_bridge_8021d_port_leave(bridge_device, br_port, port);
 
-	mvsw_pr_port_learning_set(port, false);
-	mvsw_pr_port_uc_flood_set(port, false);
-	mvsw_pr_port_mc_flood_set(port, false);
-	mvsw_pr_port_vid_stp_set(port, MVSW_PR_VID_ALL, BR_STATE_FORWARDING);
+	prestera_br_port_flags_reset(br_port, port);
+	prestera_port_vid_stp_set(port, MVSW_PR_VID_ALL, BR_STATE_FORWARDING);
 	mvsw_pr_bridge_port_put(sw->bridge, br_port);
 
 	/* Offload rif that was previosly disabled */
-	if (mvsw_pr_rif_exists(sw, port->net_dev))
-		mvsw_pr_rif_enable(sw, port->net_dev, true);
+	if (prestera_rif_exists(sw, port->net_dev))
+		prestera_rif_enable(sw, port->net_dev, true);
 
 }
 
 static bool
-prestera_lag_master_check(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
+prestera_lag_master_check(struct prestera_switch *sw,
+			  struct net_device *lag_dev,
 			  struct netdev_lag_upper_info *upper_info,
 			  struct netlink_ext_ack *ext_ack)
 {
@@ -1189,17 +1211,17 @@ prestera_lag_master_check(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
 	return true;
 }
 
-static void mvsw_pr_port_lag_clean(struct mvsw_pr_port *port,
+static void mvsw_pr_port_lag_clean(struct prestera_port *port,
 				   struct net_device *lag_dev)
 {
 	struct net_device *br_dev = netdev_master_upper_dev_get(lag_dev);
-	struct mvsw_pr_port_vlan *port_vlan, *tmp;
+	struct prestera_port_vlan *port_vlan, *tmp;
 	struct net_device *upper_dev;
 	struct list_head *iter;
 
 	list_for_each_entry_safe(port_vlan, tmp, &port->vlans_list, list) {
-		mvsw_pr_port_vlan_bridge_leave(port_vlan);
-		mvsw_pr_port_vlan_destroy(port_vlan);
+		prestera_port_vlan_bridge_leave(port_vlan);
+		prestera_port_vlan_destroy(port_vlan);
 	}
 
 	if (netif_is_bridge_port(lag_dev))
@@ -1212,10 +1234,10 @@ static void mvsw_pr_port_lag_clean(struct mvsw_pr_port *port,
 		mvsw_pr_port_bridge_leave(port, upper_dev, br_dev);
 	}
 
-	mvsw_pr_port_pvid_set(port, MVSW_PR_DEFAULT_VID);
+	prestera_port_pvid_set(port, PRESTERA_DEFAULT_VID);
 }
 
-static int mvsw_pr_port_lag_join(struct mvsw_pr_port *port,
+static int mvsw_pr_port_lag_join(struct prestera_port *port,
 				 struct net_device *lag_dev)
 {
 	u16 lag_id;
@@ -1233,10 +1255,10 @@ static int mvsw_pr_port_lag_join(struct mvsw_pr_port *port,
 	return 0;
 }
 
-static void mvsw_pr_port_lag_leave(struct mvsw_pr_port *port,
+static void mvsw_pr_port_lag_leave(struct prestera_port *port,
 				   struct net_device *lag_dev)
 {
-	mvsw_pr_router_lag_member_leave(port, lag_dev);
+	prestera_router_lag_member_leave(port, lag_dev);
 
 	if (prestera_lag_member_del(port))
 		return;
@@ -1249,10 +1271,10 @@ static int mvsw_pr_netdevice_port_upper_event(struct net_device *lower_dev,
 					      unsigned long event, void *ptr)
 {
 	struct netdev_notifier_changeupper_info *info;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 	struct netlink_ext_ack *extack;
 	struct net_device *upper_dev;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	int err = 0;
 
 	port = netdev_priv(dev);
@@ -1294,7 +1316,7 @@ static int mvsw_pr_netdevice_port_upper_event(struct net_device *lower_dev,
 			return -EINVAL;
 		}
 		if (netif_is_macvlan(upper_dev) &&
-		    !mvsw_pr_rif_exists(sw, lower_dev)) {
+		    !prestera_rif_exists(sw, lower_dev)) {
 			NL_SET_ERR_MSG_MOD(extack,
 					   "macvlan is only supported on top of router interfaces");
 			return -EOPNOTSUPP;
@@ -1331,14 +1353,14 @@ static int mvsw_pr_netdevice_port_lower_event(struct net_device *dev,
 {
 	struct netdev_notifier_changelowerstate_info *info = ptr;
 	struct netdev_lag_lower_state_info *lower_state_info;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	bool enabled;
 
 	if (event != NETDEV_CHANGELOWERSTATE)
 		return 0;
 	if (!netif_is_lag_port(dev))
 		return 0;
-	if (!mvsw_pr_port_is_lag_member(port))
+	if (!prestera_port_is_lag_member(port))
 		return 0;
 
 	lower_state_info = info->lower_state_info;
@@ -1366,7 +1388,7 @@ static int mvsw_pr_netdevice_port_event(struct net_device *lower_dev,
 static int mvsw_pr_netdevice_bridge_event(struct net_device *br_dev,
 					  unsigned long event, void *ptr)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(br_dev);
+	struct prestera_switch *sw = prestera_switch_get(br_dev);
 	struct netdev_notifier_changeupper_info *info = ptr;
 	struct netlink_ext_ack *extack;
 	struct net_device *upper_dev;
@@ -1386,7 +1408,7 @@ static int mvsw_pr_netdevice_bridge_event(struct net_device *br_dev,
 		if (!info->linking)
 			break;
 		if (netif_is_macvlan(upper_dev) &&
-		    !mvsw_pr_rif_exists(sw, br_dev)) {
+		    !prestera_rif_exists(sw, br_dev)) {
 			NL_SET_ERR_MSG_MOD(extack,
 					   "macvlan is only supported on top of router interfaces");
 			return -EOPNOTSUPP;
@@ -1403,7 +1425,7 @@ static int mvsw_pr_netdevice_bridge_event(struct net_device *br_dev,
 static int mvsw_pr_netdevice_macvlan_event(struct net_device *macvlan_dev,
 					   unsigned long event, void *ptr)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(macvlan_dev);
+	struct prestera_switch *sw = prestera_switch_get(macvlan_dev);
 	struct netdev_notifier_changeupper_info *info = ptr;
 	struct netlink_ext_ack *extack;
 
@@ -1435,7 +1457,7 @@ static int mvsw_pr_netdevice_lag_event(struct net_device *lag_dev,
 	int err;
 
 	netdev_for_each_lower_dev(lag_dev, dev, iter) {
-		if (mvsw_pr_netdev_check(dev)) {
+		if (prestera_netdev_check(dev)) {
 			err = mvsw_pr_netdevice_port_event(lag_dev, dev, event,
 							   ptr);
 			if (err)
@@ -1450,7 +1472,7 @@ static int mvsw_pr_netdevice_vlan_event(struct net_device *vlan_dev,
 					unsigned long event, void *ptr)
 {
 	struct net_device *real_dev = vlan_dev_real_dev(vlan_dev);
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(real_dev);
+	struct prestera_switch *sw = prestera_switch_get(real_dev);
 	struct netdev_notifier_changeupper_info *info = ptr;
 	struct netlink_ext_ack *extack;
 	struct net_device *upper_dev;
@@ -1486,17 +1508,17 @@ static int mvsw_pr_netdevice_event(struct notifier_block *nb,
 				   unsigned long event, void *ptr)
 {
 	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	int err = 0;
 
-	sw = container_of(nb, struct mvsw_pr_switch, netdevice_nb);
+	sw = container_of(nb, struct prestera_switch, netdevice_nb);
 
 	if (event == NETDEV_PRE_CHANGEADDR ||
 	    event == NETDEV_CHANGEADDR)
-		err = mvsw_pr_netdevice_router_port_event(dev, event, ptr);
+		err = prestera_netdevice_router_port_event(dev, event, ptr);
 	else if (mvsw_pr_is_vrf_event(event, ptr))
-		err = mvsw_pr_netdevice_vrf_event(dev, event, ptr);
-	else if (mvsw_pr_netdev_check(dev))
+		err = prestera_netdevice_vrf_event(dev, event, ptr);
+	else if (prestera_netdev_check(dev))
 		err = mvsw_pr_netdevice_port_event(dev, dev, event, ptr);
 	else if (netif_is_bridge_master(dev))
 		err = mvsw_pr_netdevice_bridge_event(dev, event, ptr);
@@ -1510,22 +1532,22 @@ static int mvsw_pr_netdevice_event(struct notifier_block *nb,
 	return notifier_from_errno(err);
 }
 
-static int mvsw_pr_fdb_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_fdb_init(struct prestera_switch *sw)
 {
 	int err;
 
-	err = mvsw_pr_switch_ageing_set(sw, MVSW_PR_DEFAULT_AGEING_TIME);
+	err = prestera_switch_ageing_set(sw, PRESTERA_DEFAULT_AGEING_TIME);
 	if (err)
 		return err;
 
 	return 0;
 }
 
-static int prestera_switchdev_init(struct mvsw_pr_switch *sw)
+static int prestera_switchdev_init(struct prestera_switch *sw)
 {
 	int err = 0;
 	struct prestera_switchdev *swdev;
-	struct mvsw_pr_bridge *bridge;
+	struct prestera_bridge *bridge;
 
 	if (sw->switchdev)
 		return -EPERM;
@@ -1578,7 +1600,7 @@ static int prestera_switchdev_init(struct mvsw_pr_switch *sw)
 	return err;
 }
 
-static void prestera_switchdev_fini(struct mvsw_pr_switch *sw)
+static void prestera_switchdev_fini(struct prestera_switch *sw)
 {
 	if (!sw->switchdev)
 		return;
@@ -1593,7 +1615,7 @@ static void prestera_switchdev_fini(struct mvsw_pr_switch *sw)
 	kfree(sw->bridge);
 }
 
-static int mvsw_pr_netdev_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_netdev_init(struct prestera_switch *sw)
 {
 	int err = 0;
 
@@ -1605,13 +1627,13 @@ static int mvsw_pr_netdev_init(struct mvsw_pr_switch *sw)
 	return err;
 }
 
-static void mvsw_pr_netdev_fini(struct mvsw_pr_switch *sw)
+static void mvsw_pr_netdev_fini(struct prestera_switch *sw)
 {
 	if (sw->netdevice_nb.notifier_call)
 		unregister_netdevice_notifier(&sw->netdevice_nb);
 }
 
-int prestera_switchdev_register(struct mvsw_pr_switch *sw)
+int prestera_switchdev_register(struct prestera_switch *sw)
 {
 	int err;
 
@@ -1619,7 +1641,7 @@ int prestera_switchdev_register(struct mvsw_pr_switch *sw)
 	if (err)
 		return err;
 
-	err = mvsw_pr_router_init(sw);
+	err = prestera_router_init(sw);
 
 	if (err) {
 		pr_err("Failed to initialize fib notifier\n");
@@ -1633,15 +1655,15 @@ int prestera_switchdev_register(struct mvsw_pr_switch *sw)
 	return 0;
 
 err_netdevice_notifier:
-	mvsw_pr_router_fini(sw);
+	prestera_router_fini(sw);
 err_fib_notifier:
 	prestera_switchdev_fini(sw);
 	return err;
 }
 
-void prestera_switchdev_unregister(struct mvsw_pr_switch *sw)
+void prestera_switchdev_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_netdev_fini(sw);
-	mvsw_pr_router_fini(sw);
+	prestera_router_fini(sw);
 	prestera_switchdev_fini(sw);
 }
